Name,Author,Link,Time,Summary,Downloads,Tag,Big Description,Columns,Metadata,Label
French firms by town and size , Etienne LQ , www.kaggle.com/etiennelq/french-employment-by-town , Tue Oct 17 2017 23:26:57 GMT+0530 (IST) , Some data to see how spread is employment in France ,71, +,"Context INSEE is the official french institute gathering data of many types around France. It can be demographic (Births Deaths Population Density...) Economic (Salary Firms by activity / size...) and more.  It can be a great help to observe and measure inequality in the french population. Content Four files are in the dataset   base_etablissement_par_tranche_effectif  give information on the number of firms in every french town categorized by size  come from INSEE. CODGEO  geographique code for the town (can be joined with *code_insee* column from ""name_geographic_information.csv') LIBGEO  name of the town (in french) REG  region number DEP  depatment number E14TST  total number of firms in the town E14TS0ND  number of unknown or null size firms in the town E14TS1  number of firms with 1 to 5 employees in the town E14TS6  number of firms with 6 to 9 employees in the town E14TS10  number of firms with 10 to 19 employees in the town E14TS20  number of firms with 20 to 49 employees in the town E14TS50  number of firms with 50 to 99 employees in the town E14TS100  number of firms with 100 to 199 employees in the town E14TS200  number of firms with 200 to 499 employees in the town E14TS500  number of firms with more than 500 employees in the town name_geographic_information  give geographic data on french town (mainly latitude and longitude but also region / department codes and names ) EU_circo  name of the European Union Circonscription code_région  code of the region attached to the town nom_région  name of the region attached to the town chef.lieu_région  name the administrative center around the town numéro_département  code of the department attached to the town nom_département  name of the department attached to the town préfecture  name of the local administrative division around the town numéro_circonscription  number of the circumpscription nom_commune  name of the town codes_postaux  post-codes relative to the town code_insee  unique code for the town latitude  GPS latitude longitude  GPS longitude éloignement  i couldn't manage to figure out what was the meaning of this number net_salary_per_town_per_category  salaries around french town per job categories age and sex CODGEO  unique code of the town LIBGEO  name of the town SNHM14  mean net salary SNHMC14  mean net salary per hour for executive SNHMP14  mean net salary per hour for middle manager SNHME14  mean net salary per hour for employee SNHMO14  mean net salary per hour for worker SNHMF14  mean net salary for women SNHMFC14  mean net salary per hour for feminin executive SNHMFP14  mean net salary per hour for feminin middle manager SNHMFE14  mean net salary per hour for feminin employee SNHMFO14  mean net salary per hour for feminin worker SNHMH14  mean net salary for man SNHMHC14  mean net salary per hour for masculin executive SNHMHP14  mean net salary per hour for masculin middle manager SNHMHE14  mean net salary per hour for masculin employee SNHMHO14  mean net salary per hour for masculin worker SNHM1814  mean net salary per hour for 18-25 years old SNHM2614  mean net salary per hour for 26-50 years old SNHM5014  mean net salary per hour for >50 years old SNHMF1814  mean net salary per hour for women between 18-25 years old SNHMF2614  mean net salary per hour for women between 26-50 years old SNHMF5014  mean net salary per hour for women >50 years old SNHMH1814  mean net salary per hour for men between 18-25 years old SNHMH2614  mean net salary per hour for men between 26-50 years old SNHMH5014  mean net salary per hour for men >50 years old  population  demographic information in France per town age sex and living mode NIVGEO  geographic level (arrondissement communes...) CODGEO  unique code for the town LIBGEO  name of the town (might contain some utf-8 errors this information has better quality name_geographic_information) MOCO  cohabitation mode  [list and meaning available in Data description] AGE80_17  age category (slice of 5 years) | ex  0 -> people between 0 and 4 years old SEXE  sex 1 for men | 2 for women NB  Number of people in the category departments.geojson  contains the borders of french departments. From Gregoire David (github)  These datasets can be merged by  CODGEO = code_insee Acknowledgements The entire dataset has been created (and actualized) by INSEE I just uploaded it on Kaggle after doing some jobs and checks on it. I haven't seen INSEE on Kaggle yet but I think it would be great to bring the organization in as a Kaggle actor. Inspiration First aim I had creating that dataset was to provide a map of french towns with the number of firm that are settled in by size.  Now my goal is to explore inequality between men and women youngsters and elders working / social classes.  Population can also be a great filter to explain some phenomenons on the maps.",CODGEO:LIBGEO:REG:DEP:E14TST:E14TS0ND:E14TS1:E14TS6:E14TS10:E14TS20:E14TS50:E14TS100:E14TS200:E14TS500:,numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,demography
London-based restaurants' reviews on TripAdvisor , PromptCloud , www.kaggle.com/PromptCloudHQ/londonbased-restaurants-reviews-on-tripadvisor , Sat Sep 16 2017 01:55:27 GMT+0530 (IST) , 20000 restaurant's reviews on TripAdvisor.co.uk ,30, internet- ,Context This is a pre-crawled dataset taken as subset of a bigger dataset (more than 1.8 million restaurants) that was created by extracting data from Tripadvisor.co.uk. Content This dataset has following fields  uniq_id url restaurant_id restaurant_location name category title review_date review_text author author_url location rating food value service visited_on  Acknowledgements This dataset was created by PromptCloud's in-house web-crawling service. Inspiration Analyses of the restaurant reviews and ratings can be performed.,uniq_id:url:restaurant_id:restaurant_location:name:category:title:review_date:review_text:author:author_url:location:rating:food:value:service:visited_on:,string:string:string:string:string:string:string:dateTime:string:string:string:string:string:string:string:string:dateTime:,online information
Doctor and lawyer profiles on Avvo.com , PromptCloud , www.kaggle.com/PromptCloudHQ/doctor-and-lawyer-profiles-on-avvocom , Sat Sep 16 2017 01:36:18 GMT+0530 (IST) , 20000 doctor and lawyer profiles ,9, legal categories of people- internet- ,Context This is a pre-crawled dataset taken as subset of a bigger dataset (more than 2.4 million profiles) that was created by extracting data from Avvo.com. Content This dataset has following fields  address categories description image_count name payment_option phone profile_id profile_url video_count website  Acknowledgements This dataset was created by PromptCloud's in-house web-crawling service. Inspiration Analysis can be performed on the profile category.,address:categories:description:image_count:name:payment_option:phone:profile_id:profile_url:uniq_id:video_count:website:,string:string:string:string:string:string:string:string:string:string:string:string:,online information
Roman emperors from 26 BC to 395 AD , LaurentBerder , www.kaggle.com/lberder/roman-emperors-from-26-bc-to-395-ad , Thu Oct 19 2017 21:49:13 GMT+0530 (IST) , Life death and reign of Roman emperors ,58, life- death- politicians- history- politics- ,Context We all know of the Roman empire but what about its emperors specifically? Content Here you will find information on each of the emperors of the Roman empire which lasted between 26 BC and 395 AD. Specifically you can use data on their  Names Date of birth City and Province of birth Date of death Method of accession to power Date of accession to power Date of end of reign Cause of death Identity of killer Dynasty Era Photo  Acknowledgements This dataset was provided by Zonination who made it available on Wikipedia. See his repository on Github Inspiration What kind of trend can you find in these emperors' lives and reigns? What aspects of them allowed them to live longer?,Index:Name:Full Name:Birth:Death:Birth City:Birth Province:Succession:Reign Start:Reign End:Cause:Killer:Dynasty:Era:Notes:Verif:Image:,numeric:string:string:dateTime:dateTime:string:string:string:dateTime:dateTime:string:string:string:string:string:string:string:,history
Bitcoin Historical Data , Zielak , www.kaggle.com/mczielinski/bitcoin-historical-data , Sun Oct 22 2017 02:19:06 GMT+0530 (IST) , Bitcoin data at 1-min intervals from select exchanges Jan 2012 to May 2017 ,3786, history- finance- ,"Context Bitcoin is the longest running and most well known cryptocurrency first released as open source in 2009 by the anonymous Satoshi Nakamoto. Bitcoin serves as a decentralized medium of digital exchange with transactions verified and recorded in a public distributed ledger (the blockchain) without the need for a trusted record keeping authority or central intermediary. Transaction blocks contain a SHA-256 cryptographic hash of previous transaction blocks and are thus ""chained"" together serving as an immutable record of all transactions that have ever occurred. As with any currency/commodity on the market bitcoin trading and financial instruments soon followed public adoption of bitcoin and continue to grow. Included here is historical bitcoin market data at 1-min intervals for select bitcoin exchanges where trading takes place. Happy (data) mining!  Content coincheckJPY_1-min_data_2014-10-31_to_2017-10-20.csv - 32% of all BTC Volume (past 30 days from last update of this data set) coinbaseUSD_1-min_data_2014-12-01_to_2017-10-20.csv - 8% of all BTC Volume  (past 30 days from last update of this data set)  bitstampUSD_1-min_data_2012-01-01_to_2017-10-20.csv - 9% of all BTC Volume  (past 30 days from last update of this data set) Legacy/to be updated   krakenEUR_1-min_data_2014-01-08_to_2017-05-31.csv   btceUSD_1-min_data_2012-01-01_to_2017-05-31.csv   btcnCNY_1-min_data_2012-01-01_to_2017-05-31.csv   krakenUSD_1-min_data_2014-01-07_to_2017-05-31.csv  CSV files for select bitcoin exchanges for the time period of Jan 2012 to October 2017 with minute to minute updates of OHLC (Open High Low Close) Volume in BTC and indicated currency and weighted bitcoin price.  Timestamps are in Unix time.  Timestamps without any trades or activity have their data fields populated with NaNs. If a timestamp is missing or if there are jumps this may be because the exchange (or its API) was down the exchange (or its API) did not exist or some other unforseen technical error in data reporting or gathering. All effort has been made to deduplicate entries and verify the contents are correct and complete to the best of my ability but obviously trust at your own risk.  Acknowledgements and Inspiration The various exchange APIs for making it difficult or unintuitive enough to get OHLC and volume data at 1-min intervals that I set out on this data scraping project. Satoshi Nakamoto and the novel core concept of the blockchain as well as its first execution via the bitcoin protocol. I'd also like to thank viewers like you! Can't wait to see what code or insights you all have to share.  I am a lowly Ph.D. student who did this for fun in my meager spare time. If you find this data interesting and you can spare a coffee to fuel my science send it my way and I'd be immensely grateful! 1kmWmcQa8qN9ZrdGfdkw8EHKBgugKBRcF",Timestamp:Open:High:Low:Close:Volume_(BTC):Volume_(Currency):Weighted_Price:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,blockchain and crytocurrencies
Properties on StayZilla , PromptCloud , www.kaggle.com/PromptCloudHQ/properties-on-stayzilla , Sat Sep 16 2017 11:54:38 GMT+0530 (IST) , 6000 Properties on StayZilla ,45, hotels- internet- ,Context This is a pre-crawled dataset taken as subset of a bigger dataset (more than 61000 properties) that was created by extracting data from StayZilla.com an Indian AirBnB-like startup founded in 2005 that closed its operations in 2017.  Content This dataset has following fields  additional_info - Special considerations regarding this property. amenities - Pipe (|) delimited list of amenities offered at the property. check_in_date check_out_date city country crawl_date description - Textual description of the property as entered into the site by the lister. highlight_value - Property highlights as entered into the site by the lister. hotel_star_rating - In case the property is a hotel its out-of-five star rating. Not all hotels have ratings. image_count - Number of images posted to the site by the lister. image_urls internet - Does this property have Internet access yes/no. landmark latitude longitude occupancy - How many adults and children may book the listing. pageurl property_address property_id property_name property_type - Home? Hotel? Resort? Etc. qts - Crawler timestamp. query_time_stamp - Copy of qts. room_price room_types - Number of beds and baths for the room. search_term service_value - Whether or not the property is verified with StayZilla (plus some junk entries). similar_hotel - Some similar listings by name. sitename things_to_do - Nearby activities as entered by the lister. things_to_note - Special notes entered by the lister.  Acknowledgements This dataset was created by PromptCloud's in-house web-crawling service. Inspiration  What is the shape of the Indian property-sharing market and how does it differ from that of say the United States? (try comparing this dataset to say the Boston AirBnB dataset). What are the contents of textual descriptions for properties? Where are StayZilla properties located geographically? ,additional_info:amenities:check_in_date:check_out_date:city:country:crawl_date:description:highlight_value:hotel_star_rating:image_count:image_urls:internet:landmark:latitude:longitude:occupancy:pageurl:property_address:property_id:property_name:property_type:qts:query_time_stamp:room_price:room_types:search_term:service_value:similar_hotel:sitename:things_to_do:things_to_note:uniq_id:,string:string:dateTime:dateTime:string:string:dateTime:string:string:string:numeric:string:string:string:numeric:numeric:string:string:string:numeric:string:string:dateTime:dateTime:string:string:string:string:string:string:string:string:string:,online information
Human Resources Analytics , ludoben , www.kaggle.com/ludobenistant/hr-analytics , Tue Nov 29 2016 23:11:48 GMT+0530 (IST) , Why are our best and most experienced employees leaving prematurely? ,37248, employment- ,This dataset is simulated Why are our best and most experienced employees leaving prematurely? Have fun with this database and try to predict which valuable employees will leave next. Fields in the dataset include  Satisfaction Level Last evaluation Number of projects Average monthly hours Time spent at the company Whether they have had a work accident Whether they have had a promotion in the last 5 years Departments (column sales) Salary Whether the employee has left ,satisfaction_level:last_evaluation:number_project:average_montly_hours:time_spend_company:Work_accident:left:promotion_last_5years:sales:salary:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:,demography
Where it Pays to Attend College , The Wall Street Journal , www.kaggle.com/wsj/college-salaries , Sat Apr 29 2017 21:18:55 GMT+0530 (IST) , Salaries by college region and academic major ,3008, news agencies- universities and colleges- employment- ,Salary Increase By Type of College Party school? Liberal Arts college? State School? You already know your starting salary will be different depending on what type of school you attend. But increased earning power shows less disparity. Ten years out graduates of Ivy League schools earned 99% more than they did at graduation. Party school graduates saw an 85% increase. Engineering school graduates fared worst earning 76% more 10 years out of school. See where your school ranks.  Salaries By Region Attending college in the Midwest leads to the lowest salary both at graduation and at mid-career according to the PayScale Inc. survey. Graduates of schools in the Northeast and California fared best.  Salary Increase By Major Your parents might have worried when you chose Philosophy or International Relations as a major. But a year-long survey of 1.2 million people with only a bachelor's degree by PayScale Inc. shows that graduates in these subjects earned 103.5% and 97.8% more respectively about 10 years post-commencement. Majors that didn't show as much salary growth include Nursing and Information Technology.  All data was obtained from the Wall Street Journal based on data from Payscale Inc  Salaries for Colleges by Type Salaries for Colleges by Region Degrees that Pay you Back ,Undergraduate Major:Starting Median Salary:Mid-Career Median Salary:Percent change from Starting to Mid-Career Salary:Mid-Career 10th Percentile Salary:Mid-Career 25th Percentile Salary:Mid-Career 75th Percentile Salary:Mid-Career 90th Percentile Salary:,string:string:string:numeric:string:string:string:string:,universities and colleges
Business and Industry Reports , US Census Bureau , www.kaggle.com/census/business-and-industry-reports , Wed Oct 18 2017 04:51:56 GMT+0530 (IST) , 7000 economics time series for 1956-2017 ,94, finance- economics- ,Context Along with their core mission of counting the US population the United States Census Bureau gathers a wide range of economic data. This dataset covers 16 of their economic reports and surveys  Advance Monthly Sales for Retail and Food Services Construction Spending Housing Vacancies and Homeownership Manufactured Housing Survey (1980-2013) Manufactured Housing Survey (Current) Manufacturers' Shipments Inventories and Orders Manufacturing and Trade Inventories and Sales Monthly Retail Trade and Food Services Monthly Wholesale Trade Sales and Inventories New Home Sales New Residential Construction Quarterly Financial Report Quarterly Services Survey Quarterly Summary of State & Local Taxes Quarterly Survey of Public Pensions U.S. International Trade in Goods and Services  Content  The data csv is arranged in a long format with the time_series_code column tying it back to the metadata csv. If you're trying to figure out what data is available you'll want to start with the metadata. Just over a third of the time series store error codes usually confidence intervals rather than actual values. The metadata for these time series will have values in the columns et_code et_desc and et_unit. All of the dates are stored as complete beginning of the period dates but all of the time series are at either monthly quarterly or annual resolution. Exact days and months are provided for convenience when aligning time series and so that you don't have to unpack period codes like 'Q22009'. There may be many time series bundled under a given data category or description. For example the largest category (taxes) contains dozens of types of tax categories and each of those contains a separate time series for each state in the country.  Two of the error code time series have non-numeric values. To convert the values column into reasonable units you'll need to drop all entries equal to the string Less than .05 percent. The data have been substantially reformatted from how they are provided by the Census Bureau. You can find the script I used to prepare the data here.  Acknowledgements This data was kindly made available by the United States Census. You can find the original data here. If you enjoyed this dataset you might also like one of the  other US Census datasets available on Kaggle. Inspiration  The National Bureau of Economic Research's macroeconomic history of the United States covers many similar time series but before the census data was reported. Can you integrate it with this census data? This should allow you to generate many time series stretching from the present back to the 19th century. ,time_series_code:date:value:,string:dateTime:numeric:,trade and business
Indian hotels on Booking.com , PromptCloud , www.kaggle.com/PromptCloudHQ/indian-hotels-on-bookingcom , Sat Sep 16 2017 01:50:00 GMT+0530 (IST) , 6000 Indian hotels on Booking.com ,56, hotels- internet- ,Context This is a pre-crawled dataset taken as subset of a bigger dataset (more than 94000 hotels) that was created by extracting data from Booking.com a leading travel portal. Content This dataset has following fields  address city country crawl_date hotel_brand hotel_description hotel_facilities hotel_star_rating image_count latitude locality longitude pageurl property_id property_name property_type province qts room_count room_type similar_hotel site_review_count site_review_rating site_stay_review_rating sitename special_tag state uniq_id zone  Acknowledgements This dataset was created by PromptCloud's in-house web-crawling service. Inspiration Analyses of the property ratings and property type can be performed.,address:city:country:crawl_date:hotel_brand:hotel_description:hotel_facilities:hotel_star_rating:image_count:latitude:locality:longitude:pageurl:property_id:property_name:property_type:province:qts:room_count:room_type:similar_hotel:site_review_count:site_review_rating:site_stay_review_rating:sitename:special_tag:state:uniq_id:zone:,string:string:string:dateTime:string:string:string:string:numeric:numeric:string:numeric:string:numeric:string:numeric:string:dateTime:numeric:string:string:numeric:numeric:string:string:string:string:string:string:,online information
StarCraft II matches history , alimbekovkz , www.kaggle.com/alimbekovkz/starcraft-ii-matches-history , Wed Oct 18 2017 21:42:18 GMT+0530 (IST) , Predict the results of matches in StarCraft 2 using historical data ,37, video games- games- history- strategy- ,Context This data set is a collection of all StarCraft pro-player 2 matches. The data is taken from the site - http//aligulac.com/ Content Dataset data - 18 October 2017. You can parse actual data. Just use my script (Github) This dataset contains 10 variables  match_date -Date of match in format mm/dd/yyyy player_1 - Player 1 Nickname player_1_match_status - Match status for Player 1 winner or loser score - match score (example 1-0 1-2 etc) player_2 - Player 2 Nickname player_2_match_status - Match status for Player 2 winner or loser player_1_race - Player 1 Race Z - Zerg P - Protoss T - Terran player_2_race - Player 2 Race Z - Zerg P - Protoss T - Terran addon - Game addon WoL- Wings of Liberty HotS - Heart of the Swarm LotV - Legacy of the Void tournament_type - online or offline  Acknowledgements The source is http//aligulac.com/ Inspiration Questions worth exploring  Predict the outcome of a match between two players or whatever you want .... ,match_date:player_1:player_1_match_status:score:player_2:player_2_match_status:player_1_race:player_2_race:addon:tournament_type:,dateTime:string:string:string:boolean:string:string:string:string:string:,video games
Chemical Substance Registry (CAS registry numbers) , US Environmental Protection Agency , www.kaggle.com/epa/cas-registry-numbers , Thu Oct 19 2017 02:12:15 GMT+0530 (IST) , The EPA's Toxic Substances Control Act Chemical Substance Inventory ,5, science and culture- chemistry- health- chemical engineering- ,"Context What is the TSCA Chemical Substances Control Inventory? Section 8 (b) of the Toxic Substances Control Act (TSCA) requires EPA to compile keep current and publish a list of each chemical substance that is manufactured or processed including imports in the United States for uses under TSCA. Also called the “TSCA Inventory” or simply “the Inventory” it plays a central role in the regulation of most industrial chemicals in the United States. The initial reporting period by manufacturers processors and importers was January to May of 1978 for chemical substances that had been in commerce since January of 1975. The Inventory was initially published in 1979 and a second version containing about 62000 chemical substances was published in 1982. The TSCA Inventory has continued to grow since then and now lists about 85000 chemicals. EPA’s compilation of the public TSCA Inventory information is updated twice a year to include new and corrected TSCA Inventory chemical listings and it contains none of the chemical identities claimed as confidential. Thus it is not as complete nor current as the information contained in EPA's TSCA Master Inventory File which includes the chemical identities claimed as confidential and is updated continuously as new and corrected information is received by EPA. Consequently for the purposes of TSCA compliance the TSCA Master Inventory File maintained by EPA's Office of Pollution Prevention and Toxics is the only complete and accurate source that can provide authoritative and conclusive information about which chemical substances are currently included in the TSCA Inventory. Content TSCAINV_062017.csv  ID Record ID Number RN Chemical Abstracts Service (CAS) Registry Number casregno CAS registry number without ""-"" [dashes] IN Index Name (Chemical name) DF Chemical substance definition FL EPA TSCA Regulatory Flag UV UVCB Flag CS Commercial Status Designation  PMNACC_062017.csv  ID Record Number ID PMNNO PMN Number/Form Number ACCNO EPA Accession Number GN Generic Name FL EPA TSCA Regulatory Flag CS Commercial Status Designation  Acknowledgements The EPA updates this registry is twice per year. The version here was downloaded on Oct 18th 2017. Check the EPA website for updated versions https//www.epa.gov/tsca-inventory/how-access-tsca-inventory.  Inspiration There are lots of air quality and pollution datasets that you can use in conjunction with this TSCA Registry to learn more about contaminants and chemicals in general.",ID:PMNNO:ACCNO:GN:FL:CS:,numeric:string:numeric:string:string:string:,chemistry
Credit Card Fraud Detection , Andrea , www.kaggle.com/dalpozz/creditcardfraud , Sat Nov 05 2016 14:38:46 GMT+0530 (IST) , Anonymized credit card transactions labeled as fraudulent or genuine ,37167, crime- finance- ,The datasets contains transactions made by credit cards in September 2013 by european cardholders.  This dataset presents transactions that occurred in two days where we have 492 frauds out of 284807 transactions. The dataset is highly unbalanced the positive class (frauds) account for 0.172% of all transactions. It contains only numerical input variables which are the result of a PCA transformation. Unfortunately due to confidentiality issues we cannot provide the original features and more background information about the data. Features V1 V2 ... V28 are the principal components obtained with PCA the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.  Given the class imbalance ratio we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful for unbalanced classification. The dataset has been collected and analysed during a  research collaboration of Worldline and the Machine Learning Group (http//mlg.ulb.ac.be) of ULB (Université Libre de Bruxelles) on big data mining and fraud detection. More details on current and past projects on related topics are available on http//mlg.ulb.ac.be/BruFence and http//mlg.ulb.ac.be/ARTML Please cite Andrea Dal Pozzolo Olivier Caelen Reid A. Johnson and Gianluca Bontempi. Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium on Computational Intelligence and Data Mining (CIDM) IEEE 2015,Time:V1:V2:V3:V4:V6:V7:V8:V9:V10:V11:V12:V13:V14:V15:V16:V17:V18:V19:V20:V21:V22:V23:V24:V25:V26:V27:V28:Amount:Class:V5:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,crime
Japan Trade Statistics , TadashiNagao , www.kaggle.com/zanjibar/japan-trade-statistics , Fri Sep 29 2017 14:04:53 GMT+0530 (IST) , Japan's international trade by country and type of good ,3954, business- finance- ,Because of memory limitationsdata format change csv -> db (sqlite format) This dataset includes yearly and monthly versions of Japan's international trading data (segmented by country  the type of good  and local custom ). Japan trade statistics is searchable here,Country:Country_name:Area:,numeric:string:string:,trade and business
League of Legends , Chuck Ephron , www.kaggle.com/chuckephron/leagueoflegends , Thu May 25 2017 02:39:15 GMT+0530 (IST) , Competitive matches 2015 to 2017 ,1881, video games- ,League of Legends competitive matches between 2015-2017. The matches include the NALCS EULCS LCK LMS and CBLoL leagues as well as the World Championship and Mid-Season Invitational tournaments.,ColumnName:ColumnDescription:,string:string:,video games
Nutrition Facts for McDonald's Menu , McDonald's , www.kaggle.com/mcdonalds/nutrition-facts , Fri Mar 03 2017 19:00:58 GMT+0530 (IST) , Calories fat and sugar for every cheeseburger fries and milkshake on menu ,6554, food and drink- health- ,Context Ray Kroc wanted to build a restaurant system that would be famous for providing food of consistently high quality and uniform methods of preparation. He wanted to serve burgers buns fries and beverages that tasted just the same in Alaska as they did in Alabama. To achieve this he chose a unique path persuading both franchisees and suppliers to buy into his vision working not for McDonald’s but for themselves together with McDonald’s. Many of McDonald’s most famous menu items – like the Big Mac Filet-O-Fish and Egg McMuffin – were created by franchisees. Content This dataset provides a nutrition analysis of every menu item on the US McDonald's menu including breakfast beef burgers chicken and fish sandwiches fries salads soda coffee and tea milkshakes and desserts. Acknowledgements The menu items and nutrition facts were scraped from the McDonald's website. Inspiration How many calories does the average McDonald's value meal contain? How much do beverages like soda or coffee contribute to the overall caloric intake? Does ordered grilled chicken instead of crispy increase a sandwich's nutritional value? What about ordering egg whites instead of whole eggs? What is the least number of items could you order from the menu to meet one day's nutritional requirements? Start a new kernel,Category:Item:Serving Size:Calories:Calories from Fat:Total Fat:Total Fat (% Daily Value):Saturated Fat:Saturated Fat (% Daily Value):Trans Fat:Cholesterol:Cholesterol (% Daily Value):Sodium:Sodium (% Daily Value):Carbohydrates:Carbohydrates (% Daily Value):Dietary Fiber:Dietary Fiber (% Daily Value):Sugars:Protein:Vitamin A (% Daily Value):Vitamin C (% Daily Value):Calcium (% Daily Value):Iron (% Daily Value):,string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,food and nutrition
Video Game Sales with Ratings , Rush Kirubi , www.kaggle.com/rush4ratio/video-game-sales-with-ratings , Fri Dec 30 2016 21:03:11 GMT+0530 (IST) , Video game sales from Vgchartz and corresponding ratings from Metacritic ,6871, video games- ,Context Motivated by Gregory Smith's web scrape of VGChartz Video Games Sales this data set simply extends the number of variables with another web scrape from Metacritic. Unfortunately there are missing observations as Metacritic only covers a subset of the platforms. Also a game may not have all the observations of the additional variables discussed below. Complete cases are ~ 6900 Content Alongside the fields Name Platform Year_of_Release Genre Publisher NA_Sales EU_Sales JP_Sales Other_Sales Global_Sales we have-  Critic_score - Aggregate score compiled by Metacritic staff Critic_count - The number of critics used in coming up with the Critic_score User_score - Score by Metacritic's subscribers User_count - Number of users who gave the user_score Developer - Party responsible for creating the game Rating  - The ESRB ratings  Acknowledgements This repository https//github.com/wtamu-cisresearch/scraper after a few adjustments worked extremely well! Inspiration It would be interesting to see any machine learning techniques or continued data visualizations applied on this data set.,Name:Platform:Year_of_Release:Genre:Publisher:NA_Sales:EU_Sales:JP_Sales:Other_Sales:Global_Sales:Critic_Score:Critic_Count:User_Score:User_Count:Developer:Rating:,string:string:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:,video games
Donald Trump Forbes 400 Rankings , DaveRosenman , www.kaggle.com/daverosenman/donald-trump-forbes-400-rankings-1985-to-2017 , Thu Oct 19 2017 08:09:06 GMT+0530 (IST) , Estimated net wealth of the president of the USA since 1985 ,44, ,"Context Donald Trump's 'Forbes Richest 400 Americans' rankings and estimated net worth from 1985 to 2017.   Content Forbes Magazine's yearly Richest 400 Americans list was first published in 1982. Trump was on the list in 1982 1983 and 1984 which are the only three years that I haven't been able to find his ranking. I left those years off the list. In 1982 according to ""TrumpNation The Art of Being the Donald"" by Timothy O'Brien ""Forbes gave Donald an undefined share of a family fortune the magazine estimate at $200 million - at at time when all Donald owned personally was a half interest in the Grand Hyatt and a share of the yet-to-be completed Trump Tower. 1983- Wealth Share of Fred's estimated $400 million fortune...1984- Wealth Fred has $200 million Donald has $400 million... 1985-Rank51 Wealth $600 million. Donald becomes a solo Forbes 400 act; Fred disappears from list."" The ""Worth"" column contains Trump's estimated net worth in billions. Years when his ranking and net worth are ""NA"" are years when he did not make the Forbes 400 list (1990-1995).",Year:Rank:Worth:Source:,numeric:numeric:numeric:string:,politics
Retail Data Analytics , Manjeet Singh , www.kaggle.com/manjeetsingh/retaildataset , Fri Sep 01 2017 08:33:57 GMT+0530 (IST) , Historical sales data from 45 stores ,920, ,Context The Challenge - One challenge of modeling retail data is the need to make decisions based on limited history. Holidays and select major events come once a year and so does the chance to see how strategic decisions impacted the bottom line. In addition markdowns are known to affect sales – the challenge is to predict which departments will be affected and to what extent.   Content You are provided with historical sales data for 45 stores located in different regions - each store contains a number of departments.  The company also runs several promotional markdown events throughout the year. These markdowns precede prominent holidays the four largest of which are the Super Bowl Labor Day Thanksgiving and Christmas. The weeks including these holidays are weighted five times higher in the evaluation than non-holiday weeks. Within the Excel Sheet there are 3 Tabs – Stores Features and Sales  Stores Anonymized information about the 45 stores indicating the type and size of store Features Contains additional data related to the store department and regional activity for the given dates.   Store - the store number Date - the week Temperature - average temperature in the region Fuel_Price - cost of fuel in the region MarkDown1-5 - anonymized data related to promotional markdowns. MarkDown data is only available after Nov 2011 and is not available for all stores all the time. Any missing value is marked with an NA CPI - the consumer price index Unemployment - the unemployment rate IsHoliday - whether the week is a special holiday week  Sales Historical sales data which covers to 2010-02-05 to 2012-11-01. Within this tab you will find the following fields  Store - the store number Dept - the department number Date - the week Weekly_Sales -  sales for the given department in the given store IsHoliday - whether the week is a special holiday week  The Task  Predict the department-wide sales for each store for the following year Model the effects of markdowns on holiday weeks Provide recommended actions based on the insights drawn with prioritization placed on largest business impact ,Store:Date:Temperature:Fuel_Price:MarkDown1:MarkDown2:MarkDown3:MarkDown4:MarkDown5:CPI:Unemployment:IsHoliday:,numeric:dateTime:numeric:numeric:string:string:string:string:string:numeric:numeric:boolean:,trade and business
Historical Cryptocurrency Prices (All Tokens) , jvent , www.kaggle.com/jessevent/all-crypto-currencies , Sat Oct 21 2017 23:12:21 GMT+0530 (IST) , 582020 rows of daily closing market data for 1170 coins/tokens over 5 years ,581, data analysis- business- finance- internet- ,"Historical Cryptocurrency Prices For ALL Tokens! Features  1265 unique crypto currencies/tokens  1700 different days of market data 620000 glorious rows 12 variables Data current up until 7th November 2017  Description After not easily being able to find crypto market datasets I figured I'd do my part for the community and scrape my own. This huge dataset contains all the daily details of the crypto-markets as they close for all the different crypto currencies and tokens listed on CoinMarketCaps historical tables.  My process I used the amazing doSnow and doParallel packages which allowed me to call 2 APIs scrape a ridiculous amount of lengthy HTML pages all the data in around 5 minutes. I've included the link to the scraping script hosted on my GitHub repository below. Feel free to check it out  https//github.com/JesseVent/Crypto-Market-Scraper Content The earliest date available is 28/04/2013 which is the earliest period coinmarketcap displays for any coin. In addition to the standard fields I've added two derived columns for open and close prices in $AUD as well as the variance between open and close prices. Some particularly interesting things I noticed were how much the alt-coins fall when bitcoin rises dramatically (people pulling out of alt-coins to invest in bitcoin) and the beginning and ends of every calendar month seems to be when the market as a whole seems to gain the most. 'data.frame'   620245 obs. of  12 variables  $ symbol     chr  ""$$$"" ""$$$"" ""$$$"" ""$$$"" ...  $ date       chr  ""2016-09-04"" ""2016-09-02"" ""2017-09-07"" ""2017-01-06"" ...  $ open       num  0.000006 0.000011 0.001754 0.00003 0.001679 ...  $ high       num  0.000012 0.000011 0.001875 0.000037 0.001917 ...  $ low        num  0.000006 0.000006 0.001614 0.000027 0.001594 ...  $ close      num  1.20e+05 6.00e+06 1.67e-03 2.70e+05 1.76e-03 ...  $ volume     num  1 4 873 1 1467 ...  $ market     num  275 525 80499 1395 77047 ...  $ name       chr  ""Money"" ""Money"" ""Money"" ""Money"" ...  $ ranknow    num  814 814 814 814 814 814 814 814 814 814 ...  $ variance   num  1 1 -0.0503 1 0.0449 ...  $ volatility num  5.00e-11 8.33e-13 1.56e-01 3.70e-11 1.84e-01 ...  Closing Comments Thanks to the team at https//coinmarketcap.com for the great work they do and to the team at CoinTelegraph where the images were sourced. Please up vote this data set if you find it useful and remember the crypto currency market is volatile by nature please be responsible if trading. If by chance you do manage to make your fortune through some game-changing model I'd appreciate your consideration in the below ) BTC 1LPjH7KyH5aD65pTBhByXFCFXZNTUVdeRY  ETH 0x375923Bf82F0b728d23A5704261a6e16341fd860",symbol:date:open:high:low:close:volume:market:name:ranknow:variance:volatility:,string:dateTime:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:,blockchain and crytocurrencies
TMDB 5000 Movie Dataset , The Movie Database (TMDb) , www.kaggle.com/tmdb/tmdb-movie-metadata , Thu Sep 28 2017 06:39:12 GMT+0530 (IST) , Metadata on ~5000 movies from TMDb ,51581, film- ,Background What can we say about the success of a movie before it is released? Are there certain companies (Pixar?) that have found a consistent formula? Given that major films costing over $100 million to produce can still flop this question is more important than ever to the industry. Film aficionados might have different interests. Can we predict which films will be highly rated whether or not they are a commercial success? This is a great place to start digging in to those questions with data on the plot cast crew budget and revenues of several thousand films. Data Source Transfer Summary We (Kaggle) have removed the original version of this dataset per a DMCA takedown request from IMDB. In order to minimize the impact we're replacing it with a similar set of films and data fields from The Movie Database (TMDb) in accordance with their terms of use. The bad news is that kernels built on the old dataset will most likely no longer work. The good news is that  You can port your existing kernels over with a bit of editing. This kernel offers functions and examples for doing so. You can also find a general introduction to the new format here. The new dataset contains full credits for both the cast and the crew rather than just the first three actors. Actor and actresses are now listed in the order they appear in the credits. It's unclear what ordering the original dataset used; for the movies I spot checked it didn't line up with either the credits order or IMDB's stars order. The revenues appear to be more current. For example IMDB's figures for Avatar seem to be from 2010 and understate the film's global revenues by over $2 billion. Some of the movies that we weren't able to port over (a couple of hundred) were just bad entries. For example this IMDB entry has basically no accurate information at all. It lists Star Wars Episode VII as a documentary.  Data Source Transfer Details  Several of the new columns contain json. You can save a bit of time by porting the load data functions from this kernel. Even in simple fields like runtime may not be consistent across versions. For example previous dataset shows the duration for Avatar's extended cut while TMDB shows the time for the original version. There's now a separate file containing the full credits for both the cast and crew. All fields are filled out by users so don't expect them to agree on keywords genres ratings or the like. Your existing kernels will continue to render normally until they are re-run. If you are curious about how this dataset was prepared the code to access TMDb's API is posted here.  New columns  homepage id original_title overview popularity production_companies production_countries release_date spoken_languages status tagline vote_average  Lost columns  actor_1_facebook_likes actor_2_facebook_likes actor_3_facebook_likes aspect_ratio cast_total_facebook_likes color content_rating director_facebook_likes facenumber_in_poster movie_facebook_likes movie_imdb_link num_critic_for_reviews num_user_for_reviews  Open Questions About the Data There are some things we haven't had a chance to confirm about the new dataset. If you have any insights please let us know in the forums!  Are the budgets and revenues all in US dollars? Do they consistently show the global revenues? This dataset hasn't yet gone through a data quality analysis. Can you find any obvious corrections? For example in the IMDb version it was necessary to treat values of zero in the budget field as missing. Similar findings would be very helpful to your fellow Kagglers! (It's probably a good idea to keep treating zeros as missing with the caveat that missing budgets much more likely to have been from small budget films in the first place).  Inspiration  Can you categorize the films by type such as animated or not? We don't have explicit labels for this but it should be possible to build them from the crew's job titles. How sharp is the divide between major film studios and the independents? Do those two groups fall naturally out of a clustering analysis or is something more complicated going on?  Acknowledgements This dataset was generated from The Movie Database API. This product uses the TMDb API but is not endorsed or certified by TMDb. Their API also provides access to data on many additional movies actors and actresses crew members and TV shows. You can try it for yourself here. ,movie_id:title:cast:crew:,numeric:string:string:string:,movies
Auto-mpg dataset , UCI Machine Learning , www.kaggle.com/uciml/autompg-dataset , Sun Jul 02 2017 10:55:54 GMT+0530 (IST) , Mileage per gallon performances of various cars ,337, automobiles- ,"Context The data is technical spec of cars. The dataset is downloaded from UCI Machine Learning Repository Content  Title Auto-Mpg Data Sources (a) Origin  This dataset was taken from the StatLib library which is             maintained at Carnegie Mellon University. The dataset was              used in the 1983 American Statistical Association Exposition. (c) Date July 7 1993 Past Usage See 2b (above) QuinlanR. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine  Learning 236-243 University of Massachusetts Amherst. Morgan Kaufmann. Relevant Information This dataset is a slightly modified version of the dataset provided in the StatLib library.  In line with the use by Ross Quinlan (1993) in predicting the attribute ""mpg"" 8 of the original instances were removed  because they had unknown values for the ""mpg"" attribute.  The original  dataset is available in the file ""auto-mpg.data-original"". ""The data concerns city-cycle fuel consumption in miles per gallon to be predicted in terms of 3 multivalued discrete and 5 continuous attributes."" (Quinlan 1993) Number of Instances 398 Number of Attributes 9 including the class attribute Attribute Information mpg           continuous cylinders     multi-valued discrete displacement  continuous horsepower    continuous weight        continuous acceleration  continuous model year    multi-valued discrete origin        multi-valued discrete car name      string (unique for each instance) Missing Attribute Values  horsepower has 6 missing values  Acknowledgements Dataset UCI Machine Learning Repository  Data link  https//archive.ics.uci.edu/ml/datasets/auto+mpg Inspiration I have used this dataset for practicing my exploratory analysis skills.",mpg:cylinders:displacement:horsepower:weight:acceleration:model year:origin:car name:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:,roadways
TED Talks , Rounak Banik , www.kaggle.com/rounakbanik/ted-talks , Tue Sep 26 2017 02:44:33 GMT+0530 (IST) , Data about TED Talks on the TED.com website until September 21st 2017 ,859, data analysis- ,Context These datasets contain information about all audio-video recordings of TED Talks uploaded to the official TED.com website until September 21st 2017. The TED main dataset contains information about all talks including number of views number of comments descriptions speakers and titles. The TED transcripts dataset contains the transcripts for all talks available on TED.com. Content (for the CSV files) TED Main Dataset  name The official name of the TED Talk. Includes the title and the speaker. title The title of the talk description A blurb of what the talk is about. main_speaker The first named speaker of the talk. speaker_occupation The occupation of the main speaker. num_speaker The number of speakers in the talk. duration The duration of the talk in seconds. event The TED/TEDx event where the talk took place. film_date The Unix timestamp of the filming. published_date The Unix timestamp for the publication of the talk on TED.com comments The number of first level comments made on the talk. tags The themes associated with the talk. languages The number of languages in which the talk is available. ratings A stringified dictionary of the various ratings given to the talk (inspiring fascinating jaw dropping etc.) related_talks A list of dictionaries of recommended talks to watch next. url The URL of the talk. views The number of views on the talk.  TED Transcripts Dataset  url The URL of the talk transcript The official English transcript of the talk.  Acknowledgements The data has been scraped from the official TED Website and is available under the Creative Commons License. Inspiration I've always been fascinated by TED Talks and the immense diversity of content that it provides for free. I was also thoroughly inspired by a TED Talk that visually explored TED Talks stats and I was motivated to do the same thing albeit on a much less grander scale. Some of the questions that can be answered with this dataset 1. How is each TED Talk related to every other TED Talk? 2. Which are the most viewed and most favorited Talks of all time? Are they mostly the same? What does this tell us? 3. What kind of topics attract the maximum discussion and debate (in the form of comments)? 4. Which months are most popular among TED and TEDx chapters? 5. Which themes are most popular amongst TEDsters?,comments:description:duration:event:film_date:languages:main_speaker:name:num_speaker:published_date:ratings:related_talks:speaker_occupation:tags:title:url:views:,numeric:string:numeric:string:numeric:numeric:string:string:numeric:numeric:string:string:string:string:string:string:numeric:,videos
Medical Appointment No Shows , JoniHoppen , www.kaggle.com/joniarroba/noshowappointments , Mon Aug 21 2017 05:19:38 GMT+0530 (IST) , Why do 30% of patients miss their scheduled appointments? ,6208, brazil- public health- human medicine- ,Context A person makes a doctor appointment receives all the instructions and no-show. Who to blame?  If that is helpful somehow to you knowledge and work - please up vote. Content 300k medical appointments of the public healthcare of the capital city of Espirito Santo State - Vitoria -  Brazil and its 15 variables (characteristics) of each. The most important one if the patient show-up or no-show the appointment.  Variable names are self-explanatory if you have doubts just let me know!  Handcap is the total amount of handcaps a person presents it is not binary. Version 2 - has appointments groups by patients IDs.  scholarship variable means this concept = https//en.wikipedia.org/wiki/Bolsa_Fam%C3%ADlia Inspiration What if that possible to predict someone to no-show an appointment? Acknowledgments  Municipality of Vitoria and its forward thinking and leading position in terms of data maturity that is helping the world to better understand human behavior.  Aquarela Advanced Analytics - For the dozens of hours of analysis given for free on this project. All Kaggle users that are spreading the ideas codes and knowledge.  ,,,fitness and personal well being
US Mass Shootings  , Zeeshan-ul-hassan Usmani , www.kaggle.com/zusmani/us-mass-shootings-last-50-years , Wed Oct 11 2017 05:00:12 GMT+0530 (IST) , Last 50 Years (1966-2017) ,2346, united states- crime- violence- terrorism- ,Context Mass Shootings in the United States of America (1966-2017) The US has witnessed 398 mass shootings in last 50 years that resulted in 1996 deaths and 2488 injured. The latest and the worst mass shooting of October 2 2017 killed 58 and injured 515 so far. The number of people injured in this attack is more than the number of people injured in all mass shootings of 2015 and 2016 combined.  The average number of mass shootings per year is 7 for the last 50 years that would claim 39 lives and 48 injured per year.  Content Geography United States of America Time period 1966-2017 Unit of analysis Mass Shooting Attack Dataset The dataset contains detailed information of 398 mass shootings in the United States of America that killed 1996 and injured 2488 people.   Variables The dataset contains Serial No Title Location Date Summary Fatalities Injured Total Victims Mental Health Issue Race Gender and Lat-Long information. Acknowledgements I’ve consulted several public datasets and web pages to compile this data.  Some of the major data sources include Wikipedia Mother Jones Stanford USA Today and other web sources.  Inspiration With a broken heart I like to call the attention of my fellow Kagglers to use Machine Learning and Data Sciences to help me explore these ideas •   How many people got killed and injured per year? •   Visualize mass shootings on the U.S map •   Is there any correlation between shooter and his/her race gender •   Any correlation with calendar dates? Do we have more deadly days weeks or months on average •   What cities and states are more prone to such attacks •   Can you find and combine any other external datasets to enrich the analysis for example gun ownership by state •   Any other pattern you see that can help in prediction crowd safety or in-depth analysis of the event •   How many shooters have some kind of mental health problem? Can we compare that shooter with general population with same condition Mass Shootings Dataset Ver 3 This is the new Version of Mass Shootings Dataset. I've added eight new variables  Incident Area (where the incident took place)  Open/Close Location (Inside a building or open space)  Target (possible target audience or company)  Cause (Terrorism Hate Crime Fun (for no obvious reason etc.) Policeman Killed (how many on duty officers got killed) Age (age of the shooter) Employed (Y/N)  Employed at  (Employer Name)  Age Employed and Employed at (3 variables) contain shooter details Mass Shootings Dataset Ver 4 Quite a few missing values have been added Mass Shootings Dataset Ver 5 Three more recent mass shootings have been added including the Texas Church shooting of November 5 2017 I hope it will help create more visualization and extract patterns.  Keep Coding!,S#:Title:Location:Date:Summary:Fatalities:Injured:Total victims:Mental Health Issues:Race:Gender:Latitude:Longitude:,numeric:string:string:dateTime:string:numeric:numeric:numeric:string:string:string:string:string:,crime
Indian Hotels on Goibibo , PromptCloud , www.kaggle.com/PromptCloudHQ/hotels-on-goibibo , Fri Sep 15 2017 15:24:00 GMT+0530 (IST) , 4000 Indian hotels on Goibibo ,51, india- hotels- internet- ,Context This is a pre-crawled dataset taken as subset of a bigger dataset (more than 33344 hotels) that was created by extracting data from goibibo.com a leading travel site from India. Content This dataset has following fields  address area - The sub-city region that this hotel is located in geographically. city country - Always India. crawl_date guest_recommendation - How many guests that stayed here have recommended this hotels to others on the site. hotel_brand - The chain that owns this hotel if this hotel is part of a chain. hotel_category hotel_description - A hotel description as provided by the lister. hotel_facilities -  hotel_star_rating - The out-of-five star rating of this hotel. image_count - The number of images provided with the listing. latitude locality longitude pageurl point_of_interest - Nearby locations of interest. property_name property_type - The type of property. Usually a hotel. province qts - Crawl timestamp. query_time_stamp - Copy of qts. review_count_by_category - Reviews for the hotel broken across several different categories. room_area room_count room_facilities room_type similar_hotel site_review_count - The number of reviews for this hotel left on the site by users. site_review_rating - The overall rating for this hotel by users. site_stay_review_rating sitename - Always goibibo.com state uniq_id  Acknowledgements This dataset was created by PromptCloud's in-house web-crawling service. Inspiration  Try exploring some of the amenity categories. What do you see? Try applying some natural language processing algorithms to the hotel descriptions. What are the some common words and phrases? How do they relate to the amenities the hotel offers? What can you discover by drilling down further into hotels in different regions? ,additional_info:address:area:city:country:crawl_date:guest_recommendation:hotel_brand:hotel_category:hotel_description:hotel_facilities:hotel_star_rating:image_count:latitude:locality:longitude:pageurl:point_of_interest:property_id:property_name:property_type:province:qts:query_time_stamp:review_count_by_category:room_area:room_count:room_facilities:room_type:similar_hotel:site_review_count:site_review_rating:site_stay_review_rating:sitename:state:uniq_id:,string:string:string:string:string:dateTime:numeric:string:string:string:string:numeric:numeric:numeric:string:numeric:string:string:string:string:string:string:dateTime:dateTime:string:string:numeric:string:string:string:numeric:numeric:string:string:string:string:,online information
Car Sale Advertisements , Anton Bobanev , www.kaggle.com/antfarol/car-sale-advertisements , Thu May 04 2017 11:32:13 GMT+0530 (IST) , Data collected from private car sale advertisements in Ukraine ,504, automobiles- ,Context This dataset was collected by me from car sale advertisements for study/practice purposes in 2016. Though there is couple well known car features datasets they seems quite simple and outdated. Car topic is really interesting. But I wanted to practice with real raw data which has all inconvenient moments (as NA’s for example). This dataset contains data for more than 9.5K cars sale in Ukraine. Most of them are used cars so it opens the possibility to analyze features related to car operation. At the end of the day I look at this data as a subset from all Ukrainian car fleet. Content Dataset contains 9576 rows and 10 variables with essential meanings  car manufacturer brand  price seller’s price in advertisement (in USD) body car body type  mileage as mentioned in advertisement (‘000 Km) engV rounded engine volume (‘000 cubic cm) engType type of fuel (“Other” in this case should be treated as NA)  registration whether car registered in Ukraine or not  year year of production  model specific model name  drive drive type  Data has gaps so be careful and check for NA’s. I tried to check and drop repeated offers but theoretically duplications are possible. Inspiration Data will be handy to study and practice different models and approaches.  As a further step you can compare patters in Ukrainian market to your own domestic car market characteristics.,car:price:body:mileage:engV:engType:registration:year:model:drive:,string:numeric:string:numeric:numeric:string:string:numeric:string:string:,trade and business
Climate Change: Earth Surface Temperature Data , Berkeley Earth , www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data , Mon May 01 2017 22:59:10 GMT+0530 (IST) , Exploring global temperatures since 1750 ,18830, environment- climate- ,Some say climate change is the biggest threat of our age while others say it’s a myth based on dodgy science. We are turning some of the data over to you so you can form your own view.  Even more than with other data sets that Kaggle has featured there’s a huge amount of data cleaning and preparation that goes into putting together a long-time study of climate trends. Early data was collected by technicians using mercury thermometers where any variation in the visit time impacted measurements. In the 1940s the construction of airports caused many weather stations to be moved. In the 1980s there was a move to electronic thermometers that are said to have a cooling bias. Given this complexity there are a range of organizations that collate climate trends data. The three most cited land and ocean temperature data sets are NOAA’s MLOST NASA’s GISTEMP and the UK’s HadCrut.  We have repackaged the data from a newer compilation put together by the Berkeley Earth which is affiliated with Lawrence Berkeley National Laboratory. The Berkeley Earth Surface Temperature Study combines 1.6 billion temperature reports from 16 pre-existing archives. It is nicely packaged and allows for slicing into interesting subsets (for example by country). They publish the source data and the code for the transformations they applied. They also use methods that allow weather observations from shorter time series to be included meaning fewer observations need to be thrown away.  In this dataset we have include several files Global Land and Ocean-and-Land Temperatures (GlobalTemperatures.csv)    Date starts in 1750 for average land temperature and 1850 for max and min land temperatures and global ocean and land temperatures LandAverageTemperature global average land temperature in celsius   LandAverageTemperatureUncertainty the 95% confidence interval around the average   LandMaxTemperature global average maximum land temperature in celsius   LandMaxTemperatureUncertainty the 95% confidence interval around the maximum land temperature   LandMinTemperature  global average minimum land temperature in celsius   LandMinTemperatureUncertainty the 95% confidence interval around the minimum land temperature   LandAndOceanAverageTemperature global average land and ocean temperature in celsius   LandAndOceanAverageTemperatureUncertainty the 95% confidence interval around the global average land and ocean temperature    Other files include    Global Average Land Temperature by Country (GlobalLandTemperaturesByCountry.csv)   Global Average Land Temperature by State (GlobalLandTemperaturesByState.csv)   Global Land Temperatures By Major City (GlobalLandTemperaturesByMajorCity.csv)   Global Land Temperatures By City (GlobalLandTemperaturesByCity.csv)  The raw data comes from the Berkeley Earth data page.,dt:AverageTemperature:AverageTemperatureUncertainty:City:Country:Latitude:Longitude:,dateTime:numeric:numeric:string:string:string:string:,weather and climate
Weekly Sales Transactions , Chris Crawford , www.kaggle.com/crawford/weekly-sales-transactions , Wed Aug 23 2017 02:42:37 GMT+0530 (IST) , Weekly purchase quantities of over 800 products over 52 weeks ,341, timelines- time series- business- product- ,"Context Contains weekly purchased quantities of 800 over products over 52 weeks. These data were used in the paper ""Time series clustering A superior alternative for market basket analysis"" by Tan Swee Chuan and San Lau Jess Pei. Content  Each row represents a different product Each column represents a week of the year (52 total weeks). The last half of the columns are normalized for you. Values represent quantity of the products sold during the week 52 weeks W0 W1 ... W51 Normalised vlaues of weekly data Normalised 0 Normalised 1 ... Normalised 51   Acknowledgements Tan Swee Chuan and San Lau Jess Pei Time series clustering A superior alternative for market basket analysis. This dataset was downloaded from the UCI Machine Learning Repository.  https//archive.ics.uci.edu/ml/datasets/Sales_Transactions_Dataset_Weekly",Product_Code:W0:W1:W2:W3:W4:W5:W6:W7:W8:W9:W10:W11:W12:W13:W14:W15:W16:W17:W18:W19:W20:W21:W22:W23:W24:W25:W26:W27:W28:W29:W30:W31:W32:W33:W34:W35:W36:W37:W38:W39:W40:W41:W42:W43:W44:W45:W46:W47:W48:W49:W50:W51:MIN:MAX:Normalized 0:Normalized 1:Normalized 2:Normalized 3:Normalized 4:Normalized 5:Normalized 6:Normalized 7:Normalized 8:Normalized 9:Normalized 10:Normalized 11:Normalized 12:Normalized 13:Normalized 14:Normalized 15:Normalized 16:Normalized 17:Normalized 18:Normalized 19:Normalized 20:Normalized 21:Normalized 22:Normalized 23:Normalized 24:Normalized 25:Normalized 26:Normalized 27:Normalized 28:Normalized 29:Normalized 30:Normalized 31:Normalized 32:Normalized 33:Normalized 34:Normalized 35:Normalized 36:Normalized 37:Normalized 38:Normalized 39:Normalized 40:Normalized 41:Normalized 42:Normalized 43:Normalized 44:Normalized 45:Normalized 46:Normalized 47:Normalized 48:Normalized 49:Normalized 50:Normalized 51:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,trade and business
FIFA 18 Complete Player Dataset , Aman Shrivastava , www.kaggle.com/thec03u5/fifa-18-demo-player-dataset , Thu Sep 28 2017 20:34:51 GMT+0530 (IST) , 17k+ players 70+ attributes extracted from the latest edition of FIFA ,2384, popular culture- video games- association football- ,The Dataset you can play with.   Context Dataset for people who love data science and have grown up playing FIFA.  Content  Every player featuring in FIFA 18 70+ attributes  Player and Flag Images Playing Position Data Attributes based on actual data of the latest  EA's FIFA 18 game Attributes include on all player style statistics like Dribbling Aggression GK Skills etc. Player personal data like Nationality Photo Club Age Wage Salary etc.   Upcoming Update will Include   Team (National and Club) Data Player Images in Zip folder Betting Odds  The dataset contains all the statistics and playing attributes of all the players in the Full version of FIFA 18.  Data Source The data is scraped from the website https//sofifa.com by extracting the Player personal data and Player Ids and then the playing and style statistics.    Github Project  Possible Explorations  Make your dream team Analyse which Club or National Team has the best-rated players Assess the strength of a team at a particular position Analyse the team with the best dribbling speed Co-relate between Age and Overall rating Co-relate between Age and Nationality  Co-relate between Age and Potential   Could prove of immense value to Fantasy Premier League enthusiasts. These are just basic examples sky is the limit.   Acknowledgements The data has been crawled from the https//sofifa.com website.  Inspiration Several insights and correlations between player value wage age and performance can be derived from the dataset. Furthermore how do the players in this dataset compare against themselves in last year's dataset?  Contributing Changes and Improvement suggestions are welcome. Feel free to comment new additions that you think are useful or drop a PR on the github project.,:Name:Age:Photo:Nationality:Flag:Overall:Potential:Club:Club Logo:Value:Wage:Special:Acceleration:Aggression:Agility:Balance:Ball control:Composure:Crossing:Curve:Dribbling:Finishing:Free kick accuracy:GK diving:GK handling:GK kicking:GK positioning:GK reflexes:Heading accuracy:Interceptions:Jumping:Long passing:Long shots:Marking:Penalties:Positioning:Reactions:Short passing:Shot power:Sliding tackle:Sprint speed:Stamina:Standing tackle:Strength:Vision:Volleys:CAM:CB:CDM:CF:CM:ID:LAM:LB:LCB:LCM:LDM:LF:LM:LS:LW:LWB:Preferred Positions:RAM:RB:RCB:RCM:RDM:RF:RM:RS:RW:RWB:ST:,numeric:string:numeric:string:string:string:numeric:numeric:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:,video games
Match Statistics from top 5 European Leagues , Jemilu Mohammed , www.kaggle.com/jangot/ligue1-match-statistics , Fri Jul 07 2017 02:59:26 GMT+0530 (IST) , Italy Spain England Germany France 2012-2017 ,310, association football- ,Context I am a student exploring the possibility of making money in football betting. I am currently doing a literature review on modelling association football scores and trying to put together a machine learning system to use for my first betting campaign next season. What I have learned thus far is that outcomes of football events are partly deterministic and partly random. I do not know exactly how to go about implementing this in a machine learning system yet. I am also hoping to find useful features from this dataset. Content The data here contains match statistics collected from whoscored.com europes top five leagues from 2012-2013 to 2016-2017 season. It contains just about all match statistics that anyone can ever hope for including but not limited to  Goals Corners Possession Ratings Coaches LineUps and other relevent match statistics The features are simply just self explanatory and have been given long but meaningful names Acknowledgement I collected the data from the whoscored.com website. I scraped it using beautifulSoup in python and just extracted the features I thought could have some use. Inspiration This is just something I hope could become something but hey it may be nothing. I am just interested to know the kind of insights that could be generated from this.,:id:homeTacklesTotalHT:homeShotsTotalHT:awayDispossessedFT:awayPassSuccessFT:awayRatingsFT:awayDribbleSuccessFT:awayDribblesAttemptedHT:awayTeamLineUp:awayShotsBlockedHT:awayShotsTotalHT:homeDribbleSuccessHT:homeFoulsCommitedFT:homeAerialsTotalFT:homeRatingsHT:awayShotsOnTargetFT:awayShotsBlockedFT:homeInterceptionsHT:awayPossessionHT:homePassesKeyFT:awayShotsOnTargetHT:awayDribblesWonFT:awayTackleSuccessHT:homeCornersTotalFT:homeAerialsTotalHT:homeShotsBlockedFT:awayCornersTotalHT:homeCornersTotalHT:homeDribbleSuccessFT:homeTeamLineUp:awayPassSuccessHT:awayDribblesWonHT:homeDispossessedHT:awayAerialsTotalFT:homeShotsBlockedHT:awayPassesKeyFT:homeTackleSuccessHT:awayPassesKeyHT:homeFormation:awayInterceptionsHT:awayDispossessedHT:refereeName:homeDribblesWonHT:homePossessionFT:awayAerialsTotalHT:awayGoalHT:awayManagerName:awayInterceptionsFT:homeDribbledPastFT:homeGoalHT:awayDribbleSuccessHT:homeGoalFT:awayTacklesTotalHT:homeDribblesWonFT:awayTackleSuccessFT:awayTeam:homeDispossessedFT:awayOffsidesCaughtFT:awayDribbledPastFT:homeShotsOnTargetHT:awayFormation:awayOffsidesCaughtHT:homeDribbledPastHT:awayFoulsCommitedHT:homeShotsTotalFT:homePassSuccessFT:homeFoulsCommitedHT:awayCornersTotalFT:homeTeam:homeManagerName:awayFoulsCommitedFT:homeShotsOnTargetFT:homeDribblesAttemptedHT:awayRatingsHT:homeOffsidesCaughtHT:homeTacklesTotalFT:awayDribbledPastHT:awayGoalFT:homePassesKeyHT:homeOffsidesCaughtFT:homePossessionHT:venueName:awayDribblesAttemptedFT:homeInterceptionsFT:homePassSuccessHT:date:awayTacklesTotalFT:homeRatingsFT:homeDribblesAttemptedFT:homeTackleSuccessFT:awayPossessionFT:awayShotsTotalFT:division:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:dateTime:numeric:numeric:numeric:numeric:numeric:numeric:string:,football
Road Accidents Incidence , Akshay Babbar , www.kaggle.com/akshay4/road-accidents-incidence , Mon Jan 23 2017 15:17:25 GMT+0530 (IST) , Road Accidents Data Great Britain 1979-2015 ,1017, road transport- ,Context Road Accidents Content Dataset has been fetched from here and the files have been merged and cleaned to reach the final data attached. Primarily Captures Road Accidents in UK between 1979 and 2015 and has 70 features/columns and about 250K rows. Also attached with it is an excel file with Multiple Tabs that can help one to understand the Data. Acknowledgements Data has been fetched from Open Data Platform UK and is being shared under Open Government Licence. For more details refer to Open Data UK,accident_index:vehicle_reference:vehicle_type:towing_and_articulation:vehicle_manoeuvre:vehicle_location-restricted_lane:junction_location:skidding_and_overturning:hit_object_in_carriageway:vehicle_leaving_carriageway:hit_object_off_carriageway:1st_point_of_impact:was_vehicle_left_hand_drive?:journey_purpose_of_driver:sex_of_driver:age_of_driver:age_band_of_driver:engine_capacity_(cc):propulsion_code:age_of_vehicle:driver_imd_decile:driver_home_area_type:vehicle_imd_decile:NUmber_of_Casualities_unique_to_accident_index:No_of_Vehicles_involved_unique_to_accident_index:location_easting_osgr:location_northing_osgr:longitude:latitude:police_force:accident_severity:number_of_vehicles:number_of_casualties:date:day_of_week:time:local_authority_(district):local_authority_(highway):1st_road_class:1st_road_number:road_type:speed_limit:junction_detail:junction_control:2nd_road_class:2nd_road_number:pedestrian_crossing-human_control:pedestrian_crossing-physical_facilities:light_conditions:weather_conditions:road_surface_conditions:special_conditions_at_site:carriageway_hazards:urban_or_rural_area:did_police_officer_attend_scene_of_accident:lsoa_of_accident_location:casualty_reference:casualty_class:sex_of_casualty:age_of_casualty:age_band_of_casualty:casualty_severity:pedestrian_location:pedestrian_movement:car_passenger:bus_or_coach_passenger:pedestrian_road_maintenance_worker:casualty_type:casualty_home_area_type:casualty_imd_decile:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:dateTime:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,accidents
A Million News Headlines , Rohk , www.kaggle.com/therohk/million-headlines , Wed Oct 11 2017 02:09:38 GMT+0530 (IST) , News headlines published over a period of 14 years. ,647, news agencies- historiography- linguistics- sociology- ,Context This contains data of news headlines published over a period of 14 years. From the reputable Australian news source ABC (Australian Broadcasting Corp.) Site http//www.abc.net.au/ Prepared by Rohit Kulkarni Content Format CSV Rows 1093281 Column 1 publish_date (yyyyMMdd format) Column 2 headline_text (ascii lowercase) Start Date 2003-02-19 End Date 2017-09-30 Acknowledgements Special thanks to the java jsoup library https//jsoup.org/ Inspiration I look at this news dataset as a summarised historical record of noteworthy events in the globe from early-2003 to mid-2017 with a more granular focus on Australia. This includes the entire corpus of articles published by the ABC website in the given time range.  With a volume of 200 articles per day and a good focus on international news we can be fairly certain that every event of significance has been captured here. Digging into the keywords one can see all the important episodes shaping the last decade and how they evolved over time. Ex financial crisis iraq war multiple US elections ecological disasters terrorism famous people Australian crimes  etc. Similar Work Your kernals can be reused with minimal changes across all these datasets  3M Clickbait Headlines for 6 years Examine the Examiner 1.3M Global Headlines from 20K sources over 1 week Global News Week 2.5M News Headlines from India upto 2017 Coming Soon... ,,,news
Deep Learning A-Z - ANN dataset , Filippo , www.kaggle.com/filippoo/deep-learning-az-ann , Tue May 16 2017 17:50:30 GMT+0530 (IST) ," Kirill Eremenko ""Deep Learning A-Z™: Hands-On Artificial Neural Networks"" course ",311, artificial intelligence- ,"Context This is the dataset used in the section ""ANN (Artificial Neural Networks)"" of the Udemy course from Kirill Eremenko (Data Scientist & Forex Systems Expert) and Hadelin de Ponteves (Data Scientist) called Deep Learning A-Z™ Hands-On Artificial Neural Networks. The dataset is very useful for beginners of Machine Learning and a simple playground where to compare several techniques/skills. It can be freely downloaded here https//www.superdatascience.com/deep-learning/  The story A bank is investigating a very high rate of customer leaving the bank. Here is a 10.000 records dataset to investigate and predict which of the customers are more likely to leave the bank soon. The story of the story I'd like to compare several techniques (better if not alone and with the experience of several Kaggle users) to improve my basic knowledge on Machine Learning. Content I will write more later but the columns names are very self-explaining. Acknowledgements Udemy instructors Kirill Eremenko (Data Scientist & Forex Systems Expert) and Hadelin de Ponteves (Data Scientist) and their efforts to provide this dataset to their students. Inspiration Which methods score best with this dataset? Which are fastest (or executable in a decent time)? Which are the basic steps with such a simple dataset very useful to beginners?",RowNumber:CustomerId:Surname:CreditScore:Geography:Gender:Age:Tenure:Balance:NumOfProducts:HasCrCard:IsActiveMember:EstimatedSalary:Exited:,numeric:numeric:string:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,artificial intelligence
Used cars database , Orges Leka , www.kaggle.com/orgesleka/used-cars-database , Mon Nov 28 2016 21:16:47 GMT+0530 (IST) , Over 370000 used cars scraped from Ebay Kleinanzeigen ,8135, automobiles- ,"If you want to download and experiment with the Scrapy script you can do so from forum data science Over 370000 used cars scraped with Scrapy from Ebay-Kleinanzeigen. The content of the data is in german so one has to translate it first if one can not speak german. Those fields are included autos.csv  dateCrawled  when this ad was first crawled all field-values are taken from this date name  ""name"" of the car seller  private or dealer offerType price  the price on the ad to sell the car abtest vehicleType yearOfRegistration  at which year the car was first registered gearbox powerPS  power of the car in PS model kilometer  how many kilometers the car has driven monthOfRegistration  at which month the car was first registered fuelType brand notRepairedDamage  if the car has a damage which is not repaired yet dateCreated  the date for which the ad at ebay was created nrOfPictures  number of pictures in the ad (unfortunately this field contains everywhere a 0 and is thus useless (bug in crawler!) ) postalCode  lastSeenOnline  when the crawler saw this ad last online  The fields lastSeen and dateCreated could be used to estimate how long a car will be at least online before it is sold. brought to you by Orges Leka Regression on average Price per Year based on this dataset Table of value loss of an average used car per year The second file is produced in MySQL from the first one through the query select   count(*) as count   kilometer   yearOfRegistration  20*round(powerPS/20) as powerPS  min(price) as minprice  max(price) as maxPrice  avg(price) as avgPreis  sqrt(variance(price)) as sdPreis from items where       yearOfRegistration > 1990 and yearOfRegistration < 2016      and price > 100 and price < 100000      and powerPS < 600 and powerPS > 0   group by yearOfRegistration round(powerPS/20)kilometer  having count > 10  into outfile '/tmp/cnt_km_year_powerPS_minPrice_maxPrice_avgPrice_sdPrice.csv'  fields terminated by '' lines terminated by '\n';  Happy Coding!",dateCrawled:name:seller:offerType:price:abtest:vehicleType:yearOfRegistration:gearbox:,dateTime:string:string:string:numeric:string:string:numeric:numeric:,online information
NYC Property Sales , City of New York , www.kaggle.com/new-york-city/nyc-property-sales , Sat Sep 23 2017 01:13:30 GMT+0530 (IST) , A year's worth of properties sold on the NYC real estate market ,471, cities- real estate- ,Context This dataset is a record of every building or building unit (apartment etc.) sold in the New York City property market over a 12-month period. Content This dataset contains the location address type sale price and sale date of building units sold. A reference on the trickier fields  BOROUGH A digit code for the borough the property is located in; in order these are Manhattan (1) Bronx (2) Brooklyn (3) Queens (4) and Staten Island (5). BLOCK; LOT The combination of borough block and lot forms a unique key for property in New York City. Commonly called a BBL. BUILDING CLASS AT PRESENT and BUILDING CLASS AT TIME OF SALE The type of building at various points in time. See the glossary linked to below.  For further reference on individual fields see the Glossary of Terms. For the building classification codes see the Building Classifications Glossary. Note that because this is a financial transaction dataset there are some points that need to be kept in mind  Many sales occur with a nonsensically small dollar amount $0 most commonly. These sales are actually transfers of deeds between parties for example parents transferring ownership to their home to a child after moving out for retirement. This dataset uses the financial definition of a building/building unit for tax purposes. In case a single entity owns the building in question a sale covers the value of the entire building. In case a building is owned piecemeal by its residents (a condominium) a sale refers to a single apartment (or group of apartments) owned by some individual.  Acknowledgements This dataset is a concatenated and slightly cleaned-up version of the New York City Department of Finance's Rolling Sales dataset. Inspiration What can you discover about New York City real estate by looking at a year's worth of raw transaction records? Can you spot trends in the market or build a model that predicts sale value in the future?,:BOROUGH:NEIGHBORHOOD:BUILDING CLASS CATEGORY:TAX CLASS AT PRESENT:BLOCK:LOT:EASE-MENT:BUILDING CLASS AT PRESENT:ADDRESS:APARTMENT NUMBER:ZIP CODE:RESIDENTIAL UNITS:COMMERCIAL UNITS:TOTAL UNITS:LAND SQUARE FEET:GROSS SQUARE FEET:YEAR BUILT:TAX CLASS AT TIME OF SALE:BUILDING CLASS AT TIME OF SALE:SALE PRICE:SALE DATE:,numeric:numeric:string:string:numeric:numeric:numeric:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:dateTime:,real estate
Indian Hotels on Cleartrip , PromptCloud , www.kaggle.com/PromptCloudHQ/indian-hotels-on-cleartrip , Fri Sep 15 2017 12:48:53 GMT+0530 (IST) , This dataset contains Indian hotel (5000) present on Cleartrip.com ,27, hotels- internet- ,Context This is a pre-crawled dataset taken as subset of a bigger dataset (more than 42000 hotels) that was created by extracting data from Cleartrip.com a leading travel portal in India.  Content Analyses can be performed on the hotel description facilities and various ratings to name a few. Acknowledgements This dataset was created by PromptCloud's in-house web-crawling service.,address:area:city:cleartrip_seller_rating:country:crawl_date:hotel_description:hotel_facilities:hotel_star_rating:image_count:image_urls:landmark:latitude:locality:longitude:pageurl:property_id:property_name:property_type:province:qts:room_area:room_count:room_facilities:room_type:similar_hotel:sitename:state:tad_review_count:tad_review_rating:tad_stay_review_rating:tripadvisor_seller_rating:uniq_id:,string:string:string:numeric:string:dateTime:string:string:string:numeric:string:string:numeric:string:numeric:string:numeric:string:string:string:dateTime:string:numeric:string:string:string:string:string:numeric:numeric:string:string:string:,online information
Restaurants on TripAdvisor , PromptCloud , www.kaggle.com/PromptCloudHQ/restaurants-on-tripadvisor , Fri Sep 15 2017 14:43:56 GMT+0530 (IST) , Data on 18000 restaurants ,516, internet- ,Context This is a pre-crawled dataset taken as subset of a bigger dataset (more than 1492992 restaurants) that was created by extracting data from TripAdvisor.com. Content This dataset has following fields  Restaurant URL Name Address Phone City State Country Neighbourhood Email ID Menu Website Latitude Longitude About Restaurant Cuisine Good for(suitable) Price Currency Rating Ranking Deal(Promotion) Total Review Last Reviewed Recommended Dining Option Award  Acknowledgements This dataset was created by PromptCloud's in-house web-crawling service. Inspiration The country-wise analyses of cuisine rating ranking etc. can be performed.,Restaurant ID:Restaurant URL:Name:Address:Phone:City:State:Country:Neighbourhood:Email ID:Menu:Website:Latitude:Longitude:About Restaurant:Cuisine:Good for(suitable):Price:Currency:Rating:Ranking:Deal(Promotion):Total Review:Last Reviewed:Recommended:Dining Option:Award:Uniq Id:,numeric:string:string:string:numeric:string:string:string:string:string:string:string:numeric:numeric:string:string:string:dateTime:string:string:string:string:numeric:dateTime:string:string:string:string:,online information
Commercial Bank Failures 1934-Present , Federal Deposit Insurance Corporation , www.kaggle.com/fdic/bank-failures , Thu Mar 09 2017 21:35:31 GMT+0530 (IST) , Every bank failure in the United States since the Great Depression ,657, history- finance- ,Content This report lists each failure of a commercial bank savings association and savings bank since the establishment of the FDIC in 1933. Each record includes the institution name and FIN number institution and charter types location of headquarters (city and state) effective date insurance fund and certificate number failure transaction type total deposits and total assets last reported prior to failure (in thousands of dollars) and the estimated cost of resolution. Data on estimated losses are not available for FDIC insured failures prior to 1986 or for FSLIC insured failures from 1934-88. Acknowledgements The bank failure report was downloaded from the FDIC website. Inspiration What type of banking institution is the most likely to fail? How have bank failure rates changed over time? What commercial bank failure cost the federal government the most to resolve?,Financial Institution Number:Institution Name:Institution Type:Charter Type:Headquarters:Failure Date:Insurance Fund:Certificate Number:Transaction Type:Total Deposits:Total Assets:Estimated Loss (2015):,string:string:string:string:string:dateTime:string:string:string:numeric:numeric:string:,banking
Pokemon with stats , Alberto Barradas , www.kaggle.com/abcsds/pokemon , Mon Aug 29 2016 11:31:43 GMT+0530 (IST) , 721 Pokemon with stats and types ,13110, popular culture- games and toys- video games- ,This data set includes 721 Pokemon including their number name first and second type and basic stats HP Attack Defense Special Attack Special Defense and Speed. It has been of great use when teaching statistics to kids. With certain types you can also give a geeky introduction to machine learning. This are the raw attributes that are used for calculating how much damage an attack will do in the games. This dataset is about the pokemon games (NOT pokemon cards or Pokemon Go). The data as described by Myles O'Neill is  # ID for each pokemon Name Name of each pokemon Type 1 Each pokemon has a type this determines weakness/resistance to attacks Type 2 Some pokemon are dual type and have 2 Total sum of all stats that come after this a general guide to how strong a pokemon is HP hit points or health defines how much damage a pokemon can withstand before fainting Attack the base modifier for normal attacks (eg. Scratch Punch) Defense the base damage resistance against normal attacks SP Atk special attack the base modifier for special attacks (e.g. fire blast bubble beam) SP Def the base damage resistance against special attacks Speed determines which pokemon attacks first each round  The data for this table has been acquired from several different sites including   pokemon.com pokemondb bulbapeida  One question has been answered with this database The type of a pokemon cannot be inferred only by it's Attack and Deffence. It would be worthy to find which two variables can define the type of a pokemon if any. Two variables can be plotted in a 2D space and used as an example for machine learning. This could mean the creation of a visual example any geeky Machine Learning class would love.,#:Name:Type 1:Type 2:Total:HP:Attack:Defense:Sp. Atk:Sp. Def:Speed:Generation:Legendary:,numeric:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:boolean:,video games
Hurricane Harvey Tweets , Dan , www.kaggle.com/dan195/hurricaneharvey , Sat Sep 09 2017 23:10:57 GMT+0530 (IST) , Recent tweets on Hurricane Harvey ,269, weather- internet- ,"Context Tweets containing Hurricane Harvey from the morning of 8/25/2017. I hope to keep this updated if computer problems do not persist.  *8/30 Update This update includes the most recent tweets tagged ""Tropical Storm Harvey"" which spans from 8/20 to 8/30 as well as the properly merged version of dataset including Tweets from when Harvey before it was downgraded back to a tropical storm.  Inspiration What are the popular tweets? Can we find popular news stories from this? Can we identify people likely staying or leaving and is there a difference in sentiment between the two groups? Is it possible to predict popularity with respect to retweets likes and shares?",:,numeric:,social media
Daily News for Stock Market Prediction , Aaron7sun , www.kaggle.com/aaron7sun/stocknews , Thu Aug 25 2016 22:26:51 GMT+0530 (IST) , Using 8 years daily news headlines to predict stock market movement ,8410, news agencies- finance- ,"Actually I prepare this dataset for students on my Deep Learning and NLP course.  But I am also very happy to see kagglers play around with it. Have fun! Description There are two channels of data provided in this dataset  News data I crawled historical news headlines from Reddit WorldNews Channel (/r/worldnews). They are ranked by reddit users' votes and only the top 25 headlines are considered for a single date. (Range 2008-06-08 to 2016-07-01) Stock data Dow Jones Industrial Average (DJIA) is used to ""prove the concept"". (Range 2008-08-08 to 2016-07-01)  I provided three data files in .csv format  RedditNews.csv two columns The first column is the ""date"" and second column is the ""news headlines"". All news are ranked from top to bottom based on how hot they are. Hence there are 25 lines for each date. DJIA_table.csv  Downloaded directly from Yahoo Finance check out the web page for more info. Combined_News_DJIA.csv To make things easier for my students I provide this combined dataset with 27 columns. The first column is ""Date"" the second is ""Label"" and the following ones are news headlines ranging from ""Top1"" to ""Top25"".  ========================================= To my students I made this a binary classification task. Hence there are only two labels ""1"" when DJIA Adj Close value rose or stayed as the same; ""0"" when DJIA Adj Close value decreased. For task evaluation please use data from 2008-08-08 to 2014-12-31 as Training Set and Test Set is then the following two years data (from 2015-01-02 to 2016-07-01). This is roughly a 80%/20% split. And of course use AUC as the evaluation metric. ========================================= +++++++++++++++++++++++++++++++++++++++++ To all kagglers Please upvote this dataset if you like this idea for market prediction. If you think you coded an amazing trading algorithm friendly advice  do play safe with your own money ) +++++++++++++++++++++++++++++++++++++++++ Feel free to contact me if there is any question~  And remember me when you become a millionaire P",,,stock data
2016 Parties in New York , Evgeniy Vasilev , www.kaggle.com/somesnm/partynyc , Wed Aug 23 2017 22:05:39 GMT+0530 (IST) , 225k noise complaints to the police about ongoing parties in the city ,709, parties- cities- ,"Context This dataset contains all noise complaints calls that were received by the  city police with complaint type ""Loud music/Party"" in 2016. The data contains the time of the call time of the police response coordinates and part of the city. This data should help match taxi rides from ""New York City Taxi Trip Duration"" competition to the night rides of partygoers.  Content The New York city hotline receives non-urgent community concerns which are made public by the city through NYC Open Data portal. The full dataset contains a variety of complaints ranging from illegal parking to customer complaints. This dataset focuses on Noise complaints that were collected in 2016  and indicate ongoing party in a given neighborhood.  parties_in_nyc.csv Columns Created Date - time of the call  Closed Date - time when ticket was closed by police  Location Type - type of the location  Incident Zip - zip code of the location  City - name of the city (almost the same as the Borough field)  Borough - administrative division of the city  Latitude - latitude of the location  Longitude - longitude of the location   test_parties and train_parties Columns id - id of the ride  num_complaints - number of noise complaints about ongoing parties within ~500 meters and within 2 hours of pickup place and time  Acknowledgements https//opendata.cityofnewyork.us/ - NYC Open Data portal contains many other interesting datasets Photo by Yvette de Wit on Unsplash Inspiration After a fun night out in the city majority of people are too exhausted to travel by public transport so they catch a cab to their home. I hope this data will help the community to find the patterns in the data that will lead to better solutions.",Location Type:Incident Zip:City:Borough:Latitude:Longitude:num_calls:,string:numeric:string:string:numeric:numeric:numeric:,noise pollution
Demonetization in India Twitter Data , Amandeep Rathee , www.kaggle.com/arathee2/demonetization-in-india-twitter-data , Fri Apr 21 2017 23:05:02 GMT+0530 (IST) , Data extracted from Twitter regarding the recent currency demonetization ,2816, finance- twitter- human-computer interaction- internet- ,"Context The demonetization of ₹500 and ₹1000 banknotes was a step taken by the Government of India on 8 November 2016 ceasing the usage of all ₹500 and ₹1000 banknotes of the Mahatma Gandhi Series as a form of legal tender in India from 9 November 2016. The announcement was made by the Prime Minister of India Narendra Modi in an unscheduled live televised address to the nation at 2015 Indian Standard Time (IST) the same day. In the announcement Modi declared circulation of all ₹500 and ₹1000 banknotes of the Mahatma Gandhi Series as invalid and announced the issuance of new ₹500 and ₹2000 banknotes of the Mahatma Gandhi New Series in exchange for the old banknotes. Content The data contains 6000 most recent tweets on #demonetization. There are 6000 rows(one for each tweet) and 14 columns. Metadata  Text (Tweets) favorited favoriteCount replyToSN created truncated replyToSID id replyToUID statusSource screenName retweetCount isRetweet retweeted  Acknowledgement The data was collected using the ""twitteR"" package in R using the twitter API. Past Research I have performed my own analysis on the data. I only did a sentiment analysis and formed a word cloud. Click here to see the analysis on GitHub Inspiration  What percentage of tweets are negative positive or neutral ? What are the most famous/re-tweeted tweets ? ",:X:text:favorited:favoriteCount:replyToSN:created:truncated:replyToSID:id:replyToUID:statusSource:screenName:retweetCount:isRetweet:retweeted:,numeric:numeric:string:boolean:numeric:string:dateTime:boolean:string:numeric:numeric:string:string:numeric:boolean:boolean:,social media
Workers Browser Activity in CrowdFlower Tasks , Human Computation , www.kaggle.com/humancomp/worker-activity-crowdflower , Fri Oct 20 2017 18:41:59 GMT+0530 (IST) , In-page behaviour of crowdworkers performing tasks on CrowdFlower ,46, web sites- data analysis- ,"Context Data Scientists often use crowdsourcing platforms such as Amazon Mechanical Turk or CrowdFlower to collect labels for their data. Controlling high quality and timeless execution of tasks is an important part of such collection process. It is not possible (or not efficient) to manually check every worker assignment. There is an intuition that there quality could be predicted based on workers task browser behaviour (e.g. key presses scrolling mouse clicks tab switching). In this dataset there are assignment results for 3 different crowdsourcing tasks launched on CrowdFlower along with associated workers behaviour. Content We collected data running 3 tasks   Image labelling   Receipt Transcription   Business Search.   Tasks are described in tasks.csv. Results for corresponding tasks are given in files results_{task_id}.csv. Workers's activity could be found in the following files  activity_keyboard.csv - timestamps of keyboard keys pressed activity_mouse.csv - timestamps of mouse clicks with associated HTML elements activity_tab.csv - timestamps of event task browser tab changes (opened active hidden closed) activity_page.csv - a summary of events happened in the task page every 2 seconds (boolean keyboard activity boolean mouse movement activity boolean scrolling activity the position of the screen boolean if text was selected)  Result files have a similar structure to the original one given by CrowdFlower  _unit_id A unique ID number created by the system for each row _created_at The time the contributor submitted the judgement  _golden This will be ""true"" if this is a test question otherwise it is ""false"" _id A unique ID number generated for this specific judgment _missed This will be ""true"" if the row is an incorrect judgment on a test question. _started_at The time at which the contributor started working on the judgement _tainted This will be ""true"" if the contributor has been flagged for falling below the required accuracy. This judgment will not be used in the aggregation. _channel The work channel that the contributor accessed the job through _trust The contributor's accuracy. Learn more about trust here _worker_id A unique ID number assigned to the contributor (in the current dataset MD5 value is given) _country The country the contributor is from _region A region code for the area the contributor is from _city The city the contributor is from _ip The IP address for the contributor (in the current dataset MD5 value is given) {{field}} There will be a column for each field in the job with a header equal to the field's name. {{field}}_gold The correct answer for the test question  Acknowledgements We thank crowd workers who accomplished our not always exciting tasks on CrowdFlower. ",task_id:unit_id:assignment_id:session_id:dt_start:key:,numeric:numeric:string:numeric:numeric:numeric:,Online forums 
Adult Census Income , UCI Machine Learning , www.kaggle.com/uciml/adult-census-income , Sat Oct 08 2016 05:12:59 GMT+0530 (IST) , Predict whether income exceeds $50K/yr based on census data ,4049, employment- demographics- ,"This data was extracted from the 1994 Census bureau database by Ronny Kohavi and Barry Becker (Data Mining and Visualization Silicon Graphics). A set of reasonably clean records was extracted using the following conditions ((AAGE>16) && (AGI>100) && (AFNLWGT>1) && (HRSWK>0)). The prediction task is to determine whether a person makes over $50K a year. Description of fnlwgt (final weight) The weights on the Current Population Survey (CPS) files are controlled to independent estimates of the civilian noninstitutional population of the US.  These are prepared monthly for us by Population Division here at the Census Bureau. We use 3 sets of controls. These are   A single cell estimate of the population 16+ for each state. Controls for Hispanic Origin by age and sex. Controls by Race age and sex.  We use all three sets of controls in our weighting program and ""rake"" through them 6 times so that by the end we come back to all the controls we used. The term estimate refers to population totals derived from CPS by creating ""weighted tallies"" of any specified socio-economic characteristics of the population. People with similar demographic characteristics should have similar weights. There is one important caveat to remember about this statement. That is that since the CPS sample is actually a collection of 51 state samples each with its own probability of selection the statement only applies within state. Relevant papers Ron Kohavi ""Scaling Up the Accuracy of Naive-Bayes Classifiers a Decision-Tree Hybrid"" Proceedings of the Second International Conference on Knowledge Discovery and Data Mining 1996. (PDF)",,,demography
Fatal Police Shootings 2015-Present , The Washington Post , www.kaggle.com/washingtonpost/police-shootings , Sat Mar 11 2017 01:30:25 GMT+0530 (IST) , Civilians shot and killed by on-duty police officers in United States ,1505, crime- demographics- ,The Washington Post is compiling a database of every fatal shooting in the United States by a police officer in the line of duty since January 1 2015. In 2015 The Post began tracking more than a dozen details about each killing — including the race of the deceased the circumstances of the shooting whether the person was armed and whether the victim was experiencing a mental-health crisis — by culling local news reports law enforcement websites and social media and by monitoring independent databases such as Killed by Police and Fatal Encounters. The Post is documenting only those shootings in which a police officer in the line of duty shot and killed a civilian — the circumstances that most closely parallel the 2014 killing of Michael Brown in Ferguson Missouri which began the protest movement culminating in Black Lives Matter and an increased focus on police accountability nationwide. The Post is not tracking deaths of people in police custody fatal shootings by off-duty officers or non-shooting deaths. The FBI and the Centers for Disease Control and Prevention log fatal shootings by police but officials acknowledge that their data is incomplete. In 2015 The Post documented more than two times more fatal shootings by police than had been recorded by the FBI. The Post’s database is updated regularly as fatal shootings are reported and as facts emerge about individual cases. The Post is seeking assistance in making the database as comprehensive as possible. To provide information about fatal police shootings send us an email at policeshootingsfeedback@washpost.com. CREDITSResearch and Reporting Julie Tate Jennifer Jenkins and Steven RichProduction and Presentation John Muyskens Kennedy Elliott and Ted Mellnik,id:,numeric:,crime
Fashion MNIST , Zalando Research , www.kaggle.com/zalando-research/fashionmnist , Wed Aug 30 2017 23:21:06 GMT+0530 (IST) , An MNIST-like dataset of 70000 28x28 labeled fashion images ,1107, clothing- data- ,"Context Fashion-MNIST is a dataset of Zalando's article images—consisting of a training set of 60000 examples and a test set of 10000 examples. Each example is a 28x28 grayscale image associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits. The original MNIST dataset contains a lot of handwritten digits. Members of the AI/ML/Data Science community love this dataset and use it as a benchmark to validate their algorithms. In fact MNIST is often the first dataset researchers try. ""If it doesn't work on MNIST it won't work at all"" they said. ""Well if it does work on MNIST it may still fail on others."" Zalando seeks to replace the original MNIST dataset Content Each image is 28 pixels in height and 28 pixels in width for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it indicating the lightness or darkness of that pixel with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above) and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.  To locate a pixel on the image suppose that we have decomposed x as x = i * 28 + j where i and j are integers between 0 and 27. The pixel is located on row i and column j of a 28 x 28 matrix.  For example pixel31 indicates the pixel that is in the fourth column from the left and the second row from the top as in the ascii-diagram below.   Labels Each training and test example is assigned to one of the following labels  0 T-shirt/top 1 Trouser 2 Pullover 3 Dress 4 Coat 5 Sandal 6 Shirt 7 Sneaker 8 Bag 9 Ankle boot   TL;DR  Each row is a separate image   Column 1 is the class label.  Remaining columns are pixel numbers (784 total).  Each value is the darkness of the pixel (1 to 255)  Acknowledgements  Original dataset was downloaded from https//github.com/zalandoresearch/fashion-mnist Dataset was converted to CSV with this script https//pjreddie.com/projects/mnist-in-csv/  License The MIT License (MIT) Copyright © [2017] Zalando SE https//tech.zalando.com Permission is hereby granted free of charge to any person obtaining a copy of this software and associated documentation files (the “Software”) to deal in the Software without restriction including without limitation the rights to use copy modify merge publish distribute sublicense and/or sell copies of the Software and to permit persons to whom the Software is furnished to do so subject to the following conditions The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS” WITHOUT WARRANTY OF ANY KIND EXPRESS OR IMPLIED INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM DAMAGES OR OTHER LIABILITY WHETHER IN AN ACTION OF CONTRACT TORT OR OTHERWISE ARISING FROM OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",label:pixel1:pixel2:pixel3:pixel4:pixel5:pixel6:pixel7:pixel8:pixel9:pixel10:pixel11:pixel12:pixel13:pixel14:pixel15:pixel16:pixel17:pixel18:pixel19:pixel20:pixel21:pixel22:pixel23:pixel24:pixel25:pixel26:pixel27:pixel28:pixel29:pixel30:pixel31:pixel32:pixel33:pixel34:pixel35:pixel36:pixel37:pixel38:pixel39:pixel40:pixel41:pixel42:pixel43:pixel44:pixel45:pixel46:pixel47:pixel48:pixel49:pixel50:pixel51:pixel52:pixel53:pixel54:pixel55:pixel56:pixel57:pixel58:pixel59:pixel60:pixel61:pixel62:pixel63:pixel64:pixel65:pixel66:pixel67:pixel68:pixel69:pixel70:pixel71:pixel72:pixel73:pixel74:pixel75:pixel76:pixel77:pixel78:pixel79:pixel80:pixel81:pixel82:pixel83:pixel84:pixel85:pixel86:pixel87:pixel88:pixel89:pixel90:pixel91:pixel92:pixel93:pixel94:pixel95:pixel96:pixel97:pixel98:pixel99:pixel100:pixel101:pixel102:pixel103:pixel104:pixel105:pixel106:pixel107:pixel108:pixel109:pixel110:pixel111:pixel112:pixel113:pixel114:pixel115:pixel116:pixel117:pixel118:pixel119:pixel120:pixel121:pixel122:pixel123:pixel124:pixel125:pixel126:pixel127:pixel128:pixel129:pixel130:pixel131:pixel132:pixel133:pixel134:pixel135:pixel136:pixel137:pixel138:pixel139:pixel140:pixel141:pixel142:pixel143:pixel144:pixel145:pixel146:pixel147:pixel148:pixel149:pixel150:pixel151:pixel152:pixel153:pixel154:pixel155:pixel156:pixel157:pixel158:pixel159:pixel160:pixel161:pixel162:pixel163:pixel164:pixel165:pixel166:pixel167:pixel168:pixel169:pixel170:pixel171:pixel172:pixel173:pixel174:pixel175:pixel176:pixel177:pixel178:pixel179:pixel180:pixel181:pixel182:pixel183:pixel184:pixel185:pixel186:pixel187:pixel188:pixel189:pixel190:pixel191:pixel192:pixel193:pixel194:pixel195:pixel196:pixel197:pixel198:pixel199:pixel200:pixel201:pixel202:pixel203:pixel204:pixel205:pixel206:pixel207:pixel208:pixel209:pixel210:pixel211:pixel212:pixel213:pixel214:pixel215:pixel216:pixel217:pixel218:pixel219:pixel220:pixel221:pixel222:pixel223:pixel224:pixel225:pixel226:pixel227:pixel228:pixel229:pixel230:pixel231:pixel232:pixel233:pixel234:pixel235:pixel236:pixel237:pixel238:pixel239:pixel240:pixel241:pixel242:pixel243:pixel244:pixel245:pixel246:pixel247:pixel248:pixel249:pixel250:pixel251:pixel252:pixel253:pixel254:pixel255:pixel256:pixel257:pixel258:pixel259:pixel260:pixel261:pixel262:pixel263:pixel264:pixel265:pixel266:pixel267:pixel268:pixel269:pixel270:pixel271:pixel272:pixel273:pixel274:pixel275:pixel276:pixel277:pixel278:pixel279:pixel280:pixel281:pixel282:pixel283:pixel284:pixel285:pixel286:pixel287:pixel288:pixel289:pixel290:pixel291:pixel292:pixel293:pixel294:pixel295:pixel296:pixel297:pixel298:pixel299:pixel300:pixel301:pixel302:pixel303:pixel304:pixel305:pixel306:pixel307:pixel308:pixel309:pixel310:pixel311:pixel312:pixel313:pixel314:pixel315:pixel316:pixel317:pixel318:pixel319:pixel320:pixel321:pixel322:pixel323:pixel324:pixel325:pixel326:pixel327:pixel328:pixel329:pixel330:pixel331:pixel332:pixel333:pixel334:pixel335:pixel336:pixel337:pixel338:pixel339:pixel340:pixel341:pixel342:pixel343:pixel344:pixel345:pixel346:pixel347:pixel348:pixel349:pixel350:pixel351:pixel352:pixel353:pixel354:pixel355:pixel356:pixel357:pixel358:pixel359:pixel360:pixel361:pixel362:pixel363:pixel364:pixel365:pixel366:pixel367:pixel368:pixel369:pixel370:pixel371:pixel372:pixel373:pixel374:pixel375:pixel376:pixel377:pixel378:pixel379:pixel380:pixel381:pixel382:pixel383:pixel384:pixel385:pixel386:pixel387:pixel388:pixel389:pixel390:pixel391:pixel392:pixel393:pixel394:pixel395:pixel396:pixel397:pixel398:pixel399:pixel400:pixel401:pixel402:pixel403:pixel404:pixel405:pixel406:pixel407:pixel408:pixel409:pixel410:pixel411:pixel412:pixel413:pixel414:pixel415:pixel416:pixel417:pixel418:pixel419:pixel420:pixel421:pixel422:pixel423:pixel424:pixel425:pixel426:pixel427:pixel428:pixel429:pixel430:pixel431:pixel432:pixel433:pixel434:pixel435:pixel436:pixel437:pixel438:pixel439:pixel440:pixel441:pixel442:pixel443:pixel444:pixel445:pixel446:pixel447:pixel448:pixel449:pixel450:pixel451:pixel452:pixel453:pixel454:pixel455:pixel456:pixel457:pixel458:pixel459:pixel460:pixel461:pixel462:pixel463:pixel464:pixel465:pixel466:pixel467:pixel468:pixel469:pixel470:pixel471:pixel472:pixel473:pixel474:pixel475:pixel476:pixel477:pixel478:pixel479:pixel480:pixel481:pixel482:pixel483:pixel484:pixel485:pixel486:pixel487:pixel488:pixel489:pixel490:pixel491:pixel492:pixel493:pixel494:pixel495:pixel496:pixel497:pixel498:pixel499:pixel500:pixel501:pixel502:pixel503:pixel504:pixel505:pixel506:pixel507:pixel508:pixel509:pixel510:pixel511:pixel512:pixel513:pixel514:pixel515:pixel516:pixel517:pixel518:pixel519:pixel520:pixel521:pixel522:pixel523:pixel524:pixel525:pixel526:pixel527:pixel528:pixel529:pixel530:pixel531:pixel532:pixel533:pixel534:pixel535:pixel536:pixel537:pixel538:pixel539:pixel540:pixel541:pixel542:pixel543:pixel544:pixel545:pixel546:pixel547:pixel548:pixel549:pixel550:pixel551:pixel552:pixel553:pixel554:pixel555:pixel556:pixel557:pixel558:pixel559:pixel560:pixel561:pixel562:pixel563:pixel564:pixel565:pixel566:pixel567:pixel568:pixel569:pixel570:pixel571:pixel572:pixel573:pixel574:pixel575:pixel576:pixel577:pixel578:pixel579:pixel580:pixel581:pixel582:pixel583:pixel584:pixel585:pixel586:pixel587:pixel588:pixel589:pixel590:pixel591:pixel592:pixel593:pixel594:pixel595:pixel596:pixel597:pixel598:pixel599:pixel600:pixel601:pixel602:pixel603:pixel604:pixel605:pixel606:pixel607:pixel608:pixel609:pixel610:pixel611:pixel612:pixel613:pixel614:pixel615:pixel616:pixel617:pixel618:pixel619:pixel620:pixel621:pixel622:pixel623:pixel624:pixel625:pixel626:pixel627:pixel628:pixel629:pixel630:pixel631:pixel632:pixel633:pixel634:pixel635:pixel636:pixel637:pixel638:pixel639:pixel640:pixel641:pixel642:pixel643:pixel644:pixel645:pixel646:pixel647:pixel648:pixel649:pixel650:pixel651:pixel652:pixel653:pixel654:pixel655:pixel656:pixel657:pixel658:pixel659:pixel660:pixel661:pixel662:pixel663:pixel664:pixel665:pixel666:pixel667:pixel668:pixel669:pixel670:pixel671:pixel672:pixel673:pixel674:pixel675:pixel676:pixel677:pixel678:pixel679:pixel680:pixel681:pixel682:pixel683:pixel684:pixel685:pixel686:pixel687:pixel688:pixel689:pixel690:pixel691:pixel692:pixel693:pixel694:pixel695:pixel696:pixel697:pixel698:pixel699:pixel700:pixel701:pixel702:pixel703:pixel704:pixel705:pixel706:pixel707:pixel708:pixel709:pixel710:pixel711:pixel712:pixel713:pixel714:pixel715:pixel716:pixel717:pixel718:pixel719:pixel720:pixel721:pixel722:pixel723:pixel724:pixel725:pixel726:pixel727:pixel728:pixel729:pixel730:pixel731:pixel732:pixel733:pixel734:pixel735:pixel736:pixel737:pixel738:pixel739:pixel740:pixel741:pixel742:pixel743:pixel744:pixel745:pixel746:pixel747:pixel748:pixel749:pixel750:pixel751:pixel752:pixel753:pixel754:pixel755:pixel756:pixel757:pixel758:pixel759:pixel760:pixel761:pixel762:pixel763:pixel764:pixel765:pixel766:pixel767:pixel768:pixel769:pixel770:pixel771:pixel772:pixel773:pixel774:pixel775:pixel776:pixel777:pixel778:pixel779:pixel780:pixel781:pixel782:pixel783:pixel784:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,photos and images 
Exercise Pattern Prediction , Athni , www.kaggle.com/athniv/exercisepatternpredict , Thu Apr 06 2017 04:14:00 GMT+0530 (IST) , What does your exercise pattern fall into? ,251, exercise- ,Context Using devices such as Jawbone Up Nike FuelBand and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement – a group of enthusiasts who take measurements about themselves regularly to improve their health to find patterns in their behavior or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do but they rarely quantify how well they do it. Our goal here will be to use data from accelerometers on the belt forearm arm and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here http//groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). Content The dataset contains about 160 predictors (most of which are not required) and classifiers column is 'classe' and the exercise pattern is classified into 5 types- A B C D E Acknowledgements Velloso E.; Bulling A.; Gellersen H.; Ugulino W.; Fuks H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart Germany ACM SIGCHI 2013. Read more http//groupware.les.inf.puc-rio.br/har#wle_paper_section#ixzz4dPxKFugX Inspiration What better ways of cleaning up the data? Which model will fit it best and how to go about handling it in R,:user_name:raw_timestamp_part_1:raw_timestamp_part_2:cvtd_timestamp:new_window:num_window:roll_belt:pitch_belt:yaw_belt:total_accel_belt:kurtosis_roll_belt:kurtosis_picth_belt:kurtosis_yaw_belt:skewness_roll_belt:skewness_roll_belt.1:skewness_yaw_belt:max_roll_belt:max_picth_belt:max_yaw_belt:min_roll_belt:min_pitch_belt:min_yaw_belt:amplitude_roll_belt:amplitude_pitch_belt:amplitude_yaw_belt:var_total_accel_belt:avg_roll_belt:stddev_roll_belt:var_roll_belt:avg_pitch_belt:stddev_pitch_belt:var_pitch_belt:avg_yaw_belt:stddev_yaw_belt:var_yaw_belt:gyros_belt_x:gyros_belt_y:gyros_belt_z:accel_belt_x:accel_belt_y:accel_belt_z:magnet_belt_x:magnet_belt_y:magnet_belt_z:roll_arm:pitch_arm:yaw_arm:total_accel_arm:var_accel_arm:avg_roll_arm:stddev_roll_arm:var_roll_arm:avg_pitch_arm:stddev_pitch_arm:var_pitch_arm:avg_yaw_arm:stddev_yaw_arm:var_yaw_arm:gyros_arm_x:gyros_arm_y:gyros_arm_z:accel_arm_x:accel_arm_y:accel_arm_z:magnet_arm_x:magnet_arm_y:magnet_arm_z:kurtosis_roll_arm:kurtosis_picth_arm:kurtosis_yaw_arm:skewness_roll_arm:skewness_pitch_arm:skewness_yaw_arm:max_roll_arm:max_picth_arm:max_yaw_arm:min_roll_arm:min_pitch_arm:min_yaw_arm:amplitude_roll_arm:amplitude_pitch_arm:amplitude_yaw_arm:roll_dumbbell:pitch_dumbbell:yaw_dumbbell:kurtosis_roll_dumbbell:kurtosis_picth_dumbbell:kurtosis_yaw_dumbbell:skewness_roll_dumbbell:skewness_pitch_dumbbell:skewness_yaw_dumbbell:max_roll_dumbbell:max_picth_dumbbell:max_yaw_dumbbell:min_roll_dumbbell:min_pitch_dumbbell:min_yaw_dumbbell:amplitude_roll_dumbbell:amplitude_pitch_dumbbell:amplitude_yaw_dumbbell:total_accel_dumbbell:var_accel_dumbbell:avg_roll_dumbbell:stddev_roll_dumbbell:var_roll_dumbbell:avg_pitch_dumbbell:stddev_pitch_dumbbell:var_pitch_dumbbell:avg_yaw_dumbbell:stddev_yaw_dumbbell:var_yaw_dumbbell:gyros_dumbbell_x:gyros_dumbbell_y:gyros_dumbbell_z:accel_dumbbell_x:accel_dumbbell_y:accel_dumbbell_z:magnet_dumbbell_x:magnet_dumbbell_y:magnet_dumbbell_z:roll_forearm:pitch_forearm:yaw_forearm:kurtosis_roll_forearm:kurtosis_picth_forearm:kurtosis_yaw_forearm:skewness_roll_forearm:skewness_pitch_forearm:skewness_yaw_forearm:max_roll_forearm:max_picth_forearm:max_yaw_forearm:min_roll_forearm:min_pitch_forearm:min_yaw_forearm:amplitude_roll_forearm:amplitude_pitch_forearm:amplitude_yaw_forearm:total_accel_forearm:var_accel_forearm:avg_roll_forearm:stddev_roll_forearm:var_roll_forearm:avg_pitch_forearm:stddev_pitch_forearm:var_pitch_forearm:avg_yaw_forearm:stddev_yaw_forearm:var_yaw_forearm:gyros_forearm_x:gyros_forearm_y:gyros_forearm_z:accel_forearm_x:accel_forearm_y:accel_forearm_z:magnet_forearm_x:magnet_forearm_y:magnet_forearm_z:problem_id:,numeric:string:numeric:numeric:dateTime:string:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,fitness and personal well being
Residential Energy Consumption Survey , LiamLarsen , www.kaggle.com/kingburrito666/residential-energy-consumption-survey , Tue Mar 28 2017 23:08:45 GMT+0530 (IST) , The Residential Energy Consumption Survey is a national energy survey ,354, energy- ,"Context This 2009 version represents the 13th iteration of the RECS program. First conducted in 1978 the Residential Energy Consumption Survey is a national sample survey that collects energy-related data for housing units occupied as a primary residence and the households that live in them. Data were collected from 12083 households selected at random using a complex multistage area-probability sample design. The sample represents 113.6 million U.S. households the Census Bureau's statistical estimate for all occupied housing units in 2009 derived from their American Community Survey (ACS) The csv data file is accompanied by a corresponding ""Layout file"" which contains descriptive labels and formats for each data variable. The ""Variable and response codebook"" file contains descriptive labels for variables descriptions of the response codes and indicators for the variables used in each end-use model.",Variable Name:Variable Label:Variable Order in File:Variable Type:Length:,string:string:numeric:string:numeric:,energy consumption
Consumer Business Complaints in Brazil , Luiz Gerosa , www.kaggle.com/gerosa/procon , Thu Oct 12 2017 02:52:17 GMT+0530 (IST) , Consumer complaints about issues with business in Brazil ,83, brazil- business- ,Context When Brazilian consumers need to resolve a dispute with business the first step is to go to a local Procon (Consumer Protection Agency) and file a complaint. The Procon assists the consumer and intermediates the resolution with the company. Content This dataset contains information about complaints filed in Procons between 2012 and 2016.  This data was download from official Brazilian government open data website,AnoCalendario:DataArquivamento:DataAbertura:CodigoRegiao:Regiao:UF:strRazaoSocial:strNomeFantasia:Tipo:NumeroCNPJ:RadicalCNPJ:RazaoSocialRFB:NomeFantasiaRFB:CNAEPrincipal:DescCNAEPrincipal:Atendida:CodigoAssunto:DescricaoAssunto:CodigoProblema:DescricaoProblema:SexoConsumidor:FaixaEtariaConsumidor:CEPConsumidor:,numeric:dateTime:dateTime:numeric:string:string:string:string:numeric:numeric:numeric:string:string:numeric:string:string:numeric:string:numeric:string:string:string:numeric:,trade and business
Mental Health in Tech Survey , Open Sourcing Mental Illness , www.kaggle.com/osmi/mental-health-in-tech-survey , Thu Nov 03 2016 22:58:47 GMT+0530 (IST) , Survey on Mental Health in the Tech Workplace in 2014 ,3384, mental health- human medicine- employment- information technology- ,Dataset Information This dataset is from a 2014 survey that measures attitudes towards mental health and frequency of mental health disorders in the tech workplace. You are also encouraged to analyze data from the ongoing 2016 survey found here. Content This dataset contains the following data  Timestamp Age Gender Country state If you live in the United States which state or territory do you live in? self_employed Are you self-employed? family_history Do you have a family history of mental illness? treatment Have you sought treatment for a mental health condition? work_interfere If you have a mental health condition do you feel that it interferes with your work? no_employees How many employees does your company or organization have? remote_work Do you work remotely (outside of an office) at least 50% of the time? tech_company Is your employer primarily a tech company/organization? benefits Does your employer provide mental health benefits? care_options Do you know the options for mental health care your employer provides? wellness_program Has your employer ever discussed mental health as part of an employee wellness program? seek_help Does your employer provide resources to learn more about mental health issues and how to seek help? anonymity Is your anonymity protected if you choose to take advantage of mental health or substance abuse treatment resources? leave How easy is it for you to take medical leave for a mental health condition? mental_health_consequence Do you think that discussing a mental health issue with your employer would have negative consequences? phys_health_consequence Do you think that discussing a physical health issue with your employer would have negative consequences? coworkers Would you be willing to discuss a mental health issue with your coworkers? supervisor Would you be willing to discuss a mental health issue with your direct supervisor(s)? mental_health_interview Would you bring up a mental health issue with a potential employer in an interview? phys_health_interview Would you bring up a physical health issue with a potential employer in an interview? mental_vs_physical Do you feel that your employer takes mental health as seriously as physical health? obs_consequence Have you heard of or observed negative consequences for coworkers with mental health conditions in your workplace? comments Any additional notes or comments  Inspiration Some questions worth exploring  How does the frequency of mental health illness and attitudes towards mental health vary by geographic location? What are the strongest predictors of mental health illness or certain attitudes towards mental health in the workplace?  Acknowledgements The original dataset is from Open Sourcing Mental Illness and can be downloaded here.,Timestamp:Age:Gender:Country:state:self_employed:family_history:treatment:work_interfere:no_employees:remote_work:tech_company:benefits:care_options:wellness_program:seek_help:anonymity:leave:mental_health_consequence:phys_health_consequence:coworkers:supervisor:mental_health_interview:phys_health_interview:mental_vs_physical:obs_consequence:comments:,numeric:numeric:string:string:string:string:string:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:,mental health
Global Terrorism Database , START Consortium , www.kaggle.com/START-UMD/gtd , Tue Jul 18 2017 23:00:13 GMT+0530 (IST) , More than 170000 terrorist attacks worldwide 1970-2016 ,13412, crime- terrorism- international relations- ,"Context Information on more than 170000 Terrorist Attacks The Global Terrorism Database (GTD) is an open-source database including information on terrorist attacks around the world from 1970 through 2016 (with annual updates planned for the future). The GTD includes systematic data on domestic as well as international terrorist incidents that have occurred during this time period and now includes more than 170000 cases. The database is maintained by researchers at the National Consortium for the Study of Terrorism and Responses to Terrorism (START) headquartered at the University of Maryland. More Information Content Geography Worldwide Time period 1970-2016 except 1993 (2017 in progress publication expected June 2018) Unit of analysis Attack Variables >100 variables on location tactics perpetrators targets and outcomes Sources Unclassified media articles (Note Please interpret changes over time with caution. Global patterns are driven by diverse trends in particular regions and data collection is influenced by fluctuations in access to media coverage over both time and place.) Definition of terrorism ""The threatened or actual use of illegal force and violence by a non-state actor to attain a political economic religious or social goal through fear coercion or intimidation."" See the GTD Codebook for important details on data collection methodology definitions and coding schema. Acknowledgements The Global Terrorism Database is funded through START by the US Department of State (Contract Number SAQMMA12M1292) and the US Department of Homeland Security Science and Technology Directorate’s Office of University Programs (Award Number 2012-ST-061-CS0001 CSTAB 3.1). The coding decisions and classifications contained in the database are determined independently by START researchers and should not be interpreted as necessarily representing the official views or policies of the United States Government. GTD Team Publications The GTD has been leveraged extensively in scholarly publications reports and media articles. Putting Terrorism in Context Lessons from the Global Terrorism Database by GTD principal investigators LaFree Dugan and Miller investigates patterns of terrorism and provides perspective on the challenges of data collection and analysis. The GTD's data collection manager Michael Jensen discusses important Benefits and Drawbacks of Methodological Advancements in Data Collection and Coding. Terms of Use Use of the data signifies your agreement to the following terms and conditions. Definitions Within this section ""GTD"" will refer to the Global Terrorism Database produced by the National Consortium for the Study of Terrorism and Responses to Terrorism. This includes the data and codebook any auxiliary materials present and the World Wide Web interface by which the data are presented. ""START"" will refer to the National Consortium for the Study of Terrorism and Responses to Terrorism a United States Department of Homeland Security Center of Excellence based at the University of Maryland. ""USER"" denotes the individual or set of individuals who access the GTD i.e. the data codebook any auxiliary materials and the World Wide Web interface by which the data are presented. ""GTD representatives"" denotes any senior management staff of START and any employee or representative of said organization whom senior management staff designate to represent START in dealings with the USER. Usage Rights Pursuant to this agreement START grants the USER the non-exclusive non-guaranteed right to search browse and view all contents of the GTD World Wide Web interface. Authorship All contents of the GTD were assembled by representatives of START and do not purport to reflect the official position or data collections of the Department of Homeland Security or any other agency of the United States government. Acknowledgement All information sourced from the GTD should be acknowledged by the USER and cited as follows ""National Consortium for the Study of Terrorism and Responses to Terrorism (START). (2017). Global Terrorism Database [Data file]. Retrieved from https//www.kaggle.com/START-UMD/gtd"" Unauthorized Publication of the Data No part of the GTD may be republished on any website or accessible for public download in any format without the express permission of a GTD staff member. In addition no part of the GTD may be distributed for any commercial purpose nor with the intent that the data be used in any commercial enterprise without the express permission of a GTD staff member. START reserves the right to withhold this permission. Penalties Penalties for failure to comply with the terms of this agreement may result in loss of access to the GTD and the forfeiture of user privileges in addition to any other appropriate legal remedies. Limitation of Liability Although every reasonable effort has been made to check sources and verify facts START cannot guarantee that accounts reported in the open literature are complete and accurate. START shall not be held liable for any loss or damage caused by errors or omissions or resulting from any use misuse or alteration of GTD data by the USER. The USER should not infer any additional actions or results beyond what is presented in a GTD entry and specifically the USER should not infer an individual associated with a particular incident was tried and convicted of terrorism or any other criminal offense. If new documentation about an event becomes available an entry may be modified as necessary and appropriate. Termination of Rights The GTD developers reserve the right to remove access to the GTD website from any particular IP address or set of IP addresses or to remove the database entirely from public access at their discretion. In such an event all USER rights granted in this document are terminated. Training START has released the first in a series of training modules designed to equip GTD users with the knowledge and tools to best leverage the database. This training module provides a general overview of the GTD including the data collection process uses of the GTD and patterns of global terrorism. Participants will learn basic data handling and how to generate summary statistics from the GTD using PivotTables in Microsoft Excel. Questions? Find answers to Frequently Asked Questions. Contact the GTD staff at gtd@start.umd.edu.",eventid:iyear:imonth:iday:approxdate:extended:resolution:country:country_txt:region:region_txt:provstate:city:latitude:longitude:specificity:vicinity:location:summary:crit1:crit2:crit3:doubtterr:alternative:alternative_txt:multiple:success:suicide:attacktype1:attacktype1_txt:attacktype2:attacktype2_txt:attacktype3:attacktype3_txt:targtype1:targtype1_txt:targsubtype1:targsubtype1_txt:corp1:target1:natlty1:natlty1_txt:targtype2:targtype2_txt:targsubtype2:targsubtype2_txt:corp2:target2:natlty2:natlty2_txt:targtype3:targtype3_txt:targsubtype3:targsubtype3_txt:corp3:target3:natlty3:natlty3_txt:gname:gsubname:gname2:gsubname2:gname3:gsubname3:motive:guncertain1:guncertain2:guncertain3:individual:nperps:nperpcap:claimed:claimmode:claimmode_txt:claim2:claimmode2:claimmode2_txt:claim3:claimmode3:claimmode3_txt:compclaim:weaptype1:weaptype1_txt:weapsubtype1:weapsubtype1_txt:weaptype2:weaptype2_txt:weapsubtype2:weapsubtype2_txt:weaptype3:weaptype3_txt:weapsubtype3:weapsubtype3_txt:weaptype4:weaptype4_txt:weapsubtype4:weapsubtype4_txt:weapdetail:nkill:nkillus:nkillter:nwound:nwoundus:nwoundte:property:propextent:propextent_txt:propvalue:propcomment:ishostkid:nhostkid:nhostkidus:nhours:ndays:divert:kidhijcountry:ransom:ransomamt:ransomamtus:ransompaid:ransompaidus:ransomnote:hostkidoutcome:hostkidoutcome_txt:nreleased:addnotes:scite1:scite2:scite3:dbsource:INT_LOG:INT_IDEO:INT_MISC:INT_ANY:related:,numeric:numeric:numeric:numeric:string:numeric:string:numeric:string:numeric:string:string:string:numeric:numeric:numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:string:string:string:string:numeric:string:numeric:string:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:string:string:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:numeric:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:string:numeric:numeric:numeric:string:string:string:string:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:string:,crime
Bug Triaging , Monika Munjal , www.kaggle.com/monika11/bug-triagingbug-assignment , Wed Sep 28 2016 13:10:09 GMT+0530 (IST) , Bug triaging...contains details bug prioritization or assign defect analysis. ,295, programming- ,Bug triage.,,,programming
Young People Survey , Miroslav Sabo , www.kaggle.com/miroslavsabo/young-people-survey , Tue Dec 06 2016 08:40:30 GMT+0530 (IST) , Explore the preferences interests habits opinions and fears of young people ,13728, social groups- psychometrics- demographics- psychology- sociology- ,Introduction In 2013 students of the Statistics class at FSEV UK were asked to invite their friends to participate in this survey.  The data file (responses.csv) consists of 1010 rows and 150 columns (139 integer and 11 categorical). For convenience the original variable names were shortened in the data file. See the columns.csv file if you want to match the data with the original names. The data contain missing values. The survey was presented to participants in both electronic and written form. The original questionnaire was in Slovak language and was later translated into English. All participants were of Slovakian nationality aged between 15-30.  The variables can be split into the following groups  Music preferences (19 items) Movie preferences (12 items) Hobbies & interests (32 items) Phobias (10 items) Health habits (3 items) Personality traits views on life & opinions (57 items) Spending habits (7 items) Demographics (10 items)  Research questions Many different techniques can be used to answer many questions e.g.  Clustering Given the music preferences do people make up any clusters of similar behavior? Hypothesis testing Do women fear certain phenomena significantly more than men? Do the left handed people have different interests than right handed? Predictive modeling Can we predict spending habits of a person from his/her interests and movie or music preferences? Dimension reduction Can we describe a large number of human interests by a smaller number of latent concepts? Correlation analysis Are there any connections between music and movie preferences? Visualization How to effectively visualize a lot of variables in order to gain some meaningful insights from the data? (Multivariate) Outlier detection Small number of participants often cheats and randomly answers the questions. Can you identify them? Hint Local outlier factor may help. Missing values analysis Are there any patterns in missing responses? What is the optimal way of imputing the values in surveys? Recommendations If some of user's interests are known can we predict the other? Or if we know what a person listen can we predict which kind of movies he/she might like?  Past research  (in slovak) Sleziak P. - Sabo M. Gender differences in the prevalence of specific phobias. Forum Statisticum Slovacum. 2014 Vol. 10 No. 6. [Differences (gender + whether people lived in village/town) in the prevalence of phobias.]  Sabo Miroslav. Multivariate Statistical Methods with Applications. Diss. Slovak University of Technology in Bratislava 2014. [Clustering of variables (music preferences movie preferences phobias) + Clustering of people w.r.t. their interests.]  Questionnaire MUSIC PREFERENCES  I enjoy listening to music. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I prefer. Slow paced music 1-2-3-4-5 Fast paced music (integer) Dance Disco Funk Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Folk music Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Country Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Classical Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Musicals Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Pop Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Rock Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Metal Hard rock Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Punk Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Hip hop Rap Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Reggae Ska Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Swing Jazz Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Rock n Roll Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Alternative music Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Latin Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Techno Trance Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Opera Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)  MOVIE PREFERENCES  I really enjoy watching movies. Strongly disagree 1-2-3-4-5 Strongly agree (integer) Horror movies Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Thriller movies Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Comedies Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Romantic movies Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Sci-fi movies Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) War movies Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Tales Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Cartoons Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Documentaries Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Western movies Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer) Action movies Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)  HOBBIES & INTERESTS  History Not interested 1-2-3-4-5 Very interested (integer) Psychology Not interested 1-2-3-4-5 Very interested (integer) Politics Not interested 1-2-3-4-5 Very interested (integer) Mathematics Not interested 1-2-3-4-5 Very interested (integer) Physics Not interested 1-2-3-4-5 Very interested (integer) Internet Not interested 1-2-3-4-5 Very interested (integer) PC Software Hardware Not interested 1-2-3-4-5 Very interested (integer) Economy Management Not interested 1-2-3-4-5 Very interested (integer) Biology Not interested 1-2-3-4-5 Very interested (integer) Chemistry Not interested 1-2-3-4-5 Very interested (integer) Poetry reading Not interested 1-2-3-4-5 Very interested (integer) Geography Not interested 1-2-3-4-5 Very interested (integer) Foreign languages Not interested 1-2-3-4-5 Very interested (integer) Medicine Not interested 1-2-3-4-5 Very interested (integer) Law Not interested 1-2-3-4-5 Very interested (integer) Cars Not interested 1-2-3-4-5 Very interested (integer) Art Not interested 1-2-3-4-5 Very interested (integer) Religion Not interested 1-2-3-4-5 Very interested (integer) Outdoor activities Not interested 1-2-3-4-5 Very interested (integer) Dancing Not interested 1-2-3-4-5 Very interested (integer) Playing musical instruments Not interested 1-2-3-4-5 Very interested (integer) Poetry writing Not interested 1-2-3-4-5 Very interested (integer) Sport and leisure activities Not interested 1-2-3-4-5 Very interested (integer) Sport at competitive level Not interested 1-2-3-4-5 Very interested (integer) Gardening Not interested 1-2-3-4-5 Very interested (integer) Celebrity lifestyle Not interested 1-2-3-4-5 Very interested (integer) Shopping Not interested 1-2-3-4-5 Very interested (integer) Science and technology Not interested 1-2-3-4-5 Very interested (integer) Theatre Not interested 1-2-3-4-5 Very interested (integer) Socializing Not interested 1-2-3-4-5 Very interested (integer) Adrenaline sports Not interested 1-2-3-4-5 Very interested (integer) Pets Not interested 1-2-3-4-5 Very interested (integer)  PHOBIAS  Flying Not afraid at all 1-2-3-4-5 Very afraid of (integer) Thunder lightning Not afraid at all 1-2-3-4-5 Very afraid of (integer) Darkness Not afraid at all 1-2-3-4-5 Very afraid of (integer) Heights Not afraid at all 1-2-3-4-5 Very afraid of (integer) Spiders Not afraid at all 1-2-3-4-5 Very afraid of (integer) Snakes Not afraid at all 1-2-3-4-5 Very afraid of (integer) Rats mice Not afraid at all 1-2-3-4-5 Very afraid of (integer) Ageing Not afraid at all 1-2-3-4-5 Very afraid of (integer) Dangerous dogs Not afraid at all 1-2-3-4-5 Very afraid of (integer) Public speaking Not afraid at all 1-2-3-4-5 Very afraid of (integer)  HEALTH HABITS  Smoking habits Never smoked - Tried smoking - Former smoker - Current smoker (categorical) Drinking Never - Social drinker - Drink a lot (categorical) I live a very healthy lifestyle. Strongly disagree 1-2-3-4-5 Strongly agree (integer)  PERSONALITY TRAITS VIEWS ON LIFE & OPINIONS  I take notice of what goes on around me. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I try to do tasks as soon as possible and not leave them until last minute. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I always make a list so I don't forget anything. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I often study or work even in my spare time. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I look at things from all different angles before I go ahead. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I believe that bad people will suffer one day and good people will be rewarded. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I am reliable at work and always complete all tasks given to me. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I always keep my promises. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I can fall for someone very quickly and then completely lose interest. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I would rather have lots of friends than lots of money. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I always try to be the funniest one. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I can be two faced sometimes. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I damaged things in the past when angry. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I take my time to make decisions. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I always try to vote in elections. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I often think about and regret the decisions I make. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I can tell if people listen to me or not when I talk to them. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I am a hypochondriac. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I am emphatetic person. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I eat because I have to. I don't enjoy food and eat as fast as I can. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I try to give as much as I can to other people at Christmas. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I don't like seeing animals suffering. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I look after things I have borrowed from others. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I feel lonely in life. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I used to cheat at school. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I worry about my health. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I wish I could change the past because of the things I have done. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I believe in God. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I always have good dreams. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I always give to charity. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I have lots of friends. Strongly disagree 1-2-3-4-5 Strongly agree (integer) Timekeeping. I am often early. - I am always on time. - I am often running late. (categorical) Do you lie to others? Never. - Only to avoid hurting someone. - Sometimes. - Everytime it suits me. (categorical) I am very patient. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I can quickly adapt to a new environment. Strongly disagree 1-2-3-4-5 Strongly agree (integer) My moods change quickly. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I am well mannered and I look after my appearance. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I enjoy meeting new people. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I always let other people know about my achievements. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I think carefully before answering any important letters. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I enjoy childrens' company. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I am not afraid to give my opinion if I feel strongly about something. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I can get angry very easily. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I always make sure I connect with the right people. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I have to be well prepared before public speaking. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I will find a fault in myself if people don't like me. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I cry when I feel down or things don't go the right way. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I am 100% happy with my life. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I am always full of life and energy. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I prefer big dangerous dogs to smaller calmer dogs. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I believe all my personality traits are positive. Strongly disagree 1-2-3-4-5 Strongly agree (integer) If I find something the doesn't belong to me I will hand it in. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I find it very difficult to get up in the morning. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I have many different hobbies and interests. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I always listen to my parents' advice. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I enjoy taking part in surveys. Strongly disagree 1-2-3-4-5 Strongly agree (integer) How much time do you spend online? No time at all - Less than an hour a day - Few hours a day - Most of the day (categorical)  SPENDING HABITS  I save all the money I can. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I enjoy going to large shopping centres. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I prefer branded clothing to non branded. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I spend a lot of money on  partying and socializing. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I spend a lot of money on my appearance. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I spend a lot of money on gadgets. Strongly disagree 1-2-3-4-5 Strongly agree (integer) I will hapilly pay more money for good quality or healthy food. Strongly disagree 1-2-3-4-5 Strongly agree (integer)  DEMOGRAPHICS  Age  (integer) Height  (integer) Weight  (integer) How many siblings do you have?  (integer) Gender Female - Male (categorical) I am Left handed - Right handed (categorical) Highest education achieved Currently a Primary school pupil - Primary school - Secondary school - College/Bachelor degree (categorical) I am the only child No - Yes (categorical) I spent most of my childhood in a City - village (categorical) I lived most of my childhood in a house/bungalow - block of flats (categorical) ,original:short:,string:string:,demography
(MBTI) Myers-Briggs Personality Type Dataset , Mitchell J , www.kaggle.com/datasnaek/mbti-type , Fri Sep 22 2017 19:30:59 GMT+0530 (IST) , Includes a large number of people's MBTI type and content written by them ,711, personality- demographics- linguistics- psychology- internet- ,"Context The Myers Briggs Type Indicator (or MBTI for short) is a personality type system that divides everyone into 16 distinct personality types across 4 axis  Introversion (I) – Extroversion (E) Intuition (N) – Sensing (S) Thinking (T) – Feeling (F) Judging (J) – Perceiving (P)  (More can be learned about what these mean here) So for example someone who prefers introversion intuition thinking and perceiving would be labelled an INTP in the MBTI system and there are lots of personality based components that would model or describe this person’s preferences or behaviour based on the label. It is one of if not the the most popular personality test in the world. It is used in businesses online for fun for research and lots more. A simple google search reveals all of the different ways the test has been used over time. It’s safe to say that this test is still very relevant in the world in terms of its use. From scientific or psychological perspective it is based on the work done on cognitive functions by Carl Jung i.e. Jungian Typology. This was a model of 8 distinct functions thought processes or ways of thinking that were suggested to be present in the mind. Later this work was transformed into several different personality systems to make it more accessible the most popular of which is of course the MBTI.  Recently its use/validity has come into question because of unreliability in experiments surrounding it among other reasons. But it is still clung to as being a very useful tool in a lot of areas and the purpose of this dataset is to help see if any patterns can be detected in specific types and their style of writing which overall explores the validity of the test in analysing predicting or categorising behaviour. Content This dataset contains over 8600 rows of data on each row is a person’s  Type (This persons 4 letter MBTI code/type) A section of each of the last 50 things they have posted (Each entry separated by ""|||"" (3 pipe characters))  Acknowledgements This data was collected through the PersonalityCafe forum as it provides a large selection of people and their MBTI personality type as well as what they have written.  Inspiration Some basic uses could include  Use machine learning to evaluate the MBTIs validity and ability to predict language styles and behaviour online. Production of a machine learning algorithm that can attempt to determine a person’s personality type based on some text they have written. ",type:posts:,string:string:,demography
US jobs on Monster.com , PromptCloud , www.kaggle.com/PromptCloudHQ/us-jobs-on-monstercom , Fri Sep 15 2017 14:27:19 GMT+0530 (IST) , 22000 US-based Job Listings ,112, internet- ,"Context This is a pre-crawled dataset taken as subset of a bigger dataset (more than 4.7 million job listings) that was created by extracting data from Monster.com a leading job board. Content This dataset has following fields  country country_code date_added has_expired - Always false. job_description - The primary field for this dataset containing the bulk of the information on what the job is about. job_title job_type - The type of tasks and skills involved in the job. For example ""management"". location organization page_url salary sector - The industry sector the job is in. For example ""Medical services"".  Acknowledgements This dataset was created by PromptCloud's in-house web-crawling service. Inspiration  What kinds of jobs titles correspond with what kinds of wages? What can you learn about the Moster.com-based US job market based on analyzing the contents of the job descriptions? How do job descriptions different between different industry sectors? ",country:country_code:date_added:has_expired:job_board:job_description:job_title:job_type:location:organization:page_url:salary:sector:uniq_id:,string:string:string:string:string:string:string:string:string:string:string:string:string:string:,online information
Ground State Energies of 16242 Molecules , BurakH , www.kaggle.com/burakhmmtgl/energy-molecule , Wed Apr 12 2017 23:59:19 GMT+0530 (IST) , Predict molecular properties from a database of atomic level simulations ,237, chemistry- physics- ,Context This dataset contains ground state energies of 16242 molecules calculated by quantum mechanical simulations.  Content The data contains 1277 columns. The first 1275 columns are entries in the Coulomb matrix that act as molecular features. The 1276th column is the Pubchem Id where the molecular structures are obtained. The 1277th column is the atomization energy calculated by simulations using the Quantum Espresso package. In the csv file the first column (X1) is the data index and unused.  Past Research The data is used for a publication in Journal of Chemical Physics. A blog post was also published explaining the data and the research behind it in less technical terms.  A Github repository is available that contains the source code used for generating the data as well as some of the R scripts used for analysis.  Inspiration Simulations of molecular properties are computationally expensive. The purpose of this project is to use machine learning methods to come up with a model that can predict molecular properties from a database of simulations. If this can be done with high accuracy properties of new molecules can be calculated using the trained model. This could open up many possibilities in computational design and discovery of molecules compounds and new drugs.  The purpose is to use the 1275 molecular features to predict the atomization energy. This is a regression problem so mean squared error is minimized during training.  I am looking for Kagglers to find the best model and reduce mean squared error as much as possible! ,:0:1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:19:20:21:22:23:24:25:26:27:28:29:30:31:32:33:34:35:36:37:38:39:40:41:42:43:44:45:46:47:48:49:50:51:52:53:54:55:56:57:58:59:60:61:62:63:64:65:66:67:68:69:70:71:72:73:74:75:76:77:78:79:80:81:82:83:84:85:86:87:88:89:90:91:92:93:94:95:96:97:98:99:100:101:102:103:104:105:106:107:108:109:110:111:112:113:114:115:116:117:118:119:120:121:122:123:124:125:126:127:128:129:130:131:132:133:134:135:136:137:138:139:140:141:142:143:144:145:146:147:148:149:150:151:152:153:154:155:156:157:158:159:160:161:162:163:164:165:166:167:168:169:170:171:172:173:174:175:176:177:178:179:180:181:182:183:184:185:186:187:188:189:190:191:192:193:194:195:196:197:198:199:200:201:202:203:204:205:206:207:208:209:210:211:212:213:214:215:216:217:218:219:220:221:222:223:224:225:226:227:228:229:230:231:232:233:234:235:236:237:238:239:240:241:242:243:244:245:246:247:248:249:250:251:252:253:254:255:256:257:258:259:260:261:262:263:264:265:266:267:268:269:270:271:272:273:274:275:276:277:278:279:280:281:282:283:284:285:286:287:288:289:290:291:292:293:294:295:296:297:298:299:300:301:302:303:304:305:306:307:308:309:310:311:312:313:314:315:316:317:318:319:320:321:322:323:324:325:326:327:328:329:330:331:332:333:334:335:336:337:338:339:340:341:342:343:344:345:346:347:348:349:350:351:352:353:354:355:356:357:358:359:360:361:362:363:364:365:366:367:368:369:370:371:372:373:374:375:376:377:378:379:380:381:382:383:384:385:386:387:388:389:390:391:392:393:394:395:396:397:398:399:400:401:402:403:404:405:406:407:408:409:410:411:412:413:414:415:416:417:418:419:420:421:422:423:424:425:426:427:428:429:430:431:432:433:434:435:436:437:438:439:440:441:442:443:444:445:446:447:448:449:450:451:452:453:454:455:456:457:458:459:460:461:462:463:464:465:466:467:468:469:470:471:472:473:474:475:476:477:478:479:480:481:482:483:484:485:486:487:488:489:490:491:492:493:494:495:496:497:498:499:500:501:502:503:504:505:506:507:508:509:510:511:512:513:514:515:516:517:518:519:520:521:522:523:524:525:526:527:528:529:530:531:532:533:534:535:536:537:538:539:540:541:542:543:544:545:546:547:548:549:550:551:552:553:554:555:556:557:558:559:560:561:562:563:564:565:566:567:568:569:570:571:572:573:574:575:576:577:578:579:580:581:582:583:584:585:586:587:588:589:590:591:592:593:594:595:596:597:598:599:600:601:602:603:604:605:606:607:608:609:610:611:612:613:614:615:616:617:618:619:620:621:622:623:624:625:626:627:628:629:630:631:632:633:634:635:636:637:638:639:640:641:642:643:644:645:646:647:648:649:650:651:652:653:654:655:656:657:658:659:660:661:662:663:664:665:666:667:668:669:670:671:672:673:674:675:676:677:678:679:680:681:682:683:684:685:686:687:688:689:690:691:692:693:694:695:696:697:698:699:700:701:702:703:704:705:706:707:708:709:710:711:712:713:714:715:716:717:718:719:720:721:722:723:724:725:726:727:728:729:730:731:732:733:734:735:736:737:738:739:740:741:742:743:744:745:746:747:748:749:750:751:752:753:754:755:756:757:758:759:760:761:762:763:764:765:766:767:768:769:770:771:772:773:774:775:776:777:778:779:780:781:782:783:784:785:786:787:788:789:790:791:792:793:794:795:796:797:798:799:800:801:802:803:804:805:806:807:808:809:810:811:812:813:814:815:816:817:818:819:820:821:822:823:824:825:826:827:828:829:830:831:832:833:834:835:836:837:838:839:840:841:842:843:844:845:846:847:848:849:850:851:852:853:854:855:856:857:858:859:860:861:862:863:864:865:866:867:868:869:870:871:872:873:874:875:876:877:878:879:880:881:882:883:884:885:886:887:888:889:890:891:892:893:894:895:896:897:898:899:900:901:902:903:904:905:906:907:908:909:910:911:912:913:914:915:916:917:918:919:920:921:922:923:924:925:926:927:928:929:930:931:932:933:934:935:936:937:938:939:940:941:942:943:944:945:946:947:948:949:950:951:952:953:954:955:956:957:958:959:960:961:962:963:964:965:966:967:968:969:970:971:972:973:974:975:976:977:978:979:980:981:982:983:984:985:986:987:988:989:990:991:992:993:994:995:996:997:998:999:1000:1001:1002:1003:1004:1005:1006:1007:1008:1009:1010:1011:1012:1013:1014:1015:1016:1017:1018:1019:1020:1021:1022:1023:1024:1025:1026:1027:1028:1029:1030:1031:1032:1033:1034:1035:1036:1037:1038:1039:1040:1041:1042:1043:1044:1045:1046:1047:1048:1049:1050:1051:1052:1053:1054:1055:1056:1057:1058:1059:1060:1061:1062:1063:1064:1065:1066:1067:1068:1069:1070:1071:1072:1073:1074:1075:1076:1077:1078:1079:1080:1081:1082:1083:1084:1085:1086:1087:1088:1089:1090:1091:1092:1093:1094:1095:1096:1097:1098:1099:1100:1101:1102:1103:1104:1105:1106:1107:1108:1109:1110:1111:1112:1113:1114:1115:1116:1117:1118:1119:1120:1121:1122:1123:1124:1125:1126:1127:1128:1129:1130:1131:1132:1133:1134:1135:1136:1137:1138:1139:1140:1141:1142:1143:1144:1145:1146:1147:1148:1149:1150:1151:1152:1153:1154:1155:1156:1157:1158:1159:1160:1161:1162:1163:1164:1165:1166:1167:1168:1169:1170:1171:1172:1173:1174:1175:1176:1177:1178:1179:1180:1181:1182:1183:1184:1185:1186:1187:1188:1189:1190:1191:1192:1193:1194:1195:1196:1197:1198:1199:1200:1201:1202:1203:1204:1205:1206:1207:1208:1209:1210:1211:1212:1213:1214:1215:1216:1217:1218:1219:1220:1221:1222:1223:1224:1225:1226:1227:1228:1229:1230:1231:1232:1233:1234:1235:1236:1237:1238:1239:1240:1241:1242:1243:1244:1245:1246:1247:1248:1249:1250:1251:1252:1253:1254:1255:1256:1257:1258:1259:1260:1261:1262:1263:1264:1265:1266:1267:1268:1269:1270:1271:1272:1273:1274:pubchem_id:Eat:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,chemistry
EEG brain wave for confusion , Haohan Wang , www.kaggle.com/wanghaohan/eeg-brain-wave-for-confusion , Thu Dec 01 2016 06:16:51 GMT+0530 (IST) , For variable selection and causal inference. Challenging for classification ,2010, human medicine- neuroscience- ,Description We collected EEG signal data from 10 college students while they watched MOOC video clips. We extracted online education videos that are assumed not to be confusing for college students such as videos of the introduction of basic algebra or geometry. We also prepare videos that are expected to confuse a typical college student if a student is not familiar with the video topics like Quantum Mechanics and Stem Cell Research. We prepared 20 videos 10 in each category. Each video was about 2 minutes long. We chopped the two-minute clip in the middle of a topic to make the videos more confusing.  The students wore a single-channel wireless MindSet that measured activity over the frontal lobe. The MindSet measures the voltage between an electrode resting on the forehead and two electrodes (one ground and one reference) each in contact with an ear. After each session the student rated his/her confusion level on a scale of 1-7 where one corresponded to the least confusing and seven corresponded to the most confusing. These labels if further normalized into labels of whether the students are confused or not. This label is offered as self-labelled confusion in addition to our predefined label of confusion.  Data information -----data.csv  Column 1 Subject ID  Column 2 Video ID Column 3 Attention (Proprietary measure of mental focus) Column 4 Mediation (Proprietary measure of calmness) Column 5 Raw (Raw EEG signal) Column 6 Delta (1-3 Hz of power spectrum) Column 7 Theta (4-7 Hz of power spectrum) Column 8 Alpha 1 (Lower 8-11 Hz of power spectrum) Column 9 Alpha 2 (Higher 8-11 Hz of power spectrum) Column 10 Beta 1 (Lower 12-29 Hz of power spectrum) Column 11 Beta 2 (Higher 12-29 Hz of power spectrum) Column 12 Gamma 1 (Lower 30-100 Hz of power spectrum) Column 13 Gamma 2 (Higher 30-100 Hz of power spectrum) Column 14 predefined label (whether the subject is expected to be confused) Column 15 user-defined label (whether the subject is actually confused)  -----subject demographic  Column 1 Subject ID Column 2 Age Column 3 Ethnicity (Categorized according to https//en.wikipedia.org/wiki/List_of_contemporary_ethnic_groups) Column 4 Gender  -----video data Each video lasts roughly two-minute long we remove the first 30 seconds and last 30 seconds only collect the EEG data during the middle 1 minute.  Format These data are collected from ten students each watching ten videos.  Therefore it can be seen as only 100 data points for these 12000+ rows. If you look at this way then each data point consists of 120+ rows which is sampled every 0.5 seconds (so each data point is a one minute video). Signals with higher frequency are reported as the mean value during each 0.5 second.  Reference  Wang H. Li Y. Hu X. Yang Y. Meng Z. & Chang K. M. (2013 June). Using EEG to Improve Massive Open Online Courses Feedback Interaction. In AIED Workshops. [PDF]  Data Collection The data is collected from a software that we implemented ourselves. Check HaohanWang/Bioimaging for the source code.  Inspiration  This dataset is an extremely challenging data set to perform binary classification. 65% of prediction accuracy is quite decent according to our experience.  It is an interesting data set to carry out the variable selection  (causal inference) task that may help further research. Past research has indicated that Theta signal is correlated with confusion level.  It is also an interesting data set for confounding factors correction model because we offer two labels (subject id and video id) that could profoundly confound the results.  Warning The data for subject 3 might be corrupted.  Other Resources Promotion Video Source Code of Data Collection Software Contact Haohan Wang ,subject ID: age: ethnicity: gender:,numeric:numeric:string:string:,diagnostics
Pima Indians Diabetes Database , UCI Machine Learning , www.kaggle.com/uciml/pima-indians-diabetes-database , Fri Oct 07 2016 00:01:56 GMT+0530 (IST) , Predict the onset of diabetes based on diagnostic measures ,6625, human medicine- ,This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective is to predict based on diagnostic measurements whether a patient has diabetes. Dataset information Several constraints were placed on the selection of these instances from a larger database. In particular all patients here are females at least 21 years old of Pima Indian heritage. Relevant papers Smith J.W. Everhart J.E. Dickson W.C. Knowler W.C. & Johannes R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261--265). IEEE Computer Society Press.,Pregnancies:Glucose:BloodPressure:SkinThickness:Insulin:BMI:DiabetesPedigreeFunction:Age:Outcome:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,diagnostics
Crypto Currencies , Albert Costas , www.kaggle.com/acostasg/crypto-currencies , Mon Oct 16 2017 04:14:22 GMT+0530 (IST) , Cryptocurrency Market Capitalizations ,81, ,«Datasets per la comparació de moviments i patrons entre els principals índexs borsatils espanyols i les crypto-monedes» Context En aquest cas el context és detectar o preveure els diferents moviments que es produeixen per una serie factors tant de moviment interns (compra-venda) com externs (moviments polítics econòmics etc...) en els principals índexs borsatils espanyols i de les crypto-monedes. Hem seleccionat diferents fonts de dades per generar fitxers «csv» guardar diferents valors en el mateix període de temps. És important destacar que ens interessa més les tendències alcistes o baixes que podem calcular o recuperar en aquests períodes de temps. Content En aquest cas el contingut està format per diferents csv especialment tenim els fitxers de moviments de cryptomoneda els quals s’ha generat un fitxer per dia del període de temps estudiat. Pel que fa als moviments del principals índexs borsatils s’ha generat una carpeta per dia del període en cada directori un fitxer amb cadascun del noms dels índexs. Degut això s’han comprimit aquests últims abans de publicar-los en el directori de «open data» kaggle.com. Pel que fa als camps ens interessà detectar els moviments alcistes i baixistes o almenys aquelles que tenen un patró similar en les cryptomonedes i els índexs. Els camps especialment destacats són • Nom Nom empresa o cryptomoneda; • Preu Valor en euros d’una acció o una cryptomoneda; • Volum En euros/volum 24 horesacumulat de les transaccions diàries en milions d’euros • Simbol Símbol o acrònim de la moneda • Cap de mercat Valor total de totes les monedes en el moment actual • Oferta circulant Valor en oportunitat de negoci • % 1h % 2h i %7d tant per cent del valor la moneda en 1h 2h o 7d sobre la resta de cyprtomonedes.  Acknowledgements En aquest cas les fonts de dades que s’han utilitzat per a la realització dels datasets corresponent a  http//www.eleconomista.es https//coinmarketcap.com  Per aquest fet les dades de borsa i crypto-moneda estan en última instància sota llicència de les webs respectivament. Pel que fa a la terminologia financera podem veure vocabulari en renta4banco.  [https//www.r4.com/que-necesitas/formacion/diccionario] Inspiration Hi ha un estudi anterior on poder tenir primícies de com han enfocat els algoritmes       https//arxiv.org/pdf/1410.1231v1.pdf  En aquest cas el «trading» en cryptomoneda és relativament nou força popular per la seva formulació com a mitja digital d’intercanvi utilitzant un protocol que garanteix la seguretat integritat i equilibri del seu estat de compte per mitjà d’un entramat d’agents. La comunitat podrà respondre entre altres preguntes a  Està afectant o hi ha patrons comuns en les cotitzacions de cryptomonedes i el mercat de valors principals del país d'Espanya? Els efectes o agents externs afecten per igual a les accions o cryptomonedes?  Hi ha relacions cause efecte entre les acciones i cryptomonedes?  Project repository https//github.com/acostasg/scraping Datasets Els fitxers csv generats que componen el dataset s’han publicat en el repositori kaggle.com  https//www.kaggle.com/acostasg/stock-index/  https//www.kaggle.com/acostasg/crypto-currencies  Per una banda els fitxers els «stock-index» estan comprimits per carpetes amb la data d’extracció i cada fitxer amb el nom dels índexs borsatil.  De forma diferent les cryptomonedes aquestes estan dividides per fitxer on són totes les monedes amb la data d’extracció.,Numero:Nom:Simbol:Cap de mercat:Preu:Oferta circulant:Volum 24 hores:% 1h:% 2h:% 7d:,numeric:string:string:string:string:string:string:string:string:string:,blockchain and crytocurrencies
Breast Cancer Wisconsin (Diagnostic) Data Set , UCI Machine Learning , www.kaggle.com/uciml/breast-cancer-wisconsin-data , Sun Sep 25 2016 16:19:04 GMT+0530 (IST) , Predict whether the cancer is benign or malignant ,12020, human medicine- ,"Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.  n the 3-dimensional space is that described in [K. P. Bennett and O. L. Mangasarian ""Robust Linear Programming Discrimination of Two Linearly Inseparable Sets"" Optimization Methods and Software 1 1992 23-34].  This database is also available through the UW CS ftp server  ftp ftp.cs.wisc.edu  cd math-prog/cpo-dataset/machine-learn/WDBC/ Also can be found on UCI Machine Learning Repository https//archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29 Attribute Information 1) ID number  2) Diagnosis (M = malignant B = benign)  3-32)  Ten real-valued features are computed for each cell nucleus  a) radius (mean of distances from center to points on the perimeter)  b) texture (standard deviation of gray-scale values)  c) perimeter  d) area  e) smoothness (local variation in radius lengths)  f) compactness (perimeter^2 / area - 1.0)  g) concavity (severity of concave portions of the contour)  h) concave points (number of concave portions of the contour)  i) symmetry  j) fractal dimension (""coastline approximation"" - 1) The mean standard error and ""worst"" or largest (mean of the three largest values) of these features were computed for each image resulting in 30 features.  For instance field 3 is Mean Radius field 13 is Radius SE field 23 is Worst Radius. All feature values are recoded with four significant digits. Missing attribute values none Class distribution 357 benign 212 malignant",id:diagnosis:radius_mean:texture_mean:perimeter_mean:area_mean:smoothness_mean:compactness_mean:concavity_mean:concave points_mean:symmetry_mean:fractal_dimension_mean:radius_se:texture_se:perimeter_se:area_se:smoothness_se:compactness_se:concavity_se:concave points_se:symmetry_se:fractal_dimension_se:radius_worst:texture_worst:perimeter_worst:area_worst:smoothness_worst:compactness_worst:concavity_worst:concave points_worst:symmetry_worst:fractal_dimension_worst:,numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,diagnostics
Toy Products on Amazon , PromptCloud , www.kaggle.com/PromptCloudHQ/toy-products-on-amazon , Sat Sep 16 2017 01:15:36 GMT+0530 (IST) , 10000 toy products on Amazon.com ,374, internet- ,"Context This is a pre-crawled dataset taken as subset of a bigger dataset (more than 7 million products) that was created by extracting data from Amazon.com. Content This dataset has following fields  product_name manufacturer - The item manufacturer as reported on Amazon. Some common ""manufacturers"" like Disney actually outsource their assembly line. price number_available_in_stock number_of_reviews number_of_answered_questions - Amazon includes a Question and Answer service on all or most of its products. This field is a count of how many questions that were asked actually got answered. average_review_rating amazon_category_and_sub_category - A tree-based >>-delimited categorization for the item in question. customers_who_bought_this_item_also_bought - References to other items that similar users bought. This is a recommendation engine component that played a big role in making Amazon popular initially. description product_information product_description items_customers_buy_after_viewing_this_item customer_questions_and_answers - A string entry with all of the product's JSON question and answer pairs. customer_reviews - A string entry with all of the product's JSON reviews. sellers - A string entry with all of the product's JSON seller information (many products on Amazon are sold by third parties).  Acknowledgements This dataset was created by PromptCloud's in-house web-crawling service. Inspiration This detailed dataset can be used to answer questions like  What types of toys are most popular on Amazon? How dominant are brands in the Amazon toy market? Can you break down reviews to analyze their sentiment and contents? ",uniq_id:product_name:manufacturer:price:number_available_in_stock:number_of_reviews:number_of_answered_questions:average_review_rating:amazon_category_and_sub_category:customers_who_bought_this_item_also_bought:description:product_information:product_description:items_customers_buy_after_viewing_this_item:customer_questions_and_answers:customer_reviews:sellers:,string:string:string:string:string:numeric:numeric:string:string:string:string:string:string:string:string:string:string:,online shopping
Swiss Rail Plan , Kevin Mader , www.kaggle.com/kmader/swiss-rail-plan , Tue Apr 18 2017 15:06:11 GMT+0530 (IST) , The locations timetables and fare information for the SBB/CFF/FFS Rail Network ,67, rail transport- ,Introduction The basic inspiration was the inability to search through lots of alternative routes while traveling over Easter weekend and having to manually to point-to-point searches. The hope is by using a bit of R/Python the search for the best routes can be made a lot easier. Data Structure The data is organized in a format called GTFS which is explained in detail here but only available in German. Kernels should make it clear how to work with most of the data Source / Attribution The data all comes from opentransportdata.swiss and can be downloaded in the original format by following this link,agency_id:,numeric:,rail and metro
U.S. Commercial Aviation Industry Metrics , Franklin Bradfield , www.kaggle.com/shellshock1911/us-commercial-aviation-industry-metrics , Thu Jul 13 2017 13:31:09 GMT+0530 (IST) , Monthly passengers flights seat-miles and revenue-miles from 2002 to 2017 ,215, transport- aviation- vehicles- ,"Context Have you taken a flight in the U.S. in the past 15 years? If so then you are a part of monthly data that the U.S. Department of Transportation's TranStats service makes available on various metrics for 15 U.S. airlines and 30 major U.S airports. Their website unfortunately does not include a method for easily downloading and sharing files. Furthermore the source is built in ASP.NET so extracting the data is rather cumbersome. To allow easier community access to this rich source of information I scraped the metrics for every airline / airport combination and stored them in separate CSV files. Occasionally an airline doesn't serve a certain airport or it didn't serve it for the entire duration that the data collection period covers*. In those cases the data either doesn't exist or is typically too sparse to be of much use. As such I've only uploaded complete files for airports that an airline served for the entire uninterrupted duration of the collection period. For these files there should be 174 time series points for one or more of the nine columns below. I recommend any of the files for American Delta or United Airlines for outstanding examples of complete and robust airline data. * No data for Atlas Air exists and Virgin America commenced service in 2007  so no folders for either airline are included. Content There are 13 airlines that have at least one complete dataset. Each airline's folder includes CSV file(s) for each airport that are complete as defined by the above criteria. I've double-checked the files but if you find one that violates the criteria please point it out. The file names have the format ""AIRLINE-AIRPORT.csv"" where both AIRLINE and AIRPORT are IATA codes. For a full listing of the airlines and airports that the codes correspond to check out the airline_codes.csv or airport_codes.csv files that are included or perform a lookup here. Note that the data in each airport file represents metrics for flights that originated at the airport. Among the 13 airlines in data.zip there are a total of 161 individual datasets. There are also two special folders included - airlines_all_airports.csv and airports_all_airlines.csv. The first contains datasets for each airline aggregated over all airports while the second contains datasets for each airport aggregated over all airlines. To preview a sample dataset check out all_airlines_all_airports.csv which contains industry-wide data. Each file includes the following metrics for each month from October 2002 to March 2017  Date (YYYY-MM-DD) All dates are set to the first of the month. The day value is just a placeholder and has no significance. ASM_Domestic Available Seat-Miles in thousands (000s). Number of domestic flights * Number of seats on each flight ASM_International* Available Seat-Miles in thousands (000s). Number of international flights * Number of seats on each flight Flights_Domestic  Flights_International* Passengers_Domestic Passengers_International* RPM_Domestic Revenue Passenger-Miles in thousands (000s). Number of domestic flights * Number of paying passengers RPM_International* Revenue Passenger-Miles in thousands (000s). Number of international  flights * Number of paying passengers  * Frequently contains missing values Acknowledgements Thanks to the U.S. Department of Transportation for collecting this data every month and making it publicly available to us all. Source  https//www.transtats.bts.gov/Data_Elements.aspx Inspiration The airline / airport datasets are perfect for practicing and/or testing time series forecasting with classic statistical models such as autoregressive integrated moving average (ARIMA) or modern deep learning techniques such as long short-term memory (LSTM) networks. The datasets typically show evidence of trends seasonality and noise so modeling and accurate forecasting can be challenging but still more tractable than time series problems possessing more stochastic elements e.g. stocks currencies commodities etc. The source releases new data each month so feel free to check your models' performances against new data as it comes out. I will update the files here every 3 to 6 months depending on how things go.  A future plan is to build a SQLite database so a vast array of queries can be run against the data. The data in it its current time series format is not conducive for this so coming up with a workable structure for the tables is the first step towards this goal. If you have any suggestions for how I can improve the data presentation or anything that you would like me to add please let me know. Looking forward to seeing the questions that we can answer together!",Airline Code:,string:,airways
Airlines Delay , Giovanni Gonzalez , www.kaggle.com/giovamata/airlinedelaycauses , Sat Nov 12 2016 02:19:39 GMT+0530 (IST) , Airline on-time statistics and delay causes ,4621, aviation- ,The U.S. Department of Transportation's (DOT) Bureau of Transportation Statistics (BTS) tracks the on-time performance of domestic flights operated by large air carriers. Summary information on the number of on-time delayed canceled and diverted flights appears in DOT's monthly Air Travel Consumer Report published about 30 days after the month's end as well as in summary tables posted on this website. BTS began collecting details on the causes of flight delays in June 2003. Summary statistics and raw data are made available to the public at the time the Air Travel Consumer Report is released. This version of the dataset was compiled from the Statistical Computing Statistical Graphics 2009 Data Expo and is also available here.,,,airways
World Development Indicators , World Bank , www.kaggle.com/theworldbank/world-development-indicators , Mon Aug 14 2017 22:10:08 GMT+0530 (IST) , The most accurate global development data available ,185, ,World Development Indicators provides a compilation of relevant high-quality and internationally comparable statistics about global development and the fight against poverty. It is intended to help policymakers students analysts professors program managers and citizens find and use data related to all aspects of development including those that help monitor progress toward the World Bank Group’s two goals of ending poverty and promoting shared prosperity.  Content This dataset includes indicators at both national and regional levels for  -Agriculture & Rural Development -Aid Effectiveness -Climate Change -Economy & Growth -Education -Energy & Mining -Environment -External Debt -Financial Sector -Gender -Health -Infrastructure -Labor & Social Protection -Poverty -Private Sector -Public Sector -Science & Technology -Social Development -Trade Urban Development Acknowledgements This dataset was kindly made available by the World Bank. Please check their instance at http//data.worldbank.org/data-catalog/world-development-indicators for updates and related information.,Country Code:Short Name:Table Name:Long Name:2-alpha code:Currency Unit:Special Notes:Region:Income Group:WB-2 code:National accounts base year:National accounts reference year:SNA price valuation:Lending category:Other groups:System of National Accounts:Alternative conversion factor:PPP survey year:Balance of Payments Manual in use:External debt Reporting status:System of trade:Government Accounting concept:IMF data dissemination standard:Latest population census:Latest household survey:Source of most recent Income and expenditure data:Vital registration complete:Latest agricultural census:Latest industrial data:Latest trade data:Latest water withdrawal data::,string:string:string:string:string:string:string:string:string:string:numeric:numeric:string:string:string:string:string:numeric:string:string:string:string:string:numeric:string:string:string:numeric:numeric:numeric:numeric:string:,politics
YouTube Faces With Facial Keypoints , Selfish Gene , www.kaggle.com/selfishgene/youtube-faces-with-facial-keypoints , Sun Oct 15 2017 04:54:14 GMT+0530 (IST) , Videos of Celebrity Faces with Facial Keypoints for each Image Frame ,71, popular culture- celebrity- humans- internet- ,YouTube Faces Dataset with Facial Keypoints This dataset is a processed version of the YouTube Faces Dataset that basically contained short videos of celebrities that are publicly available and were downloaded from YouTube. There are multiple videos of each celebrity (up to 6 videos per celebrity). I've cropped the original videos around the faces plus kept only consecutive frames of up to 240 frames for each original video. This is done also for reasons of disk space but mainly to make the dataset easier to use. Additionally for this kaggle version of the dataset I've extracted facial keypoints for each frame of each video using this amazing 2D and 3D Face alignment library that was recently published. please check out this video demonstrating the library. It's performance is really amazing and I feel I'm quite qualified to say that after manually curating many thousands of individual frames and their corresponding keypoints. I removed all videos with extremely bad keypoints labeling. The end result of my curation process is approximately 2800 videos. Right now only 1293 of those videos are uploaded due to dataset size limitations (10GB) but since overall this totals into 155560 single image frames I think this is more than enough to do a lot of interesting kernels as well as potentially very interesting research. Context Kaggle datasets platform and it's integration with kernels is really amazing but it yet to have a videos dataset (at least not that I'm aware of). Videos are special in the fact that they contain rich spatial patterns (in this case images of human faces) and rich temporal patterns (in this case how the faces move in time). I was also inspired by this dataset uploaded by DrGuillermo and decided to seek out a dataset that will be similar but also add something extra.  Acknowledgements If you use The YouTube Faces Dataset or refer to its results please cite the following paper  Lior Wolf Tal Hassner and Itay Maoz  Face Recognition in Unconstrained Videos with Matched Background Similarity.  IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) 2011. (pdf) if you use the 2D or 3D keypoints or refer to its results please cite the following paper  Adrian Bulat and Georgios Tzimiropoulos.  How far are we from solving the 2D & 3D Face Alignment problem?  (and a dataset of 230000 3D facial landmarks) arxiv 2017. (pdf) Also I would like to thank Gil Levi for pointing out YouTube Faces to me a few years back. Inspiration The YouTube Faces Dataset was originally intended to be used for face recognition across videos i.e. given two videos are those videos of the same person or not?  I think it can be used to serve many additional goals especially when combined with the keypoints information.  For example can we build a face movement model and predict what facial expression will come next?   This dataset can also be used to test transfer learning between other face dataset (like this that I've mentioned earlier) or even other types of faces like cat or dog faces (like here or here).  Also using the pre-trained Keras models might be useful (example script). Have Fun!,videoID:personName:imageHeight:imageWidth:videoDuration:averageFaceSize:numVideosForPerson:,string:string:numeric:numeric:numeric:numeric:numeric:,videos
Jobs on Naukri.com , PromptCloud , www.kaggle.com/PromptCloudHQ/jobs-on-naukricom , Sat Sep 16 2017 01:23:58 GMT+0530 (IST) , 22000 job listings on Naukri.com ,58, ,Context This is a pre-crawled dataset taken as subset of a bigger dataset (more than 9.4 million job listings) that was created by extracting data from Naukri.com a leading job board. Content This dataset has following fields  company education experience industry job description jobid joblocation_address job title number of positions pay rate postdate site_name skills  Acknowledgements This dataset was created by PromptCloud's in-house web-crawling service. Inspiration Analyses of the pay rate job title industry and experience can be performed to name a few starting points.,company:education:experience:industry:jobdescription:jobid:joblocation_address:jobtitle:numberofpositions:payrate:postdate:site_name:skills:uniq_id:,string:string:string:string:string:numeric:string:string:numeric:string:dateTime:string:string:string:,online information
Open Exoplanet Catalogue , Megan Risdal , www.kaggle.com/mrisdal/open-exoplanet-catalogue , Fri Jun 09 2017 01:29:22 GMT+0530 (IST) , Characteristics of all discovered extrasolar planets ,1292, astronomy- space- ,Our first glimpse at planets outside of the solar system we call home came in 1992 when several terrestrial-mass planets were detected orbiting the pulsar PSR B1257+12. In this dataset you can become a space explorer too by analyzing the characteristics of all discovered exoplanets (plus some familiar faces like Mars Saturn and even Earth). Data fields include planet and host star attributes discovery methods and (of course) date of discovery. Data was originally collected and continues to be updated by Hanno Rein at the Open Exoplanet Catalogue Github repository. If you discover any new exoplanets please submit a pull request there. Constants  Jupiter mass 1.8991766e+27 kg Solar mass 1.9891e+30 kg Jupiter radius 69911000 m Solar radius 6.96e+08 m  License The database is licensed under an MIT license. If you use it for a scientific publication please include a reference to the Open Exoplanet Catalogue on GitHub or to this arXiv paper.,PlanetIdentifier:,string:,astronomy
Drosophila Melanogaster Genome , Myles O'Neill , www.kaggle.com/mylesoneill/drosophila-melanogaster-genome , Thu May 26 2016 08:51:22 GMT+0530 (IST) , Explore the annotated genome of the common fruit fly ,581, biology- medicine- ,Drosophila Melanogaster Drosophila Melanogaster the common fruit fly is a model organism which has been extensively used in entymological research. It is one of the most studied organisms in biological research particularly in genetics and developmental biology.  When its not being used for scientific research D. melanogaster is a common pest in homes restaurants and anywhere else that serves food. They are not to be confused with Tephritidae flys (also known as fruit flys).  https//en.wikipedia.org/wiki/Drosophila_melanogaster About the Genome This genome was first sequenced in 2000. It contains four pairs of chromosomes (234 and X/Y). More than 60% of the genome appears to be functional non-protein-coding DNA.   The genome is maintained and frequently updated at FlyBase. This dataset is sourced from the UCSC Genome Bioinformatics download page. It uses the August 2014 version of the D. melanogaster genome (dm6 BDGP Release 6 + ISO1 MT). http//hgdownload.soe.ucsc.edu/downloads.html#fruitfly Files were modified by Kaggle to be a better fit for analysis on Scripts. This primarily involved turning files into CSV format with a header row as well as converting the genome itself from 2bit format into a FASTA sequence file. Bioinformatics Genomic analysis can be daunting to data scientists who haven't had much experience with bioinformatics before. We have tried to give basic explanations to each of the files in this dataset as well as links to further reading on the biological basis for each. If you haven't had the chance to study much biology before some light reading (ie wikipedia) on the following topics may be helpful to understand the nuances of the data provided here Genetics Genomics (Sequencing/Genome Assembly) Chromosomes DNA RNA (mRNA/miRNA) Genes Alleles Exons Introns Transcription Translation Peptides Proteins Gene Regulation Mutation Phylogenetics and SNPs.  Of course if you've got some idea of the basics already - don't be afraid to jump right in!  Learning Bioinformatics There are a lot of great resources for learning bioinformatics on the web. One cool site is Rosalind - a platform that gives you bioinformatic coding challenges to complete. You can use Kaggle Scripts on this dataset to easily complete the challenges on Rosalind (and see Myles' solutions here if you get stuck). We have set up Biopython on Kaggle's docker image which is a great library to help you with your analyses. Check out their tutorial here and we've also created a python notebook with some of the tutorial applied to this dataset as a reference. Files in this Dataset  Drosophila Melanogaster Genome  genome.fa  The assembled genome itself is presented here in FASTA format. Each chromosome is a different sequence of nucleotides. Repeats from RepeatMasker and Tandem Repeats Finder (with period of 12 or less) are show in lower case; non-repeating sequence is shown in upper case.  Meta Information There are 3 additional files with meta information about the genome.  meta-cpg-island-ext-unmasked.csv  This file contains descriptive information about CpG Islands in the genome. https//en.wikipedia.org/wiki/CpG_site  meta-cytoband.csv  This file describes the positions of cytogenic bands on each chromosome. https//en.wikipedia.org/wiki/Cytogenetics  meta-simple-repeat.csv  This file describes simple tandem repeats in the genome. https//en.wikipedia.org/wiki/Repeated_sequence_(DNA) https//en.wikipedia.org/wiki/Tandem_repeat  Drosophila Melanogaster mRNA Sequences Messenger RNA (mRNA) is an intermediate molecule created as part of the cellular process of converting genomic information into proteins. Some mRNA are never translated into proteins and have functional roles in the cell on their own. Collectively organism mRNA information is known as a Transcriptome. mRNA files included in this dataset give insight into the activity of genes in the organism. https//en.wikipedia.org/wiki/Messenger_RNA  mrna-genbank.fa  This file includes all mRNA sequences from GenBank associated with Drosophila Melanogaster. http//www.ncbi.nlm.nih.gov/genbank/  mrna-refseq.fa  This file includes all mRNA sequences from RefSeq associated with Drosophila Melanogaster. http//www.ncbi.nlm.nih.gov/refseq/  Gene Predictions A gene is a segment of DNA on the genome which through mRNA is used to create proteins in the organism. Knowing which parts of DNA are coding (genes) or non-coding is difficult and a number of different systems for prediction exist. This dataset includes a number of different gene prediction systems applied to the drosophila melanogaster genome. https//en.wikipedia.org/wiki/Gene_prediction  genes-augustus.csv  AUGUSTUS is a piece of software that predicts genes ab initio using Hidden Markov Models. http//www.ncbi.nlm.nih.gov/pmc/articles/PMC441517/  genes-genscan.csv  GENSCAN is an older ab initio software for predicting genes.  http//genes.mit.edu/GENSCANinfo.html  genes-ensembl.csv ensembl-gtp.csv ensembl-pep.csv ensembl-source.csv ensembl-to-gene-name.csv  Ensembl provides gene annotation generated by their software Genebuild. This process combines automatic annotation alongside manual curation.  http//uswest.ensembl.org/info/genome/genebuild/genome_annotation.html We have also included some supplementary files for these including predicted protein peptide sequences for each predicted gene.  genes-refseq.csv genes-xeno-refseq.csv refseq-link.csv refseq-summary.csv  We have included two RefSeq gene predictions in this dataset. The first is based solely on information from the drosophila melanogaster genome. The second (genes-xeno-refseq.csv) uses genes from other organisms as a basis for predicting genes in drosophila melanogaster. RefSeq RNAs were aligned against the D. melanogaster genome using blat; those with an alignment of less than 15% were discarded. When a single RNA aligned in multiple places the alignment having the highest base identity was identified. Only alignments having a base identity level within 0.1% of the best and at least 96% base identity with the genomic sequence were kept. We have also included supplementary files for these which include information about the genes that have been identified. http//www.ncbi.nlm.nih.gov/refseq/  What can you do with this data? Genomic data is the foundation of bioinformatics and there is an incredible array of things you can do with this data. A good place to start is to look at some of the meta supplementary files alongside the genomic sequence itself.  We have a number of different gene prediction systems in the dataset how do they compare to each other? How do they compare to the mRNA data?  Working back from the refseq-summary.csv file you can look at genes that code for particular proteins - can you find these genes in the genome? How much of the genome codes for the mRNA's found in our mRNA data? Of the mRNA's we have how many map to the predicted genes and the predicted peptided sequence data? How much of the mRNA seems to be protein-coding vs how much looks like it is miRNA? Can you find pre-mRNA or splice variants within the mRNA data? Does meta information like cytogenic bands or CpG sites correspond with splice variants or a lack of mRNA altogether? Those are just some of many ideas that could get you started. Looking for Feedback This is the first genomic dataset on Kaggle and we are looking for feedback from our community about how interesting this dataset is to them or if there are ways we could improve it to better suit analysis. Please post suggestions for supplementary data future genomes we could host bioinformatics packages we should include on scripts and any other feedback on the dataset forum.,transcript:protein:gene:,string:string:string:,genomics
Transcriptomics in yeast , CostalAether , www.kaggle.com/costalaether/yeast-transcriptomics , Tue Jan 24 2017 16:43:04 GMT+0530 (IST) , A computational bioinformatics dataset with 92 sets of yeast data on 6000 genes ,302, biology- ,Disclaimer This is a data set of mine that I though might be enjoyable to the community.  It's concerning Next generation sequencing and Transcriptomics. I used several raw datasets that are public but the processing to get to this dataset is extensive.  This is my first contribution to kaggle so be nice and let me know how I can improve the experience. NGS machines are combined the biggest data producer worldwide. So why not add some (more? ) to kaggle.  A look into Yeast transcriptomics  Background Yeasts ( in this case saccharomyces cerevisiae) are used in the production of beer wine bread and a whole lot of Biotech applications such as creating complex pharmaceuticals.  They are living eukaryotic organisms  (meaning quite complex).  All living organisms store information in their DNA but action within a cell is carried out by specific Proteins. The path from DNA to Protein (from data to action) is simple. a specific region on the DNA gets transcribed to mRNA that gets translated to proteins.  Common assumption says that the translation step is linear  more mRNA means more protein.  Cells actively regulate the amount of protein by the amount of mRNA it creates. The expression of each gene depends on the condition the cell is in (starving stressed etc..) Modern methods in Biology show us all mRNA that is currently inside a cell. Assuming the linearity of the process we can get more protein the more specific mRNA is available to a cell. Making mRNA an excellent marker for what is actually happening inside a cell. It is important to consider that mRNA is fragile. It is actively replenished only when it is needed.  Both mRNA and proteins are expensive for a cell to produce . Yeasts are good model organisms for this since they only have about 6000 genes. They are also single cells which is more homogeneous and contain few advanced features (splice junctions etc.) ( all of this is heavily simplified let me know if I should go into more details ) The data  files  The following files are provided SC_expression.csv expression values for each gene over the available conditions **labels_CC.csv  ** labels for the individual genes  their status and where known intracellular localization ( see below) Maybe this would be nice as a little competition I'll see how this one is going before I'll upload the other label files.  Please provide some feedback on the presentation and whatever else you would want me to share.  background  I used 92 samples from various openly available raw datasets and ran them through a modern RNAseq pipeline.  Spanning a range of different conditions (I hid the raw names). The conditions covered stress conditions temperature and heavy metals as well as growth media changes and the deletion of specific genes. Originally I had 150 sets  92 are of good enough quality. Evaluation was done on gene level. Each gene got it's own row  Samples are columns (some are in replicates over several columns) .  Expression levels were normalized with by TPM (transcripts per million) a default normalization procedure. Raw counts would have been integers  normalized they are floats. Analysis and labels  Genes  The function of individual genes is a matter of dispute. Clearly living cells are complex. The inner machinations of cells are not visible. Gene functionality is commonly inferred indirectly by removing a gene and test the cells behavior.  This is time consuming and not very precise. As you can see in the dataset there is still much to be done to fully understand even single cell yeasts. The provided dataset is allows for a different approach to functional classification of genes. The label files contained in the set correspond a gene to a specific label. The classification is based on the official Gene Onthology associations classification. I simplified the nomenclature. Gene functionality is usually given in a hierarchical structure. [inside cell --> cytoplasma --> associated to complex A ... ] I'm only keeping high level associations and using readable terms instead of GO terms.  I'll extend if people are interested.  Labels  CC    labels  concern Cellular Component.  Where the gene is within a cell.  goes into details of found associations.  the term 'cellular_component' should be seen as  E.g the label 'cellular_component' is synonymous with 'unknown location' . CC is the easiest label to attach to a gene. It is the one that can be studied the easiest. Still there are many genes missing.   MF    labels concern Molecular Function. What is the gene doing. [upcoming] BP     labels concern Biological Processes.  What is the genes involvement. [upcoming] The core interest here is whether it is possible to improve the genes classification by modeling the data. A common assumption says that genes that are expressed in the same conditions have functional relations.  There are a bunch of possible applications out there many of which are limited by our current state of knowledge on the complex systems we observe or fail to do so. Bringing biology into the realm of data science is an ongoing effort. Having a better insight into the data might very well help.  Note  The dataset is real and therefore noisy the labels are incomplete even though I'm using the current state of the art. That is how much is known. Using expression levels for classification was already attempted by softwares like SPELL  (Serial Pattern of Expression Levels Locator).  Acknowledgements I guess I own the dataset.  It is a by product of another project of mine. If someone is interested in publishing this contact me.   Inspiration Unraveling genetic mechanisms is a complex but rewarding task. Humans and yeast are quite similar in many ways. So apart from the fact that we use it for food and medicine we might actually use knowledge gained from yeast eventually for studying diseases.   Again any feedback is welcome Enjoy CE,ID:primary:secondary:,string:string:string:,genomics
Significant Earthquakes 1965-2016 , US Geological Survey , www.kaggle.com/usgs/earthquake-database , Fri Jan 27 2017 01:44:10 GMT+0530 (IST) , Date time and location of all earthquakes with magnitude of 5.5 or higher ,3149, earth sciences- ,Context The National Earthquake Information Center (NEIC) determines the location and size of all significant earthquakes that occur worldwide and disseminates this information immediately to national and international agencies scientists critical facilities and the general public. The NEIC compiles and provides to scientists and to the public an extensive seismic database that serves as a foundation for scientific research through the operation of modern digital national and global seismograph networks and cooperative international agreements. The NEIC is the national data center and archive for earthquake information. Content This dataset includes a record of the date time location depth magnitude and source of every earthquake with a reported magnitude 5.5 or higher since 1965. Start a new kernel,Date:Time:Latitude:Longitude:Type:Depth:Depth Error:Depth Seismic Stations:Magnitude:Magnitude Type:Magnitude Error:Magnitude Seismic Stations:Azimuthal Gap:Horizontal Distance:Horizontal Error:Root Mean Square:ID:Source:Location Source:Magnitude Source:Status:,dateTime:dateTime:numeric:numeric:string:numeric:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:,disasters
55000+ Song Lyrics , Sergey Kuznetsov , www.kaggle.com/mousehead/songlyrics , Thu Jan 05 2017 22:11:30 GMT+0530 (IST) , Lyrics for 55000+ songs in English from LyricsFreak ,1773, languages- music- linguistics- ,Context These are the lyrics for 57650 songs. They can be used for Natural Language Processing purposes such as clustering of the words with similar meanings or predicting artist by the song. The dataset can be expanded with some more features for more advanced research like sentiment analysis. The data is not modified only slightly cleaned which gives a lot of freedom to devise your own applications. Mining I have mined this dataset as a corpus for my NLP studies. However before performing any transformation to bag-of-words or bag-of-N-grams I decided to share the data. The data has been acquired from LyricsFreak through scraping. Then I did some very basic work on removing inconvenient data non-English lyrics extremely short and extremely long lyrics lyrics with non-ASCII symbols. However there's still work to be done in terms of data preparation. Content The dataset contains 4 columns  Artist Song Name Link to a webpage with the song (for reference). This is to be concatenated with http//www.lyricsfreak.com to form a real URL. Lyrics of the song unmodified.  Acknowledgements I would like to acknowledge LyricsFreak which is the direct source of the data.,artist:song:link:text:,string:string:string:string:,music
Eye Gaze , 4Quant , www.kaggle.com/4quant/eye-gaze , Tue May 02 2017 17:40:22 GMT+0530 (IST) , Simulated and Real datasets of eyes looking in different directions ,372, psychometrics- ,Context The main reason for making this dataset is the publication of the paper Learning from Simulated and Unsupervised Images through Adversarial Training and the idea of the SimGAN. The dataset and kernels should make it easier to get started making SimGAN networks and testing them out and comparing them to other approaches like KNN GAN InfoGAN and the like.  Source The synthetic images were generated with the windows version of UnityEyes http//www.cl.cam.ac.uk/research/rainbow/projects/unityeyes/tutorial.html The real images were taken from https//www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/gaze-based-human-computer-interaction/appearance-based-gaze-estimation-in-the-wild-mpiigaze/ which can be cited like this Appearance-based Gaze Estimation in the Wild X. Zhang Y. Sugano M. Fritz and A. Bulling Proc. of the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR) June p.4511-4520 (2015). Challenges Enhancement One of the challenges (as covered in the paper) is enhancing the simulated images by using the real images. One possible approach is using the SimGAN which is implemented for reference in one of the notebooks. There are a number of other approaches (pix2pix CycleGAN) which could have interesting results. Gaze Detection The synthetic dataset has the gaze information since it was generated by UnityEyes with a predefined look-vector. The overview notebook covers what this vector means and how each component can be interpreted. It would be very useful to have a simple quick network for automatically generating this look vector from an image,:caruncle_2d:eye_region_details:head_pose:interior_margin_2d:iris_2d:lighting_details:path:eye_details:image_path:,numeric:string:string:string:string:string:string:string:string:string:,artificial intelligence
The Marvel Universe Social Network , Claudio Sanhueza , www.kaggle.com/csanhueza/the-marvel-universe-social-network , Sat Jan 28 2017 16:58:49 GMT+0530 (IST) , An artificial social network of heroes ,674, popular culture- comics- ,"The Marvel Universe Marvel Comics originally called Timely Comics Inc. has been publishing comic books for several decades. ""The Golden Age of Comics"" name that was given due to the popularity of the books during the first years was later followed by a period of decline of interest in superhero stories due to World War ref. In 1961 Marvel relaunched its superhero comic books publishing line. This new era started what has been known as the Marvel Age of Comics. Characters created during this period such as Spider-Man the Hulk the Fantastic Four and the X-Men together with those created during the Golden Age such as Captain America are known worldwide and have become cultural icons during the last decades. Later Marvel's characters popularity has been revitalized even more due to the release of several recent movies which recreate the comic books using spectacular modern special effects. Nowadays it is possible to access the content of the comic books via a digital platform created by Marvel where it is possible to subscribe monthly or yearly to get access to the comics. More information about the Marvel Universe can be found here. Content The dataset contains heroes and comics and the relationship between them. The dataset is divided into three files  nodes.csv Contains two columns (node type) indicating the name and the type (comic hero) of the nodes. edges.csv Contains two columns (hero comic) indicating in which comics the heroes appear. hero-edge.csv Contains the network of heroes which appear together in the comics. This file was originally taken from http//syntagmatic.github.io/exposedata/marvel/  Past Research (Acknowledgements) The Marvel Comics character collaboration graph was originally constructed by Cesc Rosselló Ricardo Alberich and Joe Miro from the University of the Balearic Islands. They compare the characteristics of this universe to real-world collaboration networks such as the Hollywood network or the one created by scientists who work together in producing research papers. Their original sources can be found here. With this dataset the authors published the paper titled ""Marvel Universe looks almost like a real social network"".",hero:comic:,string:string:,books and comics
Federal Emergencies and Disasters 1953-Present , Federal Emergency Management Agency , www.kaggle.com/fema/federal-disasters , Sun Feb 19 2017 08:00:20 GMT+0530 (IST) , Has the number of emergencies declared by the president risen over time? ,185, ecology- history- ,Context The president can declare an emergency for any occasion or instance when the President determines federal assistance is needed.  Emergency declarations supplement State and local or Indian tribal government efforts in providing emergency services such as the protection of lives property public health and safety or to lessen or avert the threat of a catastrophe in any part of the United States.  The total amount of assistance provided for in a single emergency may not exceed $5 million. The president can declare a major disaster for any natural event including any hurricane tornado storm high water wind-driven water tidal wave tsunami earthquake volcanic eruption landslide mudslide snowstorm or drought or regardless of cause fire flood or explosion that the President determines has caused damage of such severity that it is beyond the combined capabilities of state and local governments to respond.  A major disaster declaration provides a wide range of federal assistance programs for individuals and public infrastructure including funds for both emergency and permanent work. Content This dataset includes a record for every federal emergency or disaster declared by the President of the United States since 1953. Acknowledgements The disaster database was published by the Federal Emergency Management Agency with data from the National Emergency Management Information System. Inspiration What type of disaster is the most commonly declared by FEMA? Which disasters or emergencies have lasted the longest? What disaster was declared in the most counties or states? Has the number of disasters declared by FEMA risen or fallen over time?,Declaration Number:Declaration Type:Declaration Date:State:County:Disaster Type:Disaster Title:Start Date:End Date:Close Date:Individual Assistance Program:Individuals & Households Program:Public Assistance Program:Hazard Mitigation Program:,string:string:dateTime:string:string:string:string:dateTime:dateTime:dateTime:string:string:string:string:,disasters
Groundhog Day Forecasts and Temperatures , Punxsutawney Groundhog Club , www.kaggle.com/groundhogclub/groundhog-day , Wed Feb 01 2017 02:05:23 GMT+0530 (IST) , How accurate is Punxsutawney Phil's winter weather forecast? ,167, climate- cultural mythology- ,Context Thousands gather at Gobbler’s Knob in Punxsutawney Pennsylvania on the second day of February to await the spring forecast from a groundhog known as Punxsutawney Phil. According to legend if Phil sees his shadow the United States is in store for six more weeks of winter weather. But if Phil doesn’t see his shadow the country should expect warmer temperatures and the arrival of an early spring. Acknowledgements The historical weather predictions were provided by the Punxsutawney Groundhog Club and the average monthly temperatures were published by NOAA's National Climatic Data Center.,,,weather and climate
LEGO Database , Rachael Tatman , www.kaggle.com/rtatman/lego-database , Fri Jul 14 2017 23:30:24 GMT+0530 (IST) , The LEGO Parts/Sets/Colors and Inventories of every official LEGO set ,1189, games and toys- ,Context LEGO is a popular brand of toy building bricks. They are often sold in sets with in order to build a specific object. Each set contains a number of parts in different shapes sizes and colors. This database contains information on which parts are included in different LEGO sets. It was originally compiled to help people who owned some LEGO sets already figure out what other sets they could build with the pieces they had. Content This dataset contains the LEGO Parts/Sets/Colors and Inventories of every official LEGO set in the Rebrickable database. These files are current as of July 2017. If you need it to be more recent data you can use Rebrickable’s API which provides up to date data and additional features. Acknowledgements This dataset was compiled by Rebrickable which is a website to help identify what  LEGO sets can be built given bricks and pieces from other LEGO sets. You can use these files for any purpose.  Inspiration This is a very rich dataset that offers lots of rooms for exploration especially since the “sets” file includes the year in which a set was first released.  * How have the size of sets changed over time? * What colors are associated with witch themes? Could you predict which theme a set is from just by the bricks it contains? * What sets have the most-used pieces in them? What sets have the rarest pieces in them? * Have the colors of LEGOs included in sets changed over time?,id:name:rgb:is_trans:,numeric:string:numeric:string:,board games
House Sales in King County USA , harlfoxem , www.kaggle.com/harlfoxem/housesalesprediction , Thu Aug 25 2016 21:22:49 GMT+0530 (IST) , Predict house price using regression ,10883, home- finance- ,This dataset contains house sale prices for King County which includes Seattle. It includes homes sold between May 2014 and May 2015. It's a great dataset for evaluating simple regression models.,id:date:price:bedrooms:bathrooms:sqft_lot:floors:waterfront:view:condition:grade:sqft_above:sqft_basement:yr_built:yr_renovated:zipcode:lat:long:sqft_living15:sqft_lot15:sqft_living:,numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:dateTime:,real estate
Indian Premier League , Manas , www.kaggle.com/manasgarg/ipl , Sun Nov 06 2016 05:35:35 GMT+0530 (IST) , Data for all the IPL seasons ,6880, cricket- india- ,This is the ball by ball data of all the IPL cricket matches till season 9.   Source http//cricsheet.org/ (data is available on this website in the YAML format. This is converted to CSV format by the contributors)  The dataset contains 2 files deliveries.csv and matches.csv. matches.csv contains details related to the match such as location contesting teams umpires results etc. deliveries.csv is the ball-by-ball data of all the IPL matches including data of the batting team batsman bowler non-striker  runs scored etc.  Research scope Predicting the winner of the next season of IPL based on past data  Visualizations Perspectives etc.,,,cricket
Synthetic Financial Datasets For Fraud Detection , TESTIMON @ NTNU , www.kaggle.com/ntnu-testimon/paysim1 , Mon Apr 03 2017 14:10:34 GMT+0530 (IST) , Synthetic datasets generated by the PaySim mobile money simulator ,2910, crime- finance- ,"Context There is a lack of public available datasets on financial services and specially in the emerging mobile money transactions domain. Financial datasets are important to many researchers and in particular to us performing research in the domain of fraud detection. Part of the problem is the intrinsically private nature of financial transactions that leads to no publicly available datasets. We present a synthetic dataset generated using the simulator called PaySim as an approach to such a problem. PaySim uses aggregated data from the private dataset to generate a synthetic dataset that resembles the normal operation of transactions and injects malicious behaviour to later evaluate the performance of fraud detection methods. Content PaySim simulates mobile money transactions based on a sample of real transactions extracted from one month of financial logs from a mobile money service implemented in an African country. The original logs were provided by a multinational company who is  the provider of the mobile financial service which is currently running in more than 14 countries all around the world. This synthetic dataset is scaled down 1/4 of the original dataset and it is created just for Kaggle. Headers This is a sample of 1 row with headers explanation 1PAYMENT1060.31C4292141171089.028.69M15916544620.00.000 step - maps a unit of time in the real world. In this case 1 step is 1 hour of time. Total steps 744 (30 days simulation). type - CASH-IN CASH-OUT DEBIT PAYMENT  and TRANSFER. amount -  amount of the transaction in local currency. nameOrig - customer who started the transaction oldbalanceOrg - initial balance before the transaction newbalanceOrig - new balance after the transaction nameDest - customer who is the recipient of the transaction oldbalanceDest - initial balance recipient before the transaction. Note that there is not information for customers that start with M (Merchants). newbalanceDest - new balance recipient after the transaction. Note that there is not information for customers that start with M (Merchants). isFraud - This is the transactions made by the fraudulent agents inside the simulation. In this specific dataset the fraudulent behavior of the agents aims to profit by taking control or customers accounts and try to empty the funds by transferring to another account and then cashing out of the system. isFlaggedFraud - The business model aims to control massive transfers from one account to another and flags illegal attempts. An illegal attempt in this dataset is an attempt to transfer more than 200.000 in a single transaction. Past Research There are 5 similar files that contain the run of 5 different scenarios. These files are better explained at my PhD thesis chapter 7 (PhD Thesis Available here http//urn.kb.se/resolve?urn=urnnbnsebth-12932). We ran PaySim several times using random seeds for 744 steps representing each hour of one month of real time which matches the original logs. Each run took around 45 minutes on an i7 intel processor with 16GB of RAM. The final result of a run contains approximately 24 million of financial records divided into the 5 types of categories CASH-IN CASH-OUT DEBIT PAYMENT  and TRANSFER. Acknowledgements This work is part of the research project ”Scalable resource-efficient systems for big data analytics” funded by the Knowledge Foundation (grant 20140032) in Sweden. Please refer to this dataset using the following citations  PaySim first paper of the simulator E. A. Lopez-Rojas  A. Elmir and S. Axelsson. ""PaySim A financial mobile money simulator for fraud detection"". In The 28th European Modeling and Simulation Symposium-EMSS Larnaca Cyprus. 2016",step:type:amount:nameOrig:oldbalanceOrg:newbalanceOrig:nameDest:oldbalanceDest:newbalanceDest:isFraud:isFlaggedFraud:,numeric:string:numeric:string:numeric:numeric:string:numeric:numeric:numeric:numeric:,crime
80 Cereals , Chris Crawford , www.kaggle.com/crawford/80-cereals , Sat Aug 19 2017 00:51:58 GMT+0530 (IST) , Nutrition data on 80 cereal products ,348, food and drink- ,Context If you like to eat cereal do yourself a favor and avoid this dataset at all costs. After seeing these data it will never be the same for me to eat Fruity Pebbles again. Content Fields in the dataset  Name Name of cereal  mfr Manufacturer of cereal  A = American Home Food Products;  G = General Mills K = Kelloggs N = Nabisco P = Post Q = Quaker Oats R = Ralston Purina  type  cold  hot  calories calories per serving  protein grams of protein  fat grams of fat  sodium milligrams of sodium  fiber grams of dietary fiber  carbo grams of complex carbohydrates  sugars grams of sugars  potass milligrams of potassium  vitamins vitamins and minerals - 0 25 or 100 indicating the typical percentage of FDA recommended  shelf display shelf (1 2 or 3 counting from the floor)  weight weight in ounces of one serving  cups number of cups in one serving  rating a rating of the cereals (Possibly from Consumer Reports?)  Acknowledgements These datasets have been gathered and cleaned up by Petra Isenberg Pierre Dragicevic and Yvonne Jansen. The original source can be found here This dataset has been converted to CSV Inspiration Eat too much sugary cereal? Ruin your appetite with this dataset!,name:mfr:type:calories:protein:fat:sodium:fiber:carbo:sugars:potass:vitamins:shelf:weight:cups:rating:,string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,food and nutrition
Annotated Corpus for Named Entity Recognition , Abhinav Walia , www.kaggle.com/abhinavwalia95/entity-annotated-corpus , Thu Sep 21 2017 19:26:00 GMT+0530 (IST) , Corpus (CoNLL 2002) annotated with IOB and POS tags ,696, linguistics- ,"Context Annotated Corpus for Named Entity Recognition using GMB(Groningen Meaning Bank) corpus for entity classification with enhanced and popular features by Natural Language Processing applied to the data set.  Tip Use Pandas Dataframe to load dataset if using Python for convenience.  Content This is the extract from GMB corpus which is tagged annotated and built specifically to train the classifier to predict named entities such as name location etc.  Number of tagged entities  'O' 1146068' geo-nam' 58388 'org-nam' 48034 'per-nam' 23790 'gpe-nam' 20680 'tim-dat' 12786 'tim-dow' 11404 'per-tit' 9800 'per-fam' 8152 'tim-yoc' 5290 'tim-moy' 4262 'per-giv' 2413 'tim-clo' 891 'art-nam' 866 'eve-nam' 602 'nat-nam' 300 'tim-nam' 146 'eve-ord' 107 'per-ini' 60 'org-leg' 60 'per-ord' 38 'tim-dom' 10 'per-mid' 1 'art-add' 1  Essential info about entities  geo = Geographical Entity org = Organization per = Person gpe = Geopolitical Entity tim = Time indicator art = Artifact eve = Event nat = Natural Phenomenon  Total Words Count = 1354149 Target Data Column ""tag"" Inspiration This dataset is getting more interested because of more features added to the recent version of this dataset. Also it helps to create a broad view of Feature Engineering with respect to this dataset. Why this dataset is helpful or playful? It might not sound so interested for earlier versions but when you are able to pick intent and custom named entities from your own sentence with more features then it is getting interested and helps you solve real business problems(like picking entities from Electronic Medical Records etc) Please feel free to ask questions do variations and let's play together!",,,grammar
CAT Scan Localization , UCI Machine Learning , www.kaggle.com/uciml/ct-slice-localization , Thu Sep 07 2017 03:31:03 GMT+0530 (IST) , 384 features extracted from CT images ,35, human medicine- biology- health- ,"Context This dataset consists of 384 features extracted from CT images. The class variable is numeric and denotes the relative location of the CT slice on the axial axis of the human body. The data was retrieved from a set of 53500 CT images from 74 different  patients (43 male 31 female).   Content Each CT slice is described by two histograms in polar space. The first histogram describes the location of bone structures in the image the second the location of air inclusions inside of the body. Both histograms are concatenated to form the final feature vector. Bins that are outside of the image are marked with the value -0.25.  The class variable (relative location of an image on the axial axis) was constructed by manually annotating up to 10 different distinct landmarks in each CT Volume with known location. The location of slices in between landmarks was interpolated. Field Descriptions  patientId Each ID identifies a different patient  value[1-241] Histogram describing bone structures  value[242 - 385] Histogram describing air inclusions  386 Relative location of the image on the axial axis (class value).   Values are in the range [0; 180] where 0 denotes the top of the head and 180 the soles of the feet. Acknowledgements Original dataset was downloaded from UCI Machine learning Repository Lichman M. (2013). UCI Machine Learning Repository [http//archive.ics.uci.edu/ml]. Irvine CA University of California School of Information and Computer Science. Banner image acknowledgement   Self Portre on cat scan 1997 Title ""Soon I will be there"" Date 8 April 1997 Author   Sérgio Valle Duarte License CC BY 3.0 Source Wikipedia  Inspiration Predict the relative location of CT slices on the axial axis",patientId:value0:value1:value2:value3:value4:value5:value6:value7:value8:value9:value10:value11:value12:value13:value14:value15:value16:value17:value18:value19:value20:value21:value22:value23:value24:value25:value26:value27:value28:value29:value30:value31:value32:value33:value34:value35:value36:value37:value38:value39:value40:value41:value42:value43:value44:value45:value46:value47:value48:value49:value50:value51:value52:value53:value54:value55:value56:value57:value58:value59:value60:value61:value62:value63:value64:value65:value66:value67:value68:value69:value70:value71:value72:value73:value74:value75:value76:value77:value78:value79:value80:value81:value82:value83:value84:value85:value86:value87:value88:value89:value90:value91:value92:value93:value94:value95:value96:value97:value98:value99:value100:value101:value102:value103:value104:value105:value106:value107:value108:value109:value110:value111:value112:value113:value114:value115:value116:value117:value118:value119:value120:value121:value122:value123:value124:value125:value126:value127:value128:value129:value130:value131:value132:value133:value134:value135:value136:value137:value138:value139:value140:value141:value142:value143:value144:value145:value146:value147:value148:value149:value150:value151:value152:value153:value154:value155:value156:value157:value158:value159:value160:value161:value162:value163:value164:value165:value166:value167:value168:value169:value170:value171:value172:value173:value174:value175:value176:value177:value178:value179:value180:value181:value182:value183:value184:value185:value186:value187:value188:value189:value190:value191:value192:value193:value194:value195:value196:value197:value198:value199:value200:value201:value202:value203:value204:value205:value206:value207:value208:value209:value210:value211:value212:value213:value214:value215:value216:value217:value218:value219:value220:value221:value222:value223:value224:value225:value226:value227:value228:value229:value230:value231:value232:value233:value234:value235:value236:value237:value238:value239:value240:value241:value242:value243:value244:value245:value246:value247:value248:value249:value250:value251:value252:value253:value254:value255:value256:value257:value258:value259:value260:value261:value262:value263:value264:value265:value266:value267:value268:value269:value270:value271:value272:value273:value274:value275:value276:value277:value278:value279:value280:value281:value282:value283:value284:value285:value286:value287:value288:value289:value290:value291:value292:value293:value294:value295:value296:value297:value298:value299:value300:value301:value302:value303:value304:value305:value306:value307:value308:value309:value310:value311:value312:value313:value314:value315:value316:value317:value318:value319:value320:value321:value322:value323:value324:value325:value326:value327:value328:value329:value330:value331:value332:value333:value334:value335:value336:value337:value338:value339:value340:value341:value342:value343:value344:value345:value346:value347:value348:value349:value350:value351:value352:value353:value354:value355:value356:value357:value358:value359:value360:value361:value362:value363:value364:value365:value366:value367:value368:value369:value370:value371:value372:value373:value374:value375:value376:value377:value378:value379:value380:value381:value382:value383:reference:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,diagnostics
World University Rankings , Myles O'Neill , www.kaggle.com/mylesoneill/world-university-rankings , Wed Sep 28 2016 02:22:01 GMT+0530 (IST) , Investigate the best universities in the world ,17343, universities and colleges- ,Of all the universities in the world which are the best? Ranking universities is a difficult political and controversial practice. There are hundreds of different national and international university ranking systems many of which disagree with each other. This dataset contains three global university rankings from very different places. University Ranking Data The Times Higher Education World University Ranking is widely regarded as one of the most influential and widely observed university measures. Founded in the United Kingdom in 2010 it has been criticized for its commercialization and for undermining non-English-instructing institutions. The Academic Ranking of World Universities also known as the Shanghai Ranking is an equally influential ranking. It was founded in China in 2003 and has been criticized for focusing on raw research power and for undermining humanities and quality of instruction. The Center for World University Rankings is a less well know listing that comes from Saudi Arabia it was founded in 2012.  How do these rankings compare to each other? Are the various criticisms levied against these rankings fair or not? How does your alma mater fare against the world?  Supplementary Data To further extend your analyses we've also included two sets of supplementary data.  The first of these is a set of data on educational attainment around the world. It comes from The World Data Bank and comprises information from the UNESCO Institute for Statistics and the Barro-Lee Dataset. How does national educational attainment relate to the quality of each nation's universities? The second supplementary dataset contains information about public and private direct expenditure on education across nations. This data comes from the National Center for Education Statistics. It represents expenditure as a percentage of gross domestic product. Does spending more on education lead to better international university rankings?,world_rank:institution:country:national_rank:quality_of_education:alumni_employment:quality_of_faculty:publications:influence:citations:broad_impact:patents:score:year:,numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:,universities and colleges
IMDB data from 2006 to 2016 , PromptCloud , www.kaggle.com/PromptCloudHQ/imdb-data , Mon Jun 26 2017 13:02:04 GMT+0530 (IST) , A data set of 1000 popular movies on IMDB in the last 10 years ,767, film- ,Here's a data set of 1000 most popular movies on IMDB in the last 10 years. The data points included are Title Genre Description Director  Actors Year Runtime Rating Votes Revenue Metascrore Feel free to tinker with it and derive interesting insights.,Rank:Title:Genre:Description:Director:Actors:Year:Runtime (Minutes):Rating:Votes:Revenue (Millions):Metascore:,numeric:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:,movies
Stack Overflow Tag Network , Stack Overflow , www.kaggle.com/stackoverflow/stack-overflow-tag-network , Fri Sep 29 2017 02:45:07 GMT+0530 (IST) , Network (links and nodes) of Stack Overflow tags based on Developer Stories ,149, internet- programming languages- networks- ,Context On the data team at Stack Overflow we spend a lot of time and energy thinking about tech ecosystems and how technologies are related to each other.  One way to get at this idea of relationships between technologies is tag correlations how often technology tags at Stack Overflow appear together relative to how often they appear separately. One place we see developers using tags at Stack Overflow is on their Developer Stories or professional profiles/CVs/resumes. If we are interested in how technologies are connected and how they are used together developers' own descriptions of their work and careers is a great place to get that. Content A network of technology tags from Developer Stories on the Stack Overflow online developer community website. This is organized as two tables stack_network_links contains links of the network the source and target tech tags plus the value of the the link between each pair stack_network_nodes contains nodes of the network the name of each node which group that node belongs to (calculated via a cluster walktrap) and a node size based on how often that technology tag is used Acknowledgements All Stack Overflow user contributions are licensed under CC-BY-SA 3.0 with attribution required.,source:target:value:,string:string:numeric:,programming
2015 Flight Delays and Cancellations , Department of Transportation , www.kaggle.com/usdot/flight-delays , Fri Feb 10 2017 03:06:00 GMT+0530 (IST) , Which airline should you fly on to avoid significant delays? ,6519, aviation- ,Context The U.S. Department of Transportation's (DOT) Bureau of Transportation Statistics tracks the on-time performance of domestic flights operated by large air carriers. Summary information on the number of on-time delayed canceled and diverted flights is published in DOT's monthly Air Travel Consumer Report and in this dataset of 2015 flight delays and cancellations. Acknowledgements The flight delay and cancellation data was collected and published by the DOT's Bureau of Transportation Statistics.,IATA_CODE:AIRLINE:,string:string:,airways
Epicurious - Recipes with Rating and Nutrition , HugoDarwood , www.kaggle.com/hugodarwood/epirecipes , Tue Feb 21 2017 15:27:30 GMT+0530 (IST) , Recipes from Epicurious by rating nutritional content and categories ,1379, food and drink- nutrition- ,Context I created this dataset to explore different factors affecting people's enjoyment of food and/or cooking! Content Over 20k recipes listed by recipe rating nutritional information and assigned category (sparse). I may later upload a version binned by recipe creation date and also including recipe ingredients. Use the 'full_format_recipes.json' file to interact with all recipe data 'epi_r.csv' drops ingredients and directions in favour of sparse category dummies.  Acknowledgements Recipe information lifted from http//www.epicurious.com/recipes-menus,"title:rating:calories:protein:fat:sodium:#cakeweek:#wasteless:22-minute meals:3-ingredient recipes:30 days of groceries:advance prep required:alabama:alaska:alcoholic:almond:amaretto:anchovy:anise:anniversary:anthony bourdain:aperitif:appetizer:apple:apple juice:apricot:arizona:artichoke:arugula:asian pear:asparagus:aspen:atlanta:australia:avocado:back to school:backyard bbq:bacon:bake:banana:barley:basil:bass:bastille day:bean:beef:beef rib:beef shank:beef tenderloin:beer:beet:bell pepper:berry:beverly hills:birthday:biscuit:bitters:blackberry:blender:blue cheese:blueberry:boil:bok choy:bon appétit:bon app��tit:boston:bourbon:braise:bran:brandy:bread:breadcrumbs:breakfast:brie:brine:brisket:broccoli:broccoli rabe:broil:brooklyn:brown rice:brownie:brunch:brussel sprout:buffalo:buffet:bulgaria:bulgur:burrito:butter:buttermilk:butternut squash:butterscotch/caramel:cabbage:cake:california:calvados:cambridge:campari:camping:canada:candy:candy thermometer:cantaloupe:capers:caraway:cardamom:carrot:cashew:casserole/gratin:cauliflower:caviar:celery:chambord:champagne:chard:chartreuse:cheddar:cheese:cherry:chestnut:chicago:chicken:chickpea:chile:chile pepper:chili:chill:chive:chocolate:christmas:christmas eve:cilantro:cinco de mayo:cinnamon:citrus:clam:clove:cobbler/crumble:cocktail:cocktail party:coconut:cod:coffee:coffee grinder:cognac/armagnac:collard greens:colorado:columbus:condiment:condiment/spread:connecticut:cook like a diner:cookbook critic:cookie:cookies:coriander:corn:cornmeal:costa mesa:cottage cheese:couscous:crab:cranberry:cranberry sauce:cream cheese:créme de cacao:crêpe:cr��me de cacao:cuba:cucumber:cumin:cupcake:currant:curry:custard:dairy:dairy free:dallas:date:deep-fry:denver:dessert:digestif:dill:dinner:dip:diwali:dominican republic:dorie greenspan:double boiler:dried fruit:drink:drinks:duck:easter:eau de vie:edible gift:egg:egg nog:eggplant:egypt:emeril lagasse:endive:engagement party:england:entertaining:epi + ushg:epi loves the microwave:escarole:fall:family reunion:fat free:father's day:fennel:feta:fig:fish:flaming hot summer:flat bread:florida:fontina:food processor:fortified wine:fourth of july:france:frangelico:frankenrecipe:freeze/chill:freezer food:friendsgiving:frittata:fritter:frozen dessert:fruit:fruit juice:fry:game:garlic:georgia:germany:gin:ginger:goat cheese:goose:gouda:gourmet:graduation:grains:grand marnier:granola:grape:grapefruit:grappa:green bean:green onion/scallion:grill:grill/barbecue:ground beef:ground lamb:guam:guava:haiti:halibut:halloween:ham:hamburger:hanukkah:harpercollins:hawaii:hazelnut:healdsburg:healthy:herb:high fiber:hollywood:hominy/cornmeal/masa:honey:honeydew:hors d'oeuvre:horseradish:hot drink:hot pepper:house & garden:house cocktail:houston:hummus:ice cream:ice cream machine:iced coffee:iced tea:idaho:illinois:indiana:iowa:ireland:israel:italy:jalapeño:jam or jelly:jamaica:japan:jerusalem artichoke:juicer:jícama:kahlúa:kale:kansas:kansas city:kentucky:kentucky derby:kid-friendly:kidney friendly:kirsch:kitchen olympics:kiwi:kosher:kosher for passover:kumquat:kwanzaa:labor day:lamb:lamb chop:lamb shank:lancaster:las vegas:lasagna:leafy green:leek:legume:lemon:lemon juice:lemongrass:lentil:lettuce:lima bean:lime:lime juice:lingonberry:liqueur:lobster:london:long beach:los angeles:louisiana:louisville:low cal:low carb:low cholesterol:low fat:low sodium:low sugar:low/no sugar:lunar new year:lunch:lychee:macadamia nut:macaroni and cheese:maine:mandoline:mango:maple syrup:mardi gras:margarita:marinade:marinate:marsala:marscarpone:marshmallow:martini:maryland:massachusetts:mayonnaise:meat:meatball:meatloaf:melon:mexico:mezcal:miami:michigan:microwave:midori:milk/cream:minneapolis:minnesota:mint:mississippi:missouri:mixer:molasses:monterey jack:mortar and pestle:mother's day:mozzarella:muffin:mushroom:mussel:mustard:mustard greens:nancy silverton:nebraska:nectarine:new hampshire:new jersey:new mexico:new orleans:new year's day:new year's eve:new york:no meat, no problem:no sugar added:no-cook:non-alcoholic:noodle:north carolina:nut:nutmeg:oat:oatmeal:octopus:ohio:oklahoma:okra:oktoberfest:olive:omelet:one-pot meal:onion:orange:orange juice:oregano:oregon:organic:orzo:oscars:oyster:pacific palisades:paleo:pan-fry:pancake:papaya:paprika:parade:paris:parmesan:parsley:parsnip:party:pasadena:passion fruit:passover:pasta:pasta maker:pastry:pea:peach:peanut:peanut butter:peanut free:pear:pecan:pennsylvania:pepper:pernod:persian new year:persimmon:peru:pescatarian:philippines:phyllo/puff pastry dough:pickles:picnic:pie:pine nut:pineapple:pistachio:pittsburgh:pizza:plantain:plum:poach:poblano:poker/game night:pomegranate:pomegranate juice:poppy:pork:pork chop:pork rib:pork tenderloin:port:portland:pot pie:potato:potato salad:potluck:poultry:poultry sausage:pressure cooker:prosciutto:providence:prune:pumpkin:punch:purim:quail:quiche:quick & easy:quick and healthy:quince:quinoa:rabbit:rack of lamb:radicchio:radish:raisin:ramadan:ramekin:raspberry:raw:red wine:rhode island:rhubarb:rice:ricotta:roast:root vegetable:rosemary:rosh hashanah/yom kippur:rosé:rub:rum:rutabaga:rye:saffron:sage:sake:salad:salad dressing:salmon:salsa:san francisco:sandwich:sandwich theory:sangria:santa monica:sardine:sauce:sausage:sauté:scallop:scotch:seafood:seattle:seed:self:semolina:sesame:sesame oil:shallot:shavuot:shellfish:sherry:shower:shrimp:side:simmer:skewer:slow cooker:smoker:smoothie:snapper:sorbet:soufflé/meringue:soup/stew:sour cream:sourdough:south carolina:soy:soy free:soy sauce:spain:sparkling wine:spice:spinach:spirit:spring:spritzer:squash:squid:st. louis:st. patrick's day:steak:steam:stew:stir-fry:stock:strawberry:stuffing/dressing:sugar conscious:sugar snap pea:sukkot:summer:super bowl:suzanne goin:sweet potato/yam:swiss cheese:switzerland:swordfish:taco:tailgating:tamarind:tangerine:tapioca:tarragon:tart:tea:tennessee:tequila:tested & improved:texas:thanksgiving:thyme:tilapia:tofu:tomatillo:tomato:tortillas:tree nut:tree nut free:triple sec:tropical fruit:trout:tuna:turnip:utah:valentine's day:vanilla:veal:vegan:vegetable:vegetarian:venison:vermont:vermouth:vinegar:virginia:vodka:waffle:walnut:wasabi:washington:washington, d.c.:watercress:watermelon:wedding:weelicious:west virginia:westwood:wheat/gluten-free:whiskey:white wine:whole wheat:wild rice:windsor:wine:winter:wisconsin:wok:yellow squash:yogurt:yonkers:yuca:zucchini:cookbooks:leftovers:snack:snack week:turkey:",string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,food and nutrition
R Questions from Stack Overflow , Stack Overflow , www.kaggle.com/stackoverflow/rquestions , Tue Sep 26 2017 06:22:03 GMT+0530 (IST) , Full text of Stack Overflow Q&A about the R statistical programming language ,838, linguistics- internet- programming languages- ,Full text of questions and answers from Stack Overflow that are tagged with the r tag useful for natural language processing and community analysis. This is organized as three tables  Questions contains the title body creation date score and owner ID for each R question. Answers contains the body creation date score and owner ID for each of the answers to these questions. The ParentId column links back to the Questions table. Tags contains the tags on each question besides the R tag.  For space reasons only non-deleted and non-closed content are included in the dataset. The dataset contains questions up to 24 September 2017 (UTC). License All Stack Overflow user contributions are licensed under CC-BY-SA 3.0 with attribution required.,Id:OwnerUserId:CreationDate:ParentId:Score:IsAcceptedAnswer:Body:,numeric:numeric:dateTime:numeric:numeric:boolean:string:,programming
Ethereum Historical Data , LiamLarsen , www.kaggle.com/kingburrito666/ethereum-historical-data , Wed Jun 14 2017 02:00:29 GMT+0530 (IST) , All Ethereum data from the start to the June spike 2017 ,1153, history- finance- ,Context The Ethereum blockchain gives a revolutionary way of decentralized applications and provides its own cryptocurrency. Ethereum is a  decentralized platform that runs smart contracts applications that run exactly as programmed without any possibility of downtime censorship fraud or third party interference. These apps run on a custom built blockchain an enormously powerful shared global infrastructure that can move value around and represent the ownership of property. This enables developers to create markets store registries of debts or promises move funds in accordance with instructions given long in the past (like a will or a futures contract) and many other things that have not been invented yet all without a middle man or counterparty risk. Content What you may see in the CSVs are just numbers but there is more to this. Numbers make machine learning easy. I've labeled each column the first in all of them is the day; it may look weird but it makes sense if you look closely.  What are the files? Here's a list of what the files are  All_data if you want to import them all at once instead of one at a time. Obviously more computational power needed address is the total amount of addresses in the blockchain on any given day. blocksize is the total blocksize on any given day. etherprice is the price per ether (In USD) on any given day. ethersupplygrowth is the total amount of ethereum in the ether. hashrate is the total hashrate of everyone on the blockchain. marketcap is the total cap of the ethereum cryptocurrency also has ETH -> USD and USD cap total. tx is a number of transactions made on any given day.  Note TIMESTAMP FORMAT How to convert timestamp in python import datetime as dt # The (would-be) timestamp value is below timestamp = 1339521878.04  # Technechly you would iterate through and change them all if you were graphing timeValue = dt.datetime.fromtimestamp(timestamp) #Year month day hour minute second print(timeValue.strftime('%Y-%m-%d %H%M%S'))  Acknowledgements MR. Vitalik Buterin. co-founder of Ethereum and as a co-founder of Bitcoin Magazine. Hit a brother up 0x516976cE81751eBe077Ca01C57B97c9665b0e10b Will be updating every month with new Ethereum history!,timestamp:total_addresses:,numeric:numeric:,blockchain and crytocurrencies
WUZZUF Job Posts (2014-2016) , WUZZUF , www.kaggle.com/WUZZUF/wuzzuf-job-posts , Tue Apr 11 2017 14:41:52 GMT+0530 (IST) , Explore jobs and job seekers applications on WUZZUF (2014-2016) ,215, employment- ,Context One of the main challenges in any marketplace business is achieving the balance between demand and supply. At WUZZUF we optimize for demand relevance and quality while connecting employers with the matching applicants and recommending relevant jobs to the job seekers.  Content The dataset includes  Wuzzuf_Job_Posts_Sample  a sample of jobs posted on WUZZUF during 2014-2016. Wuzzuf_Applications_Sample  the corresponding applications  (Excluding some entries).   Note  The jobs are mainly in Egypt but other locations are included. Exploration Ideas There are several areas to explore including but not limited to   Correlations between different features Salaries trends Insights about supply/demand Growth opportunities Data quality ,id:user_id:job_id:app_date:,numeric:string:string:dateTime:,online information
Oil Pipeline Accidents 2010-Present , Department of Transportation , www.kaggle.com/usdot/pipeline-accidents , Wed Feb 08 2017 23:06:24 GMT+0530 (IST) , Causes injuries/fatalities and costs of pipeline leaks and spills ,901, environment- energy- ,Content This database includes a record for each oil pipeline leak or spill reported to the Pipeline and Hazardous Materials Safety Administration since 2010. These records include the incident date and time operator and pipeline cause of incident type of hazardous liquid and quantity lost injuries and fatalities and associated costs. Acknowledgements The oil pipeline accident reports were collected and published by the DOT's Pipeline and Hazardous Materials Safety Administration.,Report Number:Supplemental Number:Accident Year:Accident Date/Time:Operator ID:Operator Name:Pipeline/Facility Name:Pipeline Location:Pipeline Type:Liquid Type:Liquid Subtype:Liquid Name:Accident City:Accident County:Accident State:Accident Latitude:Accident Longitude:Cause Category:Cause Subcategory:Unintentional Release (Barrels):Intentional Release (Barrels):Liquid Recovery (Barrels):Net Loss (Barrels):Liquid Ignition:Liquid Explosion:Pipeline Shutdown:Shutdown Date/Time:Restart Date/Time:Public Evacuations:Operator Employee Injuries:Operator Contractor Injuries:Emergency Responder Injuries:Other Injuries:Public Injuries:All Injuries:Operator Employee Fatalities:Operator Contractor Fatalities:Emergency Responder Fatalities:Other Fatalities:Public Fatalities:All Fatalities:Property Damage Costs:Lost Commodity Costs:Public/Private Property Damage Costs:Emergency Response Costs:Environmental Remediation Costs:Other Costs:All Costs:,numeric:numeric:numeric:dateTime:numeric:string:string:string:string:string:string:string:string:string:string:numeric:numeric:string:string:numeric:numeric:numeric:numeric:string:string:string:dateTime:dateTime:numeric:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,accidents
Elon Musk's Tweets , Kaan Ulgen , www.kaggle.com/kulgen/elon-musks-tweets , Thu Oct 12 2017 16:11:47 GMT+0530 (IST) , Tweets by @elonmusk from 2012 to 2017 ,83, ,All tweets made by @elonmusk between November 16 2012 and September 29 2017. Columns  row ID Tweet Time Retweet from User ,row ID:Tweet:Time:Retweet from:User:,string:string:dateTime:string:string:,social media
SF Library Usage Data , DataSF , www.kaggle.com/datasf/sf-library-usage-data , Sat Jan 07 2017 04:29:50 GMT+0530 (IST) , Anonymized library usage data ,535, libraries- ,"Context The Integrated Library System (ILS) is composed of bibliographic records including inventoried items and patron records including circulation data. The data is used in the daily operation of the library including circulation online public catalog cataloging acquisitions collection development processing and serials control. This dataset represents the usage of inventoried items by patrons (~420K records). Potential question(s) to get started with!  What attributes are most associated with library activity (# of checkouts # of renewals)? Can you group the data into type of patrons?  What classifiers would you use to predict patron type?  Fields Full data dictionary available here  Patron Type Code - (Numeric) - Type of patron record (adult teen child senior etc.) Some blank. Patron Type Definition - (Text) - Description of patron (adult teen child senior etc.) Total Checkouts - (Numeric) - Total number of items the patron has checked out from the library since the record was created. Total Renewals - (Numeric) - Total number of times the patron has renewed checked-out items. Birth Date - (Text) - Age ranges 0 to 9 years 10 to 19 years 20 to 24 years 25 to 34 years 35 to 44 years 45 to 54 years 55 to 59 years 60 to 64 years 65 to 74 years 75 years and over. Some blank. Home Library Code - (Text) - Default value indicates the branch library where the patron was originally registered. Patrons can change this value if they change their preferred branch. Home Library Definition - (Text) - Description of the branch library where the patron was originally registered. Circulation Active Year - (Text) - Year the patron last checked out library materials or last logged into the library’s subscription databases from a computer outside the library. Notice Preference Code - (Text) - This field is used to indicate the patron’s preferred method of receiving library notices (email print phone). Some blank. Notice Preference Definition - (Text) - Description of  the patron’s preferred method of receiving library notices. Provided Email Address - (Boolean (True/False)) - Indicates whether the patron provided an email address Year Patron Registered - (Text) - Year patron registered with library system. No dates prior to 2003  due to system migration. Outside of County - (Boolean (True/False)) - If a patron's home address is not in San Francisco then flagged as true otherwise false. Supervisor District - (Numeric) - Based on patron address San Francisco Supervisor District.  Note This is an automated field please note that if ""Outside of County"" is true then there will be no supervisor district. Also if the input address was not well-formed the supervisor district will be blank.  We have included the following commonly used geographic shapefile(s) Supervisor Districts as of April 2012 Acknowledgements Data provided by SF Public Library via the San Francisco Open Data Portal at https//data.sfgov.org/d/qzz6-2jup  PDDL 1.0 ODC Public Domain Dedication and Licence (PDDL)  Photo via Flickr Kolya Miller (CC BY-NC-SA 2.0)",Patron Type Code:,numeric:,books and comics
Pokémon for Data Mining and Machine Learning , alopez247 , www.kaggle.com/alopez247/pokemon , Sun Mar 05 2017 20:31:26 GMT+0530 (IST) , (Almost) all Pokémon stats until generation 6: 21 variables per Pokémon ,1692, video games- ,"Context With the rise of the popularity of machine learning this is a good opportunity to share a wide database of the even more popular video-game Pokémon by Nintendo Game freak and Creatures originally released in 1996. Pokémon started as a Role Playing Game (RPG) but due to its increasing popularity its owners ended up producing many TV series manga comics and so on as well as other types of video-games (like the famous Pokémon Go!). This dataset is focused on the stats and features of the Pokémon in the RPGs. Until now (08/01/2017) seven generations of Pokémon have been published. All in all this dataset does not include the data corresponding to the last generation since 1) I created the databased when the seventh generation was not released yet and 2) this database is a modification+extension of the database ""721 Pokemon with stats"" by Alberto Barradas (https//www.kaggle.com/abcsds/pokemon) which does not include (of course) the latest generation either. Content This database includes 21 variables per each of the 721 Pokémon of the first six generations plus the Pokémon ID and its name. These variables are briefly described next  Number. Pokémon ID in the Pokédex. Name. Name of the Pokémon. Type_1. Primary type. Type_2. Second type in case the Pokémon has it. Total. Sum of all the base stats (Health Points Attack Defense Special Attack Special Defense and Speed).  HP. Base Health Points. Attack. Base Attack.   Defense. Base Defense. Sp_Atk. Base Special Attack. Sp_Def. Base Special Defense. Speed. Base Speed. Generation. Number of the generation when the Pokémon was introduced. isLegendary. Boolean that indicates whether the Pokémon is Legendary or not. Color. Color of the Pokémon according to the Pokédex. hasGender. Boolean that indicates if the Pokémon can be classified as female or male. Pr_male. In case the Pokémon has Gender the probability of its being male. The probability of being female is of course 1 minus this value. Egg_Group_1. Egg Group of the Pokémon. Egg_Group_2. Second Egg Group of the Pokémon in case it has two. hasMegaEvolution. Boolean that indicates whether the Pokémon is able to Mega-evolve or not. Height_m. Height of the Pokémon in meters. Weight_kg. Weight of the Pokémon in kilograms. Catch_Rate. Catch Rate. Body_Style. Body Style of the Pokémon according to the Pokédex.  Notes Please note that many Pokémon are multi-form and also some of them can Mega-evolve. I wanted to keep the structure of the dataset as simple and general as possible as well as the Number variable (the ID of the Pokémon) unique. Hence  in the cases of the multi-form Pokémon or the ones capable of Mega-evolve I just chose one of the forms the one I (and my brother) considered the standard and/or the most common. The specific choice for each of this Pokémon are shown below  Mega-Evolutions are not considered as Pokémon. Kyogre Groudon. Primal forms not considered. Deoxis. Only normal form considered. Wormadam. Only plant form considered. Rotom. Only normal form considered the one with types Electric and Ghost. Giratina. Origin form considered. Shaymin. Land form considered. Darmanitan. Standard mode considered. Tornadus Thundurus Landorus. Incarnate form considered. Kyurem. Normal form considered not white or black forms. Meloetta. Aria form considered. Mewstic. Both female and male forms are equal in the considered variables. Aegislash. Shield form considered. Pumpkaboo Gourgeist. Average size considered. Zygarde. 50% form considered. Hoopa. Confined form considered.  Acknowledgements As said at the beginning this database was based on the Kaggle database  ""721 Pokemon with stats"" by Alberto Barradas (https//www.kaggle.com/abcsds/pokemon). The other resources I mainly used are listed below  WikiDex (http//es.pokemon.wikia.com/wiki/WikiDex). Bulbapedia the community driven Pokémon encyclopedia (http//bulbapedia.bulbagarden.net/wiki/Main_Page). Smogon University (http//www.smogon.com/).  Possible future work This dataset can be used with different objectives such as Pokémon clustering trying to find relations or dependencies between the variables and also for supervised classification purposes where the class could be the Primary Type but also many of the other variables. Author Asier López Zorrilla",Name:Number:Type_1:Type_2:Total:HP:Attack:Defense:Sp_Atk:Sp_Def:Speed:Generation:isLegendary:Color:hasGender:Pr_Male:Egg_Group_1:Egg_Group_2:hasMegaEvolution:Height_m:Weight_kg:Catch_Rate:,string:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:boolean:string:boolean:numeric:string:string:boolean:numeric:numeric:numeric:,video games
Bias Media CAT , Jose Berengueres , www.kaggle.com/harriken/bias-media-cat , Sun Oct 15 2017 03:39:09 GMT+0530 (IST) , Sentiment Bias of News on Catalonia Independence Crisis ,57, journalism- cognitive biases- biases- politics- linguistics- ,"What I talk about when I talk about Catalonia This is my grain of sand to help in the Catalonia Independence crisis. The Iberian media has been a key driver to incubate disaffection between Catalonia and Spain. For example a leading newspaper tweeted boycott and Catalonia 9 times in the last month. In this dataset we analyze  tweets  topics of tweets and  sentiment differentials in news    Context The dramatic Catalonia independence crisis offers a unique opportunity to analyze bias in news reporting as opinions on the issue are quite polarized (See #catalanReferendum on twitter). In this dataset we compare how different newspapers (NYT Washington-Post Bloomberg...) have reported one singular specific event in the saga The reply of the Spanish Government to M.H. Puigdemont speech of October 11th of 2017.  For each of the 30 newspapers considered the most popular news article that reported this news is represented as a row in the dataset.  Why this news? The Spanish government published a pdf called (""requerimiento"") which was faxed to Puigdemont. The document requires that  Puigdemont reply in five days a clarification of the meaning of his speech.  This ""clean"" news offers a rare example where the news is about a written document rather than a speech or an action (usually subjected to more interpretations and biases) Content  news_...csv each row contains the news article and its translation to English. all3.csv contains 100k tweets.  Acknowledgements All the journalists who made this dataset possible. Thanks to @DataCanary for helping make the visualizations better! Inspiration I always thought that sentiment analysis was a useless topic but here there is a chance to use an objective measure to show how polarized reporting has become (even if sentiment does not account for fakenews nuances or sarcasm). The linear regressions shows that news written in Spanish language are less positive about the event than the global mean. In other words sentiment seems strongly biased by language. Bias by location of the newspapers is also analyzed.  Disclaimer Note that the 'bing' scale is used. Other scales such AFINN might yield different results.",screen_name:name:twitter_id:description:year:month:date:time:tweet_id:tweet:,string:string:numeric:string:numeric:numeric:numeric:numeric:numeric:string:,news
Devanagari Character Set , Rishi Anand , www.kaggle.com/rishianand/devanagari-character-set , Fri Aug 25 2017 04:06:21 GMT+0530 (IST) , Over 92 thousand images of characters from devanagari script ,255, languages- linguistics- ,"Context This is a dataset of Devanagari Script Characters. It comprises of 92000 images [32x32 px] corresponding to 46 characters consonants ""ka"" to ""gya"" and the digits 0 to 9. The vowels are missing. Content The CSV file is of the dimension 92000 * 1025. There are 1024 input features of pixel values in grayscale (0 to 255). The column ""character"" represents the Devanagari Character Name corresponding to each image. Acknowledgements This dataset was originally created by Computer Vision Research Group Nepal. [website archive] (https//web.archive.org/web/20160105230017/http//cvresearchnepal.com/wordpress/dhcd/) Example Script https//nbviewer.jupyter.org/github/rishianand9/devanagari-character-recognition/blob/master/DCRS.ipynb",pixel_0000:pixel_0001:pixel_0002:pixel_0003:pixel_0004:pixel_0005:pixel_0006:pixel_0007:pixel_0008:pixel_0009:pixel_0010:pixel_0011:pixel_0012:pixel_0013:pixel_0014:pixel_0015:pixel_0016:pixel_0017:pixel_0018:pixel_0019:pixel_0020:pixel_0021:pixel_0022:pixel_0023:pixel_0024:pixel_0025:pixel_0026:pixel_0027:pixel_0028:pixel_0029:pixel_0030:pixel_0031:pixel_0032:pixel_0033:pixel_0034:pixel_0035:pixel_0036:pixel_0037:pixel_0038:pixel_0039:pixel_0040:pixel_0041:pixel_0042:pixel_0043:pixel_0044:pixel_0045:pixel_0046:pixel_0047:pixel_0048:pixel_0049:pixel_0050:pixel_0051:pixel_0052:pixel_0053:pixel_0054:pixel_0055:pixel_0056:pixel_0057:pixel_0058:pixel_0059:pixel_0060:pixel_0061:pixel_0062:pixel_0063:pixel_0064:pixel_0065:pixel_0066:pixel_0067:pixel_0068:pixel_0069:pixel_0070:pixel_0071:pixel_0072:pixel_0073:pixel_0074:pixel_0075:pixel_0076:pixel_0077:pixel_0078:pixel_0079:pixel_0080:pixel_0081:pixel_0082:pixel_0083:pixel_0084:pixel_0085:pixel_0086:pixel_0087:pixel_0088:pixel_0089:pixel_0090:pixel_0091:pixel_0092:pixel_0093:pixel_0094:pixel_0095:pixel_0096:pixel_0097:pixel_0098:pixel_0099:pixel_0100:pixel_0101:pixel_0102:pixel_0103:pixel_0104:pixel_0105:pixel_0106:pixel_0107:pixel_0108:pixel_0109:pixel_0110:pixel_0111:pixel_0112:pixel_0113:pixel_0114:pixel_0115:pixel_0116:pixel_0117:pixel_0118:pixel_0119:pixel_0120:pixel_0121:pixel_0122:pixel_0123:pixel_0124:pixel_0125:pixel_0126:pixel_0127:pixel_0128:pixel_0129:pixel_0130:pixel_0131:pixel_0132:pixel_0133:pixel_0134:pixel_0135:pixel_0136:pixel_0137:pixel_0138:pixel_0139:pixel_0140:pixel_0141:pixel_0142:pixel_0143:pixel_0144:pixel_0145:pixel_0146:pixel_0147:pixel_0148:pixel_0149:pixel_0150:pixel_0151:pixel_0152:pixel_0153:pixel_0154:pixel_0155:pixel_0156:pixel_0157:pixel_0158:pixel_0159:pixel_0160:pixel_0161:pixel_0162:pixel_0163:pixel_0164:pixel_0165:pixel_0166:pixel_0167:pixel_0168:pixel_0169:pixel_0170:pixel_0171:pixel_0172:pixel_0173:pixel_0174:pixel_0175:pixel_0176:pixel_0177:pixel_0178:pixel_0179:pixel_0180:pixel_0181:pixel_0182:pixel_0183:pixel_0184:pixel_0185:pixel_0186:pixel_0187:pixel_0188:pixel_0189:pixel_0190:pixel_0191:pixel_0192:pixel_0193:pixel_0194:pixel_0195:pixel_0196:pixel_0197:pixel_0198:pixel_0199:pixel_0200:pixel_0201:pixel_0202:pixel_0203:pixel_0204:pixel_0205:pixel_0206:pixel_0207:pixel_0208:pixel_0209:pixel_0210:pixel_0211:pixel_0212:pixel_0213:pixel_0214:pixel_0215:pixel_0216:pixel_0217:pixel_0218:pixel_0219:pixel_0220:pixel_0221:pixel_0222:pixel_0223:pixel_0224:pixel_0225:pixel_0226:pixel_0227:pixel_0228:pixel_0229:pixel_0230:pixel_0231:pixel_0232:pixel_0233:pixel_0234:pixel_0235:pixel_0236:pixel_0237:pixel_0238:pixel_0239:pixel_0240:pixel_0241:pixel_0242:pixel_0243:pixel_0244:pixel_0245:pixel_0246:pixel_0247:pixel_0248:pixel_0249:pixel_0250:pixel_0251:pixel_0252:pixel_0253:pixel_0254:pixel_0255:pixel_0256:pixel_0257:pixel_0258:pixel_0259:pixel_0260:pixel_0261:pixel_0262:pixel_0263:pixel_0264:pixel_0265:pixel_0266:pixel_0267:pixel_0268:pixel_0269:pixel_0270:pixel_0271:pixel_0272:pixel_0273:pixel_0274:pixel_0275:pixel_0276:pixel_0277:pixel_0278:pixel_0279:pixel_0280:pixel_0281:pixel_0282:pixel_0283:pixel_0284:pixel_0285:pixel_0286:pixel_0287:pixel_0288:pixel_0289:pixel_0290:pixel_0291:pixel_0292:pixel_0293:pixel_0294:pixel_0295:pixel_0296:pixel_0297:pixel_0298:pixel_0299:pixel_0300:pixel_0301:pixel_0302:pixel_0303:pixel_0304:pixel_0305:pixel_0306:pixel_0307:pixel_0308:pixel_0309:pixel_0310:pixel_0311:pixel_0312:pixel_0313:pixel_0314:pixel_0315:pixel_0316:pixel_0317:pixel_0318:pixel_0319:pixel_0320:pixel_0321:pixel_0322:pixel_0323:pixel_0324:pixel_0325:pixel_0326:pixel_0327:pixel_0328:pixel_0329:pixel_0330:pixel_0331:pixel_0332:pixel_0333:pixel_0334:pixel_0335:pixel_0336:pixel_0337:pixel_0338:pixel_0339:pixel_0340:pixel_0341:pixel_0342:pixel_0343:pixel_0344:pixel_0345:pixel_0346:pixel_0347:pixel_0348:pixel_0349:pixel_0350:pixel_0351:pixel_0352:pixel_0353:pixel_0354:pixel_0355:pixel_0356:pixel_0357:pixel_0358:pixel_0359:pixel_0360:pixel_0361:pixel_0362:pixel_0363:pixel_0364:pixel_0365:pixel_0366:pixel_0367:pixel_0368:pixel_0369:pixel_0370:pixel_0371:pixel_0372:pixel_0373:pixel_0374:pixel_0375:pixel_0376:pixel_0377:pixel_0378:pixel_0379:pixel_0380:pixel_0381:pixel_0382:pixel_0383:pixel_0384:pixel_0385:pixel_0386:pixel_0387:pixel_0388:pixel_0389:pixel_0390:pixel_0391:pixel_0392:pixel_0393:pixel_0394:pixel_0395:pixel_0396:pixel_0397:pixel_0398:pixel_0399:pixel_0400:pixel_0401:pixel_0402:pixel_0403:pixel_0404:pixel_0405:pixel_0406:pixel_0407:pixel_0408:pixel_0409:pixel_0410:pixel_0411:pixel_0412:pixel_0413:pixel_0414:pixel_0415:pixel_0416:pixel_0417:pixel_0418:pixel_0419:pixel_0420:pixel_0421:pixel_0422:pixel_0423:pixel_0424:pixel_0425:pixel_0426:pixel_0427:pixel_0428:pixel_0429:pixel_0430:pixel_0431:pixel_0432:pixel_0433:pixel_0434:pixel_0435:pixel_0436:pixel_0437:pixel_0438:pixel_0439:pixel_0440:pixel_0441:pixel_0442:pixel_0443:pixel_0444:pixel_0445:pixel_0446:pixel_0447:pixel_0448:pixel_0449:pixel_0450:pixel_0451:pixel_0452:pixel_0453:pixel_0454:pixel_0455:pixel_0456:pixel_0457:pixel_0458:pixel_0459:pixel_0460:pixel_0461:pixel_0462:pixel_0463:pixel_0464:pixel_0465:pixel_0466:pixel_0467:pixel_0468:pixel_0469:pixel_0470:pixel_0471:pixel_0472:pixel_0473:pixel_0474:pixel_0475:pixel_0476:pixel_0477:pixel_0478:pixel_0479:pixel_0480:pixel_0481:pixel_0482:pixel_0483:pixel_0484:pixel_0485:pixel_0486:pixel_0487:pixel_0488:pixel_0489:pixel_0490:pixel_0491:pixel_0492:pixel_0493:pixel_0494:pixel_0495:pixel_0496:pixel_0497:pixel_0498:pixel_0499:pixel_0500:pixel_0501:pixel_0502:pixel_0503:pixel_0504:pixel_0505:pixel_0506:pixel_0507:pixel_0508:pixel_0509:pixel_0510:pixel_0511:pixel_0512:pixel_0513:pixel_0514:pixel_0515:pixel_0516:pixel_0517:pixel_0518:pixel_0519:pixel_0520:pixel_0521:pixel_0522:pixel_0523:pixel_0524:pixel_0525:pixel_0526:pixel_0527:pixel_0528:pixel_0529:pixel_0530:pixel_0531:pixel_0532:pixel_0533:pixel_0534:pixel_0535:pixel_0536:pixel_0537:pixel_0538:pixel_0539:pixel_0540:pixel_0541:pixel_0542:pixel_0543:pixel_0544:pixel_0545:pixel_0546:pixel_0547:pixel_0548:pixel_0549:pixel_0550:pixel_0551:pixel_0552:pixel_0553:pixel_0554:pixel_0555:pixel_0556:pixel_0557:pixel_0558:pixel_0559:pixel_0560:pixel_0561:pixel_0562:pixel_0563:pixel_0564:pixel_0565:pixel_0566:pixel_0567:pixel_0568:pixel_0569:pixel_0570:pixel_0571:pixel_0572:pixel_0573:pixel_0574:pixel_0575:pixel_0576:pixel_0577:pixel_0578:pixel_0579:pixel_0580:pixel_0581:pixel_0582:pixel_0583:pixel_0584:pixel_0585:pixel_0586:pixel_0587:pixel_0588:pixel_0589:pixel_0590:pixel_0591:pixel_0592:pixel_0593:pixel_0594:pixel_0595:pixel_0596:pixel_0597:pixel_0598:pixel_0599:pixel_0600:pixel_0601:pixel_0602:pixel_0603:pixel_0604:pixel_0605:pixel_0606:pixel_0607:pixel_0608:pixel_0609:pixel_0610:pixel_0611:pixel_0612:pixel_0613:pixel_0614:pixel_0615:pixel_0616:pixel_0617:pixel_0618:pixel_0619:pixel_0620:pixel_0621:pixel_0622:pixel_0623:pixel_0624:pixel_0625:pixel_0626:pixel_0627:pixel_0628:pixel_0629:pixel_0630:pixel_0631:pixel_0632:pixel_0633:pixel_0634:pixel_0635:pixel_0636:pixel_0637:pixel_0638:pixel_0639:pixel_0640:pixel_0641:pixel_0642:pixel_0643:pixel_0644:pixel_0645:pixel_0646:pixel_0647:pixel_0648:pixel_0649:pixel_0650:pixel_0651:pixel_0652:pixel_0653:pixel_0654:pixel_0655:pixel_0656:pixel_0657:pixel_0658:pixel_0659:pixel_0660:pixel_0661:pixel_0662:pixel_0663:pixel_0664:pixel_0665:pixel_0666:pixel_0667:pixel_0668:pixel_0669:pixel_0670:pixel_0671:pixel_0672:pixel_0673:pixel_0674:pixel_0675:pixel_0676:pixel_0677:pixel_0678:pixel_0679:pixel_0680:pixel_0681:pixel_0682:pixel_0683:pixel_0684:pixel_0685:pixel_0686:pixel_0687:pixel_0688:pixel_0689:pixel_0690:pixel_0691:pixel_0692:pixel_0693:pixel_0694:pixel_0695:pixel_0696:pixel_0697:pixel_0698:pixel_0699:pixel_0700:pixel_0701:pixel_0702:pixel_0703:pixel_0704:pixel_0705:pixel_0706:pixel_0707:pixel_0708:pixel_0709:pixel_0710:pixel_0711:pixel_0712:pixel_0713:pixel_0714:pixel_0715:pixel_0716:pixel_0717:pixel_0718:pixel_0719:pixel_0720:pixel_0721:pixel_0722:pixel_0723:pixel_0724:pixel_0725:pixel_0726:pixel_0727:pixel_0728:pixel_0729:pixel_0730:pixel_0731:pixel_0732:pixel_0733:pixel_0734:pixel_0735:pixel_0736:pixel_0737:pixel_0738:pixel_0739:pixel_0740:pixel_0741:pixel_0742:pixel_0743:pixel_0744:pixel_0745:pixel_0746:pixel_0747:pixel_0748:pixel_0749:pixel_0750:pixel_0751:pixel_0752:pixel_0753:pixel_0754:pixel_0755:pixel_0756:pixel_0757:pixel_0758:pixel_0759:pixel_0760:pixel_0761:pixel_0762:pixel_0763:pixel_0764:pixel_0765:pixel_0766:pixel_0767:pixel_0768:pixel_0769:pixel_0770:pixel_0771:pixel_0772:pixel_0773:pixel_0774:pixel_0775:pixel_0776:pixel_0777:pixel_0778:pixel_0779:pixel_0780:pixel_0781:pixel_0782:pixel_0783:pixel_0784:pixel_0785:pixel_0786:pixel_0787:pixel_0788:pixel_0789:pixel_0790:pixel_0791:pixel_0792:pixel_0793:pixel_0794:pixel_0795:pixel_0796:pixel_0797:pixel_0798:pixel_0799:pixel_0800:pixel_0801:pixel_0802:pixel_0803:pixel_0804:pixel_0805:pixel_0806:pixel_0807:pixel_0808:pixel_0809:pixel_0810:pixel_0811:pixel_0812:pixel_0813:pixel_0814:pixel_0815:pixel_0816:pixel_0817:pixel_0818:pixel_0819:pixel_0820:pixel_0821:pixel_0822:pixel_0823:pixel_0824:pixel_0825:pixel_0826:pixel_0827:pixel_0828:pixel_0829:pixel_0830:pixel_0831:pixel_0832:pixel_0833:pixel_0834:pixel_0835:pixel_0836:pixel_0837:pixel_0838:pixel_0839:pixel_0840:pixel_0841:pixel_0842:pixel_0843:pixel_0844:pixel_0845:pixel_0846:pixel_0847:pixel_0848:pixel_0849:pixel_0850:pixel_0851:pixel_0852:pixel_0853:pixel_0854:pixel_0855:pixel_0856:pixel_0857:pixel_0858:pixel_0859:pixel_0860:pixel_0861:pixel_0862:pixel_0863:pixel_0864:pixel_0865:pixel_0866:pixel_0867:pixel_0868:pixel_0869:pixel_0870:pixel_0871:pixel_0872:pixel_0873:pixel_0874:pixel_0875:pixel_0876:pixel_0877:pixel_0878:pixel_0879:pixel_0880:pixel_0881:pixel_0882:pixel_0883:pixel_0884:pixel_0885:pixel_0886:pixel_0887:pixel_0888:pixel_0889:pixel_0890:pixel_0891:pixel_0892:pixel_0893:pixel_0894:pixel_0895:pixel_0896:pixel_0897:pixel_0898:pixel_0899:pixel_0900:pixel_0901:pixel_0902:pixel_0903:pixel_0904:pixel_0905:pixel_0906:pixel_0907:pixel_0908:pixel_0909:pixel_0910:pixel_0911:pixel_0912:pixel_0913:pixel_0914:pixel_0915:pixel_0916:pixel_0917:pixel_0918:pixel_0919:pixel_0920:pixel_0921:pixel_0922:pixel_0923:pixel_0924:pixel_0925:pixel_0926:pixel_0927:pixel_0928:pixel_0929:pixel_0930:pixel_0931:pixel_0932:pixel_0933:pixel_0934:pixel_0935:pixel_0936:pixel_0937:pixel_0938:pixel_0939:pixel_0940:pixel_0941:pixel_0942:pixel_0943:pixel_0944:pixel_0945:pixel_0946:pixel_0947:pixel_0948:pixel_0949:pixel_0950:pixel_0951:pixel_0952:pixel_0953:pixel_0954:pixel_0955:pixel_0956:pixel_0957:pixel_0958:pixel_0959:pixel_0960:pixel_0961:pixel_0962:pixel_0963:pixel_0964:pixel_0965:pixel_0966:pixel_0967:pixel_0968:pixel_0969:pixel_0970:pixel_0971:pixel_0972:pixel_0973:pixel_0974:pixel_0975:pixel_0976:pixel_0977:pixel_0978:pixel_0979:pixel_0980:pixel_0981:pixel_0982:pixel_0983:pixel_0984:pixel_0985:pixel_0986:pixel_0987:pixel_0988:pixel_0989:pixel_0990:pixel_0991:pixel_0992:pixel_0993:pixel_0994:pixel_0995:pixel_0996:pixel_0997:pixel_0998:pixel_0999:pixel_1000:pixel_1001:pixel_1002:pixel_1003:pixel_1004:pixel_1005:pixel_1006:pixel_1007:pixel_1008:pixel_1009:pixel_1010:pixel_1011:pixel_1012:pixel_1013:pixel_1014:pixel_1015:pixel_1016:pixel_1017:pixel_1018:pixel_1019:pixel_1020:pixel_1021:pixel_1022:pixel_1023:character:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:,Written script
Cryptocurrency Historical Prices , SRK , www.kaggle.com/sudalairajkumar/cryptocurrencypricehistory , Wed Oct 04 2017 11:58:03 GMT+0530 (IST) , Prices of top cryptocurrencies including Bitcoin Ethereum Ripple Bitcoin cash ,4451, history- finance- ,Context In the last few days I have been hearing a lot of buzz around cryptocurrencies. Things like Block chain Bitcoin Bitcoin cash Ethereum Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and this post helped me get started. Once the basics are done the DS guy sleeping inside me (always lazy.!) woke up and started raising questions like  How many such cryptocurrencies are there and what are their prices and valuations? Why is there a sudden surge in the interest in recent days? Is it due to the increase in the price in the last few days? etc.  For getting answers to all these questions (and if possible to predict the future prices ;)) I started getting the data from coinmarketcap about the cryptocurrencies.  Update  Bitcoin dataset So what next.?  Now that we have the price data I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to Blockchain Info I was able to get quite a few parameters on once in two day basis. This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price. Update2 Ethereum Dataset This dataset has features related to Ethereum. This is very similar to the bitcoin dataset and is available on a daily basis. Data is taken from Etherscan and the credits go to them for allowing us to use. Content This dataset has the historical price information of some of the top cryptocurrencies by market capitalization. The currencies included are  Bitcoin Ethereum Ripple Bitcoin cash Bitconnect Dash Ethereum Classic Iota Litecoin Monero Nem Neo Numeraire Stratis Waves  In case if you are interested in the prices of some other currencies please post in comments section and I will try to add them in the next version. I am planning to revise it once in a week.     Dataset has one csv file for each currency. Price history is available on a daily basis from April 28 2013. The columns in the csv file are  Date  date of observation  Open  Opening price on the given day High  Highest price on the given day Low  Lowest price on the given day Close  Closing price on the given day Volume  Volume of transactions on the given day Market Cap  Market capitalization in USD  Bitcoin Dataset (bitcoin_dataset.csv)  This dataset has the following features.  Date  Date of observation btc_market_price  Average USD market price across major bitcoin exchanges. btc_total_bitcoins  The total number of bitcoins that have already been mined. btc_market_cap  The total USD value of bitcoin supply in circulation. btc_trade_volume  The total USD value of trading volume on major bitcoin exchanges. btc_blocks_size  The total size of all block headers and transactions. btc_avg_block_size  The average block size in MB. btc_n_orphaned_blocks  The total number of blocks mined but ultimately not attached to the main Bitcoin blockchain. btc_n_transactions_per_block  The average number of transactions per block. btc_median_confirmation_time  The median time for a transaction to be accepted into a mined block. btc_hash_rate  The estimated number of tera hashes per second the Bitcoin network is performing. btc_difficulty  A relative measure of how difficult it is to find a new block. btc_miners_revenue  Total value of coinbase block rewards and transaction fees paid to miners. btc_transaction_fees  The total value of all transaction fees paid to miners. btc_cost_per_transaction_percent  miners revenue as percentage of the transaction volume. btc_cost_per_transaction  miners revenue divided by the number of transactions. btc_n_unique_addresses  The total number of unique addresses used on the Bitcoin blockchain. btc_n_transactions  The number of daily confirmed Bitcoin transactions. btc_n_transactions_total  Total number of transactions. btc_n_transactions_excluding_popular  The total number of Bitcoin transactions excluding the 100 most popular addresses. btc_n_transactions_excluding_chains_longer_than_100  The total number of Bitcoin transactions per day excluding long transaction chains. btc_output_volume  The total value of all transaction outputs per day. btc_estimated_transaction_volume  The total estimated value of transactions on the Bitcoin blockchain. btc_estimated_transaction_volume_usd  The estimated transaction value in USD value.  Ethereum Dataset (ethereum_dataset.csv) This dataset has the following features  Date(UTC)  Date of transaction UnixTimeStamp  unix timestamp eth_etherprice  price of ethereum eth_tx  number of transactions per day eth_address  Cumulative address growth eth_supply  Number of ethers in supply eth_marketcap  Market cap in USD eth_hashrate  hash rate in GH/s eth_difficulty  Difficulty level in TH eth_blocks  number of blocks per day eth_uncles  number of uncles per day eth_blocksize  average block size in bytes eth_blocktime  average block time in seconds eth_gasprice  Average gas price in Wei eth_gaslimit  Gas limit per day eth_gasused  total gas used per day eth_ethersupply  new ether supply per day eth_chaindatasize  chain data size in bytes eth_ens_register  Ethereal Name Service (ENS) registrations per day  Acknowledgements This data is taken from coinmarketcap and it is free to use the data. Bitcoin dataset is obtained from Blockchain Info. Ethereum dataset is obtained from Etherscan. Cover Image  Photo by Thomas Malama on Unsplash Inspiration Some of the questions which could be inferred from this dataset are  How did the historical prices / market capitalizations of various currencies change over time? Predicting the future price of the currencies Which currencies are more volatile and which ones are more stable? How does the price fluctuations of currencies correlate with each other? Seasonal trend in the price fluctuations  Bitcoin / Ethereum dataset could be used to look at the following  Factors affecting the bitcoin / ether price. Directional prediction of bitcoin / ether price. (refer this paper for more inspiration) Actual bitcoin price prediction. ,Date:Open:High:Low:Close:Volume:Market Cap:,dateTime:numeric:numeric:numeric:numeric:numeric:numeric:,blockchain and crytocurrencies
Ideology Scores of Supreme Court Justices , University of Michigan , www.kaggle.com/umichigan/court-justices , Fri Feb 10 2017 05:45:17 GMT+0530 (IST) , Measure of individual justices' ideology on political spectrum per term ,65, law- politics- ,"Context Measuring the relative location of U.S. Supreme Court justices on an ideological continuum allows us to better understand the politics of the high court. Such measures are an important building blocking of statistical models of the Supreme Court the separation of powers system and the judicial hierarchy. Content The ""Martin-Quinn"" judicial ideology scores are estimated for every justice serving from the October 1937 term to the present. The measures are estimated using a dynamic item response theory model allowing judicial ideology to trend smoothly through time. Since the scores are estimated from a probability model they can be used to form other quantities of interest such as locating the pivotal ""median"" justice as all well the location of each case in the policy space.  Acknowledgements The Martin-Quinn scores were developed by Andrew D. Martin of the University of Michigan and Kevin M. Quinn of the UC Berkeley School of Law and supported by a National Science Foundation grant. The scores are based on the 2016 release of the Supreme Court Database.",court_term:justice_code:justice_name:posterior_mean:standard_deviation:posterior_median:twosigma_left:twosigma_right:,numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:,politics
JCPenney products , PromptCloud , www.kaggle.com/PromptCloudHQ/all-jc-penny-products , Fri Sep 15 2017 14:10:14 GMT+0530 (IST) , 20000 product listings from JCPenney ,75, internet- ,Context This is a pre-crawled dataset taken as subset of a bigger dataset (more than 3.7 million products) that was created by extracting data from jcpenney.com a well known retailer. Content This dataset has following fields  sku name_title description list_price sale_price category category_tree average_product_rating product_url product_image_urls brand total_number_reviews reviews  Acknowledgements This dataset was created by PromptCloud's in-house web-crawling service. Inspiration Analyses of list price  sale price rating and reviews can be performed.,uniq_id:sku:name_title:description:list_price:sale_price:category:category_tree:average_product_rating:product_url:product_image_urls:brand:total_number_reviews:Reviews:,string:string:string:string:numeric:numeric:string:string:string:string:string:string:numeric:string:,online shopping
The Enron Email Dataset , William Cukierski , www.kaggle.com/wcukierski/enron-email-dataset , Fri Jun 17 2016 02:25:19 GMT+0530 (IST) , 500000+ emails from 150 employees of the Enron Corporation ,4926, crime- linguistics- ,The Enron email dataset contains approximately 500000 emails generated by employees of the Enron Corporation. It was obtained by the Federal Energy Regulatory Commission during its investigation of Enron's collapse. This is the May 7 2015 Version of dataset as published at https//www.cs.cmu.edu/~./enron/,,,mail and messaging
Filipino Family Income and Expenditure , Francis Paul Flores , www.kaggle.com/grosvenpaul/family-income-and-expenditure , Thu Oct 05 2017 14:23:26 GMT+0530 (IST) , Annual Household Income and Expenses in the Philippines ,87, data analysis- income- demographics- ,Context The Philippine Statistics Authority (PSA) spearheads the conduct of the Family Income and Expenditure Survey (FIES) nationwide. The survey which is undertaken every three (3) years is aimed at providing data on family income and expenditure including among others levels of consumption by item of expenditure sources of income in cash and related information affecting income and expenditure levels and patterns in the Philippines. Content Inside this data set is some selected variables from the latest Family Income and Expenditure Survey (FIES) in the Philippines. It contains more than 40k observations and 60 variables which is primarily comprised of the household income and expenditures of that specific household Acknowledgements The Philippine Statistics Authority for providing the publisher with their raw data Inspiration Socio-economic classification models in the Philippines has been very problematic. In fact not one SEC model has been widely accepted. Government bodies uses their own SEC models and private research entities uses their own. We all know that household income is the greatest indicator of one's socio-economic classification that's why the publisher would like to find out the following 1) Best model in predicting household income 2) Key drivers of household income we want to make the model as sparse as possible 3) Some exploratory analysis in the data would also be useful,"Total Household Income:Region:Total Food Expenditure:Main Source of Income:Agricultural Household indicator:Bread and Cereals Expenditure:Total Rice Expenditure:Meat Expenditure:Total Fish and  marine products Expenditure:Fruit Expenditure:Vegetables Expenditure:Restaurant and hotels Expenditure:Alcoholic Beverages Expenditure:Tobacco Expenditure:Clothing, Footwear and Other Wear Expenditure:Housing and water Expenditure:Imputed House Rental Value:Medical Care Expenditure:Transportation Expenditure:Communication Expenditure:Education Expenditure:Miscellaneous Goods and Services Expenditure:Special Occasions Expenditure:Crop Farming and Gardening expenses:Total Income from Entrepreneurial Acitivites:Household Head Sex:Household Head Age:Household Head Marital Status:Household Head Highest Grade Completed:Household Head Job or Business Indicator:Household Head Occupation:Household Head Class of Worker:Type of Household:Total Number of Family members:Members with age less than 5 year old:Members with age 5 - 17 years old:Total number of family members employed:Type of Building/House:Type of Roof:Type of Walls:House Floor Area:House Age:Number of bedrooms:Tenure Status:Toilet Facilities:Electricity:Main Source of Water Supply:Number of Television:Number of CD/VCD/DVD:Number of Component/Stereo set:Number of Refrigerator/Freezer:Number of Washing Machine:Number of Airconditioner:Number of Car, Jeep, Van:Number of Landline/wireless telephones:Number of Cellular phone:Number of Personal Computer:Number of Stove with Oven/Gas Range:Number of Motorized Banca:Number of Motorcycle/Tricycle:",numeric:string:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:string:string:string:string:string:string:numeric:numeric:numeric:numeric:string:string:string:numeric:numeric:numeric:string:string:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,income
My Settlers of Catan Games , Lumin , www.kaggle.com/lumins/settlers-of-catan-games , Tue Aug 30 2016 01:22:21 GMT+0530 (IST) , Starting positions roll distributions postgame statistics of 50 4-player games ,499, board games- ,The strategic board game The Settlers of Catan is a modern classic. Introduced in 1995 it has sold over 22 million copies worldwide. Learning how to play the game well requires an inherent understanding of probability economics game theory and social interactions.  This is my personal dataset of 50 4-player games I played on playcatan.com in 2014. Using the ingame statistics page and a spreadsheet I logged starting position choices the distribution of dice rolls and how each player spent the resources they acquired by the end of the game. Note of course because this dataset only consists of my games any analysis done is most relevant for games involving me... My personal analysis of this dataset consisted of a best subsets regression and resulted a 4-variable model that likely overfitted but managed to ascertain the winner correctly in 40 of 50 games. Questions to possibly consider How much luck is involved in winning a Catan game? Does starting position matter? If so what starting settlements lead to success from each position? How much information on the eventual winner can be gained from starting position/settlements alone? By looking at postgame stats what leads to a win? Can these statistics be a guide for ingame strategy? Data details/guide gameNum - each game I played has 4 corresponding rows 1 per player. player - the starting position corresponding to each row points - how many points the player ended the game with (the game is won with 10 or more) me - the position I played during the game 2 3 ... 12 - how many rolls of each value occurred during the game (game is played with 2 dice) settlement1 settlement2 - each starting settlement is logged as 3 pairs of [number resource] L = lumber C = clay S = sheep W = wheat O = ore 3G = 31 general port 2(X) = 21 port for resource X D = desert EX in game 1 player 1's first settlement was on a 6-lumber 3-clay and 11-clay. production - total cards gained from settlements and cities during game tradeGain - total cards gained from peer AND bank trades during game robberCardsGain - total cards gained from stealing with the robber plus cards gained with non-knight development  cards. A road building card is +4 resources. totalGain - sum of previous 3 columns. tradeLoss - total cards lost from peer AND bank trades during game robberCardsLoss - total cards lost from robbers knights and other players' monopoly cards tribute - total cards lost when player had to discard on a 7 roll (separate from previous column.) totalLoss - sum of previous 3 columns. totalAvailable - totalGain minus totalLoss. I only ask that if you produce a good model you share it with me! Please don't hesitate to ask any clarifying questions.,gameNum:player:points:me:2:3:4:5:6:7:8:9:10:11:12:settlement1::settlement2:production:tradeGain:robberCardsGain:totalGain:tradeLoss:robberCardsLoss:tribute:totalLoss:totalAvailable:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,board games
UFC Fights Data 1993 - 2/23/2016 , Chris Formey , www.kaggle.com/cformey24/ufc-fights-data-1993-2232016 , Wed Sep 13 2017 09:11:30 GMT+0530 (IST) , UFC 1 to UFC Fight Night 83    Fight Data ,115, sports- ,Context I found this at https//www.reddit.com/r/datasets/comments/47a7wh/ufc_fights_and_fighter_data/ All credit goes to reddit user geyges and Sherdog. I do not own the data. Content This data has multiple categorical variables from every UFC fight from UFC 1 in 1993 - 2/23/2016. Acknowledgements Reddit u/geyges Sherdog UFC Inspiration So much information can be gained from this relevant to understanding how the sport has evolved over the years.,pageurl:eid:mid:event_name:event_org:event_date:event_place:f1pageurl:f2pageurl:f1name:f2name:f1result:f2result:f1fid:f2fid:method:method_d:ref:round:time:,string:numeric:numeric:string:string:dateTime:string:string:string:string:string:string:string:numeric:numeric:string:string:string:numeric:dateTime:,sports events
Kepler Exoplanet Search Results , NASA , www.kaggle.com/nasa/kepler-exoplanet-search-results , Tue Oct 10 2017 23:56:59 GMT+0530 (IST) , 10000 exoplanet candidates examined by the Kepler Space Observatory ,100, astronomy- space- ,"Context The Kepler Space Observatory is a NASA-build satellite that was launched in 2009. The telescope is dedicated to searching for exoplanets in star systems besides our own with the ultimate goal of possibly finding other habitable planets besides our own. The original mission ended in 2013 due to mechanical failures but the telescope has nevertheless been functional since 2014 on a ""K2"" extended mission. Kepler had verified 1284 new exoplanets as of May 2016. As of October 2017 there are over 3000 confirmed exoplanets total (using all detection methods including ground-based ones). The telescope is still active and continues to collect new data on its extended mission. Content This dataset is a cumulative record of all observed Kepler ""objects of interest"" — basically all of the approximately 10000 exoplanet candidates Kepler has taken observations on. This dataset has an extensive data dictionary which can be accessed here. Highlightable columns of note are  kepoi_name A KOI is a target identified by the Kepler Project that displays at least one transit-like sequence within Kepler time-series photometry that appears to be of astrophysical origin and initially consistent with a planetary transit hypothesis kepler_name [These names] are intended to clearly indicate a class of objects that have been confirmed or validated as planets—a step up from the planet candidate designation. koi_disposition The disposition in the literature towards this exoplanet candidate. One of CANDIDATE FALSE POSITIVE NOT DISPOSITIONED or CONFIRMED. koi_pdisposition The disposition Kepler data analysis has towards this exoplanet candidate. One of FALSE POSITIVE NOT DISPOSITIONED and CANDIDATE. koi_score A value between 0 and 1 that indicates the confidence in the KOI disposition. For CANDIDATEs a higher value indicates more confidence in its disposition while for FALSE POSITIVEs a higher value indicates less confidence in that disposition.  Acknowledgements This dataset was published as-is by NASA. You can access the original table here. More data from the Kepler mission is available from the same source here. Inspiration  How often are exoplanets confirmed in the existing literature disconfirmed by measurements from Kepler? How about the other way round? What general characteristics about exoplanets (that we can find) can you derive from this dataset? What exoplanets get assigned names in the literature? What is the distribution of confidence scores?  See also the Kepler Labeled Time Series and Open Exoplanets Catalogue datasets.",rowid:kepid:kepoi_name:kepler_name:koi_disposition:koi_pdisposition:koi_score:koi_fpflag_nt:koi_fpflag_ss:koi_fpflag_co:koi_fpflag_ec:koi_period:koi_period_err1:koi_period_err2:koi_time0bk:koi_time0bk_err1:koi_time0bk_err2:koi_impact:koi_impact_err1:koi_impact_err2:koi_duration:koi_duration_err1:koi_duration_err2:koi_depth:koi_depth_err1:koi_depth_err2:koi_prad:koi_prad_err1:koi_prad_err2:koi_teq:koi_teq_err1:koi_teq_err2:koi_insol:koi_insol_err1:koi_insol_err2:koi_model_snr:koi_tce_plnt_num:koi_tce_delivname:koi_steff:koi_steff_err1:koi_steff_err2:koi_slogg:koi_slogg_err1:koi_slogg_err2:koi_srad:koi_srad_err1:koi_srad_err2:ra:dec:koi_kepmag:,numeric:numeric:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,astronomy
The Simpsons by the Data , William Cukierski , www.kaggle.com/wcukierski/the-simpsons-by-the-data , Thu Sep 29 2016 00:52:21 GMT+0530 (IST) ," 27 seasons of ""Simpsons did it."" ",3517, popular culture- ,This dataset contains the characters locations episode details and script lines for approximately 600 Simpsons episodes dating back to 1989. Inspiration and credit for gathering the data goes to Todd Schneider http//toddwschneider.com/posts/the-simpsons-by-the-data/  https//github.com/toddwschneider/flim-springfield,id:name:normalized_name:gender:,numeric:string:string:string:,TV shows
Video Game Sales , GregorySmith , www.kaggle.com/gregorut/videogamesales , Wed Oct 26 2016 14:40:49 GMT+0530 (IST) , Analyze sales data from more than 16500 games. ,10097, video games- ,This dataset contains a list of video games with sales greater than 100000 copies.  It was generated by a scrape of vgchartz.com. Fields include  Rank - Ranking of overall sales Name - The games name Platform - Platform of the games release (i.e. PCPS4 etc.) Year - Year of the game's release Genre - Genre of the game Publisher - Publisher of the game NA_Sales - Sales in North America (in millions) EU_Sales - Sales in Europe (in millions) JP_Sales - Sales in Japan (in millions) Other_Sales - Sales in the rest of the world (in millions) Global_Sales - Total worldwide sales.  The script to scrape the data is available at https//github.com/GregorUT/vgchartzScrape. It is based on BeautifulSoup using Python. There are 16598 records.  2 records were dropped due to incomplete information.,Rank:Name:Platform:Year:Genre:Publisher:NA_Sales:EU_Sales:JP_Sales:Other_Sales:Global_Sales:,numeric:string:string:numeric:string:string:numeric:numeric:numeric:numeric:numeric:,video games
Student Survey , Razib Mustafiz , www.kaggle.com/razibmustafiz/student-survey , Thu Jul 27 2017 13:22:06 GMT+0530 (IST) , University level Student Survey for Academic quality enhancement ,214, ,This Data set was collected by a survey conducted by Google forms for a Bangladeshi University in order to examine their current academic situation and also to improve on them. This Survey was part of the Institutional Quality Assurance Program initiated by University Grant Commission Bangladesh and funded by World Bank. To meet the globalization challenges raising higher education quality to the world standard is essential. Bangladesh Govt. has taken initiatives to develop the quality of tertiary education. Govt. plans to prepare university graduates in such way that they can successfully compete in the context of international knowledge society. Accordingly the Ministry of Education with the assistance of the World Bank has undertaken a Higher Education Quality Enhancement Project (HEQEP). The project aims at improving the quality of teaching-learning and research capabilities of the tertiary education institutions through encouraging both innovation and accountability and by enhancing the technical and institutional capacity of the higher education sector. The University Grants Commission of Bangladesh is the implementing agency of the project. A HEQEP Unit has been established in UGC for implementation management monitoring and evaluation of the activities. The Data set contains 500 rows and they are Timestamped showing the exact time of data collection process. The survey was conducted on Undergraduate and Postgraduate level students of a Bangladeshi Private University. Among the various columns of data the GPA columns contains important linear data with strong correlation. These data can be used to predict other GPA columns. So that we can predict a student's GPA in advance and can take necessary steps to improve his or her score. Some acronyms that might help understand the Data set S.S.C- Secondary School Certificate ( 10th Class public exam) H.S.C- Higher Secondary School Certificate ( 12th Class public exam) Area of Evaluation - There are 1 to 5 points. Where 5 being the best and 1 being the worst.  My heartfelt Acknowledgement goes to the Students who helped me sharing their data and time to make this survey a success. Without their help this could not be possible for me.,"Timestamp:Gender:Faculty:Engineering Program:Law Program:Business Program:Arts Program:Other Program:Bachelor  Academic Year in EU:Masters Academic Year in EU:H.S.C or Equivalent study medium:S.S.C (GPA):H.S.C (GPA):Did you ever attend a Coaching center?:Coaching center name:Benifits you received from the coaching center:1st Year Semester 1:1st Year Semester 2:1st Year Semester 3:2nd Year Semester 1:2nd Year Semester 2:2nd Year Semester 3:3rd Year Semester 1:3rd Year Semester 2:3rd Year Semester 3:4th Year Semester 1:4th Year Semester 2:4th Year Semester 3:Regular/Irregular:Classes are mostly:Area of Evaluation [Department provides comprehensive guidelines to the students in advance by means of a brochure/handbook    ]:Area of Evaluation [Department ensures a conducive learning environment]:Area of Evaluation [Academic decisions are taken with fairness and transparency]:Area of Evaluation [	Academic calendar is maintained properly]:Area of Evaluation [Results are published timely in compliance with the ordinance]:Area of Evaluation [Students� opinion regarding academic and extra-academic matters are addressed properly]:Area of Evaluation [Student feedback process is in practice]:Area of Evaluation [Website is informative and updated properly]:Area of Evaluation [Curriculum load is optimum and induces no pressure]:Area of Evaluation [Courses in the curriculum from lower level to higher are properly arranged]:Area of Evaluation [Teaching strategies are clearly stated in the curriculumsparency]:Area of Evaluation [Assessment strategies are clearly stated in the curriculum ]:Item [Teaching-learning is interactive and supportive ]:Item [	Class size is optimum for interactive teaching learning]:Item [	Modern devices are used to improve teaching-learning process]:Item [Diverse methods are used to achieve learning objectives ]:Item [Lesson plans/course outlines are provided in advance to the students ]:Item [	All about assessment system are duly communicated to students on the commencement of the term/semester]:Item [Assessment system meets the objectives of the course]:Item [Diverse methods and tools are used for assessment.]:Item [Assessment feedback is provided to the students immediately.]:Item [The questions of examinations reflect the content of the course.]:Item [	Both formative (quizzes, assignments, term papers, continuous assessments, presentations etc.) and summative assessment (final examination only) strategies are followed.]:Item [Admission policy ensures entry of quality students.]:Item [Admission procedure is quite fair]:Item [Sincerity and commitment of the students exist to ensure desired progress and achievement.]:Item [Overall classroom facilities are suitable for ensuring effective learning.]:Item [Laboratories facilities are suitable for practical teaching-learning and research]:Item [The library has adequate up-to-date reading and reference materials to meet the academic & research needs ]:Item [Internet facilities with sufficient speed are available]:Item [Adequate indoor and outdoor medical facilities are available]:Item [Adequate indoor and outdoor game facilities are available]:Item [Existing gymnasium facilities are good enough]:Item [Adequate safety measures are available]:Item [There is an arrangement to provide guidance and counseling. ]:Item [Mentoring is done to take care of the students]:Item [Scholarships/ grants available to students in case of hardship]:Item [Students are encouraged to involve in co- curricular and extra-curricular activities]:Item [Alumni are organized and supportive.]:Item [Supporting staff are adequate and co-operative]:Item [There are opportunities to get involve with community services]:Item [The department has a research and development policy ]:Item [Mechanism exists for engaging the students in research and development]:Item [Research findings in the form of theses, publications and monographs are properly used in current teaching-learning]:Item [The department has a community service policy ]:Q1 [What was your expectation about the University as related to quality of education?]:Q2 [What was your expectation about the University as related to quality of Faculty?]:Q3 [What was your expectation about the University as related to quality of resources?]:Q4 [What was your expectation about the University as related to quality of learning environment?]:Q5 [To what extent your expectation was met?]:Q6 [What are the best aspects of the program?]:Q7. In your opinion,the best aspect of the program is:Q8. In your opinion,the next best aspect of the program is:What aspects of the program could be improved?:Do you feel that the quality of education improved at EU over the last year?:Do you feel that the image of the University improved over the last year?:Username:",dateTime:string:string:string:string:string:string:string:string:string:string:numeric:numeric:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:,student performances
Federal Firearm Licences , Department of Justice , www.kaggle.com/doj/federal-firearm-licensees , Fri Sep 15 2017 20:49:38 GMT+0530 (IST) , Active firearm sales licenses in the United States ,52, government- ,Context Firearms sold in the United States must be licensed by the US Department of Justice Bureau of Alcohol Tobacco Firearms and Explosives. This dataset is a record of every firearm license which was still current as of July 2017. Content This dataset contains the names license types expiration dates and locations of all Federal Firearms License (FFL) holders in the United States. The possible license types are  01    Dealer in Firearms Other Than Destructive Devices (Includes Gunsmiths) 02    Pawnbroker in Firearms Other Than Destructive Devices 03    Collector of Curios and Relics 06    Manufacturer of Ammunition for Firearms 07    Manufacturer of Firearms Other Than Destructive Devices 08    Importer of Firearms Other Than Destructive Devices 09    Dealer in Destructive Devices 10    Manufacturer of Destructive Devices 11    Importer of Destructive Devices  Acknowledgements This data is published online in a tab-separated format by the Department of Justice Bureau of Alcohol Tobacco Firearms and Explosives. It has been lightly retouched into a CSV file before publication here. Inspiration  Can you geocode this data to determine where licensed gun shops are distributed? What is the distribution of gun licenses across different types? ,:Lic Regn:Lic Dist:Lic Cnty:Lic Type:Lic Xprdte:Lic Seqn:License Name:Business Name:Premise Street:Premise City:Premise State:Premise Zip Code:Mail Street:Mail City:Mail State:Mail Zip Code:Voice Phone:Expire Date:Unnamed: 17:,numeric:numeric:numeric:numeric:numeric:string:numeric:string:string:string:string:string:numeric:string:string:string:numeric:numeric:dateTime:string:,crime
Amazon Reviews: Unlocked Mobile Phones , PromptCloud , www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones , Wed Jan 11 2017 15:52:30 GMT+0530 (IST) , More than 400000 reviews from Amazon's unlocked mobile phone category ,1782, business- internet- telecommunications- ,Context PromptCloud extracted 400 thousand reviews of unlocked mobile phones sold on Amazon.com to find out insights with respect to reviews ratings price and their relationships. Content Given below are the fields  Product Title  Brand  Price  Rating  Review text  Number of people who found the review helpful  Data was acquired in December 2016 by the crawlers build to deliver our data extraction services. Initial Analysis It can be accessed here http//www.kdnuggets.com/2017/01/data-mining-amazon-mobile-phone-reviews-interesting-insights.html,Product Name:Brand Name:Price:Rating:Reviews:Review Votes:,string:string:numeric:numeric:string:numeric:,online reviews and ratings
Heartbeat Sounds , Ed King , www.kaggle.com/kinguistics/heartbeat-sounds , Sun Nov 27 2016 07:03:54 GMT+0530 (IST) , Classifying heartbeat anomalies from stethoscope audio ,1765, human medicine- sound technology- ,"Try your hand at automatically separating normal heartbeats from abnormal heartbeats and heart murmur with this machine learning challenge by Peter Bentley et al The Data Here's a brief overview of the format of this dataset as uploaded to Kaggle. For a more detailed description look at the Description section below. The dataset is split into two sources A and B A was collected from the general public via an iPhone app and B was collected from a clinical trial in hospitals using a digital stethoscope. The goal of the task is to first (1) identify the locations of heart sounds from the audio and (2) to classify the heart sounds into one of several categories (normal v. various non-normal heartbeat sounds). The CSV files provided are set_a.csv  set_b.csv set_a_timing.csv The fields for set_a and set_b are as follows  dataset a or b fname the audio file label either ""normal"" blank (for unlabelled data) or one of various categories of abnormal heartbeats sublabel in set_b some recordings are categorized as noisy meaning they contain non-heart background noise; this field holds information on whether something is e.g. ""noisynormal"" or ""noisymurmur""  The file set_a_timing.csv contains gold-standard timing information for the ""normal"" recordings from Set A. This file contains the following fields  fname the audio file cycle anywhere from 1 to 19; the heartbeat cycle that the time observation refers to sound either S1 or S2; see below for what these mean location the time location of this sound in audio samples  Description The task as described by the original authors Task Overview Data has been gathered from two sources (A) from the general public via the iStethoscope Pro iPhone app provided in Dataset A and (B) from a clinic trial in hospitals using the digital stethoscope DigiScope provided in Dataset B. CHALLENGE 1 - Heart Sound Segmentation The first challenge is to produce a method that can locate S1(lub) and S2(dub) sounds within audio data segmenting the Normal audio files in both datasets. To enable your machine learning method to learn we provide the exact location of S1 and S2 sounds for some of the audio files. You need to use them to identify and locate the S1 and S2 sounds of all the heartbeats in the unlabelled group. The locations of sounds are measured in audio samples for better precision. Your method must use the same unit. CHALLENGE 2 - Heart Sound Classification The task is to produce a method that can classify real heart audio (also known as “beat classification”) into one of four categories for Dataset A  Normal Murmur Extra Heart Sound Artifact  and three classes for Dataset B  Normal Murmur Extrasystole  You may tackle either or both of these challenges. If you can solve the first challenge the second will be considerably easier! The winner of each challenge will be the method best able to segment and/or classify two sets of unlabelled data into the correct categories after training on both datasets provided below.  [Obviously no longer applicable -- ed.] The creator of the winning method will receive a WiFi 32Gb iPad as the prize awarded at a workshop at AISTATS 2012. The audio files are of varying lengths between 1 second and 30 seconds (some have been clipped to reduce excessive noise and provide the salient fragment of the sound). Most information in heart sounds is contained in the low frequency components with noise in the higher frequencies. It is common to apply a low-pass filter at 195 Hz. Fast Fourier transforms are also likely to provide useful information about volume and frequency over time. More domain-specific knowledge about the difference between the categories of sounds is provided below. Normal Category In the Normal category there are normal healthy heart sounds. These may contain noise in the final second of the recording as the device is removed from the body. They may contain a variety of background noises (from traffic to radios). They may also contain occasional random noise corresponding to breathing or brushing the microphone against clothing or skin. A normal heart sound has a clear “lub dub lub dub” pattern with the time from “lub” to “dub” shorter than the time from “dub” to the next “lub” (when the heart rate is less than 140 beats per minute). Note the temporal description of “lub” and “dub” locations over time in the following illustration …lub……….dub……………. lub……….dub……………. lub……….dub……………. lub……….dub… In medicine we call the lub sound ""S1"" and the dub sound ""S2"". Most normal heart rates at rest will be between about 60 and 100 beats (‘lub dub’s) per minute. However note that since the data may have been collected from children or adults in calm or excited states the heart rates in the data may vary from 40 to 140 beats or higher per minute. Dataset B also contains noisy_normal data - normal data which includes a substantial amount of background noise or distortion. You may choose to use this or ignore it however the test set will include some equally noisy examples. Murmur Category Heart murmurs sound as though there is a “whooshing roaring rumbling or turbulent fluid” noise in one of two temporal locations (1) between “lub” and “dub” or (2) between “dub” and “lub”. They can be a symptom of many heart disorders some serious. There will still be a “lub” and a “dub”. One of the things that confuses non-medically trained people is that murmurs happen between lub and dub or between dub and lub; not on lub and not on dub. Below you can find an asterisk* at the locations a murmur may be. …lub..*...dub……………. lub..*..dub ……………. lub..*..dub ……………. lub..*..dub … or …lub……….dub…*….lub………. dub…*….lub ………. dub…**….lub ……….dub… Dataset B also contains noisy_murmur data - murmur data which includes a substantial amount of background noise or distortion. You may choose to use this or ignore it however the test set will include some equally noisy examples Extra Heart Sound Category (Dataset A) Extra heart sounds can be identified because there is an additional sound e.g. a “lub-lub dub” or a “lub dub-dub”. An extra heart sound may not be a sign of disease.  However in some situations it is an important sign of disease which if detected early could help a person.  The extra heart sound is important to be able to detect as it cannot be detected by ultrasound very well. Below note the temporal description of the extra heart sounds …lub.lub……….dub………..………. lub. lub……….dub…………….lub.lub……..…….dub…….  or …lub………. dub.dub………………….lub.……….dub.dub………………….lub……..…….dub. dub…… Artifact Category (Dataset A) In the Artifact category there are a wide range of different sounds including feedback squeals and echoes speech music and noise. There are usually no discernable heart sounds and thus little or no temporal periodicity at frequencies below 195 Hz. This category is the most different from the others. It is important to be able to distinguish this category from the other three categories so that someone gathering the data can be instructed to try again. Extrasystole Category (Dataset B) Extrasystole sounds may appear occasionally and can be identified because there is a heart sound that is out of rhythm involving extra or skipped heartbeats e.g. a “lub-lub dub” or a “lub dub-dub”. (This is not the same as an extra heart sound as the event is not regularly occuring.) An extrasystole may not be a sign of disease. It can happen normally in an adult and can be very common in children. However in some situations extrasystoles can be caused by heart diseases. If these diseases are detected earlier then treatment is likely to be more effective. Below note the temporal description of the extra heart sounds …........lub……….dub………..………. lub. ………..……….dub…………….lub.lub……..…….dub…….  or …lub………. dub......………………….lub.…………………dub.dub………………….lub……..…….dub.…… Acknowledgments Please use the following citation if the data is used @misc{pascal-chsc-2011        author = ""Bentley P. and Nordehn G. and Coimbra M. and Mannor S.""        title = ""The {PASCAL} {C}lassifying {H}eart {S}ounds {C}hallenge 2011 {(CHSC2011)} {R}esults""        howpublished = ""http//www.peterjbentley.com/heartchallenge/index.html""}",dataset:fname:label:sublabel:,string:string:string:string:,diagnostics
Human Activity Recognition with Smartphones , UCI Machine Learning , www.kaggle.com/uciml/human-activity-recognition-with-smartphones , Thu Oct 06 2016 23:32:39 GMT+0530 (IST) , Recordings of 30 study participants performing activities of daily living ,3258, sociology- human-computer interaction- telecommunications- ,The Human Activity Recognition database was built from the recordings of 30 study participants performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors. The objective is to classify activities into one of the six activities performed. Description of experiment The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING WALKING_UPSTAIRS WALKING_DOWNSTAIRS SITTING STANDING LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets where 70% of the volunteers was selected for generating the training data and 30% the test data.  The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal which has gravitational and body motion components was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components therefore a filter with 0.3 Hz cutoff frequency was used. From each window a vector of features was obtained by calculating variables from the time and frequency domain. Attribute information For each record in the dataset the following is provided   Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.  Triaxial Angular velocity from the gyroscope.  A 561-feature vector with time and frequency domain variables.  Its activity label.  An identifier of the subject who carried out the experiment.  Relevant papers Davide Anguita Alessandro Ghio Luca Oneto Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. International Workshop of Ambient Assisted Living (IWAAL 2012). Vitoria-Gasteiz Spain. Dec 2012  Davide Anguita Alessandro Ghio Luca Oneto Xavier Parra Jorge L. Reyes-Ortiz. Energy Efficient Smartphone-Based Activity Recognition using Fixed-Point Arithmetic. Journal of Universal Computer Science. Special Issue in Ambient Assisted Living Home Care. Volume 19 Issue 9. May 2013 Davide Anguita Alessandro Ghio Luca Oneto Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. 4th International Workshop of Ambient Assited Living IWAAL 2012 Vitoria-Gasteiz Spain December 3-5 2012. Proceedings. Lecture Notes in Computer Science 2012 pp 216-223.  Jorge Luis Reyes-Ortiz Alessandro Ghio Xavier Parra-Llanas Davide Anguita Joan Cabestany Andreu Català. Human Activity and Motion Disorder Recognition Towards Smarter Interactive Cognitive Environments. 21st European Symposium on Artificial Neural Networks Computational Intelligence and Machine Learning ESANN 2013. Bruges Belgium 24-26 April 2013. Citation Davide Anguita Alessandro Ghio Luca Oneto Xavier Parra and Jorge L. Reyes-Ortiz. A Public Domain Dataset for Human Activity Recognition Using Smartphones. 21st European Symposium on Artificial Neural Networks Computational Intelligence and Machine Learning ESANN 2013. Bruges Belgium 24-26 April 2013.,,,fitness and personal well being
Glass Classification , UCI Machine Learning , www.kaggle.com/uciml/glass , Fri Jan 27 2017 22:57:48 GMT+0530 (IST) , Can you correctly identify glass type? ,2483, chemistry- artificial intelligence- ,Context This is a Glass Identification Data Set from UCI. It contains 10 attributes including id. The response is glass type(discrete 7 values) Content Attribute Information  Id number 1 to 214 (removed from CSV file) RI refractive index  Na Sodium (unit measurement weight percent in corresponding oxide as are attributes 4-10)  Mg Magnesium  Al Aluminum  Si Silicon  K Potassium  Ca Calcium  Ba Barium  Fe Iron  Type of glass (class attribute)  -- 1 building_windows_float_processed  -- 2 building_windows_non_float_processed  -- 3 vehicle_windows_float_processed  -- 4 vehicle_windows_non_float_processed (none in this database)  -- 5 containers  -- 6 tableware  -- 7 headlamps  Acknowledgements https//archive.ics.uci.edu/ml/datasets/Glass+Identification Source Creator  B. German  Central Research Establishment  Home Office Forensic Science Service  Aldermaston Reading Berkshire RG7 4PN  Donor  Vina Spiehler Ph.D. DABFT  Diagnostic Products Corporation  (213) 776-0180 (ext 3014) Inspiration Data exploration of this dataset reveals two important characteristics  1) The variables are highly corelated with each other including the response variables So which kind of ML algorithm is most suitable for this dataset Random Forest  KNN or other? Also since dataset is too small is there any chance of applying PCA or it should be completely avoided? 2) Highly Skewed Data Is scaling sufficient or are there any other techniques which should be applied to normalize data? Like BOX-COX Power transformation?,RI:Na:Mg:Al:Si:K:Ca:Ba:Fe:Type:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,chemistry
World Tennis Odds Database , DMPierre , www.kaggle.com/dmpierre/world-tennis-odds-database , Sun Sep 10 2017 23:14:20 GMT+0530 (IST) , +139K tennis matches 15 bookies worldwide. ,175, tennis- sports- ,Context How good of an arbitrageur would you be?  Find it out in the  World Tennis Database which gathers more than 139K matches with odds from 15 different bookies (49 MB).  If you are looking to predict the outcome of a tennis match to find arbitrage opportunities  inspecting variations in a particular player odds or simply searching to improve your Machine Learning or visualisation skills then this dataset might be looking for you too.  Content Data is packed in CSV format ready to spit out some interesting statistics. It is composed of the following 72 columns  Url string Country string Date (yyyy-mm-dd hhmm) to ease date-time transformations. Day string Tournament name string Doubles either 0 or 1 when it is not a single player match Player 1(2) name string Player 1(2) score int number of sets won Player 1(2) set 0 score int up until set 4 - indexing of sets starts at 0 ask why to python ;)  No set info either 0 or 1 when there is no informations about the final set scores Missing bookies either 0 or 1  when there is no informations about any bookies odds Retired player either 0 or 1 when one player retired Cancelled game either 0 or 1 when the game got cancelled Comments string used to insert any comments during the scraping process Walkover either 0 or 1 when one player chose to walkover Awarded player either 0 or 1 when one player got awarded  Fifteen bookies were then taken into account each having three type of infos Player 1 odd Player 2 odd Payout. This result in adding to the preceding 27 columns 45 others.  Bookies were sorted alphabetically   10Bet 18Bet 5Dimes Bet At Home Bet365 BetHard BetOlimp BetRally BWin JetBull MarathonBet Pinnacle TempoBet TonyBet Unibet  Acknowledgements Huge kudos to the OddsPortal Website for their wonderful archiving job.  Cover photo by Jeremy Galliani on Unsplash. Inspiration Various interesting infos and predictions can be made out of this dataset.  Individual players trajectories and their respective odds movements.  Bookies respective strategies. Who sets the pace?  Detecting patterns in arbitrage situations (arbitrageur perspective). And of course predicting the winner of a game as draws are not allowed.  Of course I got inspired by the European Soccer Database. Finally for details about the scraping process visit https//dmpierre.github.io/. ,url:country:date:day:tournament_name:doubles:player_1_name:player_2_name:player_1_score:player_2_score:player_1_set_0:player_1_set_1:player_1_set_2:player_1_set_3:player_1_set_4:player_2_set_0:player_2_set_1:player_2_set_2:player_2_set_3:player_2_set_4:no_set_info:missing_bookies:retired_player:cancelled_game:comments:walkover:awarded_player:10bet_payout:10bet_player_1_odd:10bet_player_2_odd:18bet_payout:18bet_player_1_odd:18bet_player_2_odd:5dimes_payout:5dimes_player_1_odd:5dimes_player_2_odd:bet-at-home_payout:bet-at-home_player_1_odd:bet-at-home_player_2_odd:bet365_payout:bet365_player_1_odd:bet365_player_2_odd:bethard_payout:bethard_player_1_odd:bethard_player_2_odd:betolimp_payout:betolimp_player_1_odd:betolimp_player_2_odd:betrally_payout:betrally_player_1_odd:betrally_player_2_odd:bwin_payout:bwin_player_1_odd:bwin_player_2_odd:jetbull_payout:jetbull_player_1_odd:jetbull_player_2_odd:marathonbet_payout:marathonbet_player_1_odd:marathonbet_player_2_odd:pinnacle_payout:pinnacle_player_1_odd:pinnacle_player_2_odd:tempobet_payout:tempobet_player_1_odd:tempobet_player_2_odd:tonybet_payout:tonybet_player_1_odd:tonybet_player_2_odd:unibet_payout:unibet_player_1_odd:unibet_player_2_odd:,string:string:dateTime:string:string:numeric:string:string:numeric:numeric:numeric:numeric:numeric:string:string:numeric:numeric:numeric:string:string:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,sports events
Cervical Cancer Risk Classification , Gokagglers  , www.kaggle.com/loveall/cervical-cancer-risk-classification , Thu Aug 31 2017 06:32:22 GMT+0530 (IST) , prediction of  cancer indicators; Please download; run kernel & upvote ,3241, human medicine- ,Cervical Cancer Risk Factors for Biopsy This Dataset is Obtained from UCI Repository and kindly acknowledged! This file contains a List of Risk Factors for Cervical Cancer leading to a Biopsy Examination! About 11000 new cases of invasive cervical cancer are diagnosed each year in the U.S. However the number of new cervical cancer cases has been declining steadily over the past decades. Although it is the most preventable type of cancer each year cervical cancer kills about 4000 women in the U.S. and about 300000 women worldwide. In the United States cervical cancer mortality rates plunged by 74% from 1955 - 1992 thanks to increased screening and early detection with the Pap test. AGE Fifty percent of cervical cancer diagnoses occur in women ages 35 - 54 and about 20% occur in women over 65 years of age. The median age of diagnosis is 48 years. About 15% of women develop cervical cancer between the ages of 20 - 30. Cervical cancer is extremely rare in women younger than age 20. However many young women become infected with multiple types of human papilloma virus which then can increase their risk of getting cervical cancer in the future. Young women with early abnormal changes who do not have regular examinations are at high risk for localized cancer by the time they are age 40 and for invasive cancer by age 50. SOCIOECONOMIC AND ETHNIC FACTORS Although the rate of cervical cancer has declined among both Caucasian and African-American women over the past decades it remains much more prevalent in African-Americans -- whose death rates are twice as high as Caucasian women. Hispanic American women have more than twice the risk of invasive cervical cancer as Caucasian women also due to a lower rate of screening. These differences however are almost certainly due to social and economic differences. Numerous studies report that high poverty levels are linked with low screening rates. In addition lack of health insurance limited transportation and language difficulties hinder a poor woman’s access to screening services. HIGH SEXUAL ACTIVITY Human papilloma virus (HPV) is the main risk factor for cervical cancer. In adults the most important risk factor for HPV is sexual activity with an infected person. Women most at risk for cervical cancer are those with a history of multiple sexual partners sexual intercourse at age 17 years or younger or both. A woman who has never been sexually active has a very low risk for developing cervical cancer. Sexual activity with multiple partners increases the likelihood of many other sexually transmitted infections (chlamydia gonorrhea syphilis).Studies have found an association between chlamydia and cervical cancer risk including the possibility that chlamydia may prolong HPV infection. FAMILY HISTORY Women have a higher risk of cervical cancer if they have a first-degree relative (mother sister) who has had cervical cancer. USE OF ORAL CONTRACEPTIVES Studies have reported a strong association between cervical cancer and long-term use of oral contraception (OC). Women who take birth control pills for more than 5 - 10 years appear to have a much higher risk HPV infection (up to four times higher) than those who do not use OCs. (Women taking OCs for fewer than 5 years do not have a significantly higher risk.) The reasons for this risk from OC use are not entirely clear. Women who use OCs may be less likely to use a diaphragm condoms or other methods that offer some protection against sexual transmitted diseases including HPV. Some research also suggests that the hormones in OCs might help the virus enter the genetic material of cervical cells. HAVING MANY CHILDREN Studies indicate that having many children increases the risk for developing cervical cancer particularly in women infected with HPV. SMOKING Smoking is associated with a higher risk for precancerous changes (dysplasia) in the cervix and for progression to invasive cervical cancer especially for women infected with HPV. IMMUNOSUPPRESSION Women with weak immune systems (such as those with HIV / AIDS) are more susceptible to acquiring HPV. Immunocompromised patients are also at higher risk for having cervical precancer develop rapidly into invasive cancer. DIETHYLSTILBESTROL (DES) From 1938 - 1971 diethylstilbestrol (DES) an estrogen-related drug was widely prescribed to pregnant women to help prevent miscarriages. The daughters of these women face a higher risk for cervical cancer. DES is no longer prsecribed.,Age:Number of sexual partners:First sexual intercourse:Num of pregnancies:Smokes:Smokes (years):Smokes (packs/year):Hormonal Contraceptives:Hormonal Contraceptives (years):IUD:IUD (years):STDs:STDs (number):STDs:condylomatosis:STDs:cervical condylomatosis:STDs:vaginal condylomatosis:STDs:vulvo-perineal condylomatosis:STDs:syphilis:STDs:pelvic inflammatory disease:STDs:genital herpes:STDs:molluscum contagiosum:STDs:AIDS:STDs:HIV:STDs:Hepatitis B:STDs:HPV:STDs: Number of diagnosis:STDs: Time since first diagnosis:STDs: Time since last diagnosis:Dx:Cancer:Dx:CIN:Dx:HPV:Dx:Hinselmann:Schiller:Citology:Biopsy:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,diagnostics
Israeli Elections 2015 , Itamar Mushkin , www.kaggle.com/itamarmushkin/israeli-elections-2015 , Mon Oct 16 2017 23:20:29 GMT+0530 (IST) , Number of votes per party per voting booth. ,139, politics- ,Results of the 2015 elections in Israel taken from the official elections website. [4th version added also the 2013 election results]. Results are given by voting booths (of comparable sizes of 0-800) and not by settlements (which are very varied - think Tel Aviv compared to a small kibbutz). The first seven columns are information about each settlement and voting booth and from the eighth to the end is the number of votes each party has recieved in each booth. This data is freely available at http//votes20.gov.il/ I just translated the column headers into English [2013 results are from http//www.votes-19.gov.il/nationalresults]. [from version 3 and onward settlement names are translated according to the central bureau of statistics http//www.cbs.gov.il/ishuvim/ishuvim_main.htm which uses the same settlement_code as the election results] Personally I've viewed this dataset in order to map out the relationships between different parties (i.e which are 'closer' which are more 'central') but I guess there are many other questions to answer. This question is significant in Israel where the composition of the parliament is determined almost directly by the popular vote (e.g a party with 25% of the total proper votes will recieve 25% of seats in parliament) but the government is formed by a coalition of parties (so the head of the largest party in parliament will not necessarily be the Prime Minister). This is my first dataset so any feedback is welcome especially if I made some newbie mistake.,settlement_name:settlement_code:settlement_name_hebrew:booth_number:Registered_voters:votes:bad_votes:proper_votes:Ale Yarok:Am Shalem:Balad:Brit Olam:Daam Workers Party:Eretz Hadasha:Green Party:Hadash:Haim Bekavod:Hatnua:Hope for Change:HaYisraelim:Kadima:Kalkala:Koah LeHashpi'a:Jewish House:Labour Party:Leader:Likud:Meretz:Moreshet Avot:Na Nach:Or:Otzma LeYisrael:Pirate Party:Raam-Taal:Senior Citizens Party:Shas:Social Justice:United Torah Judaism:We're Brothers:Yesh Atid:,string:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,elections
English Premier League Players Dataset 2017/18 , ShubhamMaurya , www.kaggle.com/mauryashubham/english-premier-league-players-dataset , Thu Aug 03 2017 15:58:08 GMT+0530 (IST) , A unique dataset containing FPL data popularity and market values ,388, association football- ,Context For most football fans May - July represents a lull period due to the lack of club football. What makes up for it is the intense transfer speculation that surrounds all major player transfers today. Their market valuations also lead to a few raised eyebrows lately more than ever.  I was curious to see how good a proxy popularity could be for ability and the predictive power it would have in a model estimating a player's market value.  Content name Name of the player club Club of the player age  Age of the player position  The usual position on the pitch   position_cat     1 for attackers   2 for midfielders   3 for defenders   4 for goalkeepers     market_value  As on transfermrkt.com on July 20th 2017   page_views  Average daily Wikipedia page views from September 1 2016 to May 1 2017   fpl_value  Value in Fantasy Premier League as on July 20th 2017   fpl_sel  % of FPL players who have selected that player in their team   fpl_points  FPL points accumulated over the previous season   region    1 for England   2 for EU   3 for Americas   4 for Rest of World     nationality  new_foreign  Whether a new signing from a different league for 2017/18 (till 20th July)   age_cat  club_id  big_club Whether one of the Top 6 clubs   new_signing Whether a new signing for 2017/18 (till 20th July)   Inspiration To statistically analyse the beautiful game.,name:club:age:position:position_cat:market_value:page_views:fpl_value:fpl_sel:fpl_points:region:nationality:new_foreign:age_cat:club_id:big_club:new_signing:,string:string:numeric:string:numeric:numeric:numeric:numeric:string:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:,sports teams and players
US Consumer Finance Complaints , Consumer Financial Protection Bureau , www.kaggle.com/cfpb/us-consumer-finance-complaints , Wed Apr 27 2016 04:03:46 GMT+0530 (IST) , US consumer complaints on financial products and company responses ,3014, finance- ,Each week the CFPB sends thousands of consumers’ complaints about financial products and services to companies for response. Those complaints are published here after the company responds or after 15 days whichever comes first. By adding their voice consumers help improve the financial marketplace.,,,trade and business
Crime in Vancouver , Wilian Osaku , www.kaggle.com/wosaku/crime-in-vancouver , Sun Aug 13 2017 11:59:20 GMT+0530 (IST) , Data of crimes in Vancouver (Canada) from 2003 to 2017 ,116, crime- ,Content The data comes from the Vancouver Open Data Catalogue. It was extracted on 2017-07-18 and it contains 530652 records from 2003-01-01 to 2017-07-13. The original data set contains coordinates in UTM Zone 10. I also included Latitude and Longitude which I converted using this spreadsheet that can be found here. Acknowledgements Photo By Charles de Jesus [CC BY 3.0 (http//creativecommons.org/licenses/by/3.0)] via Wikimedia Commons,TYPE:YEAR:MONTH:DAY:HOUR:MINUTE:HUNDRED_BLOCK:NEIGHBOURHOOD:X:Y:Latitude:Longitude:,string:numeric:numeric:numeric:numeric:numeric:string:string:numeric:numeric:numeric:numeric:,crime
UK Housing Prices Paid , HM Land Registry , www.kaggle.com/hm-land-registry/uk-housing-prices-paid , Wed Aug 16 2017 02:13:41 GMT+0530 (IST) , Records of all individual transactions in England and Wales since 1995 ,173, housing- finance- government- ,The Price Paid Data includes information on all registered property sales in England and Wales that are sold for full market value. Address details have been truncated to the town/city level.  You might also find the HM Land Registry transaction records to be a useful supplement to this dataset https//www.kaggle.com/hm-land-registry/uk-land-registry-transactions The available fields are as follows Transaction unique identifier   A reference number which is generated automatically recording each published sale. The number is unique and will change each time a sale is recorded. Price   Sale price stated on the transfer deed. Date of Transfer    Date when the sale was completed as stated on the transfer deed. Property Type   D = Detached S = Semi-Detached T = Terraced F = Flats/Maisonettes O = Other  Note that  - we only record the above categories to describe property type we do not separately identify bungalows.  - end-of-terrace properties are included in the Terraced category above.  - ‘Other’ is only valid where the transaction relates to a property type that is not covered by existing values. Old/New Indicates the age of the property and applies to all price paid transactions residential and non-residential. Y = a newly built property N = an established residential building Duration    Relates to the tenure F = Freehold L= Leasehold etc. Note that HM Land Registry does not record leases of 7 years or less in the Price Paid Dataset. Town/City     District      County    PPD Category Type   Indicates the type of Price Paid transaction. A = Standard Price Paid entry includes single residential property sold for full market value. B = Additional Price Paid entry including transfers under a power of sale/repossessions buy-to-lets (where they can be identified by a Mortgage) and transfers to non-private individuals. Note that category B does not separately identify the transaction types stated. HM Land Registry has been collecting information on Category A transactions from January 1995. Category B transactions were identified from October 2013.  Record Status - monthly file only   Indicates additions changes and deletions to the records.(see guide below). A = Addition C = Change D = Delete. Note that where a transaction changes category type due to misallocation (as above) it will be deleted from the original category type and added to the correct category with a new transaction unique identifier. This data was kindly released by HM Land Registry under the Open Government License 3.0. You can find their current release here. Data produced by HM Land Registry © Crown copyright 2017.,Transaction unique identifier:Date of Transfer:Property Type:Old/New:Duration:Town/City:District:County:PPDCategory Type:Record Status - monthly file only:Price:,string:dateTime:string:string:string:string:string:string:string:string:dateTime:,real estate
Mushroom Classification , UCI Machine Learning , www.kaggle.com/uciml/mushroom-classification , Fri Dec 02 2016 04:38:00 GMT+0530 (IST) , Safe to eat or deadly poison? ,7082, food and drink- human medicine- plants- ,"Context Although this dataset was originally contributed to the UCI Machine Learning repository nearly 30 years ago mushroom hunting (otherwise known as ""shrooming"") is enjoying new peaks in popularity. Learn which features spell certain death and which are most palatable in this dataset of mushroom characteristics. And how certain can your model be? Content This dataset includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family Mushroom drawn from The Audubon Society Field Guide to North American Mushrooms (1981). Each species is identified as definitely edible definitely poisonous or of unknown edibility and not recommended. This latter class was combined with the poisonous one. The Guide clearly states that there is no simple rule for determining the edibility of a mushroom; no rule like ""leaflets three let it be'' for Poisonous Oak and Ivy.  Time period Donated to UCI ML 27 April 1987  Inspiration  What types of machine learning models perform best on this dataset? Which features are most indicative of a poisonous mushroom?  Acknowledgements This dataset was originally donated to the UCI Machine Learning repository. You can learn more about past research using the data here.  Start a new kernel",class:cap-shape:cap-surface:cap-color:bruises:odor:gill-attachment:gill-spacing:gill-size:gill-color:stalk-shape:stalk-root:stalk-surface-above-ring:stalk-surface-below-ring:stalk-color-above-ring:stalk-color-below-ring:veil-type:veil-color:ring-number:ring-type:spore-print-color:population:habitat:,string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:,botanical
Chocolate Bar Ratings , Rachael Tatman , www.kaggle.com/rtatman/chocolate-bar-ratings , Sat Aug 12 2017 04:55:42 GMT+0530 (IST) , Expert ratings of over 1700 chocolate bars ,475, critical theory- food and drink- ,Context Chocolate is one of the most popular candies in the world. Each year residents of the United States collectively eat more than 2.8 billions pounds. However not all chocolate bars are created equal! This dataset contains expert ratings of over 1700 individual chocolate bars along with information on their regional origin percentage of cocoa the variety of chocolate bean used and where the beans were grown. Flavors of Cacao Rating System  5= Elite (Transcending beyond the ordinary limits) 4= Premium (Superior flavor development character and style) 3= Satisfactory(3.0) to praiseworthy(3.75) (well made with special qualities) 2= Disappointing (Passable but contains at least one significant flaw) 1= Unpleasant (mostly unpalatable)  Each chocolate is evaluated from a combination of both objective qualities and subjective interpretation. A rating here only represents an experience with one bar from one batch. Batch numbers vintages and review dates are included in the database when known.  The database is narrowly focused on plain dark chocolate with an aim of appreciating the flavors of the cacao when made into chocolate. The ratings do not reflect health benefits social missions or organic status. Flavor is the most important component of the Flavors of Cacao ratings. Diversity balance intensity and purity of flavors are all considered. It is possible for a straight forward single note chocolate to rate as high as a complex flavor profile that changes throughout. Genetics terroir post harvest techniques processing and storage can all be discussed when considering the flavor component.  Texture has a great impact on the overall experience and it is also possible for texture related issues to impact flavor. It is a good way to evaluate the makers vision attention to detail and level of proficiency. Aftermelt is the experience after the chocolate has melted. Higher quality chocolate will linger and be long lasting and enjoyable. Since the aftermelt is the last impression you get from the chocolate it receives equal importance in the overall rating. Overall Opinion is really where the ratings reflect a subjective opinion. Ideally it is my evaluation of whether or not the components above worked together and an opinion on the flavor development character and style. It is also here where each chocolate can usually be summarized by the most prominent impressions that you would remember about each chocolate. Acknowledgements These ratings were compiled by Brady Brelinski Founding Member of the Manhattan Chocolate Society. For up-to-date information as well as additional content (including interviews with craft chocolate makers) please see his website Flavors of Cacao Inspiration  Where are the best cocoa beans grown? Which countries produce the highest-rated bars? What’s the relationship between cocoa solids percentage and rating? ,Company (Maker-if known):Specific Bean Origin or Bar Name:REF:Review Date:Cocoa Percent:Company Location:Rating:Bean Type:Broad Bean Origin:,string:string:numeric:numeric:string:string:numeric:string:string:,food and nutrition
World Happiness Report , Sustainable Development Solutions Network , www.kaggle.com/unsdsn/world-happiness , Thu Jun 15 2017 02:11:45 GMT+0530 (IST) , Happiness scored according to economic production social support etc. ,11460, emotion- social sciences- economics- ,Context The World Happiness Report is a landmark survey of the state of global happiness. The first report was published in 2012 the second in 2013 the third in 2015 and the fourth in the 2016 Update. The World Happiness 2017 which ranks 155 countries by their happiness levels was released at the United Nations at an event celebrating International Day of Happiness on March 20th. The report continues to gain global recognition as governments organizations and civil society increasingly use happiness indicators to inform their policy-making decisions. Leading experts across fields – economics psychology survey analysis national statistics health public policy and more – describe how measurements of well-being can be used effectively to assess the progress of nations. The reports review the state of happiness in the world today and show how the new science of happiness explains personal and national variations in happiness.  Content The happiness scores and rankings use data from the Gallup World Poll. The scores are based on answers to the main life evaluation question asked in the poll. This question known as the Cantril ladder asks respondents to think of a ladder with the best possible life for them being a 10 and the worst possible life being a 0 and to rate their own current lives on that scale. The scores are from nationally representative samples for the years 2013-2016 and use the Gallup weights to make the estimates representative. The columns following the happiness score estimate the extent to which each of six factors – economic production social support life expectancy freedom absence of corruption and generosity – contribute to making life evaluations higher in each country than they are in Dystopia a hypothetical country that has values equal to the world’s lowest national averages for each of the six factors. They have no impact on the total score reported for each country but they do explain why some countries rank higher than others. Inspiration What countries or regions rank the highest in overall happiness and each of the six factors contributing to happiness? How did country ranks or scores change between the 2015 and 2016 as well as the 2016 and 2017 reports? Did any country experience a significant increase or decrease in happiness? What is Dystopia? Dystopia is an imaginary country that has the world’s least-happy people. The purpose in establishing Dystopia is to have a benchmark against which all countries can be favorably compared (no country performs more poorly than Dystopia) in terms of each of the six key variables thus allowing each sub-bar to be of positive width. The lowest scores observed for the six key variables therefore characterize Dystopia. Since life would be very unpleasant in a country with the world’s lowest incomes lowest life expectancy lowest generosity most corruption least freedom and least social support it is referred to as “Dystopia” in contrast to Utopia. What are the residuals? The residuals or unexplained components differ for each country reflecting the extent to which the six variables either over- or under-explain average 2014-2016 life evaluations. These residuals have an average value of approximately zero over the whole set of countries. Figure 2.2 shows the average residual for each country when the equation in Table 2.1 is applied to average 2014- 2016 data for the six variables in that country. We combine these residuals with the estimate for life evaluations in Dystopia so that the combined bar will always have positive values. As can be seen in Figure 2.2 although some life evaluation residuals are quite large occasionally exceeding one point on the scale from 0 to 10 they are always much smaller than the calculated value in Dystopia where the average life is rated at 1.85 on the 0 to 10 scale. What do the columns succeeding the Happiness Score(like Family Generosity etc.) describe? The following columns GDP per Capita Family Life Expectancy Freedom Generosity Trust Government Corruption describe the extent to which these factors contribute in evaluating the happiness in each country.  The Dystopia Residual metric actually is the Dystopia Happiness Score(1.85) +  the Residual value or the unexplained value for each country as stated in the previous answer. If you add all these factors up you get the happiness score so it might be un-reliable to model them to predict Happiness Scores. Start a new kernel,Region:Country:Happiness Score:Standard Error:Economy (GDP per Capita):Family:Health (Life Expectancy):Freedom:Trust (Government Corruption):Generosity:Dystopia Residual:Happiness Rank:,string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,politics
20 Years of Games , Eric Grinstein , www.kaggle.com/egrinstein/20-years-of-games , Wed Sep 28 2016 01:35:13 GMT+0530 (IST) , 18000+ rows of review data from ign.com ,5624, video games- games- ,This dataset is the result of a crawl I did on http//ign.com/games/reviews . It contains 18625 lines with the fields like the release date it's platform and IGN's score. All the lines are fully filled. In 20 years the gaming industry has grown and sophisticated. By exploring this dataset one is able to find trends about the industry compare consoles against eachother search through the most popular genres and more. The dataset can also be a great place for beginners to start using Python modules such as Pandas and Seaborn.  You can find the crawl I used for the retrieval here,:,numeric:,video games
Pokemon Challenge , T7 - Pokemon Challenge , www.kaggle.com/terminus7/pokemon-challenge , Thu Sep 21 2017 14:13:04 GMT+0530 (IST) , Welcome to Weedle's cave ,229, popular culture- video games- data analysis- ,Welcome to Weedle's cave. The only Pokemon gambling den. Will you be able to predict the outcome of future matches?. If you make it you can earn fame and fortune. To do it you will have the pokemon characteristics and the results of previous combats. Rules Three files are available. The first one contains the pokemon characteristics (the first column being the id of the pokemon). The second one contains information about previous combats. The first two columns contain the ids of the combatants and the third one the id of the winner.  Important The pokemon in the first columns attacks first. The goal is to develop a Machine Learning model able to predict the result of future pokemon combats. Any doubts or problems found related to the competition please email  t7pokemonchallenge@intelygenz.com The test data set will be a CSV file with two columns with the ids of the pokemon fighting the combat. The response file must be a similar CSV file with another column with a third column with the id of the winning pokemon. The rows must be in the same order as the test data set file. DISCLAIMER In Intelygenz we are against animal abuse. No animal real or imaginary should be forced to fight against other.  Freedom for the pokemons !,First_pokemon:Second_pokemon:Winner:,numeric:numeric:numeric:,video games
Restaurants on Yellowpages.com , PromptCloud , www.kaggle.com/PromptCloudHQ/restaurants-on-yellowpagescom , Sat Sep 16 2017 02:26:59 GMT+0530 (IST) , 6000 Restaurants on Yellowpages.com ,49, hotels- internet- ,Context This is a pre-crawled dataset taken as subset of a bigger dataset (more than 85000 restaurants) that was created by extracting data from yellowpages.com.  Content This dataset has following fields  Url Name Street Zip Code City State Phone Email Website Categories - A comma-delimited () list of categories the listing in question falls under. Most listings are placed in multiple categories.  Acknowledgements This dataset was created by PromptCloud's in-house web-crawling service. Inspiration Analyses of city and categories can be performed.,Uniq Id:Url:Name:Street:Zip Code:City:State:Phone:Email:Website:Categories:,string:string:string:string:numeric:string:string:string:string:string:string:,online information
 Bestseller books on Paytm , PromptCloud , www.kaggle.com/PromptCloudHQ/bestseller-books-on-paytm , Sat Sep 16 2017 02:23:25 GMT+0530 (IST) ,  1500 bestseller books on Paytm ,95, books- internet- ,Context This is a pre-crawled dataset taken as subset of a bigger dataset (more than 16000 books) that was created by extracting data from paytm.com a leading eCommerce store in India. Content This dataset has following fields  amtsave brand breadcrumbs country desc discount domain gallery image insertedon list_price model name other_sellers payment_methods_supported productcode selling_price specifications type uniq_id url weight  Acknowledgements This dataset was created by PromptCloud's in-house web-crawling service. Inspiration Analyses of pricing discount specifications and authors can be performed.,amtsave:brand:breadcrumbs:country:desc:discount:domain:gallery:image:insertedon:list_price:model:name:other_sellers:payment_methods_supported:productcode:selling_price:specifications:type:uniq_id:url:weight:,numeric:string:string:string:string:string:string:string:string:dateTime:numeric:numeric:string:string:string:numeric:numeric:string:string:string:string:numeric:,books and comics
Twitter User Gender Classification , Crowdflower , www.kaggle.com/crowdflower/twitter-user-gender-classification , Mon Nov 21 2016 07:18:06 GMT+0530 (IST) , Predict user gender based on Twitter profile information ,2901, gender- twitter- internet- ,"This data set was used to train a CrowdFlower AI gender predictor. You can read all about the project here. Contributors were asked to simply view a Twitter profile and judge whether the user was a male a female or a brand (non-individual). The dataset contains 20000 rows each with a user name a random tweet account profile and image location and even link and sidebar color. Inspiration Here are a few questions you might try to answer with this dataset  how well do words in tweets and profiles predict user gender? what are the words that strongly predict male or female gender? how well do stylistic factors (like link color and sidebar color) predict user gender?  Acknowledgments Data was provided by the Data For Everyone Library on Crowdflower. Our Data for Everyone library is a collection of our favorite open data jobs that have come through our platform. They're available free of charge for the community forever. The Data The dataset contains the following fields  _unit_id a unique id for user _golden whether the user was included in the gold standard for the model; TRUE or FALSE _unit_state state of the observation; one of finalized (for contributor-judged) or golden (for gold standard observations) _trusted_judgments number of trusted judgments (int); always 3 for non-golden and what may be a unique id for gold standard observations _last_judgment_at date and time of last contributor judgment; blank for gold standard observations gender one of male female or brand (for non-human profiles) genderconfidence a float representing confidence in the provided gender profile_yn ""no"" here seems to mean that the profile was meant to be part of the dataset but was not available when contributors went to judge it profile_ynconfidence confidence in the existence/non-existence of the profile created date and time when the profile was created description the user's profile description fav_number number of tweets the user has favorited gender_gold if the profile is golden what is the gender? link_color the link color on the profile as a hex value name the user's name profile_yn_gold whether the profile y/n value is golden  profileimage a link to the profile image retweet_count number of times the user has retweeted (or possibly been retweeted) sidebar_color color of the profile sidebar as a hex value text text of a random one of the user's tweets tweet_coord if the user has location turned on the coordinates as a string with the format ""[latitude longitude]"" tweet_count number of tweets that the user has posted tweet_created when the random tweet (in the text column) was created tweet_id the tweet id of the random tweet tweet_location location of the tweet; seems to not be particularly normalized user_timezone the timezone of the user ",,,social media
Congressional Election Disbursements , Federal Election Commission , www.kaggle.com/fec/congressional-election-expenditures , Tue Sep 19 2017 21:27:49 GMT+0530 (IST) , House & Senate campaign expenditures for 2010-2016 ,129, politics- ,Modern American congressional campaigns usually spend millions of dollars. This dataset provides a detailed breakdown of where that money goes. However the descriptions are provided as unstructured text. Can you provide a useful clustering of the expenses? This data comes from the US Federal Election Commission. You can find the original dataset here.,com_id:com_nam:can_id:can_nam:ele_yea:can_off:can_off_sta:can_off_dis:lin_num:lin_ima:rec_com_id:rec_nam:rec_str1:rec_str2:rec_cit:rec_sta:rec_zip:dis_dat:dis_amo:dis_pur_des:mem_cod:mem_tex:cat_cod:cat_des:tra_id:bac_ref_id:,string:string:string:string:numeric:string:string:numeric:numeric:string:string:string:string:string:string:string:numeric:dateTime:string:string:string:string:numeric:string:string:string:,politics
New Zealand Migration , Timo Bozsolik , www.kaggle.com/timoboz/migration-nz , Wed Jun 07 2017 11:10:58 GMT+0530 (IST) , Migration numbers to and from New Zealand from 1979 to 2016 ,201, countries- demographics- ,"Context *This dataset shows the migration to and from New Zealand by country and citizenship from 1979 to 2016. * Content The columns in this dataset are  Measure The signal type given in this row one of ""Arrivals"" ""Departures"" ""Net"" Country Country from where people arrived into to New Zealand (for Measure = ""Arrivals"") or to where they left (for Measure = ""Departures""). Contains special values ""Not Stated"" and ""All countries"" (grand total) Citizenship Citizenship of the migrants one of ""New Zealand Citizen"" ""Australian Citizen"" ""Total All Citizenships"" Year Year of the measurement Value Number of migrants  Permanent and long-term arrivals include overseas migrants who arrive in New Zealand intending to stay for a period of 12 months or more (or permanently) plus New Zealand residents returning after an absence of 12 months or more. Permanent and long-term departures include New Zealand residents departing for an intended period of 12 months or more (or permanently) plus overseas visitors departing New Zealand after a stay of 12 months or more. For arrival series the country of residence is the country where a person arriving in New Zealand last lived for 12 months or more (country of last permanent residence). For departure series the country of residence is the country where a person departing New Zealand intends to live for the next 12 months or more (country of next permanent residence). Acknowledgements Curated data by figure.nz original data from Stats NZ. Dataset licensed under Creative Commons 4.0 - CC BY 4.0. Inspiration A good challenge would be to explain New Zealand migration flows as a function of the economic performance of New Zealand or other countries (combine with other datasets). The data could be possibly linked up with other data sources to predict general migration to/from countries based on external factors.",Measure:Country:Citizenship:Year:Value:,string:string:string:dateTime:numeric:,demography
Gun violence database , Gun Violence Archive , www.kaggle.com/gunviolencearchive/gun-violence-database , Sun Nov 27 2016 09:46:43 GMT+0530 (IST) , Archive of U.S. gun violence incidents collected from over 2000 sources ,907, crime- ,Context The Gun Violence Archive is an online archive of gun violence incidents collected from over 2000 media law enforcement government and commercial sources daily in an effort to provide near-real time data about the results of gun violence. GVA in an independent data collection and research group with no affiliation with any advocacy organization. Content This dataset includes files that separate gun violence incidents by category including deaths and injuries of children and teens and a collection of mass shootings. Inspiration  What has been the trend of gun violence in the past few years?  What states have the highest incidents per capita per year? How has this metric changed over time? Are officer involved shootings on the rise? Where are they most concentrated? Do they correlate with the rates of accidental deaths and mass shootings?  Acknowledgements This dataset is owned by the Gun Violence Archive and can be accessed in its original form here.,Incident Date:State:City Or County:Address:# Killed:# Injured:Operations:,dateTime:string:string:string:numeric:numeric:string:,crime
Emergency - 911 Calls , Mike Chirico , www.kaggle.com/mchirico/montcoalert , Thu Sep 21 2017 05:41:46 GMT+0530 (IST) , Montgomery County PA ,5787, crime- law- ,Emergency (911) Calls Fire Traffic EMS for Montgomery County PA You can get a quick introduction to this Dataset with this kernel Dataset Walk-through Acknowledgements Data provided by montcoalert.org,lat:lng:desc:zip:title:timeStamp:twp:addr:e:,numeric:numeric:string:string:string:dateTime:string:string:numeric:,crime
S&P 500 stock data , Cam Nugent , www.kaggle.com/camnugent/sandp500 , Sun Aug 13 2017 08:28:01 GMT+0530 (IST) , Historical stock data for all current S&P 500 companies ,1027, finance- ,Context Stock market data can be interesting to analyze and as a further incentive strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here I provide a dataset with historical stock prices (last 5 years) for all companies currently found on the S&P 500 index.  The script I used to acquire all of these .csv files can be found in this GitHub repository  In the future if you wish for a more up to date dataset this can be used to acquire new versions of the .csv files. Content The data is presented in a couple of formats to suit different individual's needs or computational limitations. I have included files containing 5 years of stock data (in the all_stocks_5yr.csv and corresponding folder) and a smaller version of the dataset (all_stocks_1yr.csv) with only the past year's stock data for those wishing to use something more manageable in size. The folder individual_stocks_5yr contains files of data for individual stocks labelled by their stock ticker name. The all_stocks_5yr.csv and all_stocks_1yr.csv contain this same data presented in merged .csv files. Depending on the intended use (graphing modelling etc.) the user may prefer one of these given formats. All the files have the following columns Date - in format yy-mm-dd  Open - price of the stock at market open (this is NYSE data so all in USD) High - Highest price reached in the day Low Close - Lowest price reached in the day Volume - Number of shares traded Name - the stock's ticker name Acknowledgements I scraped this data from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle Github and The Market. Inspiration This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time graph an compare multiple stocks at once or generate and graph new metrics from the data provided. From these data informative stock stats such as volatility and moving averages can be easily calculated. The million dollar question is can you develop a model that can beat the market and allow you to make statistically informed trades!,Date:,dateTime:,stock data
Hospital Charges for Inpatients , Pranay Aryal , www.kaggle.com/speedoheck/inpatient-hospital-charges , Mon Sep 19 2016 07:18:45 GMT+0530 (IST) , How inpatient hospital charges can differ among different providers in the US ,2491, human medicine- finance- ,Variation of hospital charges in the various hospitals in the US for the top 100 diagnoses. The dataset is owned by the US government. It is freely available on data.gov The dataset keeps getting updated periodically  here This dataset will show you how price for the same diagnosis and the same treatment and in the same city can vary differently across different providers. It might help you or your loved one  find a better hospital for your treatment. You can also analyze to detect fraud among providers.,,,health infrastructure
Derivatives Trading , Ron Leplae , www.kaggle.com/rleplae/derivatives-trading , Wed Aug 30 2017 13:08:35 GMT+0530 (IST) , Algorithmic trading using machine learning ,95, finance- ,This series of datasets represent trade signals on continuous derivates contracts. Each dataset is composed out of lines.  Every line represents a single event and contains the features at the point of the event firing. The goal is to build a model that can filter in real-time the generated signals and improve the overall performance of the trade robot.,Open:High:Low:Close:HOD:LOD:HOY:LOY:VPOC:VPOC-1:LinReg:LinRegSlope:CumDelta:Ticks:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,trade and business
Top 100 Chess Players Historical , Kelvin Wellington , www.kaggle.com/odartey/top-chess-players , Wed Jun 28 2017 13:52:57 GMT+0530 (IST) , The Top 100 ranked players in Chess between July 2000 and June 2017 ,156, board games- ,Context Rankings are a constant phenomenon in society with a  persistent interest in the stratification of items in a set across various disciplines. In sports rankings are a direct representation of the performance of a team or player over a certain period.  Given the straightforward nature of rankings in sports (points based system) there is the opportunity to statistically explore rankings of sports disciplines.  Content The dataset comprises monthly rankings data of the Top 100 Chess players between July 2000 and June 2017 . The data is housed in a single csv file.  Acknowledgements Data was sourced from the official site of the World Chess Federation fide.com Inspiration This dataset could be of use to anyone interested in the distribution of rankings in competitive events.,ranking_date:rank:name:title:country:rating:games:birth_year:,string:numeric:string:string:string:numeric:numeric:numeric:,board games
Minneapolis Air Quality Survey , Greg , www.kaggle.com/gregnetols/minneapolis-air-quality-survey , Tue Oct 10 2017 09:09:34 GMT+0530 (IST) , Air quality survey results for the city of Minneapolis spanning 2013-2014 ,52, cities- environment- pollution- chemistry- ,Context Minneapolis air quality survey results  Content Contained in the file are Minneapolis air quality survey results obtained between November 2013 and August 2014. The data set was obtained from http//opendata.minneapolismn.gov. Inspiration Visualizing air pollutants quantities over the city of Minneapolis may provide evidence for the source of certain air pollutants.,X:Y:ObjectID:Date:Sample_ID:Parameter:Results:Units:CAS:HRV:Units1:HRV_Types:Name:Description:Address:City_1:State:Zip:,numeric:numeric:numeric:dateTime:dateTime:string:numeric:string:string:numeric:string:string:string:string:string:string:string:numeric:,air pollution
Federal Reserve Interest Rates 1954-Present , Federal Reserve , www.kaggle.com/federalreserve/interest-rates , Thu Mar 16 2017 21:35:27 GMT+0530 (IST) , Interest rates economic growth unemployment and inflation data ,462, history- finance- ,Context The Federal Reserve sets interest rates to promote conditions that achieve the mandate set by the Congress — high employment low and stable inflation sustainable economic growth and moderate long-term interest rates. Interest rates set by the Fed directly influence the cost of borrowing money. Lower interest rates encourage more people to obtain a mortgage for a new home or to borrow money for an automobile or for home improvement. Lower rates encourage businesses to borrow funds to invest in expansion such as purchasing new equipment updating plants or hiring more workers. Higher interest rates restrain such borrowing by consumers and businesses.  Content This dataset includes data on the economic conditions in the United States on a monthly basis since 1954. The federal funds rate is the interest rate at which depository institutions trade federal funds (balances held at Federal Reserve Banks) with each other overnight. The rate that the borrowing institution pays to the lending institution is determined between the two banks; the weighted average rate for all of these types of negotiations is called the effective federal funds rate. The effective federal funds rate is determined by the market but is influenced by the Federal Reserve through open market operations to reach the federal funds rate target. The Federal Open Market Committee (FOMC) meets eight times a year to determine the federal funds target rate; the target rate transitioned to a target range with an upper and lower limit in December 2008. The real gross domestic product is calculated as the seasonally adjusted quarterly rate of change in the gross domestic product based on chained 2009 dollars. The unemployment rate represents the number of unemployed as a seasonally adjusted percentage of the labor force. The inflation rate reflects the monthly change in the Consumer Price Index of products excluding food and energy. Acknowledgements The interest rate data was published by the Federal Reserve Bank of St. Louis' economic data portal. The gross domestic product data was provided by the US Bureau of Economic Analysis; the unemployment and consumer price index data was provided by the US Bureau of Labor Statistics. Inspiration How does economic growth unemployment and inflation impact the Federal Reserve's interest rates decisions? How has the interest rate policy changed over time? Can you predict the Federal Reserve's next decision? Will the target range set in March 2017 be increased decreased or remain the same?,Year:Month:Day:Federal Funds Target Rate:Federal Funds Upper Target:Federal Funds Lower Target:Effective Federal Funds Rate:Real GDP (Percent Change):Unemployment Rate:Inflation Rate:,numeric:numeric:numeric:string:string:string:numeric:numeric:numeric:string:,politics
Pakistan Drone Attacks , Zeeshan-ul-hassan Usmani , www.kaggle.com/zusmani/pakistandroneattacks , Tue Oct 10 2017 13:09:07 GMT+0530 (IST) , Most authentic count of drone strikes in Pakistan 2004-2016 ,726, military- ,Context Pakistan Drone Attacks (2004-2016) The United States has targeted militants in the Federally Administered Tribal Areas [FATA] and the province of Khyber Pakhtunkhwa [KPK] in Pakistan via its Predator and Reaper drone strikes since year 2004. Pakistan Body Count (www.PakistanBodyCount.org) is the oldest and most accurate running tally of drone strikes in Pakistan. The given database (PakistanDroneAttacks.CSV) has been populated by using majority of the data from Pakistan Body Count and building up on it by canvassing open source newspapers media reports think tank analyses and personal contacts in media and law enforcement agencies. We provide a count of the people killed and injured in drone strikes including the ones who died later in hospitals or homes due to injuries caused or aggravated by drone strikes making it the most authentic source for drone related data in this region. We will keep releasing the updates every quarter at this page. Content Geography Pakistan Time period 2004-2016  Unit of analysis Attack Dataset The dataset contains detailed information of 397 drone attacks in Pakistan that killed an estimated 3558 and injured 1333 people including 2539 civilians.  Variables The dataset contains Serial No Incident Day & Date Approximate Time of the attack Specific Location City Province Number of people killed who claimed to be from Al-Qaeeda  Number of people killed who claimed to be from Taliban minimum and maximum count of foreigners killed minimum and maximum count of civilians killed minimum and maximum count of civilians injured special mention (more details) and comments about the attack longitude and latitude of the location.  Sources Unclassified media articles hospital reports think tank analysis and reports and government official press releases. Acknowledgements & References Pakistan Body Count has been leveraged extensively in scholarly publications reports media articles and books. The website and the dataset has been collected and curated by the founder Zeeshan-ul-hassan Usmani.  Users are allowed to use copy distribute and cite the dataset as follows “Zeeshan-ul-hassan Usmani Pakistan Body Count Drone Attacks Dataset Kaggle Dataset Repository Jan 25 2017.” Past Research Zeeshan-ul-hassan Usmani and Hira Bashir “The Impact of Drone Strikes in Pakistan” Cost of War Project Brown University December 16 2014 Inspiration Some ideas worth exploring •   How many people got killed and injured per year in last 12 years? •   How many attacks involved killing of actual terrorists from Al-Qaeeda and Taliban? •   How many attacks involved women and children? •   Visualize drone attacks on timeline •   Find out any correlation with number of drone attacks with specific date and time for example do we have more drone attacks in September? •   Find out any correlation with drone attacks and major global events (US funding to Pakistan and/or Afghanistan Friendly talks with terrorist outfits by local or foreign government?) •   The number of drone attacks in Bush Vs Obama tenure? •   The number of drone attacks versus the global increase/decrease in terrorism? •   Correlation between number of drone strikes and suicide bombings in Pakistan Questions? For detailed visit www.PakistanBodyCount.org  Or contact Pakistan Body Count staff at info@pakistanbodycount.org ,S#:Date:Time:Location:City:Province:No of Strike:Al-Qaeda:Taliban:Civilians Min:Civilians Max:Foreigners Min:Foreigners Max:Total Died Min:Total Died Mix:Injured Min:Injured Max:Women/Children  :Special Mention (Site):Comments:References:Longitude:Latitude:Temperature(C):Temperature(F):,numeric:dateTime:dateTime:string:string:string:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:string:string:string:string:numeric:numeric:numeric:numeric:,military
Dota 2 Matches , Devin , www.kaggle.com/devinanzelmo/dota-2-matches , Sun Nov 06 2016 08:26:42 GMT+0530 (IST) , Explore player behavior and predict match outcomes. ,2910, video games- ,"Overview This dataset contains 50000 ranked ladder matches from the Dota 2 data dump created by Opendota. It was inspired by  the Dota 2 Matches data published here by Joe Ramir. This is an update and improved version of that dataset. I have kept the same image and a similar title. Dota 2 is a popular MOBA available as free to play and can take up thousands of hours of your life.  The number of games in this dataset are played about every hour. If you like the data there are an additional 2-3 million matches easily available for download.  The aim of this dataset is to enable the exploration of player behavior skill estimation or anything you find interesting. The intent is to create an accessible and easy to use resource which can be expanded and modified if needed.  As such I am open to a wide variety of suggestions as to what additions or changes to make.  Help getting started If there is some aspect of this data you would like to explore but seems difficult to get figure out how to work with please feel free to request some starter code in one of the following two Kernels discussion section. I usually check kaggle every day or so. If you post a request about the current data I will try to get something working.  Python https//www.kaggle.com/devinanzelmo/d/devinanzelmo/dota-2-matches/misc-howtos-dota-requests-welcome/ R https//www.kaggle.com/devinanzelmo/d/devinanzelmo/dota-2-matches/howtos-request-welcome/ Whats Currently Available See https//github.com/odota/core/wiki/JSON-Data-Dump for documentaion on data. I have found a few undocumented areas in the data including the objectives information. player_slot can be used to combine most of the data and it is available in most of the tables. Additionally all tables include match_id and some have account_id to make it easier to look at an individual players matches. match_id and account_id have been reencoded to save a little space. I can upload tables to allow conversion if needed.   matches contains top level information about each match.  see https//wiki.teamfortress.com/wiki/WebAPI/GetMatchDetails#Tower_Status%22tower_status_dire%22%202047) for interpreting tower and barracks status. Cluster can link matches to geographic region.  players  Individual players are identified by account_id but there is an option to play anonymously and roughly one third of the account_id are not available. Anonymous users have the value of 0 for account_id. Contains totals for kills deaths denies etc.  Player action counts are available and are indicated by variable names beginning with unit_order_.  Counts for reasons for acquiring or losing gold and gaining experience have prefixes gold_ and xp_.  player_time Contains last hits experience and gold sampled at one minute interval for all players in all matches. The column names indicate the player_slot.  For instance xp_t_1 indicates that this column has experience sums for the player in slot one. teamfights  Start and stop time of teamfights as well as last death time.  Teamfights appear to be all battles  with three or more deaths. As such this does not include all battles for the entire match. teamfights_players   Additional information provided for each player in each teamfight. player_slot can be  used to link this back to players.csv objectives  Gives information on all the objectives completed by which player and at what time. chat  All chat for the 50k matches. There is plenty of profanity and good natured trolling.  test_labels match_id and radiant_win(as integer 1 or 0)  test_player full player and match table with hero_id player_slot match_id and account_id   Nov 5th Update Added several additional tables. None of the previously uploaded data was altered. I plan to add several Kernels in the next week going over how to use the data and performing some EDA. Many improvements to the player rating method I used are possible for those interested in MMR.   player_ratings contains match counts  win counts and TrueSkill rating calculated on 900k matches which occurred prior to other uploaded data. trueskill ratings have two components mu which can be interpreted as the skill with higher value being better and sigma which is the uncertainty of the rating.  match_outcomes data for ~900k matches used to calculate player ratings. Use this to improve on the ratings I uploaded. purchase_log item purchase times ability_upgrade ability upgrade times and levels cluster_region allows the mapping cluster found in match.csv to geographic region. patch_dates release dates for various patches use start_time from match.csv to determine which patch a match was played in.  ability_ids use with ability_upgrades.csv to get the names of upgraded abilities item_ids use with purchase_log.csv to get the names of purchased items  Kernel showing how player skill was computed Contains several resources on trueskill rating system. Past Research There seem to be some efforts to establish indicators for skillfull play based on specific parts of gameplay. Opendota has many statistics and some analysis for specific benchmarks at different times in the game. Dotabuff has a lot of information I have not explored it deeply. This is an area to gather more information.   Some possible directions of investigation Insight from domain experts would also be useful to help clarify what problems are interesting to work on. Some initial task ideas  Predict match outcomes based on aggregates for individual players using only account_id as prior information Add hero id to this and see if there is a differences in performance Estimate player skill based on a sample of in game play(this might need an external mmr source or different definition skill) Create improved indicators of skillful play based game actions to help players target areas for improvement  All of these areas have been worked on but I am not aware of the most up to date research on dota2 gameplay. I plan on setting up several different predictive tasks in the upcoming weeks. A test set of an additional 50 to 100 thousand matches with just hero_id and account_id included along with outcome of the match.  The current dataset seems pretty small for modeling individual players. I would prefer to have a wide range of features instead of a larger dataset for the moment.   Dataset idea for anyone interested in creating their own Dota 2 dataset. It would be useful to have a few full matches available to work on. They would need to be extracted from the .dem replay file to something easily parsed by R and Python as available in kernels. Given the size of a full match data only a few matches would be needed.  There are files available from opendota' s website(check for replays).  Looking at fine grained match details would potentially allow for the creation of better high level parsed data. I think it would be a lot of work just to get a handle on working with full match data so a sample would be good to have.  Acknowledgements Orginal kaggle dataset on dota2 matches by Joe Ramir I also borrowed the image and some of the content for these acknowledgements from the above thanks!. image source Data download source created by yasp Description of original dataset creation https//github.com/yasp-dota/yasp/issues/924 yasp's license ""License CC BY-SA 4.0"" ""Terms We ask that you attribute yasp.co if you create or publish anything related to our data. Also please seed for as long as possible."" Yasp is now known as opendota here are links to their website and github page https//www.opendota.com/ the data is used to for this site and its a easy way to get familier with it https//github.com/odota/core  check here for info especially this wiki page which gives details on the schema.",ability_id:,numeric:,video games
Every song you have heard (almost)! , Soumitra Agarwal , www.kaggle.com/artimous/every-song-you-have-heard-almost , Sun Aug 20 2017 15:02:52 GMT+0530 (IST) , Over 500000 song lyrics urls for over a million artists ,278, languages- music- internet- ,Dataset for people who double on Music and Data Science How it began One fine day when someone with the idea of self sufficient AI capable of writing it's own poems wanted data he stumbled upon the idea of using songs as a source. The journey wasn't easy since each song has it's own page with the lyrics and scraping pages one at a time (when there are over a million of them) is a slow task. I worked up some optimisations here and there. For people interested in going through the process GITHUB PROJECT.  Content There is a lot to play with here though all of it vertically. There isn't a lot of variation in the types of fields until you look deep enough. The main dataset is split up into 2 files each containing ~250000 songs with their artists and lyrics. The files are titled Lyrics1 and Lyrics2. The fields include band name song name and lyrics.   Go through the exploration scripts for how to use the lyrics data set and other interesting observations. Another file containing urls of description pages of different artists is also provided titled ArtistUrls.  Acknowledgements After seeing the response for the FIFA PLAYER DATASET it was exciting as ever to get this one off.  Soon it was realised not a lot of places exist where extracting data is straightforward.  Then one stumbles upon the perfectly indexed page  https//www.lyrics.com/. They deserve major credit for the existence of this dataset.  Inspiration This started off as a source for some kind of intelligent poet which writes poems on it's own. It would be great to see what the artificially intelligent world has to express once it knows enough and beautifully if at all?,Artist:Urls:,string:string:,music
Articles sharing and reading from CI&T DeskDrop , Gabriel Moreira , www.kaggle.com/gspmoreira/articles-sharing-reading-from-cit-deskdrop , Mon Aug 28 2017 03:03:01 GMT+0530 (IST) , Logs of users interactions on shared articles for content Recommender Systems ,60, web sites- human-computer interaction- internet- ,Context Deskdrop is an internal communications platform developed by CI&T focused in companies using Google G Suite. Among other features this platform allows companies employees to share relevant articles with their peers and collaborate around them.   Content This rich and rare dataset contains a real sample of 12 months logs (Mar. 2016 - Feb. 2017) from CI&T's Internal Communication platform (DeskDrop).  I contains about 73k logged users interactions on more than 3k public articles shared in the platform.    This dataset features some distinctive characteristics  Item attributes Articles' original URL title and content plain text are available in two languages (English and Portuguese).    Contextual information Context of the users visits like date/time client (mobile native app / browser) and geolocation.   Logged users All users are required to login in the platform providing a long-term tracking of users preferences (not depending on cookies in devices).   Rich implicit feedback Different interaction types were logged making it possible to infer the user's level of interest in the articles (eg. comments > likes > views). Multi-platform Users interactions were tracked in different platforms (web browsers and mobile native apps)  If you like it please upvote! Take a look in these featured Python kernels   - Deskdrop datasets EDA Exploratory analysis of the articles and interactions in the dataset   - DeskDrop Articles Topic Modeling A statistical analysis of the main articles topics using LDA   - Recommender Systems in Python 101 A practical introduction of the main Recommender Systems approaches Popularity model Collaborative Filtering Content-Based Filtering and Hybrid Filtering.    Acknowledgements We thank CI&T for the support and permission to share a sample of real usage data from its internal communication platform Deskdrop. Inspiration The two main approaches for Recommender Systems are Collaborative Filtering and Content-Based Filtering.   In the RecSys community there are some popular datasets available with users ratings on items (explicit feedback) like MovieLens and Netflix Prize which are useful for Collaborative Filtering techniques.    Therefore it is very difficult to find open datasets with additional item attributes which would allow the application of Content-Based filtering techniques or Hybrid approaches specially in the domain of ephemeral textual items (eg. articles and news).   News datasets are also reported in academic literature as very sparse in the sense that as users are usually not required to log in in news portals IDs are based on device cookies making it hard to track the users page visits in different portals browsing sessions and devices.   This difficult scenario for research and experiments on Content Recommender Systems was the main motivation for the sharing of this dataset.,timestamp:,numeric:,Online forums 
My Uber Drives , Zeeshan-ul-hassan Usmani , www.kaggle.com/zusmani/uberdrives , Thu Mar 23 2017 17:42:46 GMT+0530 (IST) , Complete Details of My Uber Drives in 2016 ,1523, road transport- ,Context My Uber Drives (2016) Here are the details of my Uber Drives of 2016. I am sharing this dataset for data science community to learn from the behavior of an ordinary Uber customer. Content Geography  USA Sri Lanka and Pakistan Time period January - December 2016  Unit of analysis Drives Total Drives 1155 Total Miles 12204 Dataset The dataset contains Start Date End Date Start Location End Location Miles Driven and Purpose of drive (Business Personal Meals Errands Meetings Customer Support etc.) Acknowledgements & References Users are allowed to use download copy distribute and cite the dataset for their pet projects and training. Please cite it  as follows “Zeeshan-ul-hassan Usmani My Uber Drives Dataset Kaggle Dataset Repository March 23 2017.” Past Research Uber TLC FOIL Response - The dataset contains over 4.5 million Uber pickups in New York City from April to September 2014 and 14.3 million more Uber pickups from January to June 2015 https//github.com/fivethirtyeight/uber-tlc-foil-response 1.1 Billion Taxi Pickups from New York -  http//toddwschneider.com/posts/analyzing-1-1-billion-nyc-taxi-and-uber-trips-with-a-vengeance/ What you can do with this data - a good example by Yao-Jen Kuo - https//yaojenkuo.github.io/uber.html Inspiration Some ideas worth exploring •   What is the average length of the trip? •   Average number of rides per week or per month? •   Total tax savings based on traveled business miles? •   Percentage of business miles vs personal vs. Meals •   How much money can be saved by a typical customer using Uber Careem or Lyft versus regular cab service?,START_DATE*:END_DATE*:CATEGORY*:START*:STOP*:MILES*:PURPOSE*:,dateTime:dateTime:string:string:string:numeric:string:,roadways
Can You Predict Product Backorders? , tiredgeek , www.kaggle.com/tiredgeek/predict-bo-trial , Thu Apr 27 2017 21:40:35 GMT+0530 (IST) , Based on historical data predict backorder risk for products ,4193, business- management- ,Context Part backorders is a common supply chain problem.  Working to identify parts at risk of backorder before the event occurs so the business has time to react. Content Training data file contains the historical data for the 8 weeks prior to the week we are trying to predict.  The data was taken as weekly snapshots at the start of each week.  Columns are defined as follows sku - Random ID for the product national_inv - Current inventory level for the part lead_time - Transit time for product (if available) in_transit_qty - Amount of product in transit from source forecast_3_month - Forecast sales for the next 3 months forecast_6_month - Forecast sales for the next 6 months forecast_9_month - Forecast sales for the next 9 months sales_1_month - Sales quantity for the prior 1 month time period  sales_3_month - Sales quantity for the prior 3 month time period  sales_6_month - Sales quantity for the prior 6 month time period  sales_9_month - Sales quantity for the prior 9 month time period  min_bank - Minimum recommend amount to stock potential_issue - Source issue for part identified pieces_past_due - Parts overdue from source perf_6_month_avg - Source performance for prior 6 month period  perf_12_month_avg - Source performance for prior 12 month period  local_bo_qty - Amount of stock orders overdue deck_risk - Part risk flag oe_constraint - Part risk flag ppap_risk - Part risk flag stop_auto_buy - Part risk flag rev_stop - Part risk flag went_on_backorder - Product actually went on backorder.  This is the target value.,sku:national_inv:lead_time:in_transit_qty:forecast_3_month:forecast_6_month:forecast_9_month:sales_1_month:sales_3_month:sales_6_month:sales_9_month:min_bank:potential_issue:pieces_past_due:perf_6_month_avg:perf_12_month_avg:local_bo_qty:deck_risk:oe_constraint:ppap_risk:stop_auto_buy:rev_stop:went_on_backorder:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:string:string:string:string:string:,trade and business
Zika Virus Epidemic , Centers for Disease Control and Prevention , www.kaggle.com/cdc/zika-virus-epidemic , Sat Jul 16 2016 09:20:21 GMT+0530 (IST) , Analyze the ongoing spread of this infectious disease ,4099, brazil- epidemiology- human medicine- ,An outbreak of the Zika virus an infection transmitted mostly by the Aedes species mosquito (Ae. aegypti and Ae. albopictus) has been sweeping across the Americas and the Pacific since mid-2015. Although first isolated in 1947 in Uganda a lack of previous research has challenged the scientific community to quickly understand its devastating effects as the epidemic continues to spread. All Countries & Territories with Active Zika Virus Transmission  The data This dataset shares publicly available data related to the ongoing Zika epidemic. It is being provided as a resource to the scientific community engaged in the public health response. The data provided here is not official and should be considered provisional and non-exhaustive. The data in reports may change over time reflecting delays in reporting or changes in classifications. And while accurate representation of the reported data is the objective in the machine readable files shared here that accuracy is not guaranteed. Before using any of these data it is advisable to review the original reports and sources which are provided whenever possible along with further information on the CDC Zika epidemic GitHub repo. The dataset includes the following fields  report_date - The report date is the date that the report was published. The date should be specified in standard ISO format (YYYY-MM-DD). location - A location is specified for each observation following the specific names specified in the country place name database. This may be any place with a 'location_type' as listed below e.g. city state country etc. It should be specified at up to three hierarchical levels in the following format [country]-[state/province]-[county/municipality/city] always beginning with the country name. If the data is for a particular city e.g. Salvador it should be specified Brazil-Bahia-Salvador. location_type - A location code is included indicating city district municipality county state province or country. If there is need for an additional 'location_type' open an Issue to create a new 'location_type'. data_field - The data field is a short description of what data is represented in the row and is related to a specific definition defined by the report from which it comes. data_field_code - This code is defined in the country data guide. It includes a two letter country code (ISO-3166 alpha-2 list) followed by a 4-digit number corresponding to a specific report type and data type. time_period - Optional. If the data pertains to a specific period of time for example an epidemiological week that number should be indicated here and the type of time period in the 'time_period_type' otherwise it should be NA. time_period_type - Required only if 'time_period' is specified. Types will also be specified in the country data guide. Otherwise should be NA. value - The observation indicated for the specific 'report_date' 'location' 'data_field' and when appropriate 'time_period'. unit - The unit of measurement for the 'data_field'. This should conform to the 'data_field' unit options as described in the country-specific data guide.  If you find the data useful please support data sharing by referencing this dataset and the original data source. If you're interested in contributing to the Zika project from GitHub you can read more here. The source for the Zika virus structure is available here.,report_date:location:location_type:data_field:data_field_code:time_period:,dateTime:string:string:string:string:numeric:,diseases and epidemics
Scientific Researcher Migrations , Jacob Boysen , www.kaggle.com/jboysen/scientist-migrations , Thu Aug 31 2017 21:04:03 GMT+0530 (IST) , Movement of ~742k Scientists ,129, demographics- ,Context ORCID provides a persistent digital identifier that distinguishes you from every other researcher and through integration in key research workflows such as manuscript and grant submission supports automated linkages between you and your professional activities ensuring that your work is recognized. Find out more. Content This data is a subset of the entire ORCID collection. The subset here was produced by John Bohannon. You can see his excellent Ipython notebook and the entire (300GB!) ORCID archives here. The data covers ~742k unique researchers and includes  orcid_id phd_year country_2016 earliest_year earliest_country has_phd phd_country has_migrated  Acknowledgements Bohannon J Doran K (2017) Introducing ORCID. Science 356(6339) 691-692. http//dx.doi.org/10.1126/science.356.6339.691 Additionally please cite the Dryad data package Bohannon J Doran K (2017) Data from Introducing ORCID. Dryad Digital Repository. http//dx.doi.org/10.5061/dryad.48s16 Inspiration  Where do most researchers move to? What countries experience the largest ‘brain drain’? As a % of population? Can you predict researcher migration? ,orcid_id:phd_year:country_2016:earliest_year:earliest_country:has_phd:phd_country:has_migrated:,string:numeric:string:numeric:string:boolean:string:boolean:,demography
380000+ lyrics from MetroLyrics , GyanendraMishra , www.kaggle.com/gyani95/380000-lyrics-from-metrolyrics , Wed Jan 11 2017 07:35:53 GMT+0530 (IST) , Lyrics Artist  Genre Year ,951, writing- music- linguistics- ,Context I tried to gather as many lyrics as I could. I ran my code on a a free ec2 instance and ran out of storage space. I have attached the code below so if any one wants to try out it and get all lyrics please do. Content There are around 380000+ lyrics in the data set from a lot of different artists from a lot of different genres arranged by year. Structure is artist/year/song. Every artist folder has a genre.txt that tells what is the genre of the musician. Find the crawler here. Acknowledgements I would like to thank Shruti Jasoria SJasoria on GitHub for writing the multi-threaded version. Inspiration I wanted to find out what genre and what artist abuses what substance. Do rapstars like cocaine or liquor? If liquor then what Liquor? Does Eminem prefer Hennesy over Jack Daniels? Do Rockstars love pot?,index:song:year:artist:genre:lyrics:,numeric:string:numeric:string:string:string:,music
Mathematicians of Wikipedia , Joe Philleo , www.kaggle.com/joephilleo/mathematicians-on-wikipedia , Sun Sep 17 2017 04:20:02 GMT+0530 (IST) , A Dataset of the World's Most Famous Mathematicians ,123, mathematics- data analysis- people- demographics- internet- ,Context What distinguishes the great from the good the remembered from the accomplished and the genius from the merely brilliant? Scrapping English Wikipedia Joseph Philleo has cleaned and compiled a database of more than 8500 famous mathematicians for the Kaggle data science community to analyze and better understand. Inspiration  What are the common characteristics of famous mathematicians? How old do they live which fields do they work in where are they born and where do they live? Can you predict which mathematicians will win a Fields Medal join the Royal Society or secure tenure at Harvard? ,"mathematicians:occupation:country of citizenship:place of birth:date of death:educated at:employer:place of death:member of:doctoral advisor:languages spoken, written or signed:academic degree:doctoral student:manner of death:position held:field of work:award received:Erdős number:instance of:sex or gender:approx. date of birth:day of birth:month of birth:year of birth:approx. date of death:day of death:month of death:year of death:",string:string:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:boolean:numeric:string:numeric:boolean:numeric:string:numeric:,
Women's Shoe Prices , Datafiniti , www.kaggle.com/datafiniti/womens-shoes-prices , Mon May 15 2017 20:59:42 GMT+0530 (IST) , A list of 10000 women's shoes and the prices at which they are sold ,1118, clothing- business- ,About This Data This is a list of of 10000 women's shoes and their associated information.  The data is provided by Datafiniti's Product Database. Each shoe will have an entry for each price found for it so a single shoe may have multiple entries.  Data includes shoe name brand price and more. The data is part of a larger data set that was used to determine brand markup and pricing strategies for luxury shoes.  See The Cost of a Designer Label. What You Can Do with This Data This data provides a lot of information which means you can pull out a lot of different trends.  Here are some possible questions you could answer  What is the average price of each distinct brand listed? Which brands have the highest prices?  Which ones have the widest distribution of prices? Is there a typical price distribution (e.g. normal) across brands or within specific brands?  Further processing data would also let you correlate specific product features with changes in price. Data Schema A full schema for the data is available in our support documentation. About Datafiniti Datafiniti provides instant access to web data.  We compile data from thousands of websites to create standardized databases of business product and property information.  Learn more. Want More? If you're interested in more data like this please contact us.,id:asins:brand:categories:colors:count:dateAdded:dateUpdated:descriptions:dimension:ean:features:flavors:imageURLs:isbn:keys:manufacturer:manufacturerNumber:merchants:name:prices.amountMin:prices.amountMax:prices.availability:prices.color:prices.condition:prices.count:prices.currency:prices.dateAdded:prices.dateSeen:prices.flavor:prices.isSale:prices.merchant:prices.offer:prices.returnPolicy:prices.shipping:prices.size:prices.source:prices.sourceURLs:prices.warranty:quantities:reviews:sizes:skus:sourceURLs:upc:vin:websiteIDs:weight::,string:string:string:string:string:string:dateTime:dateTime:string:string:numeric:string:string:string:string:numeric:string:numeric:string:string:numeric:numeric:string:string:string:string:string:dateTime:dateTime:string:boolean:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:string:string:string:string:,commodity prices
US Candy Production by Month , Rachael Tatman , www.kaggle.com/rtatman/us-candy-production-by-month , Sat Oct 14 2017 02:11:18 GMT+0530 (IST) , From January 1972 to August 2017 ,202, food and drink- time series- product- manufacturing- product management- ,Context Halloween begins frenetic candy consumption that continues into the Christmas holidays and New Year’s Day when people often make (usually short-lived) resolutions to lose weight. But all this consumption first needs production. The graph shows the relevant data from the industrial production index and its stunning seasonality Content The industrial production (IP) index measures the real output of all relevant establishments located in the United States regardless of their ownership but not those located in U.S. territories. This dataset tracks industrial production every month from January 1972 to August 2017.  Acknowledgements Board of Governors of the Federal Reserve System (US) Industrial Production Nondurable Goods Sugar and confectionery product [IPG3113N] retrieved from FRED Federal Reserve Bank of St. Louis; https//fred.stlouisfed.org/series/IPG3113N October 13 2017. Inspiration  Can you correct for the seasonality in this data? Which months have the highest candy production? Can you predict production for September through December 2017? ,observation_date:IPG3113N:,dateTime:numeric:,trade and business
NBER Macrohistory Database , Sohier Dane , www.kaggle.com/sohier/nber-macrohistory-database , Thu Oct 12 2017 01:42:46 GMT+0530 (IST) , Western economic history data spanning 1785-1974 ,39, history- economics- ,Context This data set covers all aspects of the pre-WWI and interwar economies including production construction employment money prices asset market transactions foreign trade and government activity. Many series are highly disaggregated and many exist at the monthly or quarterly frequency. The data set has some coverage of the United Kingdom France and Germany although it predominantly covers the United States. For information see  Improving the Accessibility of the NBER's Historical Data  by Daniel Feenberg and Jeff Miron. (NBER Working Paper #5186). Published in the Journal of Business and Economic Statistics Volume 15 Number 3 (July 1997) pages 293-299.  Information about seasonal adjustments is available but in most cases only unadjusted series have been made available here. Content The data.csv is organized in a long format with columns for the date variable and value.  The dates are always the beginning of period date for whatever period existed in the original data. This means that '1920' was converted to January 1st 1920 while Q2 1920 was converted to April 1 1920. This is intended as a convenience to make it easier to work with multiple time series from the original mixed frequency data. The data is currently organized into 16 chapters  Chapter1 Production of Commodities Chapter2 Construction Chapter3 Transportation and Public Utilities Chapter4 Prices Chapter5 Stocks of Commodities Chapter6 Distribution of Commodities Chapter7 Foreign Trade Chapter8 Income and Employment Chapter9 Financial Status of Business Chapter10 Savings and Investment Chapter11 Security Markets Chapter12 Volume of Transactions Chapter13 Interest Rates Chapter14 Money and Banking Chapter15 Government and Finance Chapter16 Leading Indicators  The dataset has been transformed from its original format. You can find the data preparation code here. Acknowledgements This dataset was kindly made available by the National Bureau of Economic Research (NBER). You can find the original dataset here. Inspiration  Which major historical events can you detect from the data? With roughly 3500 time series in the dataset finding relevant information can be challenging. Can you find a better way of organizing or indexing the data?  ,Date:Value:Variable:,dateTime:numeric:string:,history
U.S. Opiate Prescriptions/Overdoses ," Alan ""AJ"" Pryor ", www.kaggle.com/apryor6/us-opiate-prescriptions , Sun Oct 23 2016 22:51:30 GMT+0530 (IST) , Can you save lives through predictive modeling? ,2769, human medicine- ,U.S. Opiate Prescriptions Accidental death by fatal drug overdose is a rising trend in the United States. What can you do to help? This dataset contains summaries of  prescription records for 250 common opioid and non-opioid drugs written by 25000 unique licensed medical professionals in 2014 in the United States for citizens covered under Class D Medicare as well as some metadata about the doctors themselves. This is a small subset of data that was sourced from cms.gov. The full dataset contains almost 24 million prescription instances in long format. I have cleaned and compiled this data here in a format with 1 row per prescriber and limited the approximately 1 million total unique prescribers down to 25000 to keep it manageable. If you are interested in more data you can get the script I used to assemble the dataset here and run it yourself. The main data is in prescriber-info.csv. There is also opioids.csv that contains the names of all opioid drugs included in the data and overdoses.csv that contains information on opioid related drug overdose fatalities. The increase in overdose fatalities is a well-known problem and the search for possible solutions is an ongoing effort. My primary interest in this dataset is detecting sources of significant quantities of opiate prescriptions. However there is plenty of other studies to perform and I am interested to see what other Kagglers will come up with or if they can improve the model I have already built. The data consists of the following characteristics for each prescriber    NPI – unique National Provider Identifier number   Gender - (M/F)   State - U.S. State by abbreviation Credentials - set of initials indicative of medical degree Specialty - description of type of medicinal practice A long list of drugs with numeric values indicating the total number of prescriptions written for the year by that individual Opioid.Prescriber - a boolean label indicating whether or not that individual prescribed opiate drugs more than 10 times in the year ,Drug Name:Generic Name:,string:string:,diagnostics
Hillary Clinton and Donald Trump Tweets , Ben Hamner , www.kaggle.com/benhamner/clinton-trump-tweets , Wed Sep 28 2016 06:07:25 GMT+0530 (IST) , Tweets from the major party candidates for the 2016 US Presidential Election ,2514, politics- internet- ,Twitter has played an increasingly prominent role in the 2016 US Presidential Election. Debates have raged and candidates have risen and fallen based on tweets. This dataset provides ~3000 recent tweets from Hillary Clinton and Donald Trump the two major-party presidential nominees. ,handle:text:is_retweet:original_author:time:in_reply_to_screen_name:in_reply_to_status_id:in_reply_to_user_id:is_quote_status:lang:retweet_count:favorite_count:longitude:latitude:place_id:place_full_name:place_name:place_type:place_country_code:place_country:place_contained_within:place_attributes:place_bounding_box:source_url:truncated:entities:extended_entities:id:,string:string:boolean:string:dateTime:string:string:string:boolean:string:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:boolean:string:string:numeric:,social media
Disaster/Accident Sources , Armineh Nourbakhsh , www.kaggle.com/arminehn/disasteraccident-sources , Sat May 27 2017 08:32:48 GMT+0530 (IST) , A list of Twitter users who report on disasters accidents & crime ,139, crime- internet- ,Content Attached is a list of Twitter users who regularly report on natural and man-made disasters violence or crime. The accounts may belong to journalists news media local fire or police departments other local authorities or disaster monitors. Disaster reporting may not be the primary function of the accounts nevertheless they are a prolific source of disaster/accident reporting especially at the location they are associated with. Background Details of the curation of this dataset once published will be added to this entry. Disclaimer The dataset does not include a measure of credibility for the users. The stories reported by them may or may not be true. Further vetting and verification is required to confirm if the stories that they report are credible.,category:twitter handle:profile url:profile location:profile description:on twitter since:followers:following:profile lat/lon:,string:string:string:string:string:string:dateTime:dateTime:numeric:,social media
Student Alcohol Consumption , UCI Machine Learning , www.kaggle.com/uciml/student-alcohol-consumption , Wed Oct 19 2016 21:22:39 GMT+0530 (IST) , Social gender and study data from secondary school students ,12513, food and drink- public health- ,Context The data were obtained in a survey of students math and portuguese language courses in secondary school. It contains a lot of interesting social gender and study information about students.  You can use it for some EDA or try to predict students final grade. Content Attributes for both student-mat.csv (Math course) and student-por.csv (Portuguese language course) datasets   school - student's school (binary 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira) sex - student's sex (binary 'F' - female or 'M' - male)  age - student's age (numeric from 15 to 22)  address - student's home address type (binary 'U' - urban or 'R' - rural)  famsize - family size (binary 'LE3' - less or equal to 3 or 'GT3' - greater than 3)  Pstatus - parent's cohabitation status (binary 'T' - living together or 'A' - apart) Medu - mother's education (numeric 0 - none  1 - primary education (4th grade) 2 – 5th to 9th grade 3 – secondary education or 4 – higher education) Fedu - father's education (numeric 0 - none  1 - primary education (4th grade) 2 – 5th to 9th grade 3 – secondary education or 4 – higher education) Mjob - mother's job (nominal 'teacher' 'health' care related civil 'services' (e.g. administrative or police) 'at_home' or 'other')  Fjob - father's job (nominal 'teacher' 'health' care related civil 'services' (e.g. administrative or police) 'at_home' or 'other')  reason - reason to choose this school (nominal close to 'home' school 'reputation' 'course' preference or 'other')  guardian - student's guardian (nominal 'mother' 'father' or 'other')  traveltime - home to school travel time (numeric 1 - <15 min. 2 - 15 to 30 min. 3 - 30 min. to 1 hour or 4 - >1 hour)  studytime - weekly study time (numeric 1 - <2 hours 2 - 2 to 5 hours 3 - 5 to 10 hours or 4 - >10 hours)  failures - number of past class failures (numeric n if 1<=n<3 else 4)  schoolsup - extra educational support (binary yes or no)  famsup - family educational support (binary yes or no)  paid - extra paid classes within the course subject (Math or Portuguese) (binary yes or no)  activities - extra-curricular activities (binary yes or no)  nursery - attended nursery school (binary yes or no)  higher - wants to take higher education (binary yes or no)  internet - Internet access at home (binary yes or no)  romantic - with a romantic relationship (binary yes or no)  famrel - quality of family relationships (numeric from 1 - very bad to 5 - excellent)  freetime - free time after school (numeric from 1 - very low to 5 - very high)  goout - going out with friends (numeric from 1 - very low to 5 - very high)  Dalc - workday alcohol consumption (numeric from 1 - very low to 5 - very high)  Walc - weekend alcohol consumption (numeric from 1 - very low to 5 - very high)  health - current health status (numeric from 1 - very bad to 5 - very good)  absences - number of school absences (numeric from 0 to 93)   These grades are related with the course subject Math or Portuguese   G1 - first period grade (numeric from 0 to 20)  G2 - second period grade (numeric from 0 to 20)  G3 - final grade (numeric from 0 to 20 output target)   Additional note there are several (382) students that belong to both datasets .  These students can be identified by searching for identical attributes that characterize each student as shown in the annexed R file. Source Information P. Cortez and A. Silva. Using Data Mining to Predict Secondary School Student Performance. In A. Brito and J. Teixeira Eds. Proceedings of 5th FUture BUsiness TEChnology Conference (FUBUTEC 2008) pp. 5-12 Porto Portugal April 2008 EUROSIS ISBN 978-9077381-39-7. Fabio Pagnotta Hossain Mohammad Amran.  Emailfabio.pagnotta@studenti.unicam.it mohammadamra.hossain '@' studenti.unicam.it  University Of Camerino https//archive.ics.uci.edu/ml/datasets/STUDENT+ALCOHOL+CONSUMPTION,school:sex:age:address:famsize:Pstatus:Medu:Fedu:Mjob:Fjob:reason:guardian:traveltime:studytime:failures:schoolsup:famsup:paid:activities:nursery:higher:internet:romantic:famrel:freetime:goout:Dalc:Walc:health:absences:G1:G2:G3:,string:string:numeric:string:string:string:numeric:numeric:string:string:string:string:numeric:numeric:numeric:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,student performances
Complete FIFA 2017 Player dataset (Global) , Soumitra Agarwal , www.kaggle.com/artimous/complete-fifa-2017-player-dataset-global , Thu Apr 13 2017 14:07:43 GMT+0530 (IST) , 15k+ players 50+ Attributes per player from the latest EA Sports Fifa 17 ,4382, video games- association football- ,The dataset for people who double on Fifa and Data Science Content   17000+ players 50+ attributes per player ranging from ball skills aggression etc. Player's attributes sourced from EA Sports' FIFA video game series including the weekly updates Players from all around the globe URLs to their homepage Club logos Player images male and female National and club team data  Weekly Updates would include   Real life data (Match events etc.) The fifa generated player dataset Betting odds Growth    Data Source Data was scraped from https//www.fifaindex.com/ first by getting player profile url set (as stored in PlayerNames.csv) and then scraping the individual pages for their attributes  Improvements  You may have noticed that for a lot of players their national details are absent (Team and kit number) even though the nationality is listed. This may be attributed to the missing data on fifa sites.   GITHUB PROJECT  There is much more than just 50 attributes by which fifa decides what happens to players over time how they perform under pressure how they grow etc. This data obviously would be well hidden by the organisation and thus would be tough to find  Important note for people interested in using the scraping  The site is not uniform and thus the scraping script requires considering a lot of corner cases (i.e. interchanged position of different attributes). Also the script contains proxy preferences which may be removed if not required.  Exploring the data For starters you can become a scout  Create attribute dependent or overall best teams Create the fastest/slowest teams See which areas of the world provide which attributes (like Africa  Stamina Pace) See which players are the best at each position See which outfield players can play a better role at some other position See which youngsters have attributes which can be developed  And that is just the beginning. This is the playground.. literally!  Data description  The file FullData.csv contains attributes describing the in game play style and also some of the real statistics such as Nationality etc. The file PlayerNames.csv contains URLs for different players from their profiles on fifaindex.com. Append the URLs after the base url fifaindex.com. The compressed file Pictures.zip contains pictures for top 1000 players in Fifa 17. The compressed file Pictures_f.zip contains pictures for top 139 female players in Fifa 17. The compressed file ClubPictures.zip contains pictures for emblems of some major clubs in Fifa 17.   Inspiration I am a huge FIFA fanatic. While playing career mode I realised that I picked great young players early on every single time and since a lot of digital learning relies on how our brain works I thought scouting great qualities in players would be something that can be worked on. Since then I started working on scraping the website and here is the data. I hope we can build something on it.   With access to players attributes you can become the best scout in the world. Go for it!,,,football
Y Combinator Companies , Ben Hamner , www.kaggle.com/benhamner/y-combinator-companies , Thu Sep 08 2016 20:48:49 GMT+0530 (IST) , Publicly launched YC companies funded from summer 2005 to summer 2016 ,738, business- finance- , Data scraped from www.ycombinator.com/companies on September 8 2016.,name:vertical:year:batch:url:description:,string:string:numeric:string:string:string:,trade and business
goodbooks-10k , Foxtrot , www.kaggle.com/zygmunt/goodbooks-10k , Sat Sep 02 2017 21:04:30 GMT+0530 (IST) , Ten thousand books one million ratings. Also books marked to read and tags. ,904, books- ,"This version of the dataset is obsolete. It contains duplicate ratings (same user_idbook_id) as reported by Philipp Spachtholz in his illustrious notebook. The current version has duplicates removed and more ratings (six million) sorted by time. Book and user IDs are the same.  It is available at https//github.com/zygmuntz/goodbooks-10k.  There have been good datasets for movies (Netflix Movielens) and music (Million Songs) recommendation but not for books. That is until now.  This dataset contains ratings for ten thousand popular books. As to the source let's say that these ratings were found on the internet. Generally there are 100 reviews for each book although some have less - fewer - ratings. Ratings go from one to five. Both book IDs and user IDs are contiguous. For books they are 1-10000 for users 1-53424. All users have made at least two ratings. Median number of ratings per user is 8. There are also books marked to read by the users book metadata (author year etc.) and tags. Contents ratings.csv contains ratings and looks like that book_iduser_idrating 13145 14393 15885 111694 111854  to_read.csv provides IDs of the books marked ""to read"" by each user as user_idbook_id pairs. books.csv has metadata for each book (goodreads IDs authors title average rating etc.). The metadata have been extracted from goodreads XML files available in the third version of this dataset as books_xml.tar.gz. The archive contains 10000 XML files. One of them is available as sample_book.xml. To make the download smaller these files are absent from the current version. Download version 3 if you want them. book_tags.csv contains tags/shelves/genres assigned by users to books. Tags in this file are represented by their IDs. tags.csv translates tag IDs to names. See the notebook for some basic stats of the dataset. goodreads IDs Each book may have many editions.  goodreads_book_id and best_book_id generally point to the most popular edition of a given book while goodreads  work_id refers to the book in the abstract sense. You can use the goodreads book and work IDs to create URLs as follows https//www.goodreads.com/book/show/2767052  https//www.goodreads.com/work/editions/2792775",goodreads_book_id:tag_id:count:,numeric:numeric:numeric:,books and comics
CDC 500 Cities , Centers for Disease Control and Prevention , www.kaggle.com/cdc/500-cities , Thu Aug 10 2017 22:07:35 GMT+0530 (IST) , Dozens of Public Health Datapoints Reported by Residents of 500 US Cities ,83, ,Context Public health is a large and expensive problem for policymakers to understand in order to provide health services and prevent future epidemics. Self-reported data can be tricky due to many sampling issues but it can paint an interesting picture of how healthy a given area’s population might be. Content Data includes small area samples of residents from 500 US cities. Recorded is the percent of residents who answered a public health-related question affirmatively (see here). In addition to crude data additional data is provided with age adjustment applied. 95% Confidence Intervals also provided for both datapoints. Acknowledgements This data was collected by Centers for Disease Control and Prevention National Center for Chronic Disease Prevention and Health Promotion Division of Population Health. 500 Cities Project Data [online]. 2016 [accessed Aug 10 2017]. URL https//www.cdc.gov/500cities. Inspiration  Are there any regional health trends? Any unusual hotspots of declining health? Higher levels of wellness? Can you split the data by geography and predict neighboring cities health? Who's healthier larger or smaller cities? ,StateAbbr:PlaceName:PlaceFIPS:Population2010:ACCESS2_CrudePrev:ACCESS2_Crude95CI:ACCESS2_AdjPrev:ACCESS2_Adj95CI:ARTHRITIS_CrudePrev:ARTHRITIS_Crude95CI:ARTHRITIS_AdjPrev:ARTHRITIS_Adj95CI:BINGE_CrudePrev:BINGE_Crude95CI:BINGE_AdjPrev:BINGE_Adj95CI:BPHIGH_CrudePrev:BPHIGH_Crude95CI:BPHIGH_AdjPrev:BPHIGH_Adj95CI:BPMED_CrudePrev:BPMED_Crude95CI:BPMED_AdjPrev:BPMED_Adj95CI:CANCER_CrudePrev:CANCER_Crude95CI:CANCER_AdjPrev:CANCER_Adj95CI:CASTHMA_CrudePrev:CASTHMA_Crude95CI:CASTHMA_AdjPrev:CASTHMA_Adj95CI:CHD_CrudePrev:CHD_Crude95CI:CHD_AdjPrev:CHD_Adj95CI:CHECKUP_CrudePrev:CHECKUP_Crude95CI:CHECKUP_AdjPrev:CHECKUP_Adj95CI:CHOLSCREEN_CrudePrev:CHOLSCREEN_Crude95CI:CHOLSCREEN_AdjPrev:CHOLSCREEN_Adj95CI:COLON_SCREEN_CrudePrev:COLON_SCREEN_Crude95CI:COLON_SCREEN_AdjPrev:COLON_SCREEN_Adj95CI:COPD_CrudePrev:COPD_Crude95CI:COPD_AdjPrev:COPD_Adj95CI:COREM_CrudePrev:COREM_Crude95CI:COREM_AdjPrev:COREM_Adj95CI:COREW_CrudePrev:COREW_Crude95CI:COREW_AdjPrev:COREW_Adj95CI:CSMOKING_CrudePrev:CSMOKING_Crude95CI:CSMOKING_AdjPrev:CSMOKING_Adj95CI:DENTAL_CrudePrev:DENTAL_Crude95CI:DENTAL_AdjPrev:DENTAL_Adj95CI:DIABETES_CrudePrev:DIABETES_Crude95CI:DIABETES_AdjPrev:DIABETES_Adj95CI:HIGHCHOL_CrudePrev:HIGHCHOL_Crude95CI:HIGHCHOL_AdjPrev:HIGHCHOL_Adj95CI:KIDNEY_CrudePrev:KIDNEY_Crude95CI:KIDNEY_AdjPrev:KIDNEY_Adj95CI:LPA_CrudePrev:LPA_Crude95CI:LPA_AdjPrev:LPA_Adj95CI:MAMMOUSE_CrudePrev:MAMMOUSE_Crude95CI:MAMMOUSE_AdjPrev:MAMMOUSE_Adj95CI:MHLTH_CrudePrev:MHLTH_Crude95CI:MHLTH_AdjPrev:MHLTH_Adj95CI:OBESITY_CrudePrev:OBESITY_Crude95CI:OBESITY_AdjPrev:OBESITY_Adj95CI:PAPTEST_CrudePrev:PAPTEST_Crude95CI:PAPTEST_AdjPrev:PAPTEST_Adj95CI:PHLTH_CrudePrev:PHLTH_Crude95CI:PHLTH_AdjPrev:PHLTH_Adj95CI:SLEEP_CrudePrev:SLEEP_Crude95CI:SLEEP_AdjPrev:SLEEP_Adj95CI:STROKE_CrudePrev:STROKE_Crude95CI:STROKE_AdjPrev:STROKE_Adj95CI:TEETHLOST_CrudePrev:TEETHLOST_Crude95CI:TEETHLOST_AdjPrev:TEETHLOST_Adj95CI:Geolocation:,string:string:numeric:numeric:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:string:,diseases and epidemics
Movehub City Rankings , Blitzer , www.kaggle.com/blitzr/movehub-city-rankings , Fri Mar 24 2017 17:43:34 GMT+0530 (IST) , Compare key metrics for over 200 cities ,1209, cities- ,Context Movehub city ranking as published on http//www.movehub.com/city-rankings Content movehubqualityoflife.csv Cities ranked by Movehub Rating A combination of all scores for an overall rating for a city or country. Purchase Power This compares the average cost of living with the average local wage. Health Care Compiled from how citizens feel about their access to healthcare and its quality. Pollution Low is good. A score of how polluted people find a city includes air water and noise pollution. Quality of Life A balance of healthcare pollution purchase power crime rate to give an overall quality of life score. Crime Rating Low is good. The lower the score the safer people feel in this city. movehubcostofliving.csv Unit GBP City Cappuccino Cinema Wine Gasoline Avg Rent Avg Disposable Income cities.csv Cities to countries as parsed from Wikipedia https//en.wikipedia.org/wiki/List_of_towns_and_cities_with_100000_or_more_inhabitants/cityname_A (A-Z) Acknowledgements Movehub http//www.movehub.com/city-rankings Wikipedia https//en.wikipedia.org/wiki/List_of_towns_and_cities_with_100000_or_more_inhabitants/cityname_A,City:Country:,string:string:,online reviews and ratings
City Lines , citylines.co , www.kaggle.com/citylines/city-lines , Sat Aug 05 2017 20:17:32 GMT+0530 (IST) , Explore the transport systems of the world's cities ,350, cities- transport- ,Context What did the expansion of the London Underground the world’s first underground railway which opened in 1863 look like? What about the transportation system in your home city? Citylines collects data on transportation lines across the world so you can answer questions like these and more. Content This dataset originally shared and updated here includes transportation line data from a number of cities from around the world including London Berlin Mexico City Barcelona Washington D.C. and others covering many thousands of kilometers of lines.  Inspiration You can explore geometries to generate maps and even see how lines have changed over time based on historical records. Want to include shapefiles with your analysis? Simply publish a shapefile dataset here and then create a new kernel (R or Python script/notebook) adding your shapefile as an additional datasource.,id:,numeric:,rail and metro
World Cities , Open Knowledge International , www.kaggle.com/okfn/world-cities , Wed Jun 14 2017 01:12:32 GMT+0530 (IST) , All of the world's major cities above 15000 inhabitants ,290, cities- ,Utility Data The data is extracted from geonames a very exhaustive list of worldwide toponyms. It can be joined with datasets containing geographic fields to facilitate geospatial analysis including mapping. This datapackage only lists cities above 15000 inhabitants. Each city is associated with its country and subcountry to reduce the number of ambiguities. Subcountry can be the name of a state (e.g. in United Kingdom or the United States of America) or the major administrative section (e.g. ''region'' in France''). See admin1 field on geonames website for further info about subcountry. Notice that  Some cities like Vatican City or Singapore are a whole state so they don't belong to any subcountry. Therefore subcountry is N/A. There is no guaranty that a city has a unique name in a country and subcountry (At the time of writing there are about 60 ambiguities). But for each city the source data primary key geonameid is provided.  Preparation You can run the script yourself to update the data and publish them to GitHub/Kaggle see scripts README Acknowledgments and License All data is licensed under the Creative Common Attribution License as is the original data from geonames. This means you have to credit geonames when using the data. And while no credit is formally required a link back or credit to Lexman and the Open Knowledge Foundation is much appreciated. This dataset description is reproduced here from its original source with slight modifications.,name:country:subcountry:geonameid:,string:string:string:numeric:,demography
Horse Racing in HK , Graham Daley , www.kaggle.com/gdaley/hkracing , Thu Dec 15 2016 11:36:54 GMT+0530 (IST) , Data on thoroughbred racing in Hong Kong for fun and machine learning ,645, horse racing- ,Can you beat the market? Horse racing has always intrigued me - not so much from the point of view as a sport but more from the view of it as a money market. Inspired by the pioneers of computerised horse betting I'm sharing this dataset in the hope of finding more data scientists willing to take up the challenge and find new ways of exploiting it!  As always the goal for most of us is to find information in the data that can be used to generate profit usually by finding information that has not already been considered by the other players in the game. But I'm always interested in finding new uses for the data whatever they may be. Horse racing is a huge business in Hong Kong which has two race tracks in a city that is only 1104 square km. The betting pools are bigger than all US racetracks combined which means that the opportunity is unlimited for those who are successful. So are you up for it?  Content The data was obtained from various free sources and is presented in CSV format. Personally-identifiable information such as horse and jockey names has not been included. However these should have no relevance to the purpose of this dataset which is purely for experimental use. There are two files races.csv Each line describes the condition of an individual race. race_id - unique identifier for the race date - date of the race in YYYY-MM-DD format (note that the dates given have been obscured and are not the real ones although the durations between each race should be correct) venue - a 2-character string representing which of the 2 race courses this race took place at ST = Shatin HV = Happy Valley race_no - race number of the race in the day's meeting config - race track configuration mostly related to the position of the inside rail. For more details see the HKJC website. surface - a number representing the type of race track surface 1 = dirt 0 = turf distance - distance of the race in metres going - track condition. For more details see the HKJC website. horse_ratings - the range of horse ratings that may participate in this race prize - the winning prize in HK Dollars race_class - a number representing the class of the race sec_time1 - time taken by the leader of the race to reach the end of the end of the 1st sectional point (sec) sec_time2 - time taken by the leader of the race to reach the end of the 2nd sectional point (sec) sec_time3 - time taken by the leader of the race to reach the end of the 3rd sectional point (sec) sec_time4 - time taken by the leader of the race to reach the end of the 4th sectional point if any (sec) sec_time5 - time taken by the leader of the race to reach the end of the 5th sectional point if any (sec) sec_time6 - time taken by the leader of the race to reach the end of the fourth sectional point if any (sec) sec_time7 - time taken by the leader of the race to reach the end of the fourth sectional point if any (sec) time1 - time taken by the leader of the race in the 1st section only (sec) time2 - time taken by the leader of the race in the 2nd section only (sec) time3 - time taken by the leader of the race in the 3rd section only (sec) time4 - time taken by the leader of the race in the 4th section only if any (sec) time5 - time taken by the leader of the race in the 5th section only if any (sec) time6 - time taken by the leader of the race in the 6th section only if any (sec) time7 - time taken by the leader of the race in the 7th section only if any (sec) place_combination1 - placing horse no (1st) place_combination2 - placing horse no (2nd) place_combination3 - placing horse no (3rd) place_combination4 - placing horse no (4th) place_dividend1 - placing dividend paid (for place_combination1) place_dividend2 - placing dividend paid (for place_combination2) place_dividend3 - placing dividend paid (for place_combination2) place_dividend4 - placing dividend paid (for place_combination2) win_combination1 - winning horse no win_dividend1 - winning dividend paid (for win_combination1) win_combination2 - joint winning horse no if any win_dividend2 - winning dividend paid (for win_combination2 if any) runs.csv Each line describes the characteristics of one horse run in one of the races given in races.csv. race_id - unique identifier for the race horse_no - the number assigned to this horse in the race horse_id - unique identifier for this horse result - finishing position of this horse in the race won - whether horse won (1) or otherwise (0) lengths_behind - finishing position as the number of horse lengths behind the winner horse_age - current age of this horse at the time of the race horse_country - country of origin of this horse horse_type - sex of the horse e.g. 'Gelding' 'Mare' 'Horse' 'Rig' 'Colt' 'Filly' horse_rating - rating number assigned by HKJC to this horse at the time of the race horse_gear - string representing the gear carried by the horse in the race. An explanation of the codes used may be found on the HKJC website. declared_weight - declared weight of the horse and jockey in lbs actual_weight - actual weight carried by the horse in lbs draw - post position number of the horse in this race position_sec1 - position of this horse (ranking) in section 1 of the race position_sec2 - position of this horse (ranking) in section 2 of the race position_sec3 - position of this horse (ranking) in section 3 of the race position_sec4 - position of this horse (ranking) in section 4 of the race if any position_sec5 - position of this horse (ranking) in section 5 of the race if any position_sec6 - position of this horse (ranking) in section 6 of the race if any behind_sec1 - position of this horse (lengths behind leader) in section 1 of the race behind_sec2 - position of this horse (lengths behind leader) in section 2 of the race behind_sec3 - position of this horse (lengths behind leader) in section 3 of the race behind_sec4 - position of this horse (lengths behind leader) in section 4 of the race if any behind_sec5 - position of this horse (lengths behind leader) in section 5 of the race if any behind_sec6 - position of this horse (lengths behind leader) in section 6 of the race if any time1 - time taken by the horse to pass through the 1st section of the race (sec) time2 - time taken by the horse to pass through the 2nd section of the race (sec) time3 - time taken by the horse to pass through the 3rd section of the race (sec) time4 - time taken by the horse to pass through the 4th section of the race if any (sec) time5 - time taken by the horse to pass through the 5th section of the race if any (sec) time6 - time taken by the horse to pass through the 6th section of the race if any (sec) finish_time - finishing time of the horse in this race (sec) win_odds - win odds for this horse at start of race place_odds - place (finishing in 1st 2nd or 3rd position) odds for this horse at start of race trainer_id - unique identifier of the horse's trainer at the time of the race jockey_id - unique identifier of the jockey riding the horse in this race Acknowledgements None of this research would have even started without me standing on the shoulders of giants such as William Benter Ruth Bolton and Randall Chapman and many others who have published the results of their research. Inspiration It is probably not going to be enough to just take this dataset and feed it into Google Cloud Machine Learning Azure MI etc... but let me know if you find otherwise! Questions that need to be answered include  Feature engineering - what features are needed and how best to estimate them from the data given? Modelling - what kind of model works best? Maybe more than one model? Other data - is there any other data needed apart from that given in this data set? ,race_id:date:venue:race_no:config:surface:distance:going:horse_ratings:prize:race_class:sec_time1:sec_time2:sec_time3:sec_time4:sec_time5:sec_time6:sec_time7:time1:time2:time3:time4:time5:time6:time7:place_combination1:place_combination2:place_combination3:place_combination4:place_dividend1:place_dividend2:place_dividend3:place_dividend4:win_combination1:win_dividend1:win_combination2:win_dividend2:,numeric:dateTime:string:numeric:string:numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:numeric:numeric:numeric:numeric:string:string:string:numeric:numeric:numeric:string:numeric:numeric:numeric:string:numeric:numeric:string:string:,sports events
Missing Migrants Dataset , jmataya , www.kaggle.com/jmataya/missingmigrants , Fri Jun 16 2017 14:26:07 GMT+0530 (IST) , Explore missing migrants across the globe ,320, demographics- international relations- ,About the Missing Migrants Data This data is sourced from the International Organization for Migration.  The data is part of a specific project called the Missing Migrants Project which tracks deaths of migrants including refugees  who have gone missing along mixed migration routes worldwide. The research behind this project began with the October 2013 tragedies when at least 368 individuals died in two shipwrecks near the Italian island of Lampedusa. Since then Missing Migrants Project has developed into an important hub and advocacy source of information that media researchers and the general public access for the latest information. Where is the data from? Missing Migrants Project data are compiled from a variety of sources. Sources vary depending on the region and broadly include data from national authorities such as Coast Guards and Medical Examiners; media reports; NGOs; and interviews with survivors of shipwrecks. In the Mediterranean region data are relayed from relevant national authorities to IOM field missions who then share it with the Missing Migrants Project team. Data are also obtained by IOM and other organizations that receive survivors at landing points in Italy and Greece. In other cases media reports are used. IOM and UNHCR also regularly coordinate on such data to ensure consistency. Data on the U.S./Mexico border are compiled based on data from U.S. county medical examiners and sheriff’s offices as well as media reports for deaths occurring on the Mexico side of the border. Estimates within Mexico and Central America are based primarily on media and year-end government reports. Data on the Bay of Bengal are drawn from reports by UNHCR and NGOs. In the Horn of Africa data are obtained from media and NGOs. Data for other regions is drawn from a combination of sources including media and grassroots organizations. In all regions Missing Migrants Projectdata represents minimum estimates and are potentially lower than in actuality. Updated data and visuals can be found here https//missingmigrants.iom.int/  Who is included in Missing Migrants Project data? IOM defines a migrant as any person who is moving or has moved across an international border or within a State away from his/her habitual place of residence regardless of      (1) the person’s legal status;      (2) whether the movement is voluntary or involuntary;      (3) what the causes for the movement are; or      (4) what the length of the stay is.[1]  Missing Migrants Project counts migrants who have died or gone missing at the external borders of states or in the process of migration towards an international destination. The count excludes deaths that occur in immigration detention facilities during deportation or after forced return to a migrant’s homeland as well as deaths more loosely connected with migrants’ irregular status such as those resulting from labour exploitation. Migrants who die or go missing after they are established in a new home are also not included in the data so deaths in refugee camps or housing are excluded.  This approach is chosen because deaths that occur at physical borders and while en route represent a more clearly definable category and inform what migration routes are most dangerous. Data and knowledge of the risks and vulnerabilities faced by migrants in destination countries including death should not be neglected rather tracked as a distinct category. How complete is the data on dead and missing migrants? Data on fatalities during the migration process are challenging to collect for a number of reasons most stemming from the irregular nature of migratory journeys on which deaths tend to occur.  For one deaths often occur in remote areas on routes chosen with the explicit aim of evading detection. Countless bodies are never found and rarely do these deaths come to the attention of authorities or the media. Furthermore when deaths occur at sea frequently not all bodies are recovered - sometimes with hundreds missing from one shipwreck - and the precise number of missing is often unknown.  In 2015 over 50 per cent of deaths recorded by the Missing Migrants Project refer to migrants who are presumed dead and whose bodies have not been found mainly at sea.       Data are also challenging to collect as reporting on deaths is poor and the data that does exist are highly scattered. Few official sources are collecting data systematically. Many counts of death rely on media as a source. Coverage can be spotty and incomplete. In addition the involvement of criminal actors in incidents means there may be fear among survivors to report deaths and some deaths may be actively covered-up. The irregular immigration status of many migrants and at times their families as well also impedes reporting of missing persons or deaths. The varying quality and comprehensiveness of data by region in attempting to estimate deaths globally may exaggerate the share of deaths that occur in some regions while under-representing the share occurring in others.  What can be understood through this data? The available data can give an indication of changing conditions and trends related to migration routes and the people travelling on them which can be relevant for policy making and protection plans.  Data can be useful to determine the relative risks of irregular migration routes. For example Missing Migrants Project data show that despite the increase in migrant flows through the eastern Mediterranean in 2015 the central Mediterranean remained the more deadly route.  In 2015 nearly two people died out of every 100 travellers (1.85%) crossing the Central route as opposed to one out of every 1000 that crossed from Turkey to Greece (0.095%).  From the data we can also get a sense of whether groups like women and children face additional vulnerabilities on migration routes. However it is important to note that because of the challenges in data collection for the missing and dead basic demographic information on the deceased is rarely known. Often migrants in mixed migration flows do not carry appropriate identification. When bodies are found it may not be possible to identify them or to determine basic demographic information. In the data compiled by Missing Migrants Project sex of the deceased is unknown in over 80% of cases. Region of origin has been determined for the majority of the deceased. Even this information is at times extrapolated based on available information – for instance if all survivors of a shipwreck are of one origin it was assumed those missing also came from the same region.  The Missing Migrants Project dataset includes coordinates for where incidents of death took place which indicates where the risks to migrants may be highest.  However it should be noted that all coordinates are estimates. Why collect data on missing and dead migrants? By counting lives lost during migration even if the result is only an informed estimate we at least acknowledge the fact of these deaths. What before was vague and ill-defined is now a quantified tragedy that must be addressed.  Politically the availability of official data is important. The lack of political commitment at national and international levels to record and account for migrant deaths reflects and contributes to a lack of concern more broadly for the safety and well-being of migrants including asylum-seekers. Further it drives public apathy ignorance and the dehumanization of these groups. Data are crucial to better understand the profiles of those who are most at risk and to tailor policies to better assist migrants and prevent loss of life. Ultimately improved data should contribute to efforts to better understand the causes both direct and indirect of fatalities and their potential links to broader migration control policies and practices. Counting and recording the dead can also be an initial step to encourage improved systems of identification of those who die. Identifying the dead is a moral imperative that respects and acknowledges those who have died. This process can also provide a some sense of closure for families who may otherwise be left without ever knowing the fate of missing loved ones.                  Identification and tracing of the dead and missing As mentioned above the challenge remains to count the numbers of dead and also identify those counted. Globally the majority of those who die during migration remain unidentified. Even in cases in which a body is found identification rates are low. Families may search for years or a lifetime to find conclusive news of their loved one. In the meantime they may face psychological practical financial and legal problems.        Ultimately Missing Migrants Project would like to see that every unidentified body for which it is possible to recover is adequately “managed” analysed and tracked to ensure proper documentation traceability and dignity.  Common forensic protocols and standards should be agreed upon and used within and between States.  Furthermore data relating to the dead and missing should be held in searchable and open databases at local national and international levels to facilitate identification.  For more in-depth analysis and discussion of the numbers of missing and dead migrants around the world and the challenges involved in identification and tracing read our two reports on the issue  Fatal Journeys Tracking Lives Lost during Migration (2014) and Fatal Journeys Volume 2 Identification and Tracing of Dead and Missing Migrants         Content The data set records incidents of missing persons and deaths of migrants   columns in the data   ID - unique key documenting incident  Cause of Death - reason for death Region of Origin  Nationality  Missing Persons - counts  Dead - counts of deaths  Incident Region - region where incident was recorded  Date - the date when the incident was recorded.  Note the data set includes records from 2014 to June 2017 Latitude - spatial coordinates  Longitude - spatial coordinates  Acknowledgements This data set was created by the International Organization for Migration.   https//www.iom.int/about-iom Established in 1951 IOM is the leading inter-governmental organization in the field of migration and works closely with governmental intergovernmental and non-governmental partners. With 166 member states a further 8 states holding observer status and offices in over 100 countries IOM is dedicated to promoting humane and orderly migration for the benefit of all. It does so by providing services and advice to governments and migrants. IOM works to help ensure the orderly and humane management of migration to promote international cooperation on migration issues to assist in the search for practical solutions to migration problems and to provide humanitarian assistance to migrants in need including refugees and internally displaced people. The IOM Constitution recognizes the link between migration and economic social and cultural development as well as to the right of freedom of movement. IOM works in the four broad areas of migration management  Migration and development Facilitating migration Regulating migration Forced migration.  IOM activities that cut across these areas include the promotion of international migration law policy debate and guidance protection of migrants' rights migration health and the gender dimension of migration. Start a new kernel,id:cause_of_death:region_origin:missing:dead:incident_region:date:source:reliability:lat:lon:affected_nationality:,numeric:string:string:numeric:numeric:string:dateTime:string:string:numeric:numeric:numeric:,demography
Adverse Food Events , Food and Drug Administration , www.kaggle.com/fda/adverse-food-events , Fri Sep 08 2017 01:04:07 GMT+0530 (IST) , ~90k FDA Recorded Medical Events ,107, government agencies- food and drink- human medicine- government- medicine- ,Context The CFSAN Adverse Event Reporting System (CAERS) is a database that contains information on adverse event and product complaint reports submitted to FDA for foods dietary supplements and cosmetics. The database is designed to support CFSAN's safety surveillance program. Adverse events are coded to terms in the Medical Dictionary for Regulatory Activities (MedDRA) terminology. Content See the metadata description in the accompanying README.pdf below or here. Approximately 90k reactions are recorded from 2004-mid 2017 with 12 columns of information regarding type of reaction and related event details. Acknowledgements This dataset is collected by the US Food and Drug Administration. Inspiration  What are the most commonly reported foodstuffs? What are the most commonly reported medical reactions to foods? Where do people in the US most commonly report food-related conditions? ,RA_Report #:RA_CAERS Created Date:AEC_Event Start Date:PRI_Product Role:PRI_Reported Brand/Product Name:PRI_FDA Industry Code:PRI_FDA Industry Name:CI_Age at Adverse Event:CI_Age Unit:CI_Gender:AEC_One Row Outcomes:SYM_One Row Coded Symptoms:,numeric:dateTime:dateTime:string:string:numeric:string:numeric:string:string:string:string:,pharmaceuticals
Fatal Police Shootings in the US , Karolina Wullum , www.kaggle.com/kwullum/fatal-police-shootings-in-the-us , Sat Sep 23 2017 00:48:21 GMT+0530 (IST) , Fatal police shootings in the US since 2015 with additional US census data ,272, united states- death- crime- violence- ,"The 2014 killing of Michael Brown in Ferguson Missouri began the protest movement culminating in Black Lives Matter and an increased focus on police accountability nationwide.  Since Jan. 1 2015 The Washington Post has been compiling a database of every fatal shooting in the US by a police officer in the line of duty.  It's difficult to find reliable data from before this period as police killings haven't been comprehensively documented and the statistics on police brutality are much less available. As a result a vast number of cases go unreported. The Washington Post is tracking more than a dozen details about each killing - including the race age and gender of the deceased whether the person was armed and whether the victim was experiencing a mental-health crisis. They have gathered this information from law enforcement websites local new reports social media and by monitoring independent databases such as ""Killed by police"" and ""Fatal Encounters"". The Post has also conducted additional reporting in many cases. There are four additional datasets. These are US census data on poverty rate high school graduation rate median household income and racial demographics.  Source of census data https//factfinder.census.gov/faces/nav/jsf/pages/community_facts.xhtml",Geographic Area:City:Median Income:,string:string:numeric:,crime
SMS Spam Collection Dataset , UCI Machine Learning , www.kaggle.com/uciml/sms-spam-collection-dataset , Sat Dec 03 2016 00:59:17 GMT+0530 (IST) , Collection of SMS messages tagged as spam or legitimate ,4001, languages- linguistics- human-computer interaction- ,Context The SMS Spam Collection is a set of SMS tagged messages that have been collected for SMS Spam research. It contains one set of SMS messages in English of 5574 messages tagged acording being ham (legitimate) or spam.  Content The files contain one message per line. Each line is composed by two columns v1 contains the label (ham or spam) and v2 contains the raw text.  Acknowledgements The original dataset can be found here. The creators would like to note that in case you find the dataset useful please make a reference to previous paper and the web page http//www.dt.fee.unicamp.br/~tiago/smsspamcollection/ in your papers research etc. Inspiration  Can you use this dataset to build a prediction model that will accurately classify which texts are spam? ,,,mail and messaging
US Supreme Court Cases 1946-2016 , Washington University , www.kaggle.com/wustl/supreme-court , Thu Jan 26 2017 03:10:24 GMT+0530 (IST) , How have court decisions over legal issues changed over time? ,187, law- ,Content The Supreme Court database is the definitive source for researchers students journalists and citizens interested in the United States Supreme Court. The database contains more than two hundred variables regarding each case decided by the Court between the 1946 and 2015 terms. Examples include the identity of the court whose decision the Supreme Court reviewed the parties to the suit the legal provisions considered in the case and the votes of the Justices. The database codebook is available here. Acknowledgements The database was compiled by Professor Spaeth of Washington University Law and funded with a grant from the National Science Foundation.,case_id:docket_id:issues_id:vote_id:date_decision:decision_type:us_citation:court_citation:led_citation:lexis_citation:term:court:chief_justice:docket:case_name:date_argument:date_reargument:petitioner:petitioner_state:respondent:respondent_state:jurisdiction:administrative_action:administrative_action_state:district_court:case_origin:case_origin_state:case_source:case_source_state:lower_court_disagreement:cert_reason:lower_court_disposition:lower_disposition_direction:declaration_unconstitutionality:case_disposition:disposition_unusual:party_winning:precedent_alteration:vote_unclear:issue:issue_area:decision_direction:decision_direction_dissent:authority_decision_one:authority_decision_two:law_type:law_supplement:law_minor_supplement:majority_opinion_writer:majority_opinion_assigner:split_vote:majority_votes:minority_votes::,string:string:string:string:dateTime:numeric:string:string:string:string:numeric:numeric:string:numeric:string:dateTime:dateTime:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:string:,court cases
The History of Baseball , SeanLahman , www.kaggle.com/seanlahman/the-history-of-baseball , Thu Sep 08 2016 04:16:49 GMT+0530 (IST) , A complete history of major league baseball stats from 1871 to 2015 ,4288, baseball- history- ,Baffled why your team traded for that 34-year-old pitcher? Convinced you can create a new and improved version of WAR? Wondering what made the 1907 Cubs great and if can they do it again?  The History of Baseball is a reformatted version of the famous Lahman’s Baseball Database. It contains Major League Baseball’s complete batting and pitching statistics from 1871 to 2015 plus fielding statistics standings team stats park stats player demographics managerial records awards post-season data and more. Scripts Kaggle’s free in-browser analytics tool makes it easy to share detailed sabermetrics predict the next hall of fame inductee illustrate how speed scores runs or publish a definitive analysis on why the Los Angeles Dodgers will never win another World Series.  We have more ideas for analysis than games in a season but here are a few we’d really love to see   Is there a most error-prone position? When do players at different positions peak? Are the best performers selected for all-star game? How many walks does it take for a starting pitcher to get pulled? Do players with a high ground into double play (GIDP) have a lower batting average? Which players are the most likely to choke during the post-season? Why should or shouldn’t the National League adopt the designated hitter rule?  See the full SQLite schema.,,,sports events
Google Project Sunroof , Jacob Boysen , www.kaggle.com/jboysen/google-project-sunroof , Mon Sep 11 2017 23:10:20 GMT+0530 (IST) , Solar Panel Power Consumption Offset Estimates ,337, ,Context As the price of installing solar has gotten less expensive more homeowners are turning to it as a possible option for decreasing their energy bill. We want to make installing solar panels easy and understandable for anyone. Project Sunroof puts Google's expansive data in mapping and computing resources to use helping calculate the best solar plan for you. Content See metadata for indepth description. Data is at census-tract level. Project Sunroof computes how much sunlight hits your roof in a year. It takes into account Google's database of imagery and maps 3D modeling of your roof Shadows cast by nearby structures and trees All possible sun positions over the course of a year Historical cloud and temperature patterns that might affect solar energy production Acknowledgements Data was compiled by Google Project Sunroof. You can use Kernels to analyze share and discuss this data on Kaggle but if you’re looking for real-time updates and bigger data check out the data on BigQuery too. Inspiration  Which tracts have the highest potential possible coverage? Carbon offsets? Which tracts have the highest estimated solar panel utilization? As a percent of carbon offsets?  If you want more energy data check out 30 Years of European Wind Generation and 30 Years of European Solar Generation.,Field:Description:,string:string:,renewable energy
Retailrocket recommender system dataset , Retailrocket , www.kaggle.com/retailrocket/ecommerce-dataset , Fri Mar 24 2017 13:15:27 GMT+0530 (IST) , Ecommerce data: web events item properties (with texts) category tree ,1660, business- internet- ,"Context The dataset consists of three files a file with behaviour data (events.csv) a file with item properties (item_properties.сsv) and a file which describes category tree (category_tree.сsv). The data has been collected from a real-world ecommerce website. It is raw data i.e. without any content transformations however all values are hashed due to confidential issues. The purpose of publishing is to motivate researches in the field of recommender systems with implicit feedback. Content The behaviour data i.e. events like clicks add to carts transactions represent interactions that were collected over a period of 4.5 months. A visitor can make three types of events namely “view” “addtocart” or “transaction”. In total there are 2 756 101 events including 2 664 312 views 69 332 add to carts and 22 457 transactions produced by  1 407 580 unique visitors. For about 90% of events corresponding properties can be found in the “item_properties.csv” file.  For example  “14396940000001view100” means visitorId = 1 clicked the item with id = 100 at 1439694000000 (Unix timestamp) “14396940000002transaction1000234” means visitorId  = 2 purchased the item with id = 1000 in transaction with id = 234 at 1439694000000 (Unix timestamp)  The file with item properties (item_properties.csv) includes 20 275 902 rows i.e. different properties describing 417 053 unique items. File is divided into 2 files due to file size limitations. Since the property of an item can vary in time (e.g. price changes over time) every row in the file has corresponding timestamp. In other words the file consists of concatenated snapshots for every week in the file with the behaviour data. However if a property of an item is constant over the observed period only a single snapshot value will be present in the file. For example we have three properties for single item and 4 weekly snapshots like below timestampitemidpropertyvalue 143969400000011001000 143969500000011001000 143969600000011001000 143969700000011001000 143969400000012001000 143969500000012001100 143969600000012001200 143969700000012001300 143969400000013001000 143969500000013001000 143969600000013001100 143969700000013001100  After snapshot merge it would looks like 143969400000011001000 143969400000012001000 143969500000012001100 143969600000012001200 143969700000012001300 143969400000013001000 143969600000013001100  Because property=100 is constant over time property=200 has different values for all snapshots property=300 has been changed once. Item properties file contain timestamp column because all of them are time dependent since properties may change over time e.g. price category etc. Initially this file consisted of snapshots for every week in the events file and contained over 200 millions rows. We have merged consecutive constant  property values so it's changed from snapshot form to change log form. Thus  constant  values would appear only once in the file. This action has significantly reduced the number of rows in 10 times. All values in the “item_properties.csv” file excluding ""categoryid"" and ""available"" properties were hashed.  Value of the ""categoryid"" property contains item category identifier. Value of the ""available"" property contains availability of the item i.e. 1 means the item was available otherwise 0. All numerical values were marked with ""n"" char at the beginning and have 3 digits precision after decimal point e.g.  ""5"" will become ""n5.000"" ""-3.67584"" will become ""n-3.675"". All words in text values were normalized (stemming procedure https//en.wikipedia.org/wiki/Stemming) and hashed numbers were processed as above e.g. text ""Hello world 2017!"" will become ""24214 44214 n2017.000"" The category tree file has 1669 rows. Every row in the file specifies a child categoryId and the corresponding parent. For example  Line “100200” means that categoryid=1 has parent with categoryid=200 Line “300” means that categoryid hasn’t parent in the tree  Acknowledgements Retail Rocket (retailrocket.io) helps web shoppers make better shopping decisions by providing personalized real-time recommendations through multiple channels with over 100MM unique monthly users and 1000+ retail partners over the world. Inspiration  How to use item properties and category tree data to improve collaborative filtering model? Recurrent Neural Networks with Top-k Gains for Session-based Recommendations https//github.com/hidasib/GRU4Rec  and paper https//arxiv.org/abs/1706.03847 https//www.researchgate.net/publication/280538158_Application_of_Kullback-Leibler_divergence_for_short-term_user_interest_detection https//pdfs.semanticscholar.org/66dc/1724c4ed1e74fe6b22e636b52031a33c8ebe.pdf https//www.slideshare.net/LukasLerche/adaptation-and-evaluation-of-recommendationsfor-shortterm-shopping-goals   Adaptation and Evaluation of Recommendations for Short-term Shopping Goals  Tasks Task 1 When a customer comes to an e-commerce site he looks for a product with particular properties price range vendor product type and etc. These properties are implicit so it's hard to determine them through clicks log.  Try to create an algorithm which predicts properties of items in ""addtocart"" event by using data from ""view"" events for any visitor in the published log. Task 2 Description Process of analyzing ecommerce data include very important part of data cleaning. Researchers noticed that in some cases browsing data include up to 40% of abnormal traffic. Firstly abnormal users add a lot of noise into data and make recommendation system less effective. In order to increase efficiency of recommendation system abnormal users should be removed from the raw data. Secondly abnormal users add bias to results of split tests so this type of users should be removed also from split test data. Goals  The main goal is to find abnormal users of e-shop.  Subgoals  Generate features Build a model Create a metric that helps to evaluate quality of the model ",categoryid:parentid:,numeric:numeric:,online shopping
1000 Cameras Dataset , Chris Crawford , www.kaggle.com/crawford/1000-cameras-dataset , Sat Aug 19 2017 00:23:59 GMT+0530 (IST) , Data describing 1000 cameras in 13 properties ,140, electronics- ,Context Some camera enthusiast went and described 1000 cameras based on 13 properties!  Content Row one describes the datatype for each column and can probably be removed. The 13 properties of each camera  Model Release date Max resolution Low resolution Effective pixels Zoom wide (W) Zoom tele (T) Normal focus range Macro focus range Storage included Weight (inc. batteries) Dimensions Price  Acknowledgements These datasets have been gathered and cleaned up by Petra Isenberg Pierre Dragicevic and Yvonne Jansen.  The original source can be found here. This dataset has been converted to CSV.,Model:Release date:Max resolution:Low resolution:Effective pixels:Zoom wide (W):Zoom tele (T):Normal focus range:Macro focus range:Storage included:Weight (inc. batteries):Dimensions:Price:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,gadgets
T20 cricket matches , cricketsavant , www.kaggle.com/imrankhan17/t20matches , Wed Apr 12 2017 19:30:59 GMT+0530 (IST) , Details of over 6000 T20 matches since 2003 ,896, cricket- ,Context Match details of over 6000 T20 matches including innings scores and results. Content The first 3 columns show the original data that was scraped. The remaining columns are individual data points extracted from these columns. • match_details summary of match including stage of tournament (if applicable) home/away teams venue and date of match. • result summary of final result. Includes ties (and any winners as a result of bowl-outs/super overs etc.) no results and abandoned matches. • scores summary of scores of both innings. Includes scores even if match ends in a no result. Blank indicates that match was abandoned without a ball bowled. • date date of match in standard date format dd/mm/yyyy. If match goes to reserve day this date is used. • venue city of match. Can be assumed to be main stadium within city. If more than one stadium in a city it is usually labelled. • round stage within tournament e.g. final semi-final group stage etc. Also includes 1st 2nd T20I etc. for bilateral series. • home home or designated home team. • away away or designated away team. • winner winner of match including any winners by any method to determine a winner after a tie. • win_by_runs number of runs team batting first wins by. • win_by_wickets number of wickets team batting second wins by. • balls_remaining number of balls remaining for team batting second after win. • innings1 team batting first • innings1_runs first innings score • innings1_wickets first innings wickets • innings1_overs_batted actual length of first innings • innings1_overs maximum length of first innings • innings2 team batting second • innings2_runs second innings score • innings2_wickets second innings wickets • innings2_overs_batted actual length of second innings • innings2_overs maximum length of second innings • D/L method 1 means that the D/L method (or VJB method) was used to determine winner. • target rain-adjusted target. If blank target is first innings score plus 1 as normal. NEW all T20 series added. Please let me know if you spot any mistakes!,match_id:series_id:match_details:result:scores:date:venue:round:home:away:winner:win_by_runs:win_by_wickets:balls_remaining:innings1:innings1_runs:innings1_wickets:innings1_overs_batted:innings1_overs:innings2:innings2_runs:innings2_wickets:innings2_overs_batted:innings2_overs:D/L_method:target:,numeric:numeric:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:string:,cricket
Lower Back Pain Symptoms Dataset , sammy123 , www.kaggle.com/sammy123/lower-back-pain-symptoms-dataset , Fri Aug 19 2016 15:13:45 GMT+0530 (IST) , Collection of physical spine data ,2475, human medicine- ,310 Observations 13 Attributes (12 Numeric Predictors 1 Binary Class Attribute - No Demographics) Lower back pain can be caused by a variety of problems with any parts of the complex interconnected network of spinal muscles nerves bones discs or tendons in the lumbar spine. Typical sources of low back pain include  The large nerve roots in the low back that go to the legs may be irritated The smaller nerves that supply the low back may be irritated The large paired lower back muscles (erector spinae) may be strained The bones ligaments or joints may be damaged An intervertebral disc may be degenerating  An irritation or problem with any of these structures can cause lower back pain and/or pain that radiates or is referred to other parts of the body. Many lower back problems also cause back muscle spasms which don't sound like much but can cause severe pain and disability. While lower back pain is extremely common the symptoms and severity of lower back pain vary greatly. A simple lower back muscle strain might be excruciating enough to necessitate an emergency room visit while a degenerating disc might cause only mild intermittent discomfort. This data set is about to identify a person is abnormal or normal using collected physical spine details/data.,Col1:Col2:Col3:Col4:Col5:Col6:Col7:Col8:Col9:Col10:Col11:Col12:Class_att::,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:,diagnostics
Faulty Steel Plates , UCI Machine Learning , www.kaggle.com/uciml/faulty-steel-plates , Wed Sep 06 2017 22:06:17 GMT+0530 (IST) , Steel plate faults classified into seven types ,77, business- engineering- civil engineering- materials science- mechanical engineering- ,"Context This dataset comes from research by Semeion Research Center of Sciences of Communication. The original aim of the research was to correctly classify the type of surface defects in stainless steel plates with six types of possible defects (plus ""other"").  The  Input  vector  was  made  up  of  27  indicators  that  approximately [describe] the geometric shape of the defect and its outline. According to the research paper Semeion was commissioned by the Centro Sviluppo Materiali (Italy) for this task and therefore it is not possible to provide details on the nature of the 27 indicators used as Input vectors or the types of the 6 classes of defects.  Content There are 34 fields. The first 27 fields describe some kind of steel plate faults seen in images.  Unfortunately there is no other information that I know of to describe these columns.   X_Minimum X_Maximum Y_Minimum Y_Maximum Pixels_Areas X_Perimeter Y_Perimeter Sum_of_Luminosity Minimum_of_Luminosity Maximum_of_Luminosity Length_of_Conveyer TypeOfSteel_A300 TypeOfSteel_A400 Steel_Plate_Thickness Edges_Index Empty_Index Square_Index Outside_X_Index Edges_X_Index Edges_Y_Index Outside_Global_Index LogOfAreas Log_X_Index Log_Y_Index Orientation_Index Luminosity_Index SigmoidOfAreas  The last seven columns are one hot encoded classes i.e. if the plate fault is classified as ""Stains"" there will be a 1 in that column and 0's in the other columns. If you are unfamiliar with one hot encoding just know that the last seven columns are your class labels.   Pastry Z_Scratch K_Scatch Stains Dirtiness Bumps Other_Faults  Acknowledgements MetaNet The Theory of Independent Judges (PDF Download Available). Available from https//www.researchgate.net/publication/13731626_MetaNet_The_Theory_of_Independent_Judges [accessed Sep 6 2017]. Dataset provided by Semeion Research Center of Sciences of Communication Via Sersale 117 00128 Rome Italy.  www.semeion.it Lichman M. (2013). UCI Machine Learning Repository [http//archive.ics.uci.edu/ml]. Irvine CA University of California School of Information and Computer Science.",X_Minimum:X_Maximum:Y_Minimum:Y_Maximum:Pixels_Areas:X_Perimeter:Y_Perimeter:Sum_of_Luminosity:Minimum_of_Luminosity:Maximum_of_Luminosity:Length_of_Conveyer:TypeOfSteel_A300:TypeOfSteel_A400:Steel_Plate_Thickness:Edges_Index:Empty_Index:Square_Index:Outside_X_Index:Edges_X_Index:Edges_Y_Index:Outside_Global_Index:LogOfAreas:Log_X_Index:Log_Y_Index:Orientation_Index:Luminosity_Index:SigmoidOfAreas:Pastry:Z_Scratch:K_Scatch:Stains:Dirtiness:Bumps:Other_Faults:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,physical sciences
Chemical Health Effects and Toxicities , Khepry Quixote , www.kaggle.com/khepryquixote/chemical-health-effects-and-toxicities , Thu Jun 01 2017 03:08:29 GMT+0530 (IST) , Blended datasets of the health effects and toxicities of various chemicals ,249, human medicine- environment- chemistry- ,"Context Chemicals have health effects some recognized and some suspected. A comprehensive list of those chemicals and their health effects would be beneficial to those wishing to associate those chemicals' health effects with other sets of data.  The datasets uploaded here represent the ""blending"" of various individual chemical health effect datasets as compiled by Scorecard and hosted by the GoodGuide web site. Content As a general rule each dataset has a chemical's Chemical Abstract Society Registry Number (CASRN) for example ""100-00-5"" its name (e.g. ""P-NITROCHLOROBENZENE"") one or more health effect categories (e.g. ""recognized"" or ""suspected"") and one or more health effects (e.g. ""kidney"" and/or ""neurotoxicity"")  as well as the organization of provenance (e.g. ""HAZMAP"" and/or ""RTECS"") for the recognized and/or suspected health effects.  Acknowledgements A team from the Environmental Defense Fund created the individual datasets that presently reside at GoodGuide's Scorecard's Health Effects web page.  The ""blended"" datasets uploaded herein are various compilations of those individual datasets into ones more suitable for inclusion in data analyses and visualizations. Inspiration Initially the ""blended"" datasets were used to associate health effects with fracking well chemical disclosures as such joining of data was not readily available to most data analysts.  Examples of such datasets can be found at FrackingData.org's FracFocus Data web page.",tox_cas_edf_id:tox_chemical_name:tox_category:tox_cancer:tox_cardiovascular_blood:tox_developmental:tox_endocrine:tox_gastrointestinal_liver:tox_immunotoxicity:tox_kidney:tox_musculoskeletal:tox_neurotoxicity:tox_reproductive:tox_respiratory:tox_skin_sense:,dateTime:string:string:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:,chemistry
1 M+ Real Time stock market data [NSE/BSE] , Dipanjan , www.kaggle.com/deeiip/1m-real-time-stock-market-data-nse , Sat Jun 24 2017 00:05:44 GMT+0530 (IST) , Real time price volume data for select Nifty 50 stocks from both NSE/BSE ,356, finance- ,Context Starting something in FinTech is the most difficult thing. You have no open data. These days I'm trying to do some algo-trading. Maybe not in true sense because it's not high frequency scalping. But anyway that's that. What? The data gives almost-Realtime data for half of the Nifty 50 stocks for last week of May and first 2 Weeks of July.  Now here is the obvious question. The dataset does not have timestamp. That's because it is collected via Web-Socket streaming as it happens. Sometimes once in a couple of seconds sometimes 10-15 times in the same span. So there is no point to timestamp IMHO. Anyway it'll be client-side timestamp so not a true timestamp.  Description  tick_data.csv contains only the price-volume data. volume total volumes traded for the day  last_price denotes the quote price for latest trade List item instrument_list.csv contains description of the underlying instrument.  P.S *All the data points are not tick-by-tick update. Rather it is mostly an update after 600 ms provided a trade happened *,instrument_token:,numeric:,stock data
Homicide Reports 1980-2014 , Murder Accountability Project , www.kaggle.com/murderaccountability/homicide-reports , Fri Feb 10 2017 22:25:29 GMT+0530 (IST) , Can you develop an algorithm to detect serial killer activity? ,7778, crime- ,Content The Murder Accountability Project is the most complete database of homicides in the United States currently available. This dataset includes murders from the FBI's Supplementary Homicide Report from 1976 to the present and Freedom of Information Act data on more than 22000 homicides that were not reported to the Justice Department. This dataset includes the age race sex ethnicity of victims and perpetrators in addition to the relationship between the victim and perpetrator and weapon used. Acknowledgements The data was compiled and made available by the Murder Accountability Project founded by Thomas Hargrove.,Record ID:Agency Code:Agency Name:Agency Type:City:State:Year:Month:Incident:Crime Type:Crime Solved:Victim Sex:Victim Age:Victim Race:Victim Ethnicity:Perpetrator Sex:Perpetrator Age:Perpetrator Race:Perpetrator Ethnicity:Relationship:Weapon:Victim Count:Perpetrator Count:Record Source:,numeric:string:string:string:string:string:numeric:string:numeric:string:string:string:numeric:string:string:string:numeric:string:string:string:string:numeric:numeric:string:,crime
All the news , Andrew Thompson , www.kaggle.com/snapcrack/all-the-news , Sun Aug 20 2017 11:28:47 GMT+0530 (IST) , 143000 articles from 15 American publications ,501, journalism- ,Context I wanted to see how articles clustered together if the articles were rendered into document-term matrices---would there be greater affinity among political affiliations or medium subject matter etc. The data was scraped using BeautifulSoup and stored in Sqlite but I've chopped it up into three separate CSVs here because the entire Sqlite database came out to about 1.2 gb beyond Kaggle's max. Content Each row contains  an id for the Sqlite database author name full date month year title publication name article url (not available for all articles) full article content  The publications include the New York Times Breitbart CNN Business Insider the Atlantic Fox News Talking Points Memo Buzzfeed News National Review New York Post the Guardian NPR Reuters Vox and the Washington Post. Sampling wasn't quite scientific; I chose publications based on my familiarity of the domain and tried to get a range of political alignments as well as a mix of print and digital publications. By count the publications break down accordingly  It's not entirely even---this was something of a collect-it-all approach and some sites are more prolific than others and some have data that maintains integrity after scraping more easily than others. For each publication I used archive.org to grab the past year-and-a-half of either home-page headlines or RSS feeds and ran those links through the scraper. That is the articles are not the product of scraping an entire site but rather their more prominently placed articles. For example CNN's articles from 5/6/16 were what appeared on the homepage of CNN.com proper not everything within the CNN.com domain. Vox's articles from 5/6/16 were everything that appeared in the Vox RSS reader. on 5/6/16 and so on. RSS readers are a breeze to scrape and so I used them when possible but not every publication uses them or makes them easy to find. The data primarily falls between the years of 2016 and July 2017 although there is a not-insignificant number of articles from 2015 and a possibly insignificant number from before then. A note there are some stray spaces between non-word characters at times as well as some other minor blemishes and imperfections here and there the result of cleaning a very messy dataset.  Acknowledgements Thanks mostly go to the maesters of Stack Overflow. ,:id:title:publication:author:date:year:month:url:content:,numeric:numeric:string:string:string:dateTime:numeric:numeric:string:string:,news
Students' Academic Performance Dataset , IbrahimAljarah , www.kaggle.com/aljarah/xAPI-Edu-Data , Sun Nov 27 2016 03:28:24 GMT+0530 (IST) , xAPI-Educational Mining Dataset ,6339, education- ,Students' Academic Performance Dataset (xAPI-Edu-Data) Data Set Characteristics Multivariate Number of Instances 480 Area E-learning Education Predictive models Educational Data Mining Attribute Characteristics Integer/Categorical  Number of Attributes 16 Date 2016-11-8 Associated Tasks Classification Missing Values? No File formats xAPI-Edu-Data.csv Source Elaf Abu Amrieh Thair Hamtini and Ibrahim Aljarah The University of Jordan Amman Jordan http//www.Ibrahimaljarah.com www.ju.edu.jo Dataset Information This is an educational data set which is collected from learning management system (LMS) called Kalboard 360. Kalboard 360 is a multi-agent LMS which has been designed to facilitate learning through the use of leading-edge technology. Such system provides users with a synchronous access to educational resources from any device with Internet connection.  The data is collected using a learner activity tracker tool which called experience API (xAPI). The xAPI is a component of the training and learning architecture (TLA) that enables to monitor learning progress and learner’s actions like reading an article or watching a training video. The experience API helps the learning activity providers to determine the learner activity and objects that describe a learning experience. The dataset consists of 480 student records and 16 features. The features are classified into three major categories (1) Demographic features such as gender and nationality. (2) Academic background features such as educational stage grade Level and section. (3) Behavioral features such as raised hand on class opening resources answering survey by parents and school satisfaction. The dataset consists of 305 males and 175 females. The students come from different origins such as 179 students are from Kuwait 172 students are from Jordan 28 students from Palestine 22 students are from Iraq 17 students from Lebanon 12 students from Tunis 11 students from Saudi Arabia 9 students from Egypt 7 students from Syria 6 students from USA Iran and Libya 4 students from Morocco and one student from Venezuela. The dataset is collected through two educational semesters 245 student records are collected during the first semester and 235 student records are collected during the second semester.  The data set includes also the school attendance feature such as the students are classified into two categories based on their absence days 191 students exceed 7 absence days and 289 students their absence days under 7. This dataset includes also a new category of features; this feature is parent parturition in the educational process. Parent participation feature have two sub features Parent Answering Survey and Parent School Satisfaction. There are 270 of the parents answered survey and 210 are not 292 of the parents are satisfied from the school and 188 are not.  (See the related papers for more details). Attributes 1 Gender - student's gender (nominal 'Male' or 'Female’)  2 Nationality- student's nationality (nominal’ Kuwait’’ Lebanon’’ Egypt’’ SaudiArabia’’ USA’’ Jordan’’  Venezuela’’ Iran’’ Tunis’’ Morocco’’ Syria’’ Palestine’’ Iraq’’ Lybia’) 3 Place of birth- student's Place of birth (nominal’ Kuwait’’ Lebanon’’ Egypt’’ SaudiArabia’’ USA’’ Jordan’’  Venezuela’’ Iran’’ Tunis’’ Morocco’’ Syria’’ Palestine’’ Iraq’’ Lybia’) 4 Educational Stages- educational level student belongs (nominal ‘lowerlevel’’MiddleSchool’’HighSchool’)  5 Grade Levels- grade student belongs (nominal ‘G-01’ ‘G-02’ ‘G-03’ ‘G-04’ ‘G-05’ ‘G-06’ ‘G-07’ ‘G-08’ ‘G-09’ ‘G-10’ ‘G-11’ ‘G-12 ‘)  6 Section ID- classroom student belongs (nominal’A’’B’’C’) 7 Topic- course topic (nominal’ English’’ Spanish’ ‘French’’ Arabic’’ IT’’ Math’’ Chemistry’ ‘Biology’ ‘Science’’ History’’ Quran’’ Geology’) 8 Semester- school year semester (nominal’ First’’ Second’) 9 Parent responsible for student (nominal’mom’’father’) 10 Raised hand- how many times the student raises his/her hand on classroom (numeric0-100) 11- Visited resources- how many times the student visits a course content(numeric0-100) 12 Viewing announcements-how many times the student checks the new announcements(numeric0-100) 13 Discussion groups- how many times the student participate on discussion groups (numeric0-100) 14 Parent Answering Survey- parent answered the surveys which are provided from school or not  (nominal’Yes’’No’) 15 Parent School Satisfaction- the Degree of parent satisfaction from school(nominal’Yes’’No’) 16 Student Absence Days-the number of absence days for each student (nominal above-7 under-7) The students are classified into three numerical intervals based on their total grade/mark Low-Level interval includes values from 0 to 69  Middle-Level interval includes values from 70 to 89  High-Level interval includes values from 90-100. Relevant Papers  Amrieh E. A. Hamtini T. & Aljarah I. (2016). Mining Educational Data to Predict Student’s academic Performance using Ensemble Methods. International Journal of Database Theory and Application 9(8) 119-136. Amrieh E. A. Hamtini T. & Aljarah I. (2015 November). Preprocessing and analyzing educational data set using X-API for improving student's performance. In Applied Electrical Engineering and Computing Technologies (AEECT) 2015 IEEE Jordan Conference on (pp. 1-5). IEEE.  Citation Request Please include these citations if you plan to use this dataset  Amrieh E. A. Hamtini T. & Aljarah I. (2016). Mining Educational Data to Predict Student’s academic Performance using Ensemble Methods. International Journal of Database Theory and Application 9(8) 119-136. Amrieh E. A. Hamtini T. & Aljarah I. (2015 November). Preprocessing and analyzing educational data set using X-API for improving student's performance. In Applied Electrical Engineering and Computing Technologies (AEECT) 2015 IEEE Jordan Conference on (pp. 1-5). IEEE. ,,,student performances
What's On The Menu? , New York Public Library , www.kaggle.com/nypl/whats-on-the-menu , Sun Nov 06 2016 03:37:10 GMT+0530 (IST) , Dataset on historical menus dishes and dish prices ,821, food and drink- ,The New York Public Library is digitizing and transcribing its collection of historical menus. The collection includes about 45000 menus from the 1840s to the present and the goal of the digitization project is to transcribe each page of each menu creating an enormous database of dishes prices locations and so on. As of early November 2016 the transcribed database contains 1332279 dishes from 17545 menus. The Data This dataset is split into four files to minimize the amount of redundant information contained in each (and thus the size of each file). The four data files are Menu MenuPage MenuItem and Dish. These four files are described briefly here and in detail in their individual file descriptions below. Menu The core element of the dataset. Each Menu has a unique identifier and associated data including data on the venue and/or event that the menu was created for; the location that the menu was used; the currency in use on the menu; and various other fields. Each menu is associated with some number of MenuPage values. MenuPage Each MenuPage refers to the Menu it comes from via the menu_id variable (corresponding to Menuid). Each MenuPage also has a unique identifier of its own. Associated MenuPage data includes the page number of this MenuPage an identifier for the scanned image of the page and the dimensions of the page. Each MenuPage is associated with some number of MenuItem values. MenuItem Each MenuItem refers to both the MenuPage it is found on -- via the menu_page_id variable -- and the Dish that it represents -- via the dish_id variable. Each MenuItem also has a unique identifier of its own. Other associated data includes the price of the item and the dates when the item was created or modified in the database. Dish A Dish is a broad category that covers some number of MenuItems. Each dish has a unique id to which it is referred by its affiliated MenuItems. Each dish also has a name a description a number of menus it appears on and both date and price ranges. Inspiration What are some things we can look at with this dataset?  How has the median price of restaurant dishes changed over time? Are there particular types of dishes (alcoholic beverages seafood breakfast food) whose price changes have been greater than or less than the average change over time? Can we predict anything about a dish's price based on its name or description?  -- There's been some work on how the words used in advertisements for potato chips are reflective of their price; is that also true of the words used in the name of the food?  -- Are for example French or Italian words more likely to predict a more expensive dish?  Acknowledgments This dataset was downloaded from the New York Public Library's What's on the menu? page. The What's on the menu? data files are updated twice monthly so expect this dataset to go through multiple versions.,,,food and nutrition
New York Stock Exchange , Dominik Gawlik , www.kaggle.com/dgawlik/nyse , Wed Feb 22 2017 15:48:25 GMT+0530 (IST) , S&P 500 companies historical prices with fundamental data ,7520, finance- ,Context This dataset is a playground for fundamental and  technical analysis. It is said that 30% of traffic on stocks is already generated by machines can trading be fully automated? If not there is still a lot to learn from historical data.     Content Dataset consists of following files  prices.csv raw as-is daily prices. Most of data spans from 2010 to the end 2016 for companies new on stock market date range is shorter. There have been approx. 140 stock splits in that time this set doesn't account for that. prices-split-adjusted.csv same as prices but there have been added adjustments for splits. securities.csv general description of each company with division on sectors fundamentals.csv metrics extracted from annual SEC 10K fillings (2012-2016) should be enough to derive most of popular fundamental indicators.  Acknowledgements Prices were fetched from Yahoo Finance fundamentals are from Nasdaq Financials extended by some fields from EDGAR SEC databases. Mining Here is couple of things one could try out with this data Technical  One day ahead prediction Rolling Linear Regression ARIMA Neural Networks LSTM Momentum/Mean-Reversion Strategies Security clustering portfolio construction/hedging  Fundamental Which company has biggest chance of being bankrupt? Which one is undervalued (how prices behaved afterwards) what is Return on Investment?,:,numeric:,stock data
Getting Real about Fake News , Megan Risdal , www.kaggle.com/mrisdal/fake-news , Sat Nov 26 2016 03:59:09 GMT+0530 (IST) , Text & metadata from fake & biased news sources around the web ,3660, news agencies- languages- politics- ,"The latest hot topic in the news is fake news and many are wondering what data scientists can do to detect it and stymie its viral spread. This dataset is only a first step in understanding and tackling this problem. It contains text and metadata scraped from 244 websites tagged as ""bullshit"" here by the BS Detector Chrome Extension by Daniel Sieradski.  Warning I did not modify the list of news sources from the BS Detector so as not to introduce my (useless) layer of bias; I'm not an authority on fake news. There may be sources whose inclusion you disagree with. It's up to you to decide how to work with the data and how you might contribute to ""improving it"". The labels of ""bs"" and ""junksci"" etc. do not constitute capital ""t"" Truth. If there are other sources you would like to include start a discussion. If there are sources you believe should not be included start a discussion or write a kernel analyzing the data. Or take the data and do something else productive with it. Kaggle's choice to host this dataset is not meant to express any particular political affiliation or intent. Contents The dataset contains text and metadata from 244 websites and represents 12999 posts in total from the past 30 days. The data was pulled using the webhose.io API; because it's coming from their crawler not all websites identified by the BS Detector are present in this dataset. Each website was labeled according to the BS Detector as documented here. Data sources that were missing a label were simply assigned a label of ""bs"". There are (ostensibly) no genuine reliable or trustworthy news sources represented in this dataset (so far) so don't trust anything you read. Fake news in the news For inspiration I've included some (presumably non-fake) recent stories covering fake news in the news. This is a sensitive nuanced topic and if there are other resources you'd like to see included here please leave a suggestion. From defining fake biased and misleading news in the first place to deciding how to take action (a blacklist is not a good answer) there's a lot of information to consider beyond what can be neatly arranged in a CSV file.  How Fake News Spreads (NYT) We Tracked Down A Fake-News Creator In The Suburbs. Here's What We Learned (NPR) Does Facebook Generate Over Half of its Revenue from Fake News? (Forbes) Fake News is Not the Only Problem (Points - Medium) Washington Post Disgracefully Promotes a McCarthyite Blacklist From a New Hidden and Very Shady Group (The Intercept)  Improvements If you have suggestions for improvements or would like to contribute please let me know. The most obvious extensions are to include data from ""real"" news sites and to address the bias in the current list. I'd be happy to include any contributions in future versions of the dataset. Acknowledgements Thanks to Anthony for pointing me to Daniel Sieradski's BS Detector. Thank you to Daniel Nouri for encouraging me to add a disclaimer to the dataset's page.",ord_in_thread:author:published:title:text:language:crawled:site_url:country:domain_rank:thread_title:spam_score:main_img_url:replies_count:participants_count:likes:comments:shares:type:uuid:,numeric:string:dateTime:string:string:string:dateTime:string:string:numeric:string:numeric:string:numeric:numeric:numeric:numeric:numeric:string:string:,news
World of Warcraft Avatar History , Myles O'Neill , www.kaggle.com/mylesoneill/warcraft-avatar-history , Tue Jun 14 2016 14:40:17 GMT+0530 (IST) , Track the players of this popular online game ,1520, video games- games- ,"Overview The World of Warcraft Avatar History Dataset is a collection of records that detail information about player characters in the game over time. It includes information about their character level race class location and social guild. The Kaggle version of this dataset includes only the information from 2008 (and the dataset in general only includes information from the 'Horde' faction of players in the game from a single game server).  Full Dataset Source and Information http//mmnet.iis.sinica.edu.tw/dl/wowah/  Code used to clean the data https//github.com/myles-oneill/WoWAH-parser   Ideas for Using the Dataset From the perspective of game system designers players' behavior is one of the most important factors they must consider when designing game systems. To gain a fundamental understanding of the game play behavior of online gamers exploring users' game play time provides a good starting point. This is because the concept of game play time is applicable to all genres of games and it enables us to model the system workload as well as the impact of system and network QoS on users' behavior. It can even help us predict players' loyalty to specific games. Open Questions  Understand user gameplay behavior (game sessions movement leveling) Understand user interactions (guilds) Predict players unsubscribing from the game based on activity What are the most popular zones in WoW what level players tend to inhabit each?  Wrath of the Lich King An expansion to World of Warcraft ""Wrath of the Lich King"" (Wotlk) was released on November 13 2008. It introduced new zones for players to go to a new character class (the death knight) and a new level cap of 80 (up from 70 previously). This event intersects nicely with the dataset and is probably interesting to investigate. Map This dataset doesn't include a shapefile (if you know of one that exists let me know!) to show where the zones the dataset talks about are. Here is a list of zones an information from this version of the game including their recommended levels http//wowwiki.wikia.com/wiki/Zones_by_level_(original) .  Update (Version 3) dmi3kno has generously put together some supplementary zone information files which have now been included in this dataset. Some notes about the files Note that some zone names contain Chinese characters. Unicode names are preserved as a key to the original dataset. What this addition will allow is to understand properties of the zones a bit better - their relative location to each other competititive properties type of gameplay and hopefully their contribution to character leveling. Location coordinates contain some redundant (and possibly duplicate) records as they are collected from different sources. Working with uncleaned location coordinate data will allow users to demonstrate their data wrangling skills (both working with strings and spatial data).",Location_Name:Map_ID:X_coord:Y_coord:Z_coord:,string:numeric:numeric:numeric:numeric:,video games
NBA shot logs , DanB , www.kaggle.com/dansbecker/nba-shot-logs , Thu Aug 18 2016 10:46:10 GMT+0530 (IST) , Moneyball data for basketball. ,4878, basketball- sports- ,Data on shots taken during the 2014-2015 season who took the shot where on the floor was the shot taken from who was the nearest defender how far away was the nearest defender time on the shot clock and much more.  The column titles are generally self-explanatory. Useful for evaluating who the best shooter is who the best defender is the hot-hand hypothesis etc. Scraped from NBA's REST API.,GAME_ID:MATCHUP:LOCATION:FINAL_MARGIN:SHOT_NUMBER:PERIOD:GAME_CLOCK:SHOT_CLOCK:DRIBBLES:TOUCH_TIME:SHOT_DIST:PTS_TYPE:SHOT_RESULT:CLOSEST_DEFENDER:CLOSEST_DEFENDER_PLAYER_ID:CLOSE_DEF_DIST:FGM:PTS:player_name:player_id:W:,numeric:string:string:numeric:numeric:numeric:dateTime:numeric:numeric:numeric:numeric:numeric:string:string:numeric:numeric:numeric:numeric:string:numeric:string:,sports events
Facebook V Results: Predicting Check Ins , Facebook , www.kaggle.com/facebook/facebook-v-results , Wed Aug 03 2016 12:43:40 GMT+0530 (IST) , The competition solution along with each top teams' final submission ,950, geography- internet- ,This dataset contains the solution and the top 20 team's submissions for Facebook's 5th recruiting competition on predicting checkin places. Here's how an ensemble model leveraging the top results would have performed in the competition ,,,
SpaceX Missions 2006-Present , SpaceX , www.kaggle.com/spacex/spacex-missions , Wed Mar 01 2017 07:14:23 GMT+0530 (IST) , Location date/time and outcome for every rocket launch ,580, space- business- ,Context SpaceX has gained worldwide attention for a series of historic milestones. It is the only private company ever to return a spacecraft from low-Earth orbit which it first accomplished in December 2010. The company made history again in May 2012 when its Dragon spacecraft attached to the International Space Station exchanged cargo payloads and returned safely to Earth — a technically challenging feat previously accomplished only by governments. Since then Dragon has delivered cargo to and from the space station multiple times providing regular cargo resupply missions for NASA. Under a $1.6 billion contract with NASA SpaceX is flying numerous cargo resupply missions to the International Space Station for a total of at least 20 flights under the Commercial Resupply Services contract. In 2016 NASA awarded SpaceX a second version of that contract that will cover a minimum of 6 additional flights from 2019 onward. In the near future SpaceX will carry crew as part of NASA’s Commercial Crew Program as well. Dragon was designed from the outset to carry astronauts and SpaceX is in the process of upgrading Dragon to make it crew-ready. SpaceX is the world’s fastest-growing provider of launch services and has over 70 future missions on its manifest representing over $10 billion in contracts. These include commercial satellite launches as well as NASA and other US Government missions. Content This dataset includes a record for each payload carried during a SpaceX mission into outer space. Acknowledgements The data was scraped from the SpaceX and NASA website. Inspiration Has the rate of SpaceX rocket launches increased in the past decade? How many missions do you predict will be launched in 2018?,Flight Number:Launch Date:Launch Time:Launch Site:Vehicle Type:Payload Name:Payload Type:Payload Mass (kg):Payload Orbit:Customer Name:Customer Type:Customer Country:Mission Outcome:Failure Reason:Landing Type:Landing Outcome:,string:dateTime:dateTime:string:string:string:string:numeric:string:string:string:string:string:string:string:string:,astronomy
2016 NYC Real Time Traffic Speed Data Feed , Chris Cross , www.kaggle.com/crailtap/nyc-real-time-traffic-speed-data-feed , Fri Jul 21 2017 02:22:51 GMT+0530 (IST) , Five minute intervals 'real-time' traffic information within the five boroughs ,235, ,Context This data contains 'real-time' traffic information from locations where NYCDOT picks up sensor feeds within the five boroughs of NYC mostly on major arterials and highways.  NYCDOT uses this information for emergency response and management see Acknowledgements. Content NYC Real Time Traffic Speed Data Feed for the year 2016 separated in monthly files of 5 minutes intervals of 'real-time' traffic information within the five boroughs of NYC. Each row represents a given street section (link) for which the average speed travel time timestamp and an id of the street section (link) is given. For each link id information about this link is given in the linkinfo.csv file e.g. geo coordinates. Acknowledgements http//data.beta.nyc/dataset/nyc-real-time-traffic-speed-data-feed-archived https//data.cityofnewyork.us/Transportation/Real-Time-Traffic-Speed-Data/xsat-x5sa,Id:Speed:TravelTime:Status:DataAsOf:linkId:,numeric:numeric:numeric:numeric:dateTime:numeric:,traffic 
Indian Liver Patient Records , UCI Machine Learning , www.kaggle.com/uciml/indian-liver-patient-records , Wed Sep 20 2017 22:18:58 GMT+0530 (IST) , Patient records collected from North East of Andhra Pradesh India ,176, human medicine- health sciences- health- medicine- ,"Context Patients with Liver disease have been continuously increasing because of excessive consumption of alcohol inhale of harmful gases intake of contaminated food pickles and drugs. This dataset was used to evaluate prediction algorithms in an effort to  reduce burden on doctors.  Content This data set contains 416 liver patient records and 167 non liver patient records collected from North East of Andhra Pradesh India.  The ""Dataset"" column is a class label used to divide groups into liver patient (liver disease) or not (no disease). This data set contains 441 male patient records and 142 female patient records.  Any patient whose age exceeded 89 is listed as being of age ""90"". Columns  Age of the patient  Gender of the patient  Total Bilirubin  Direct Bilirubin  Alkaline Phosphotase  Alamine Aminotransferase  Aspartate Aminotransferase  Total Protiens  Albumin  Albumin and Globulin Ratio  Dataset field used to split the data into two sets (patient with liver disease or no disease)  Acknowledgements This dataset was downloaded from the UCI ML Repository Lichman M. (2013). UCI Machine Learning Repository [http//archive.ics.uci.edu/ml]. Irvine CA University of California School of Information and Computer Science. Inspiration Use these patient records to determine which patients have liver disease and which ones do not. ",Age:Gender:Total_Bilirubin:Direct_Bilirubin:Alkaline_Phosphotase:Alamine_Aminotransferase:Aspartate_Aminotransferase:Total_Protiens:Albumin:Albumin_and_Globulin_Ratio:Dataset:,numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,diagnostics
Hearthstone Cards , Jerad Rose , www.kaggle.com/jeradrose/hearthstone-cards , Wed Jan 04 2017 23:10:32 GMT+0530 (IST) , Explore the entire collection of Hearthstone cards ,1004, video games- games- ,This dataset contains data for the entire collection of cards for Hearthstone the popular online card game by Blizzard. Launching to the public on March 11 2011 after being under development for almost 5 years Hearthstone has gained popularity as a freemium game launching into eSports across the globe and the source of many Twitch channels. The data in this dataset was extracted from hearthstonejson.com and the documentation for all the data can be found on the cards.json documentation page. The original data was extracted from the actual card data files used in the game so all of the data should be here enabling explorations like  Card strengths and weaknesses Card strengths relative to cost and rarity Comparisons across player classes bosses and sets Whether a set of optimal cards can be determined per class  The cards can be explored in one of four ways  cards.json The raw JSON pulled from hearthstonejson.com cards_flat.csv A flat CSV containing a row for each card and any nm data stored as arrays in single fields database.sqlite A SQLite database containing relational data of the cards cards.csv mechanics.csv dust_costs.csv play_requirements.csv and entourages.csv the normalized data in CSV format.  This dataset will be updated as new releases and expansions are made to Hearthstone. Currently any localized string values are in en-us but I may look into adding other languages if the demand seems to be there.,card_id:,string:,video games
Chicago Taxi Rides 2016 , City of Chicago , www.kaggle.com/chicago/chicago-taxi-rides-2016 , Thu Jul 06 2017 23:38:58 GMT+0530 (IST) , Details of taxi rides in Chicago ,1745, road transport- ,Context This dataset includes taxi trips for 2016 reported to the City of Chicago in its role as a regulatory agency. To protect privacy but allow for aggregate analyses the Taxi ID is consistent for any given taxi medallion number but does not show the number Census Tracts are suppressed in some cases and times are rounded to the nearest 15 minutes. Due to the data reporting process not all trips are reported but the City believes that most are. See http//digital.cityofchicago.org/index.php/chicago-taxi-data-released for more information about this dataset and how it was created. Content Please see the data dictionary for details of specific fields. We also shrunk the original files by roughly two thirds by dropping redundant columns and remapping several others to use shorter IDs. For example the taxi_id column used to be a 128 character string. We’ve replaced it with an integer containing at most four digits. The redundant columns were unique_key pickup_location and dropoff_location. The remapped columns were taxi_id company pickup_census_tract dropoff_census_tract pickup_latitude pickup_longitude dropoff_latitude and dropoff_longitude. The original versions of those columns can be unpacked using the column_remapping.json. Acknowledgements This dataset was kindly made publically available by the City of Chicago at https//data.cityofchicago.org/Transportation/Taxi-Trips/wrvz-psew Please note that this site provides applications using data that has been modified for use from its original source www.cityofchicago.org the official website of the City of Chicago.  The City of Chicago makes no claims as to the content accuracy timeliness or completeness of any of the data provided at this site.  The data provided at this site is subject to change at any time.  It is understood that the data provided at this site is being used at one’s own risk. Inspiration  How centralized is Chicago? In other words what portion of trips are to or from downtown? Chicago has an extensive metro system. Are taxis competing with the trains by covering similar routes or supplementing public transit by getting people to and from train stations?  Use this dataset with BigQuery You can use Kernels to analyze share and discuss this data on Kaggle but if you’re looking for real-time updates and bigger data check out the data on BigQuery too https//cloud.google.com/bigquery/public-data/chicago-taxi. BigQuery hosts the full version of this dataset which extends from 2013 through the present.,taxi_id:trip_start_timestamp:trip_end_timestamp:trip_seconds:trip_miles:pickup_census_tract:dropoff_census_tract:pickup_community_area:dropoff_community_area:fare:tips:tolls:extras:trip_total:payment_type:company:pickup_latitude:pickup_longitude:dropoff_latitude:dropoff_longitude:,numeric:dateTime:dateTime:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:,roadways
Diamonds , shivamagrawal , www.kaggle.com/shivam2503/diamonds , Thu May 25 2017 08:36:57 GMT+0530 (IST) , Analyze diamonds by their cut color clarity price and other attributes ,881, clothing- finance- ,Context This classic dataset contains the prices and other attributes of almost 54000 diamonds. It's a great dataset for beginners learning to work with data analysis and visualization. Content price price in US dollars (\$326--\$18823) carat weight of the diamond (0.2--5.01) cut quality of the cut (Fair Good Very Good Premium Ideal) color diamond colour from J (worst) to D (best) clarity a measurement of how clear the diamond is (I1 (worst) SI2 SI1 VS2 VS1 VVS2 VVS1 IF (best)) x length in mm (0--10.74) y width in mm (0--58.9) z depth in mm (0--31.8) depth total depth percentage = z / mean(x y) = 2 * z / (x + y) (43--79) table width of top of diamond relative to widest point (43--95),:carat:cut:color:clarity:depth:table:price:x:y:z:,numeric:numeric:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:,trade and business
The Complete Pokemon Dataset , Rounak Banik , www.kaggle.com/rounakbanik/pokemon , Sat Sep 30 2017 01:19:32 GMT+0530 (IST) , Data on more than 800 Pokemon from all 7 Generations. ,517, popular culture- video games- data analysis- ,Context This dataset contains information on all 802 Pokemon from all Seven Generations of Pokemon. The information contained in this dataset include Base Stats Performance against Other Types Height Weight Classification Egg Steps Experience Points Abilities etc. The information was scraped from http//serebii.net/ Content  name The English name of the Pokemon japanese_name The Original Japanese name of the Pokemon pokedex_number The entry number of the Pokemon in the National Pokedex percentage_male The percentage of the species that are male. Blank if the Pokemon is genderless. type1 The Primary Type of the Pokemon type2 The Secondary Type of the Pokemon classification The Classification of the Pokemon as described by the Sun and Moon Pokedex height_m Height of the Pokemon in metres weight_kg The Weight of the Pokemon in kilograms capture_rate Capture Rate of the Pokemon base_egg_steps The number of steps required to hatch an egg of the Pokemon abilities A stringified list of abilities that the Pokemon is capable of having experience_growth The Experience Growth of the Pokemon base_happiness Base Happiness of the Pokemon against_? Eighteen features that denote the amount of damage taken against an attack of a particular type hp The Base HP of the Pokemon attack The Base Attack of the Pokemon defense The Base Defense of the Pokemon sp_attack The Base Special Attack of the Pokemon sp_defense The Base Special Defense of the Pokemon speed The Base Speed of the Pokemon generation The numbered generation which the Pokemon was first introduced is_legendary Denotes if the Pokemon is legendary.  Acknowledgements The data was scraped from http//serebii.net/. Inspiration Pokemon holds a very special place in my heart as it is probably the only video game I have judiciously followed for more than 10 years. With this dataset I wanted to be able to answer the following questions  Is it possible to build a classifier to identify legendary Pokemon? How does height and weight of a Pokemon correlate with its various base stats? What factors influence the Experience Growth and Egg Steps? Are these quantities correlated? Which type is the strongest overall? Which is the weakest? Which type is the most likely to be a legendary Pokemon? Can you build a Pokemon dream team? A team of 6 Pokemon that inflicts the most damage while remaining relatively impervious to any other team of 6 Pokemon. ,abilities:against_bug:against_dark:against_dragon:against_electric:against_fairy:against_fight:against_fire:against_flying:against_ghost:against_grass:against_ground:against_ice:against_normal:against_poison:against_psychic:against_rock:against_steel:against_water:attack:base_egg_steps:base_happiness:base_total:capture_rate:classfication:defense:experience_growth:height_m:hp:japanese_name:name:percentage_male:pokedex_number:sp_attack:sp_defense:speed:type1:type2:weight_kg:generation:is_legendary:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:string:string:numeric:numeric:numeric:,video games
Chicago Restaurant Inspections , City of Chicago , www.kaggle.com/chicago/chi-restaurant-inspections , Wed Aug 30 2017 22:18:29 GMT+0530 (IST) , ~154k Rows of Inspections Data ,161, food and drink- ,Context Restaurant inspections ensure that food served to the public at licensed food establishments follows food safety guidelines. The Food Protection Division of the Chicago Department of Public Health (CDPH) is committed to maintaining the safety of food bought sold or prepared for public consumption in Chicago by carrying out science-based inspections of all retail food establishments. These inspections promote public health in areas of food safety and sanitation and prevent the occurrence of food-borne illness. CDPH's licensed accredited sanitarians inspect retail food establishments such as restaurants grocery stores bakeries convenience stores hospitals nursing homes day care facilities shelters schools and temporary food service events. Inspections focus on food handling practices product temperatures personal hygiene facility maintenance and pest control. All restaurants are subject to certain recurring inspections. Each year a restaurant is subject to annual inspections to ensure continued compliance with City ordinances and regulations. In addition to recurring inspections restaurants may also be inspected in response to a complaint. Some of these recurring inspections such as the inspection by the Buildings Department will be scheduled while others will not. Generally inspections are conducted by the Health Department for sanitation and safe food handling practices the Buildings Department to ensure the safety of the structure and the Fire Department to ensure safe fire exits.The City's Dumpster Task Force a collaborative effort between the Health Department and Streets and Sanitation Department also inspects restaurants to ensure compliance with sanitation regulations. Content Data includes inspection date results violations noted business name and lat/lon license# and risk. Data covers 01/02/2013-08/28/17. Acknowledgements Data was collected by City of Chicago Department of Health. Inspiration  Can you predict restaurant closings?  Do restaurants in certain neighborhoods gather more/less violations? Any seasonal or time anomalies in the data? ,Inspection ID:DBA Name:AKA Name:License #:Facility Type:Risk:Address:City:State:Zip:Inspection Date:Inspection Type:Results:Violations:Latitude:Longitude:Location:,numeric:string:string:numeric:string:string:string:string:string:numeric:dateTime:string:string:string:numeric:numeric:string:,food and nutrition
A Year of Pumpkin Prices , US Department of Agriculture , www.kaggle.com/usda/a-year-of-pumpkin-prices , Thu Oct 12 2017 02:44:47 GMT+0530 (IST) , Pumpkin Prices in 13 US Cities: 2016-2017 ,198, food and drink- united states- finance- agriculture- ,Context Over 1.5 billions pounds of pumpkin are grown annually in the United States. Where are they sold and for how much? This dataset contains prices for which pumpkins were sold at selected U.S. cities’ terminal markets. Prices are differentiated by the commodities’ growing origin variety size package and grade. Content This dataset contains terminal market prices for different pumpkin crops in 13 cities in the United States from September 24 2016 to September 30 2017. In keeping with the structure of the original source data information on each city has been uploaded as a separate file.  Atlanta GA Baltimore MD Boston MA Chicago IL Columbia SC Dallas TX Detroit MI Los Angeles CA Miami FL New York NY Philadelphia PA San Francisco CA Saint Louis MO  Data for each city includes the following columns (although not all information is available for every city)   Commodity Name Always pumpkin since this is a pumpkin-only dataset City Name City where the pumpkin was sold Type Package Variety Sub Variety Grade In the US usually only canned pumpkin is graded Date Date of sale (rounded up to the nearest Saturday) Low Price High Price Mostly Low Mostly High Origin Where the pumpkins were grown Origin District Item Size Color Environment Unit of Sale Quality Condition Appearance Storage Crop Repack Whether the pumpkin has been repackaged before sale Trans Mode  Acknowledgements This dataset is based on Specialty Crops Terminal Markets Standard Reports distributed by the United States Department of Agriculture. Up-to-date reports can be generated here. This data is in the public domain. Inspiration  Which states produce the most pumpkin? Where are pumpkin prices highest? How does pumpkin size relate to price? Which pumpkin variety is the most expensive? Least expensive? ,Commodity Name:City Name:Type:Package:Variety:Sub Variety:Grade:Date:Low Price:High Price:Mostly Low:Mostly High:Origin:Origin District:Item Size:Color:Environment:Unit of Sale:Quality:Condition:Appearance:Storage:Crop:Repack:Trans Mode:,string:string:string:string:string:string:string:dateTime:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:,commodity prices
Cancer Inhibitors , Kelvin Xiao , www.kaggle.com/xiaotawkaggle/inhibitors , Fri Oct 28 2016 16:37:57 GMT+0530 (IST) , Predict small molecules' activity targeting  protein kinase ,1595, human medicine- ,"Outline It was reported that an estimated 4292000 new cancer cases and 2814000 cancer deaths would occur in China in 2015. Chen W. etc. (2016) Cancer statistics in China 2015. Small molecules play an non-trivial role in cancer chemotherapy. Here I focus on inhibitors of 8 protein kinases(name abbr)  Cyclin-dependent kinase 2 cdk2 Epidermal growth factor receptor erbB1 egfr_erbB1 Glycogen synthase kinase-3 beta gsk3b Hepatocyte growth factor receptor hgfr MAP kinase p38 alpha map_k_p38a Tyrosine-protein kinase LCK tpk_lck Tyrosine-protein kinase SRC tpk_src Vascular endothelial growth factor receptor 2 vegfr2  For each protein kinase several thousand inhibitors are collected  from chembl database in which molecules with IC50 lower than 10 uM are usually considered as inhibitors otherwise non-inhibitors. Challenge Based on those labeled molecules build your model and try to make the right prediction. Additionally  more than 70000 small molecules are generated from pubchem database. And you can screen these molecules to find out potential inhibitors. P.S. the majority of these molecules are non-inhibitors. DataSets(hdf5 version) There are 8 protein kinase files and 1 pubchem negative samples file. Taking ""cdk2.h5"" as an example import h5py from scipy import sparse hf = h5py.File(""../input/cdk2.h5"" ""r"") ids = hf[""chembl_id""].value # the name of each molecules ap = sparse.csr_matrix((hf[""ap""][""data""] hf[""ap""][""indices""] hf[""ap""][""indptr""]) shape=[len(hf[""ap""][""indptr""]) - 1 2039]) mg = sparse.csr_matrix((hf[""mg""][""data""] hf[""mg""][""indices""] hf[""mg""][""indptr""]) shape=[len(hf[""mg""][""indptr""]) - 1 2039]) tt = sparse.csr_matrix((hf[""tt""][""data""] hf[""tt""][""indices""] hf[""tt""][""indptr""]) shape=[len(hf[""tt""][""indptr""]) - 1 2039]) features = sparse.hstack([ap mg tt]).toarray() # the samples' features each row is a sample and each sample has 3*2039 features labels = hf[""label""].value # the label of each molecule ",Cyclin-dependent kinase 2: cdk2:,string:string:,genomics
Canada National Justice Survey 2016 , Aleksey Bilogur , www.kaggle.com/residentmario/national-justice-survey-2016 , Wed Oct 11 2017 01:16:38 GMT+0530 (IST) , Canadian government justice system survey results ,39, government agencies- crime- politics- ,"Context This dataset is the anonymized result of responses submitted to a survey collected by the Canadian Department of Justice in 2016.  This survey ""...focuses on the criminal justice system (CJS) to inform the current criminal justice system review...[this] involved a traditional public opinion research survey in informed choice survey and in person and online focus groups...this work was undertaken to support reforms and new initiatives in this area."" This dataset is the survey component of this review. Content Respondents were asked over 50 questions on their perception of how the Canadian Justice system works at large. This dataset was published in a typical survey output format in that most questions are 1-10 rating scales or 0-1 True/False questions with some free-text responses intermixed. To understand the fields please see the attached data dictionary or otherwise access it here. Acknowledgements This data was published as-is by the Government of Canada here. It is licensed under the Open Government License - Canada. Inspiration In a time of increasingly invective dialogue between police forces and the people they police this dataset provides a window on the general level of satisfaction and concern that Canadian government citizens have with their country's justice systems. These results are mostly generalizable to the developed world as a whole.",SUR_ID:SUR_CPO:SUR_PANEL:DEMO_S1AGE1:QCOMM:QRECRUIT:DEMO_S1PT:DEMO_S1GND:DEMO_S1AGE:S1Q1:S1Q2:S1Q3_1:S1Q3_2:S1Q3_3:S1Q3_4:S1Q3_5:S1Q3_6:S1Q3_7:S1Q3_8:S1Q3_9:S1Q3_10:S1Q5_1:S1Q5_2:S1Q5_3:S1Q5_4:S1Q5_5:S1Q5_6:S1Q5_7:S1Q5_8:S1Q5_9:S1Q5_10:S1Q5_11:S1Q6_1:S1Q6_2:S1Q6_3:S1Q6_4:S1Q6_5:S1Q6_6:S1Q6_7:S1Q6_8:S1Q6_9:S1Q6_10:S1Q8_1:S1Q8_2:S1Q8_3:S1Q8_4:S1Q8_5:S1Q8_6:S1Q8_7:S1Q8_8:S1Q8_9:S1Q8_10:S1Q8_11:S1Q9_1:S1Q9_2:S1Q9_3:S1Q9_4:S1Q9_5:DEMO_S1EDU:DEMO_S1INC:DEMO_S1EMPL:DEMO_S1CAN:DEMO_S1LOC:SUR_S1:SUR_WGT1:S2Q1_1:S2Q1_2:S2Q1_3:S2Q1_4:S2Q2:S2Q3:S2Q4A_1:S2Q4A_2:S2Q8:S2Q9:S2Q10:S2Q11:S2Q12A:S2Q12B:S2Q13:S2Q16_1:S2Q16_2:S2Q16_3:S2Q17_1:S2Q17_2:S2Q17_3:S2Q18_1:S2Q18_2:S2Q20_1:S2Q20_2:S2Q20_3:S2Q20_4:S2Q21_1:S2Q21_2:S2Q21_3:S2Q21_4:S2Q22A:S2Q22B:S2Q22C:S2Q23_1:S2Q23_2:S2Q23_3:S2Q23_4:S2Q23_5:S2Q23_6:S2Q23_7:S2Q24:S2Q25:S2Q27A:S2Q27B:S2Q27C:S2Q28A:S2Q28B:S2Q28C:DEMO_S2EDU:DEMO_S2INC:DEMO_S2EMPL:DEMO_S2CAN:DEMO_S2LOC:W2PRESTRATE:w2age:SUR_S2:SUR_WGT2:SUR_MODE:S1Q4_OTH:S1Q7_OTH:S1Q11_OTH:CONTACT_OTH:CONTACT_9:CONTACT_1:CONTACT_2:CONTACT_3:CONTACT_4:CONTACT_5:CONTACT_6:CONTACT_7:CONTACT_8:CONTACT_10:CONTACT_11:CONTACT_0:CONTACT_16:CONTACT_15:S2Q4COMM:S2Q5_OTH:S2Q6_OTH:S2Q7COMM:S2Q14_OTH:S2Q14COMM:S2Q15_OTH:S2Q22_OTH:S2Q19COMM:S2Q25_INFO:S2Q26_COMM:S2Q28_OTH:CONTACT_17:CONTACT_12:CONTACT_13:CONTACT_14:CONTACT:DEMO_S1RECRUIT:DEMO_S1VIMI5:DEMO_S1VIMI1:DEMO_S1VIMI2:DEMO_S1VIMI3:DEMO_S1VIMI4:DEMO_S2VIMI5:DEMO_S2VIMI1:DEMO_S2VIMI2:DEMO_S2VIMI3:DEMO_S2VIMI4:PRIVACY1:PRIVACY2:PRIVACY3:PRIVACY4:PRIVACY5:PRIVACY6:PRIVACY7:PRIVACY8:S1Q9A_1:S1Q9A_2:S1Q9A_3:S1Q9A_4:S1Q9A_5:CONF_AD:CONF_YO:CONF_AD1:CONF_YO1:CONF_AD2:CONF_YO2:S1Q3A_1:S1Q3A_2:S1Q3A_3:S1Q3A_4:S1Q3A_5:S1Q3A_6:S1Q3A_7:S1Q3A_8:S1Q3A_9:S1Q3A_10:S1Q3B_1:S1Q3B_2:S1Q3B_3:S1Q3B_4:S1Q3B_5:S1Q3B_6:S1Q3B_7:S1Q3B_8:S1Q3B_9:S1Q3B_10:S1Q5A_1:S1Q5A_2:S1Q5A_3:S1Q5A_4:S1Q5A_5:S1Q5A_6:S1Q5A_7:S1Q5A_8:S1Q5A_9:S1Q5A_10:S1Q5A_11:S1Q5B_1:S1Q5B_2:S1Q5B_3:S1Q5B_4:S1Q5B_5:S1Q5B_6:S1Q5B_7:S1Q5B_8:S1Q5B_9:S1Q5B_10:S1Q5B_11:S1Q6A_1:S1Q6A_2:S1Q6A_3:S1Q6A_4:S1Q6A_5:S1Q6A_6:S1Q6A_7:S1Q6A_8:S1Q6A_9:S1Q6A_10:S1Q6B_1:S1Q6B_2:S1Q6B_3:S1Q6B_4:S1Q6B_5:S1Q6B_6:S1Q6B_7:S1Q6B_8:S1Q6B_9:S1Q6B_10:S1Q8A_1:S1Q8A_2:S1Q8A_3:S1Q8A_4:S1Q8A_5:S1Q8A_6:S1Q8A_7:S1Q8A_8:S1Q8A_9:S1Q8A_10:S1Q8A_11:S1Q8B_1:S1Q8B_2:S1Q8B_3:S1Q8B_4:S1Q8B_5:S1Q8B_6:S1Q8B_7:S1Q8B_8:S1Q8B_9:S1Q8B_10:S1Q8B_11:S1Q11_1:S1Q11_2:S1Q11_3:S1Q11_4:S1Q11_5:S1Q11_6:S1Q11_7:S1Q11_8:S1Q11_9:S1Q11_10:S1Q11_11:S1Q11_12:S1Q11_13:S1Q11_14:S1Q11_15:S1Q11_16:S1Q11_17:S1Q11_18:S1Q11_19:S1Q12_1:S1Q12_2:S1Q12_3:S1Q12_4:S1Q12_5:S1Q12_6:S1Q12_7:S1Q12_8:S1Q12_9:S1Q12_10:S1Q12_12:S1Q12_13:S1Q12_14:S1Q12_15:S1Q12_16:S1Q12_17:S1Q12_18:S1Q12_19:S1Q12_20:S1Q12_21:S1Q12_22:S1Q12_23:S1Q12_24:S1Q12_25:S1Q12_26:S1Q12_29:S1Q12_30:S1Q12_31:S1Q12_32:S1Q12_33:S1Q12_34:S1Q12_35:S1Q12_36:S1Q12_37:S1Q12_38:S2Q1_B1:S2Q1_B2:S2Q1_B3:S2Q1_B4:S2Q1_A1:S2Q1_A2:S2Q1_A3:S2Q1_A4:S2Q2B:S2Q2A:S2Q3A:S2Q4A_A1:S2Q4B_A1:S2Q5_1:S2Q5_2:S2Q5_3:S2Q5_4:S2Q5_5:S2Q5_6:S2Q5_7:S2Q5_9:S2Q6_1:S2Q6_2:S2Q6_3:S2Q6_4:S2Q6_5:S2Q6_6:S2Q6_7:S2Q6_8:S2Q6_9:S2Q8A:S2Q9A:S2Q10A:S2Q11A:S2Q13A:S2Q12A_2:S2Q12A_1:S2Q12B_2:S2Q12B_1:S2Q14:S2Q14_1:S2Q14_2:S2Q14_3:S2Q14_4:S2Q14_5:S2Q14_6:S2Q14_7:S2Q15A:S2Q15B:S2Q15C:S2Q16A_1:S2Q16B_1:S2Q16B_2:S2Q16A_2:S2Q16B_3:S2Q16A_3:S2Q18A_1:S2Q18B_1:S2Q18A_2:S2Q18B_2:S2Q20A_1:S2Q20A_2:S2Q20A_3:S2Q20A_4:S2Q20B_1:S2Q20B_2:S2Q20B_3:S2Q20B_4:S2Q21A_1:S2Q21A_2:S2Q21A_3:S2Q21A_4:S2Q21B_1:S2Q21B_2:S2Q21B_3:S2Q21B_4:S2Q22_10:S2Q22_1:S2Q22_2:S2Q22_3:S2Q22_4:S2Q22_5:S2Q22_6:S2Q22_7:S2Q22_8:S2Q22_9:S2Q23A_1:S2Q23A_2:S2Q23A_3:S2Q23A_4:S2Q23A_5:S2Q23A_6:S2Q23A_7:S2Q24_1:S2Q25_1:S2Q24_2:S2Q25_2:S2Q27_1:S2Q27_2:S2Q27_3:S2Q27_4:S2Q27_5:S2Q27_6:S2Q27_7:S2Q27_8:S2Q27_9:S2Q27_10:S2Q28_1:S2Q28_2:S2Q28_3:S2Q28_4:S2Q28_5:S2Q28_6:S2Q28_7:S2Q28_8:S2Q28_9:S2Q28_10:S2Q28_11:S1Q1A:S1Q2A:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,politics
Data Stories of US Airlines 1987-2008 , Prajit Datta , www.kaggle.com/prajitdatta/data-stories-of-us-airlines , Sun Mar 12 2017 00:42:00 GMT+0530 (IST) , Fight arrival and departure details for all commercial flights ,306, aviation- ,About the Data The data used in this project is real and is based on the collection of over 20 years. The total number of record in this dataset is roughly around 120 million rows and the size of the data is approximately 12GB. The data consists of flight arrival and departure details for all commercial flights within the USA from October 1987 to April 2008. This is a large dataset. There are around 29 attributes. How to get the data? The data originally comes from http//stat-computing.org/dataexpo/2009/the-data.html You can download the data for each year by clicking the appropriate link in the above website (Remember the size is going to be more than 12GB). (i) Problem Statement (a)    Check the skewness of Distance travelled by airlines. (b) Calculate the mean median and quantiles of the distance travelled by US Airlines (US).  (c) Check the standard deviation of distance travelled by American Airlines (AA). (d) Draw a boxplot of  UniqueCarrier with Distance. (e) Draw the direction of relationship between ArrDelay and DepDelay by drawing a scatterplot. (ii) Problem Statement (a) What is the probability that a flight which is landing/taking off is “WN” Airlines (marginal probability) (b) What is the probability that a flight which is landing/taking off is either “WN” or “AA” Airlines (disjoint events) (c) What is the joint probability that a flight is both “WN” and travels less than 600 miles (joint probability) (d) What is the conditional probability that the flight travels less than 2500 miles given that the flight is “AA” Airlines (conditional probability) (e) What is the joint probability of a flight getting cancelled and is supposed to travel less than 2500 miles given that the flight is “AA” Airlines                                                (joint + conditional probability) (iii) Problem Statement (a) Suppose arrival delays of flights belonging to “AA” are normally distributed with mean 15 minutes and standard deviation 3 minutes. If the “AA” plans to announce a scheme where it will give 50% cash back if their flights are delayed by 20 minutes how much percentage of the trips “AA” is supposed to loose this money. (Hint pnorm) (b) Assume that 65% of flights are diverted due to bad weather through the Weather System. What is the probability that in a random sample of 10 flights 6 are diverted through the Weather System. (Hint dbinorm) (c) Do linear regression between the Arrival Delay and Departure Delay of the flights. (d) Find out the confidence interval of the fitted linear regression line. (e) Perform a multiple linear regression between the Arrival Delay along with the Departure Delay and Distance travelled by flights.,:Year:Month:DayofMonth:DayOfWeek:DepTime:CRSDepTime:ArrTime:CRSArrTime:UniqueCarrier:FlightNum:TailNum:ActualElapsedTime:CRSElapsedTime:AirTime:ArrDelay:DepDelay:Origin:Dest:Distance:TaxiIn:TaxiOut:Cancelled:CancellationCode:Diverted:CarrierDelay:WeatherDelay:NASDelay:SecurityDelay:LateAircraftDelay:,numeric:numeric:numeric:numeric:numeric:string:numeric:string:numeric:string:numeric:string:string:numeric:string:string:string:string:string:numeric:string:string:numeric:string:numeric:string:string:string:string:string:,airways
Current Population Survey , US Census Bureau , www.kaggle.com/census/current-population-survey , Mon Oct 24 2016 20:18:45 GMT+0530 (IST) , The primary source of labor force statistics for the US population ,784, employment- demographics- ,Current Population Survey - August 2016 Context The Current Population Survey (CPS) is one of the oldest largest and most well-recognized surveys in the United States.  It is immensely important providing information on many of the things that define us as individuals and as a society – our work our earnings and our education.  Frequency Monthly Period August 2016  Content In addition to being the primary source of monthly labor force statistics the CPS is used to collect data for a variety of other studies that keep the nation informed of the economic and social well-being of its people.  This is done by adding a set of supplemental questions to the monthly basic CPS questions.  Supplemental inquiries vary month to month and cover a wide variety of topics such as child support volunteerism health insurance coverage and school enrollment.  Supplements are usually conducted annually or biannually but the frequency and recurrence of a supplement depend completely on what best meets the needs of the supplement’s sponsor.  Data Dictionary http//thedataweb.rm.census.gov/pub/cps/basic/201501-/January_2015_Record_Layout.txt Acknowledgements The Current Population Survey (CPS) is administered processed researched and disseminated by the U.S. Census Bureau on behalf of the Bureau of Labor Statistics (BLS).,HRHHID:HRMONTH:HRYEAR4:HURESPLI:HUFINAL:HUSPNISH:HETENURE:HEHOUSUT:HETELHHD:HETELAVL:HEPHONEO:HEFAMINC:HUTYPEA:HUTYPB:HUTYPC:HWHHWGT:HRINTSTA:HRNUMHOU:HRHTYPE:HRMIS:HUINTTYP:HUPRSCNT:HRLONGLK:HRHHID2:HWHHWTLN:HUBUS:HUBUSL1:HUBUSL2:HUBUSL3:HUBUSL4:GEREG:GEDIV:GESTFIPS:GTCBSA:GTCBSAST:GTMETSTA:GTINDVPC:GTCBSASZ:GTCSA:FILLER:PERRP:PEPARENT:PRTAGE:PRTFAGE:PEMARITL:PESPOUSE:PESEX:PEAFEVER:PEAFNOW:PEEDUCA:PTDTRACE:PRDTHSP:PUCHINHH:PULINENO:PRFAMNUM:PRFAMREL:PRFAMTYP:PEHSPNON:PRMARSTA:PRPERTYP:PENATVTY:PEMNTVTY:PEFNTVTY:PRCITSHP:PRCITFLG:PRINUSYR:PUSLFPRX:PEMLR:PUWK:PUBUS1:PUBUS2OT:PUBUSCK1:PUBUSCK2:PUBUSCK3:PUBUSCK4:PURETOT:PUDIS:PERET1:PUDIS1:PUDIS2:PUABSOT:PULAY:PEABSRSN:PEABSPDO:PEMJOT:PEMJNUM:PEHRUSL1:PEHRUSL2:PEHRFTPT:PEHRUSLT:PEHRWANT:PEHRRSN1:PEHRRSN2:PEHRRSN3:PUHROFF1:PUHROFF2:PUHROT1:PUHROT2:PEHRACT1:PEHRACT2:PEHRACTT:PEHRAVL:PUHRCK1:PUHRCK2:PUHRCK3:PUHRCK4:PUHRCK5:PUHRCK6:PUHRCK7:PUHRCK12:PULAYDT:PULAY6M:PELAYAVL:PULAYAVR:PELAYLK:PELAYDUR:PELAYFTO:PULAYCK1:PULAYCK2:PULAYCK3:PULK:PELKM1:PULKM2:PULKM3:PULKM4:PULKM5:PULKM6:PULKDK1:PULKDK2:PULKDK3:PULKDK4:PULKDK5:PULKDK6:PULKPS1:PULKPS2:PULKPS3:PULKPS4:PULKPS5:PULKPS6:PELKAVL:PULKAVR:PELKLL1O:PELKLL2O:PELKLWO:PELKDUR:PELKFTO:PEDWWNTO:PEDWRSN:PEDWLKO:PEDWWK:PEDW4WK:PEDWLKWK:PEDWAVL:PEDWAVR:PUDWCK1:PUDWCK2:PUDWCK3:PUDWCK4:PUDWCK5:PEJHWKO:PUJHDP1O:PEJHRSN:PEJHWANT:PUJHCK1:PUJHCK2:PRABSREA:PRCIVLF:PRDISC:PREMPHRS:PREMPNOT:PREXPLF:PRFTLF:PRHRUSL:PRJOBSEA:PRPTHRS:PRPTREA:PRUNEDUR:PRUNTYPE:PRWKSCH:PRWKSTAT:PRWNTJOB:PUJHCK3:PUJHCK4:PUJHCK5:PUIODP1:PUIODP2:PUIODP3:PEIO1COW:PUIO1MFG:PADDING:PEIO2COW:PUIO2MFG:PUIOCK1:PUIOCK2:PUIOCK3:PRIOELG:PRAGNA:PRCOW1:PRCOW2:PRCOWPG:PRDTCOW1:PRDTCOW2:PRDTIND1:PRDTIND2:PRDTOCC1:PRDTOCC2:PREMP:PRMJIND1:PRMJIND2:PRMJOCC1:PRMJOCC2:PRMJOCGR:PRNAGPWS:PRNAGWS:PRSJMJ:PRERELG:PEERNUOT:PEERNPER:PEERNRT:PEERNHRY:PUERNH1C:PEERNH2:PEERNH1O:PRERNHLY:PTHR:PEERNHRO:PRERNWA:PTWK:PEERN:PUERN2:PTOT:PEERNWKP:PEERNLAB:PEERNCOV:PENLFJH:PENLFRET :PENLFACT:PUNLFCK1:PUNLFCK2:PESCHENR:PESCHFT:PESCHLVL:PRNLFSCH:PWFMWGT:PWLGWGT:PWORWGT:PWSSWGT:PWVETWGT:PRCHLD:PRNMCHLD:PXPDEMP1:PRWERNAL:PRHERNAL:HXTENURE:HXHOUSUT:HXTELHHD:HXTELAVL:HXPHONEO:PXINUSYR:PXRRP:PXPARENT:PXAGE:PXMARITL:PXSPOUSE:PXSEX:PXAFWHN1:PXAFNOW:PXEDUCA:PXRACE1:PXNATVTY:PXMNTVTY:PXFNTVTY:PXNMEMP1:PXHSPNON:PXMLR:PXRET1:PXABSRSN:PXABSPDO:PXMJOT:PXMJNUM:PXHRUSL1:PXHRUSL2:PXHRFTPT:PXHRUSLT:PXHRWANT:PXHRRSN1:PXHRACT1:PXHRACT2:PXHRACTT:PXHRRSN3:PXHRAVL:PXLAYAVL:PXLAYLK:PXLAYDUR:PXLAYFTO:PXLKM1:PXLKAVL:PXLKLL1O:PXLKLL2O:PXLKLWO:PXLKDUR:PXLKFTO:PXDWWNTO:PXDWRSN:PXDWLKO:PXDWWK:PXDW4WK:PXDWLKWK:PXDWAVL:PXDWAVR:PXJHWKO:PXJHRSN:PXJHWANT:PXIO1COW:PXIO1ICD:PXIO1OCD:PXIO2COW:PXIO2ICD:PXIO2OCD:PXERNUOT:PXERNPER:PXERNH1O:PXERNHRO:PXERN:PXPDEMP2:PXNMEMP2:PXERNWKP:PXERNRT:PXERNHRY:PXERNH2:PXERNLAB:PXERNCOV:PXNLFJH:PXNLFRET:PXNLFACT:PXSCHENR:PXSCHFT:PXSCHLVL:QSTNUM:OCCURNUM:PEDIPGED:PEHGCOMP:PECYC:PXDIPGED :PXHGCOMP:PXCYC:PWCMPWGT:PEIO1ICD:PEIO1OCD:PEIO2ICD:PEIO2OCD:PRIMIND1:PRIMIND2:PEAFWHN1:PEAFWHN2:PEAFWHN3:PEAFWHN4:PXAFEVER:PELNDAD:PELNMOM:PEDADTYP:PEMOMTYP:PECOHAB:PXLNDAD:PXLNMOM:PXDADTYP:PXMOMTYP:PEDISEAR:PEDISEYE:PEDISREM:PEDISPHY:PEDISDRS:PEDISOUT:PRDISFLG:PXDISEAR:PXDISEYE:PXDISREM:PXDISPHY:PXDISDRS:PXDISOUT:HXFAMINC:PEPDEMP1:PTNMEMP1:PEPDEMP2:PTNMEMP2:GTCO:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,demography
Meteorite Landings , NASA , www.kaggle.com/nasa/meteorite-landings , Sat Nov 05 2016 23:50:04 GMT+0530 (IST) , Data on over 45k meteorites that have struck Earth ,1675, astronomy- space- ,"The Meteoritical Society collects data on meteorites that have fallen to Earth from outer space. This dataset includes the location mass composition and fall year for over 45000 meteorites that have struck our planet. Notes on missing or incorrect data points   a few entries here contain date information that was incorrectly parsed into the NASA database. As a spot check any date that is before 860 CE or after 2016 are incorrect; these should actually be BCE years. There may be other errors and we are looking for a way to identify them. a few entries have latitude and longitude of 0N/0E (off the western coast of Africa where it would be quite difficult to recover meteorites). Many of these were actually discovered in Antarctica but exact coordinates were not given. 0N/0E locations should probably be treated as NA.  The starter kernel for this dataset has a quick way to filter out these observations using dplyr in R provided here for convenience meteorites.geo <- meteorites.all %>%    filter(year>=860 & year<=2016) %>%  # filter out weird years    filter(reclong<=180 & reclong>=-180 & (reclat!=0 | reclong!=0))  # filter out weird locations   The Data Note that a few column names start with ""rec"" (e.g. recclass reclat reclon). These are the recommended values of these variables according to The Meteoritical Society. In some cases there were historical reclassification of a meteorite or small changes in the data on where it was recovered; this dataset gives the currently recommended values. The dataset contains the following variables    name the name of the meteorite (typically a location often modified with a number year composition etc) id a unique identifier for the meteorite  nametype one of  -- valid a typical meteorite  -- relict a meteorite that has been highly degraded by weather on Earth   recclass the class of the meteorite; one of a large number of classes based on physical chemical and other characteristics (see the Wikipedia article on meteorite classification for a primer) mass the mass of the meteorite in grams fall whether the meteorite was seen falling or was discovered after its impact; one of  -- Fell the meteorite's fall was observed  -- Found the meteorite's fall was not observed   year the year the meteorite fell or the year it was found (depending on the value of fell) reclat the latitude of the meteorite's landing reclong the longitude of the meteorite's landing GeoLocation a parentheses-enclose comma-separated tuple that combines reclat and reclong  What can we do with this data? Here are a couple of thoughts on questions to ask and ways to look at this data  how does the geographical distribution of observed falls differ from that of found meteorites? -- this would be great overlaid on a cartogram or alongside a high-resolution population density map are there any geographical differences or differences over time in the class of meteorites that have fallen to Earth?  Acknowledgements This dataset was downloaded from NASA's Data Portal and is based on The Meteoritical Society's Meteoritical Bulletin Database (this latter database provides additional information such as meteorite images links to primary sources etc.).",,,astronomy
Finishers Boston Marathon 2015 2016 & 2017 , rojour , www.kaggle.com/rojour/boston-results , Sun Apr 30 2017 03:27:12 GMT+0530 (IST) , This data has the names times and general demographics of the finishers ,863, running- walking- ,Context This is a list of the finishers of the Boston Marathon of 2015 2016 and 2017. It's important to highlight that the Boston Marathon is the oldest marathon run in the US as it is the only marathon (other than olympic trails) that most of the participants have to qualify to participate. For the professional runners it's a big accomplishment to win the marathon. For most of the other participants it's an honor to be part of it. Content It contains the name age gender country city and state (where available) times at 9 different stages of the race expected time finish time and pace overall place gender place and division place. Decided to keep every year as a separate file making it more manageable and easier to deal with it. Acknowledgements Data was scrapped from the official marathon website - http//registration.baa.org/2017/cf/Public/iframe_ResultsSearch.cfm I have found that other people have done this kind of scraping so  some of those ideas together with things I have learned in my quest to become a data scientist created the set. You can actually find the scraping notebooks at - https//github.com/rojour/boston_results . Notebook it's not very clean yet but I will get to it soon... Inspiration I was a participant in the marathon 2016 and 2017 edition as well as a data science student so it was a natural curiosity. I have done a preliminary study of some fun facts. You can see the kernel here as well as in the github page listed above. Already some people have created some fun analysis of the results (mostly of the first part - 2016) that was the first upload but I am curious of what people may come up with... now that three years are available it may spark the creative juices of some. I believe it's a simple fun dataset that can be used by the new to play with and by some veterans to get creative.,:,numeric:,sports teams and players
350 000+ movies from themoviedb.org , Stephanerappeneau , www.kaggle.com/stephanerappeneau/350-000-movies-from-themoviedborg , Fri Oct 13 2017 01:19:17 GMT+0530 (IST) , More than 350k movies and main casting/crew up to Aug17 ,311, arts and entertainment- film- actors- ,"Context I love movies.  I tend to avoid marvel-transformers-standardized products and prefer a mix of classic hollywood-golden-age and obscure polish artsy movies. Throw in an occasional japanese-zombie-slasher-giallo as an alibi. Good movies don't exist without bad movies.  On average I watch 200+ movies each year with peaks at more than 500 movies. Nine years ago I started to log my movies to avoid watching the same movie twice and also assign scores. Over the years it gave me a couple insights on my viewing habits but nothing more than what a tenth-grader would learn at school.  I've recently suscribed to Netflix and it pains me to see the global inefficiency of recommendation systems for people like me who mostly swear by ""La politique des auteurs"". It's a term coined by famous new-wave french movie critic André Bazin meaning that the quality of a movie is essentially linked to the director and it's capacity to execute his vision with his crew. We could debate it depends on movie production pipeline but let's not for now. Practically what it means is that I essentially watch movies from directors who made films I've liked.  I suspect Neflix calibrate their recommandation models taking into account the way the ""average-joe"" chooses a movie. A few months ago I had read a study based on a survey showing that people chose a movie mostly based on genre (55%) then by leading actors (45%). Director or Release Date were far behind around 10% each. It is not surprising since most people I know don't care who the director is. Lots of US blockbusters don't even mention it on the movie poster. I am aware that collaborative filtering is based on user proximity  which I believe decreases (or even eliminates) the need to characterize a movie. So here I'm more interested in content based filtering which is based on product proximity for several reasons   Users tastes are not easily accessible. It is after all Netflix treasure chest Movie offer on Netflix is so bad for someone who likes author's movies that it wouldn't help Modeling a movie intrinsic qualities is a nice challenge  Enough. ""The secret of getting ahead is getting started"" (Mark Twain)  Content The primary source is www.themoviedb.org. If you watch obscure artsy romanian homemade movies you may find only 95% of your movies referenced...but for anyone else it should be in the 98%+ range.  movies details are from www.themoviedb.org API  movies/details movies crew & casting are from www.themoviedb.org API  movies/credits both can be joined by id they contain all 350k movies up from end of 19th century to august 2017. If you remove short movies from imdb you get similar amounts of movies. I uploaded the program to retrieve incremental movie details on github  https//github.com/stephanerappeneau/scienceofmovies/tree/master/PycharmProjects/GetAllMovies (need a dev API key from themoviedb.org though) I have tried various supervised (decision tree) / unsupervised (clustering NLP) approaches described in the discussions source code is on github  https//github.com/stephanerappeneau/scienceofmovies As a bonus I've uploaded the bio summary from top 500 critically-acclaimed directors from wikipedia for some interesting NLTK analysis  Here is overview of the available sources that I've tried  • Imdb.com free csv dumps (ftp//ftp.funet.fi/pub/mirrors/ftp.imdb.com/pub/temporaryaccess/) are badly documented incomplete loosely structured and impossible to join/merge. There's an API hosted by Amazon Web Service  1€ every 100 000 requests. With around 1 million movies it could become expensive also features are bare. So I've searched for other sources.  • www.themoviedb.org is based on crowdsourcing and has an excellent API limited to 40 requests every 10 seconds. It is quite generous well documented and enough to sweep the 450 000 movies in a few days. For my purpose data quality is not significantly worse than imdb and as imdb key is also included there's always the possibility to complete my dataset later (I actually did it) • www.Boxofficemojo.com has some interesting budget/revenue figures (which are sorely lacking in both imdb & tmdb) but it actually tracks only a few thousand movies mainly blockbusters. There are other professional sources that are used by film industry to get better predictive / marketing insights but that's beyond my reach for this experiment.   • www.wikipedia.com is an interesting source with no real cap on API calls however it requires a bit of webscraping and for movies or directors the layout and quality varies a lot so I suspected it'd get a lot of work to get insights so I put this source in lower priority. • www.google.com will ban you after a few minutes of web scraping because their job is to scrap data from others than sell it duh.   • It's worth mentionning that there are a few dumps of Netflix anonymized user tastes on kaggle because they've organised a few competitions to improve their recommendation models. https//www.kaggle.com/netflix-inc/netflix-prize-data • Online databases are largely white anglo-saxon centric meaning bollywood (India is the 2nd bigger producer of movies) offer is mostly absent from datasets. I'm fine with that as it's not my cup of tea plus I lack domain knowledge. The sheer amount of indian movies would probably skew my results anyway (I don't want to have too many martial-arts-musicals in my recommendations ;-)). I have however tremendous respect for indian movie industry so I'd love to collaborate with an indian cinephile !  Inspiration Starting from there I had multiple problem statements for both supervised / unsupervised machine learning  Can I program a tailored-recommendation system based on my own criteria ? What are the characteristics of movies/directors I like the most ? What is the probability that I will like my next movie ? Can I find the data ?  One of the objectives of sharing my work here is to find cinephile data-scientists who might be interested and hopefully contribute or share insights ) Other interesting leads  use tagline for NLP/Clustering/Genre guessing leverage on budget/revenue link with other data sources using the imdb normalized title etc.  Motivation Disclaimer and Acknowledgements  I've graduated from an french engineering school majoring in artificial intelligence but that was 17 years ago right in the middle of A.I-winter. Like a lot of white male rocket scientists I've ended up in one of the leading european investment bank quickly abandonning IT development to specialize in trading/risk project management and internal politics. My recent appointment in the Data Office made me aware of recent breakthroughts in datascience and I thought that developing a side project would be an excellent occasion to learn something new. Plus it'd give me a well-needed credibility which too often lack decision makers when it comes to datascience. I've worked on some of the features with Cédric Paternotte a fellow friend of mine who is a professor of philosophy of sciences in La Sorbonne. Working with someone with a different background seem a good idea for motivation creativity and rigor. Kudos to www.themoviedb.org or www.wikipedia.com sites who really have a great attitude towards open data. This is typically NOT the case of modern-bigdata companies who mostly keep data to themselves to try to monetize it. Such a huge contrast with imdb or instagram API which generously let you grab your last 3 comments at a miserable rate. Even if 15 years ago this seemed a mandatory path to get services for free I predict one day governments will need to break this data monopoly.  [Disclaimer  I apologize in advance for my engrish (I'm french ^-^) any bad-code I've written (there are probably hundreds of way to do it better and faster) any pseudo-scientific assumption I've made I'm slowly getting back in statistics and lack senior guidance one day I regress a non-stationary time series and the day after I'll discover I shouldn't have and any incorrect use of machine-learning models] ",director_name:ceremony:year:category:outcome:original_language:,string:string:numeric:string:string:string:,movies
Audio features of songs ranging from 1922 to 2011 , UCI Machine Learning , www.kaggle.com/uciml/msd-audio-features , Thu Sep 07 2017 00:54:41 GMT+0530 (IST) , A subset of the Million Song Database ,99, music- sound technology- ,Context The Million Song Dataset (MSD) is a freely-available collection of audio features and metadata for a million contemporary popular music tracks. This is a subset of the MSD and contains audio features of songs with the year of the song. The purpose being to predict the release year of a song from audio features.  Content The owners recommend that you split the data like this to avoid the 'producer effect' by making sure no song from a given artist ends up in both the train and test set.  train first 463715 examples  test last 51630 examples   Field descriptions  The first value is the year (target) ranging from 1922 to 2011.  Then there are 90 attributes  TimbreAverage[1-12] TimbreCovariance[1-78]  These features were extracted from the 'timbre' features from The Echo Nest API.  The authors took the average and covariance over all 'segments' and each segment was described by a 12-dimensional timbre vector. Acknowledgements Original dataset Thierry Bertin-Mahieux Daniel P.W. Ellis Brian Whitman and Paul Lamere. The Million Song Dataset. In Proceedings of the 12th International Society for Music Information Retrieval Conference (ISMIR 2011) 2 Subset downloaded from https//archive.ics.uci.edu/ml/datasets/yearpredictionmsd Inspiration Use this dataset to predict the years that each song was released based on it's audio features,label:TimbreAvg1:TimbreAvg2:TimbreAvg3:TimbreAvg4:TimbreAvg5:TimbreAvg6:TimbreAvg7:TimbreAvg8:TimbreAvg9:TimbreAvg10:TimbreAvg11:TimbreAvg12:TimbreCovariance1:TimbreCovariance2:TimbreCovariance3:TimbreCovariance4:TimbreCovariance5:TimbreCovariance6:TimbreCovariance7:TimbreCovariance8:TimbreCovariance9:TimbreCovariance10:TimbreCovariance11:TimbreCovariance12:TimbreCovariance13:TimbreCovariance14:TimbreCovariance15:TimbreCovariance16:TimbreCovariance17:TimbreCovariance18:TimbreCovariance19:TimbreCovariance20:TimbreCovariance21:TimbreCovariance22:TimbreCovariance23:TimbreCovariance24:TimbreCovariance25:TimbreCovariance26:TimbreCovariance27:TimbreCovariance28:TimbreCovariance29:TimbreCovariance30:TimbreCovariance31:TimbreCovariance32:TimbreCovariance33:TimbreCovariance34:TimbreCovariance35:TimbreCovariance36:TimbreCovariance37:TimbreCovariance38:TimbreCovariance39:TimbreCovariance40:TimbreCovariance41:TimbreCovariance42:TimbreCovariance43:TimbreCovariance44:TimbreCovariance45:TimbreCovariance46:TimbreCovariance47:TimbreCovariance48:TimbreCovariance49:TimbreCovariance50:TimbreCovariance51:TimbreCovariance52:TimbreCovariance53:TimbreCovariance54:TimbreCovariance55:TimbreCovariance56:TimbreCovariance57:TimbreCovariance58:TimbreCovariance59:TimbreCovariance60:TimbreCovariance61:TimbreCovariance62:TimbreCovariance63:TimbreCovariance64:TimbreCovariance65:TimbreCovariance66:TimbreCovariance67:TimbreCovariance68:TimbreCovariance69:TimbreCovariance70:TimbreCovariance71:TimbreCovariance72:TimbreCovariance73:TimbreCovariance74:TimbreCovariance75:TimbreCovariance76:TimbreCovariance77:TimbreCovariance78:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,music
Starbucks Locations Worldwide , Starbucks , www.kaggle.com/starbucks/store-locations , Tue Feb 14 2017 04:35:16 GMT+0530 (IST) , Name ownership type and location of every Starbucks store in operation ,3853, food and drink- ,Context Starbucks started as a roaster and retailer of whole bean and ground coffee tea and spices with a single store in Seattle’s Pike Place Market in 1971. The company now operates more than 24000 retail stores in 70 countries. Content This dataset includes a record for every Starbucks or subsidiary store location currently in operation as of February 2017. Acknowledgements This data was scraped from the Starbucks store locator webpage by Github user chrismeller. Inspiration What city or country has the highest number of Starbucks stores per capita? What two Starbucks locations are the closest in proximity to one another? What location on Earth is farthest from a Starbucks? How has Starbucks expanded overseas?,Brand:Store Number:Store Name:Ownership Type:Street Address:City:State/Province:Country:Postcode:Phone Number:Timezone:Longitude:Latitude:,string:string:string:string:string:string:numeric:string:string:numeric:string:numeric:numeric:,food and nutrition
Stanford Mass Shootings in America (MSA) , Carlos Paradis , www.kaggle.com/carlosparadis/stanford-msa , Sun Oct 08 2017 03:35:58 GMT+0530 (IST) , A high quality dataset from 1966-2016 with method definitions and references ,149, united states- crime- violence- terrorism- ,"https//www.youtube.com/watch?v=A8syQeFtBKc  Context The Stanford Mass Shootings in America (MSA) is a dataset released under Creative Commons Attribution 4.0 international license by the Stanford Geospatial Center. While not an exhaustive collection of mass shootings it is a high-quality dataset ranging from 1966 to 2016 with well-defined methodology definitions and source URLs for user validation.  This dataset can be used to validate other datasets such as us-mass-shootings-last-50-years which contains more recent data or conduct other analysis as more information is provided.  Content This dataset contains data by the MSA project both from it's website and from it's Github account. The difference between the two sources is only on the data format (i.e. .csv versus .geojson for the data or .csv versus .pdf for the dictionary).  mass_shooting_events_stanford_msa_release_06142016 Contains a nonexaustive list of US Mass Shootings from 1966 to 2016 in both .csv and .geojson formats. dictionary_stanford_msa_release_06142016 Contains the data dictionary in .csv and .pdf formats. Note the .pdf format provides an easier way to visualize sub-fields.  Note the data was reproduced here without any modifications other than file renaming for clarity the content is the same as in the source. The following sections are reproduced from the dataset creators website. For more details please see the source. Project background The Stanford Mass Shootings of America (MSA) data project began in 2012 in reaction to the mass shooting in Sandy Hook CT. In our initial attempts to map this phenomena it was determined that no comprehensive collection of these incidents existed online. The Stanford Geospatial Center set out to create as best we could a single point repository for as many mass shooting events as could be collected via online media. The result was the Stanford MSA. What the Stanford MSA is The Stanford MSA is a data aggregation effort. It is a curated set of spatial and temporal data about mass shootings in America taken from online media sources. It is an attempt to facilitate research on gun violence in the US by making raw data more accessible. What the Stanford MSA is not The Stanford MSA is not a comprehensive longitudinal research project. The data collected in the MSA are not investigated past the assessment for inclusion in the database. The MSA is not an attempt to answer specific questions about gun violence or gun laws. The Stanford Geospatial Center does not provide analysis or commentary on the contents of this database or any derivatives produced with it. Data collection methodology The information collected for the Stanford MSA is limited to online resources. An initial intensive investigation was completed looking back over existing online reports to fill in the historic record going back to 1966. Contemporary records come in as new events occur and are cross referenced against a number of online reporting sources. In general a minimum of three corroborating sources are required to add the full record into the MSA (as many as 6 or 7 sources may have been consulted in many cases). All sources for each event are listed in the database. Due to the time involved in vetting the details of any new incident there is often a 2 to 4 week lag between a mass shooting event and its inclusion in the public release database. It is important to note the records in the Stanford MSA span a time from well before the advent of online media reporting through its infancy to the modern era of web based news and information resources. Researchers using this database need to be aware of the reporting bias these changes in technology present. A spike in incidents for recent years is likely due to increased online reporting and not necessarily indicative of the rate of mass shootings alone. Researchers should look at this database as a curated collection of quality checked data regarding mass shootings and not an exhaustive research data set itself. Independent verification and analysis will be required to use this data in examining trends in mass shootings over time. Definition of Mass Shooting The definition of mass shooting used for the Stanford database is 3 or more shooting victims (not necessarily fatalities) not including the shooter. The shooting must not be identifiably gang drug or organized crime related. Acknowledgements The Stanford Mass Shootings in America (MSA) is a dataset released under Creative Commons Attribution 4.0 international license by the Stanford Geospatial Center. How to cite the MSA The Stanford MSA is released under a Creative Commons Attribution 4.0 international license. Please cite the MSA as “Stanford Mass Shootings in America courtesy of the Stanford Geospatial Center and Stanford Libraries”. Inspiration There is already a great number of interesting datasets in Kaggle surrounding the subject of Mass Shootings however little has been done leveraging information from multiple sources. Can you see a story among them? Can we learn anything for example comparing the different sources by city or state?  From a bigger picture  Leading Causes of Death in US https//www.kaggle.com/cdc/mortality Gun Violence Database https//www.kaggle.com/gunviolencearchive/gun-violence-database Gun Deaths in US https//www.kaggle.com/hakabuk/gun-deaths-in-the-us Homicide Reports https//www.kaggle.com/murderaccountability/homicide-reports Global Terrorism Database https//www.kaggle.com/START-UMD/gtd Crime Rates in America https//www.kaggle.com/marshallproject/crime-rates  ""Prevention?  Firearms Provisions in US States https//www.kaggle.com/jboysen/state-firearms Trial and Terror https//www.kaggle.com/jboysen/trial-and-terror Connecticut Inmates Waiting trial https//www.kaggle.com/Connecticut-open-data/connecticut-inmates-awaiting-trial  Are there warning signs?  Mental Health in Tech Survey https//www.kaggle.com/osmi/mental-health-in-tech-2016/data (Not directly related but can be used to make a parenthesis about mental health being an issue in our surroundings). ",Field:Data Item:Data Type:Definition:Examples:,string:string:string:string:numeric:,crime
Air quality in northern Taiwan , Nelson Chu , www.kaggle.com/nelsonchu/air-quality-in-northern-taiwan , Fri Jul 29 2016 12:40:40 GMT+0530 (IST) , Air quality monitoring data from northern Taiwan 2015 ,606, environment- ,Context This data is from Environmental Protection Administration Executive Yuan R.O.C. (Taiwan). There is air quality data and meteorological monitoring data for research and analysis (only include northern Taiwan 2015). Content 25 observation stations data in the 2015_Air_quality_in_northern_Taiwan.csv The columns in csv file are  time - The first column is observation time of 2015 station - The second column is station name there is 25 observation stations [Banqiao Cailiao Datong Dayuan Guanyin Guting Keelung Linkou Longtan Pingzhen Sanchong Shilin Songshan Tamsui Taoyuan Tucheng Wanhua Wanli Xindian Xinzhuang Xizhi Yangming Yonghe Zhongli Zhongshan] items - From the third column to the last one item - unit - description SO2 - ppb - Sulfur dioxide CO - ppm - Carbon monoxide O3 - ppb - ozone PM10 - μg/m3 - Particulate matter PM2.5 - μg/m3 - Particulate matter NOx - ppb - Nitrogen oxides NO - ppb - Nitric oxide NO2 - ppb - Nitrogen dioxide THC - ppm - Total Hydrocarbons NMHC - ppm - Non-Methane Hydrocarbon CH4 - ppm - Methane UVB - UVI - Ultraviolet index AMB_TEMP - Celsius - Ambient air temperature RAINFALL - mm RH - % - Relative humidity WIND_SPEED - m/sec - The average of last ten minutes per hour WIND_DIREC - degress - The average of last ten minutes per hour WS_HR - m/sec - The average of hour WD_HR - degress  - The average of hour PH_RAIN - PH - Acid rain RAIN_COND - μS/cm - Conductivity of acid rain  Data mark  # indicates invalid value by equipment inspection * indicates invalid value by program inspection x indicates invalid value by human inspection NR indicates no rainfall blank indicates no data  License Open Government Data License version 1.0 http//data.gov.tw/license,,,air pollution
Stanford Open Policing Project - Bundle 1 , Stanford Open Policing Project , www.kaggle.com/stanford-open-policing/stanford-open-policing-project-bundle-1 , Fri Jul 28 2017 04:35:38 GMT+0530 (IST) , Data on Traffic and Pedestrian Stops by Police in many states ,96, government agencies- crime- law- ,Context On a typical day in the United States police officers make more than 50000 traffic stops. The Stanford Open Policing Project team is gathering analyzing and releasing records from millions of traffic stops by law enforcement agencies across the country. Their goal is to help researchers journalists and policymakers investigate and improve interactions between police and the public. If you'd like to see data regarding other states please go to https//www.kaggle.com/stanford-open-policing. Content This dataset includes stop data from AZ CO CT IA MA MD MI and MO. Please see the data readme for the full details of the available fields. Acknowledgements This dataset was kindly made available by the Stanford Open Policing Project. If you use it for a research publication please cite their working paper E. Pierson C. Simoiu J. Overgoor S. Corbett-Davies V. Ramachandran C. Phillips S. Goel. (2017) “A large-scale analysis of racial disparities in police stops across the United States”. Inspiration  How predictable are the stop rates? Are there times and places that reliably generate stops? Concerns have been raised about jurisdictions using civil forfeiture as a funding mechanism rather than to properly fight drug trafficking. Can you identify any jurisdictions that may be exhibiting this behavior? ,id:state:stop_date:stop_time:location_raw:county_name:county_fips:fine_grained_location:police_department:driver_gender:driver_age_raw:driver_age:driver_race_raw:driver_race:violation_raw:violation:search_conducted:search_type_raw:search_type:contraband_found:stop_outcome:is_arrested:officer_id:stop_duration:road_number:milepost:consent_search:vehicle_type:ethnicity:,string:string:dateTime:string:string:string:numeric:string:string:string:string:string:string:string:string:string:boolean:string:string:boolean:string:boolean:numeric:string:string:numeric:boolean:string:string:,traffic violations
Pokemon Sun and Moon (Gen 7) Stats , Myles O'Neill , www.kaggle.com/mylesoneill/pokemon-sun-and-moon-gen-7-stats , Sat Nov 19 2016 03:15:39 GMT+0530 (IST) , Explore all 802 Pokemon from the newly released 7th Generation ,1195, video games- games- ,Pokemon Sun and Moon (released November 18th 2016) are the latest games in the widely popular Pokemon video game franchise. Pokemon games are usually released in pairs (red and blue gold and silver x and y etc.) and collectively each pair that introduces new pokemon to the game is known as a Generation. Pokemon Sun and Moon are the 7th Generation adding new pokemon to the franchise as well as adjusting the stats and movesets of some of the older pokemon. (Please note that the recently popular PokemonGo games are unrelated to the Pokemon Video Games). This dataset contains a full set of in-game statistics for all 802 pokemon in the Sun and Moon. It also includes full information on which pokemon can learn which moves (movesets.csv) what moves can do (moves.csv) and how damage is modified by pokemon type (type-chart.csv). Pokemon Battle Simulation With the level of detail in the data provided here it is possible to almost fully simulate pokemon battles using the information provided (status effects and some other nuances are still missing). If you are interested in simulating how Pokemon battles would pan out between different opponents make sure to read up on the math behind how Pokemon battles work.  ,,,video games
Crimes in Chicago , Currie32 , www.kaggle.com/currie32/crimes-in-chicago , Sat Jan 28 2017 08:47:31 GMT+0530 (IST) , An extensive dataset of crimes in Chicago (2001-2017) by City of Chicago ,4928, crime- ,"Context This dataset reflects reported incidents of crime (with the exception of murders where data exists for each victim) that occurred in the City of Chicago from 2001 to present minus the most recent seven days. Data is extracted from the Chicago Police Department's CLEAR (Citizen Law Enforcement Analysis and Reporting) system. In order to protect the privacy of crime victims addresses are shown at the block level only and specific locations are not identified. Should you have questions about this dataset you may contact the Research & Development Division of the Chicago Police Department at 312.745.6071 or RDAnalysis@chicagopolice.org. Disclaimer These crimes may be based upon preliminary information supplied to the Police Department by the reporting parties that have not been verified. The preliminary crime classifications may be changed at a later date based upon additional investigation and there is always the possibility of mechanical or human error. Therefore the Chicago Police Department does not guarantee (either expressed or implied) the accuracy completeness timeliness or correct sequencing of the information and the information should not be used for comparison purposes over time. The Chicago Police Department will not be responsible for any error or omission or for the use of or the results obtained from the use of this information. All data visualizations on maps should be considered approximate and attempts to derive specific addresses are strictly prohibited. The Chicago Police Department is not responsible for the content of any off-site pages that are referenced by or that reference this web page other than an official City of Chicago or Chicago Police Department web page. The user specifically acknowledges that the Chicago Police Department is not responsible for any defamatory offensive misleading or illegal conduct of other users links or third parties and that the risk of injury from the foregoing rests entirely with the user. The unauthorized use of the words ""Chicago Police Department"" ""Chicago Police"" or any colorable imitation of these words or the unauthorized use of the Chicago Police Department logo is unlawful. This web page does not in any way authorize such use. Data are updated daily. The dataset contains more than 6000000 records/rows of data and cannot be viewed in full in Microsoft Excel.  To access a list of Chicago Police Department - Illinois Uniform Crime Reporting (IUCR) codes go to http//data.cityofchicago.org/Public-Safety/Chicago-Police-Department-Illinois-Uniform-Crime-R/c7ck-438e Content ID - Unique identifier for the record. Case Number - The Chicago Police Department RD Number (Records Division Number) which is unique to the incident. Date - Date when the incident occurred. this is sometimes a best estimate. Block - The partially redacted address where the incident occurred placing it on the same block as the actual address. IUCR - The Illinois Unifrom Crime Reporting code. This is directly linked to the Primary Type and Description. See the list of IUCR codes at https//data.cityofchicago.org/d/c7ck-438e. Primary Type - The primary description of the IUCR code. Description - The secondary description of the IUCR code a subcategory of the primary description. Location Description - Description of the location where the incident occurred. Arrest - Indicates whether an arrest was made. Domestic - Indicates whether the incident was domestic-related as defined by the Illinois Domestic Violence Act. Beat - Indicates the beat where the incident occurred. A beat is the smallest police geographic area – each beat has a dedicated police beat car. Three to five beats make up a police sector and three sectors make up a police district. The Chicago Police Department has 22 police districts. See the beats at https//data.cityofchicago.org/d/aerh-rz74. District - Indicates the police district where the incident occurred. See the districts at https//data.cityofchicago.org/d/fthy-xz3r. Ward - The ward (City Council district) where the incident occurred. See the wards at https//data.cityofchicago.org/d/sp34-6z76. Community Area - Indicates the community area where the incident occurred. Chicago has 77 community areas. See the community areas at https//data.cityofchicago.org/d/cauq-8yn6. FBI Code - Indicates the crime classification as outlined in the FBI's National Incident-Based Reporting System (NIBRS). See the Chicago Police Department listing of these classifications at http//gis.chicagopolice.org/clearmap_crime_sums/crime_types.html. X Coordinate - The x coordinate of the location where the incident occurred in State Plane Illinois East NAD 1983 projection. This location is shifted from the actual location for partial redaction but falls on the same block. Y Coordinate - The y coordinate of the location where the incident occurred in State Plane Illinois East NAD 1983 projection. This location is shifted from the actual location for partial redaction but falls on the same block. Year - Year the incident occurred. Updated On - Date and time the record was last updated. Latitude - The latitude of the location where the incident occurred. This location is shifted from the actual location for partial redaction but falls on the same block. Longitude - The longitude of the location where the incident occurred. This location is shifted from the actual location for partial redaction but falls on the same block. Location - The location where the incident occurred in a format that allows for creation of maps and other geographic operations on this data portal. This location is shifted from the actual location for partial redaction but falls on the same block. Acknowledgements I really want to say thank you to the City of Chicago and the Chicago Police Department for making this comprehensive data set available to everyone!  Inspiration How has crime changed over the years? Is it possible to predict where or when a crime will be committed? Which areas of the city have evolved over this time span?",:ID:Case Number:Date:Block:IUCR:Primary Type:Description:Location Description:Arrest:Domestic:Beat:District:Ward:Community Area:FBI Code:X Coordinate:Y Coordinate:Year:Updated On:Latitude:Longitude:Location:,numeric:numeric:string:dateTime:string:numeric:string:string:string:boolean:boolean:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:dateTime:numeric:numeric:string:,crime
Health Insurance Marketplace , US Department of Health and Human Services , www.kaggle.com/hhs/health-insurance-marketplace , Tue May 02 2017 01:46:50 GMT+0530 (IST) , Explore health and dental plans data in the US Health Insurance Marketplace ,9435, human medicine- economics- ,"The Health Insurance Marketplace Public Use Files contain data on health and dental plans offered to individuals and small businesses through the US Health Insurance Marketplace.  Exploration Ideas To help get you started here are some data exploration ideas  How do plan rates and benefits vary across states? How do plan benefits relate to plan rates? How do plan rates vary by age? How do plans vary across insurance network providers?  See this forum thread for more ideas and post there if you want to add your own ideas or answer some of the open questions! Data Description This data was originally prepared and released by the Centers for Medicare & Medicaid Services (CMS). Please read the CMS Disclaimer-User Agreement before using this data. Here we've processed the data to facilitate analytics. This processed version has three components 1. Original versions of the data The original versions of the 2014 2015 2016 data are available in the ""raw"" directory of the download and ""../input/raw"" on Kaggle Scripts. Search for ""dictionaries"" on this page to find the data dictionaries describing the individual raw files. 2. Combined CSV files that contain In the top level directory of the download (""../input"" on Kaggle Scripts) there are six CSV files that contain the combined at across all years  BenefitsCostSharing.csv BusinessRules.csv Network.csv PlanAttributes.csv Rate.csv ServiceArea.csv  Additionally there are two CSV files that facilitate joining data across years  Crosswalk2015.csv - joining 2014 and 2015 data Crosswalk2016.csv - joining 2015 and 2016 data  3. SQLite database The ""database.sqlite"" file contains tables corresponding to each of the processed CSV files. The code to create the processed version of this data is available on GitHub.",BenefitName:BusinessYear:CoinsInnTier1:CoinsInnTier2:CoinsOutofNet:CopayInnTier1:CopayInnTier2:CopayOutofNet:EHBVarReason:Exclusions:Explanation:ImportDate:IsCovered:IsEHB:IsExclFromInnMOOP:IsExclFromOonMOOP:IsStateMandate:IsSubjToDedTier1:IsSubjToDedTier2:IssuerId:IssuerId2:LimitQty:LimitUnit:MinimumStay:PlanId:QuantLimitOnSvc:RowNumber:SourceName:StandardComponentId:StateCode:StateCode2:VersionNum:,string:numeric:string:string:string:string:string:string:string:string:string:dateTime:string:string:string:string:string:string:string:numeric:numeric:numeric:string:string:string:string:numeric:string:string:string:string:numeric:,Insurance
Pesticide Data Program (2015) , United States Department of Agriculture , www.kaggle.com/usdeptofag/pesticide-data-program-2015 , Wed Nov 16 2016 03:26:03 GMT+0530 (IST) , Study of pesticide residues in food ,522, food and drink- agriculture- ,Context This dataset contains information on pesticide residues in food. The U.S. Department of Agriculture (USDA) Agricultural Marketing Service (AMS) conducts the Pesticide Data Program (PDP) every year to help assure consumers that the food they feed themselves and their families is safe. Ultimately if EPA determines a pesticide is not safe for human consumption it is removed from the market. The PDP tests a wide variety of domestic and imported foods with a strong focus on foods that are consumed by infants and children. EPA relies on PDP data to conduct dietary risk assessments and to ensure that any pesticide residues in foods remain at safe levels. USDA uses the data to better understand the relationship of pesticide residues to agricultural practices and to enhance USDA’s Integrated Pest Management objectives. USDA also works with U.S. growers to improve agricultural practices. Content While the original 2015 MS Access database can be found [here (https//www.ams.usda.gov/datasets/pdp/pdpdata) the data has been transferred to a SQLite database for easier more open use. The database contains two tables Sample Data and Results Data. Each sampling includes attributes such as extraction method the laboratory responsible for the test and EPA tolerances among others. These attributes are labeled with codes which can be referenced in PDF format here or integrated into the database using the included csv files.  Inspiration  What are the most common types of pesticides tested in this study? Do certain states tend to use one particular pesticide type over another? Does pesticide type correspond more with crop type or location (state)? Are any produce types found to have higher pesticide levels than assumed safe by EPA standards? By combining databases from several years of PDP tests can you see any trends in pesticide use?  Acknowledgement This dataset is part of the USDA PDP yearly database and the original source can be found here.,Annotate Code:Annotated Information:,string:string:,food and nutrition
New York City Taxi with OSRM , oscarleo , www.kaggle.com/oscarleo/new-york-city-taxi-with-osrm , Sun Aug 06 2017 19:02:59 GMT+0530 (IST) , Helpful dataset for New York Taxi Playground ,2565, taxi services- ,Context I created this data set to help with the New York City Taxi Trip Duration playground. I used OSRM to extract information about the fastest routes for each data point.  I think it will be very useful for anyone doing work in that competition. Please try it out and tell me what you want me to add. I intend to improve and add features. Content starting_street The street where the taxi-trip starts. In version 1 this field contained a lot of empty values. That has been dealt with. end_street The street where the taxi-trip ends. In version 1 this field contained a lot of empty values. That has been dealt with. total_distance The total distance is measured between the pickup coordinates and the drop-off coordinates in train.csv and test.csv. The unit is meters. total_travel_time The total travel time for that data point in seconds number_of_steps The number of steps on that trip. One step consists of some driving and an action the taxi needs to perform. It can be something like a turn or going on to a highway. See step_maneuvers for more information. street_for_each_step A list of streets where each step occurs. Multiple steps can be performed on the same street. Therefore there might the same street might occur multiple times. (The values are stored as a string separated by '|') distance_per_step The distance for each step. (The values are stored as a string separated by '|') travel_time_per_step The travel time for each step (The values are stored as a string separated by '|') step_maneuvers The action (or maneuver) performed in each step. The possible maneuvers are  turn a basic turn  new name no turn is taken/possible but the road name changes. depart The trip starts arrive The trip ends merge Merge onto a street (e.g. getting on the highway from a ramp) on ramp Entering a highway (direction given my  modifier ) off ramp Exiting a highway fork The road forks end of road The road ends in a T intersection continue Turn to stay on the same road roundabout   A roundabout rotary A traffic circle (a bigger roundabout) roundabout turn  A small roundabout that can be treated as a regular turn  (The values are stored as a string separated by '|') step_direction The direction for each action (or maneuver) step_location_list The coordinates for each action (or maneuver),BOROUGH:,string:,roadways
CS:GO Dataset , Christopher Sardegna , www.kaggle.com/reagentx/HLTVData , Sun Oct 15 2017 08:58:45 GMT+0530 (IST) , All pro/semi-pro teams events players lineups and matches with statistics. ,665, video games- ,For the most up-to-date CSVs please see the GitHub page! Context In an effort to determine when players played on which teams in the esport Counter-Strike Global Offensive I made this dataset. Match results are included as well. Content All column headers are provided below. Acknowledgements The source is HLTV.org. Scraper code is available here.  Follow me on Twitter @rxcs!,2980:,numeric:,video games
The Tate Collection , Rachael Tatman , www.kaggle.com/rtatman/the-tate-collection , Sat Aug 19 2017 03:46:15 GMT+0530 (IST) , Metadata for 70000 artworks from the Tate ,50, museums- visual arts- europe- ,"Context ""Tate is an institution that houses the United Kingdom's national collection of British art and international modern and contemporary art. It is a network of four art museums Tate Britain London (until 2000 known as the Tate Gallery founded 1897) Tate Liverpool (founded 1988) Tate St Ives Cornwall (founded 1993) and Tate Modern London (founded 2000) with a complementary website Tate Online (created 1998). Tate is not a government institution but its main sponsor is the UK Department for Culture Media and Sport. ""The name 'Tate' is used also as the operating name for the corporate body which was established by the Museums and Galleries Act 1992 as 'The Board of Trustees of the Tate Gallery'. ""The gallery was founded in 1897 as the National Gallery of British Art. When its role was changed to include the national collection of modern art as well as the national collection of British art in 1932 it was renamed the Tate Gallery after sugar magnate Henry Tate of Tate & Lyle who had laid the foundations for the collection. The Tate Gallery was housed in the current building occupied by Tate Britain which is situated in Millbank London. In 2000 the Tate Gallery transformed itself into the current-day Tate or the Tate Modern which consists of a federation of four museums Tate Britain which displays the collection of British art from 1500 to the present day; Tate Modern which is also in London houses the Tate's collection of British and international modern and contemporary art from 1900 to the present day. Tate Liverpool has the same purpose as Tate Modern but on a smaller scale and Tate St Ives displays modern and contemporary art by artists who have connections with the area. All four museums share the Tate Collection. One of the Tate's most publicised art events is the awarding of the annual Turner Prize which takes place at Tate Britain."" -- Tate. (n.d.). In Wikipedia. Retrieved August 18 2017 from https//en.wikipedia.org/wiki/Plagiarism. Text reproduced here under a CC-BY-SA 3.0 license. Content This dataset contains the metadata for around 70000 artworks that Tate owns or jointly owns with the National Galleries of Scotland as part of ARTIST ROOMS. Metadata for around 3500 associated artists is also included. The metadata here is released under the Creative Commons Public Domain CC0 licence. Images are not included and are not part of the dataset.  This dataset contains the following information for each artwork  Id accession_number artist artistRole artistId title dateText medium creditLine year acquisitionYear dimensions width  height  depth units inscription thumbnailCopyright  thumbnailUr url  You may also like  Museum of Modern Art Collection Title artist date and medium of every artwork in the MoMA collection The Metropolitan Museum of Art Open Access Explore information on more than 420000 historic artworks ",id;accession_number;artist;artistRole;artistId;title;dateText;medium;creditLine;year;acquisitionYear;dimensions;width;height;depth;units;inscription;thumbnailCopyright;thumbnailUrl;url:,string:,visual arts
Brazilian Aeronautics Accidents , Paulo Henrique Vasconcellos , www.kaggle.com/paulovasconcellos/aeronautics-accidents-in-brazil , Wed Feb 08 2017 07:34:06 GMT+0530 (IST) , Occurrences involving aircrafts from the last 10 years in Brazil ,153, brazil- aviation- ,Context For many years airplanes have been considered the second safest transport mean in the world - losing just to elevators. Traveling great distances in short time those aircrafts have brought several advantaged for the world both in commercial and regular application. Unfortunately as any transport mean aircrafts have their own count of tragedies. The last event envolving airplanes - to the publication date - was the accident envolving the brazilian soccer team Chapecoense and a LAMIA's aircraft which was transporting them to Colombia for a Championship. This tragedy brought back discussions and controversies about aircraft's security and human capacity during aeronautics occurrences. Content This dataset was available by CENIPA - Centro de Investigação e Prevenção de Acidentes aeronáuticos - or Aeronautical Accidents Investigation and Prevention Center. Such files contains informations about occurrences which envolved aircrafts in the last 10 years. You may access more updated data by visiting Brazilian Open Data's official website or clicking in the download links below.  Acknowledgements This dataset is available for studies and analysis thanks to CENIPA.,:aircraft_id:occurrence_id:registration:operator_id:equipment:manufacturer:model:engine_type:engines_amount:takeoff_max_weight (Lbs):seatings_amount:year_manufacture:registration_country:registration_category:registration_aviation:origin_flight:destination_flight:operation_phase:type_operation:damage_level:fatalities_amount:extraction_day:,numeric:numeric:numeric:string:numeric:string:string:string:string:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:dateTime:,airways
Detailed NFL Play-by-Play Data 2009-2016 , Max Horowitz , www.kaggle.com/maxhorowitz/nflplaybyplay2009to2016 , Fri Jul 28 2017 07:54:29 GMT+0530 (IST) , nflscrapR generated NFL dataset wiith expected points and win probability ,456, american football- sports- ,Introduction The lack of publicly available National Football League (NFL) data sources has been a major obstacle in the creation of modern reproducible research in football analytics.  While clean play-by-play data is available via open-source software packages in other sports (e.g. nhlscrapr for hockey; PitchF/x data in baseball; the Basketball Reference for basketball) the equivalent datasets are not freely available for researchers interested in the statistical analysis of the NFL.  To solve this issue a group of Carnegie Mellon University statistical researchers including Maksim Horowitz Ron Yurko and Sam Ventura built and released nflscrapR an R package which uses an API maintained by the NFL to scrape clean parse and output clean datasets at the individual play player game and season levels.  Using the data outputted by the package the trio went on to develop reproducible methods for building expected point and win probability models for the NFL. The outputs of these models are included in this dataset and can be accessed using the nflscrapR package. Content The dataset made available on Kaggle contains all the regular season plays from the 2009-2016 NFL seasons. The dataset has 356768 rows and 100 columns. Each play is broken down into great detail containing information on game situation players involved results and advanced metrics such as expected point and win probability values. Detailed information about the dataset can be found at the following web page along with more NFL data https//github.com/ryurko/nflscrapR-data. Acknowledgements This dataset was compiled by Ron Yurko Sam Ventura and myself. Special shout-out to Ron for improving our current expected points and win probability models and compiling this dataset. All three of us are proud founders of the Carnegie Mellon Sports Analytics Club. Inspiration This dataset is meant to both grow and bring together the community of sports analytics by providing clean and easily accessible NFL data that has never been availabe on this scale for free.,Date:GameID:Drive:qtr:down:time:TimeUnder:TimeSecs:PlayTimeDiff:SideofField:yrdln:yrdline100:ydstogo:ydsnet:GoalToGo:FirstDown:posteam:DefensiveTeam:desc:PlayAttempted:Yards.Gained:sp:Touchdown:ExPointResult:TwoPointConv:DefTwoPoint:Safety:Onsidekick:PuntResult:PlayType:Passer:Passer_ID:PassAttempt:PassOutcome:PassLength:AirYards:YardsAfterCatch:QBHit:PassLocation:InterceptionThrown:Interceptor:Rusher:Rusher_ID:RushAttempt:RunLocation:RunGap:Receiver:Receiver_ID:Reception:ReturnResult:Returner:BlockingPlayer:Tackler1:Tackler2:FieldGoalResult:FieldGoalDistance:Fumble:RecFumbTeam:RecFumbPlayer:Sack:Challenge.Replay:ChalReplayResult:Accepted.Penalty:PenalizedTeam:PenaltyType:PenalizedPlayer:Penalty.Yards:PosTeamScore:DefTeamScore:ScoreDiff:AbsScoreDiff:HomeTeam:AwayTeam:Timeout_Indicator:Timeout_Team:posteam_timeouts_pre:HomeTimeouts_Remaining_Pre:AwayTimeouts_Remaining_Pre:HomeTimeouts_Remaining_Post:AwayTimeouts_Remaining_Post:No_Score_Prob:Opp_Field_Goal_Prob:Opp_Safety_Prob:Opp_Touchdown_Prob:Field_Goal_Prob:Safety_Prob:Touchdown_Prob:ExPoint_Prob:TwoPoint_Prob:ExpPts:EPA:airEPA:yacEPA:Home_WP_pre:Away_WP_pre:Home_WP_post:Away_WP_post:Win_Prob:WPA:Season:,dateTime:numeric:numeric:numeric:numeric:dateTime:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:numeric:numeric:numeric:numeric:string:string:string:numeric:numeric:string:string:string:string:numeric:string:string:numeric:numeric:numeric:string:numeric:string:string:string:numeric:string:string:string:string:numeric:string:string:string:string:string:string:string:numeric:string:string:numeric:numeric:string:numeric:string:string:string:numeric:numeric:numeric:numeric:numeric:string:string:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,football
Japanese lemma frequency , Rachael Tatman , www.kaggle.com/rtatman/japanese-lemma-frequency , Tue Jul 25 2017 01:44:06 GMT+0530 (IST) , A list of the 15000 most common word forms  in Japanese ,54, languages- linguistics- ,Context A lemma is the uninflected form of a word. So while “tree” and “trees” are two words they are the same lemma “tree”. Similarly “go” “went” and “going” are all forms of the underlying lemma “to go”. This dataset contains the most common lemmas in Japanese. Content This dataset contains the most common Japanese lemmas from the Internet Corpus as tagged by the ChaSen morphological tagger for Japanese (http//chasen.naist.jp/hiki/ChaSen/). For each lemma both the frequency (number of times it occurs in the corpus) and its relative rank to other lemmas is provided. The total corpus size is 253071774 tokens with a lexicon of 451963 types. Acknowledgements This dataset was developed at the University of Leeds by Centre for Translation Studies(more information http//corpus.leeds.ac.uk/list.html) and is distributed under a CC-BY license. Inspiration This dataset is an especially helpful resource for work on Japanese texts.  What is the distribution of hiragana katakana and kanji characters among common lemmas? Can you use machine translation to find the equivalent lemmas and their frequency in other languages? Is there a lot of cross-linguistic difference between what concepts are the most frequent? Which parts of speech are the most common in Japanese? Are these different across languages? ,rank:frequency:lemma:,numeric:numeric:string:,grammar
The Sign Language Analyses (SLAY) Database , Rachael Tatman , www.kaggle.com/rtatman/sign-language-analyses , Fri Jul 14 2017 02:49:01 GMT+0530 (IST) , A database of information on the grammers of signed languages ,60, grammar- languages- linguistics- ,Context Signed languages have many unique ways to encode meaning. Some of these ways include using different handshapes motions which direction the palm and wrist are facing whether one hand or two is used and facial expressions. This dataset compares which different sign languages use which of these grammatical building blocks. Content This database contains information on the parameters used by 87 signed languages taken from various academic sources and compiled by hand. Acknowledgements This dataset was collected by Rachael Tatman during the process of linguistic research and is released to the public domain. The database can be cited by reference to this paper   Tatman R. (2015). The Sign Language Analyses (SLAY) Database⋆ (Vol. 33). University of Washington Working Papers in Linguistics.  https//depts.washington.edu/uwwpl/vol33/2-Tatman-SLAY.pdf  Inspiration One analysis of this data is presented can be found in this paper  but there are plenty of additional questions that could be asked. Some examples - Does a language’s geographic location factor into what parameters it uses? - Does the year that a grammatical analysis was published have an effect on how many parameters it proposes for a language? You may also be interested in  Atlas of Pidgin and Creole Language Structures World Language Family Map World Atlas of Language Structures Information on the linguistic structures in 2679 languages ,language (ISO key):reference (as Bibtex entry):movement:location:handshape:palm orientation:number of hands:Non-manuals:others:notes:,string:string:string:string:string:string:string:string:string:string:,grammar
World Atlas of Language Structures , Rachael Tatman , www.kaggle.com/rtatman/world-atlas-of-language-structures , Fri Sep 08 2017 05:10:05 GMT+0530 (IST) , Information on the linguistic structures in 2679  languages ,102, languages- linguistics- ,Context There are over 7000 human languages in the world. The World Atlas of Language Structures (WALS) contains information on the structure of 2679 of them. It also includes information about where languages are used. WALS is widely-cited and used in the linguistics research community. Content The World Atlas of Language Structures (WALS) is a large database of structural (phonological grammatical lexical) properties of languages gathered from descriptive materials (such as reference grammars) by a team of 55 authors. The atlas provides information on the location linguistic affiliation and basic typological features of a great number of the world's languages WALS Online is a publication of the (Max Planck Institute for Evolutionary Anthropology)[http//www.eva.mpg.de/]. It is a separate publication edited by Dryer Matthew S. & Haspelmath Martin (Leipzig Max Planck Institute for Evolutionary Anthropology 2013) The main programmer is Robert Forkel. This dataset includes three files  source.bib A BibTex file with all of the sources cited in the dataset in it language.csv A file with a list of all the languages included in WALS wals-data.csv A file containing information on the features associated with each individual language  Acknowledgements This dataset is licensed under a Creative Commons Attribution 4.0 International License . The World Atlas of Language Structures was edited by Matthew Dryer and Martin Haspelmath. If you use this data in your work please include the following citation  Dryer Matthew S. & Haspelmath Martin (eds.) 2013. The World Atlas of Language Structures Online. Leipzig Max Planck Institute for Evolutionary Anthropology. (Available online at http//wals.info Accessed on September 7 2017.) Inspiration  This dataset was designed to make interactive maps of language features. Can you make an interactive map that shows different linguistic features? You might find it helpful to use Leaflet (for R) or Plotly (for Python). This blog post is a great resource to help you get started. There’s a lot of discussion of “linguistic universals” in linguistics. These are specific features that every language (should) have. Can you identify any features that you think may be universals from this dataset?  You may also like  Atlas of Pidgin and Creole Language Structures Information on 76 Creole and Pidgin Languages World Language Family Map The Sign Language Analyses (SLAY) Database ,"wals_code:iso_code:glottocode:Name:latitude:longitude:genus:family:macroarea:countrycodes:1A Consonant Inventories:2A Vowel Quality Inventories:3A Consonant-Vowel Ratio:4A Voicing in Plosives and Fricatives:5A Voicing and Gaps in Plosive Systems:6A Uvular Consonants:7A Glottalized Consonants:8A Lateral Consonants:9A The Velar Nasal:10A Vowel Nasalization:11A Front Rounded Vowels:12A Syllable Structure:13A Tone:14A Fixed Stress Locations:15A Weight-Sensitive Stress:16A Weight Factors in Weight-Sensitive Stress Systems:17A Rhythm Types:18A Absence of Common Consonants:19A Presence of Uncommon Consonants:20A Fusion of Selected Inflectional Formatives:21A Exponence of Selected Inflectional Formatives:22A Inflectional Synthesis of the Verb:23A Locus of Marking in the Clause:24A Locus of Marking in Possessive Noun Phrases:25A Locus of Marking: Whole-language Typology:26A Prefixing vs. Suffixing in Inflectional Morphology:27A Reduplication:28A Case Syncretism:29A Syncretism in Verbal Person/Number Marking:30A Number of Genders:31A Sex-based and Non-sex-based Gender Systems:32A Systems of Gender Assignment:33A Coding of Nominal Plurality:34A Occurrence of Nominal Plurality:35A Plurality in Independent Personal Pronouns:36A The Associative Plural:37A Definite Articles:38A Indefinite Articles:39A Inclusive/Exclusive Distinction in Independent Pronouns:40A Inclusive/Exclusive Distinction in Verbal Inflection:41A Distance Contrasts in Demonstratives:42A Pronominal and Adnominal Demonstratives:43A Third Person Pronouns and Demonstratives:44A Gender Distinctions in Independent Personal Pronouns:45A Politeness Distinctions in Pronouns:46A Indefinite Pronouns:47A Intensifiers and Reflexive Pronouns:48A Person Marking on Adpositions:49A Number of Cases:50A Asymmetrical Case-Marking:51A Position of Case Affixes:52A Comitatives and Instrumentals:53A Ordinal Numerals:54A Distributive Numerals:55A Numeral Classifiers:56A Conjunctions and Universal Quantifiers:57A Position of Pronominal Possessive Affixes:58A Obligatory Possessive Inflection:59A Possessive Classification:60A Genitives, Adjectives and Relative Clauses:61A Adjectives without Nouns:62A Action Nominal Constructions:63A Noun Phrase Conjunction:64A Nominal and Verbal Conjunction:65A Perfective/Imperfective Aspect:66A The Past Tense:67A The Future Tense:68A The Perfect:69A Position of Tense-Aspect Affixes:70A The Morphological Imperative:71A The Prohibitive:72A Imperative-Hortative Systems:73A The Optative:74A Situational Possibility:75A Epistemic Possibility:76A Overlap between Situational and Epistemic Modal Marking:77A Semantic Distinctions of Evidentiality:78A Coding of Evidentiality:79A Suppletion According to Tense and Aspect:80A Verbal Number and Suppletion:81A Order of Subject, Object and Verb:82A Order of Subject and Verb:83A Order of Object and Verb:84A Order of Object, Oblique, and Verb:85A Order of Adposition and Noun Phrase:86A Order of Genitive and Noun:87A Order of Adjective and Noun:88A Order of Demonstrative and Noun:89A Order of Numeral and Noun:90A Order of Relative Clause and Noun:91A Order of Degree Word and Adjective:92A Position of Polar Question Particles:93A Position of Interrogative Phrases in Content Questions:94A Order of Adverbial Subordinator and Clause:95A Relationship between the Order of Object and Verb and the Order of Adposition and Noun Phrase:96A Relationship between the Order of Object and Verb and the Order of Relative Clause and Noun:97A Relationship between the Order of Object and Verb and the Order of Adjective and Noun:98A Alignment of Case Marking of Full Noun Phrases:99A Alignment of Case Marking of Pronouns:100A Alignment of Verbal Person Marking:101A Expression of Pronominal Subjects:102A Verbal Person Marking:103A Third Person Zero of Verbal Person Marking:104A Order of Person Markers on the Verb:105A Ditransitive Constructions: The Verb 'Give':106A Reciprocal Constructions:107A Passive Constructions:108A Antipassive Constructions:109A Applicative Constructions:110A Periphrastic Causative Constructions:111A Nonperiphrastic Causative Constructions:112A Negative Morphemes:113A Symmetric and Asymmetric Standard Negation:114A Subtypes of Asymmetric Standard Negation:115A Negative Indefinite Pronouns and Predicate Negation:116A Polar Questions:117A Predicative Possession:118A Predicative Adjectives:119A Nominal and Locational Predication:120A Zero Copula for Predicate Nominals:121A Comparative Constructions:122A Relativization on Subjects:123A Relativization on Obliques:124A 'Want' Complement Subjects:125A Purpose Clauses:126A 'When' Clauses:127A Reason Clauses:128A Utterance Complement Clauses:129A Hand and Arm:130A Finger and Hand:131A Numeral Bases:132A Number of Non-Derived Basic Colour Categories:133A Number of Basic Colour Categories:134A Green and Blue:135A Red and Yellow:136A M-T Pronouns:137A N-M Pronouns:138A Tea:139A Irregular Negatives in Sign Languages:140A Question Particles in Sign Languages:141A Writing Systems:142A Para-Linguistic Usages of Clicks:143F Postverbal Negative Morphemes:90B Prenominal relative clauses:144Y The Position of Negative Morphemes in Object-Initial Languages:90C Postnominal relative clauses:144P NegSOV Order:144J SVNegO Order:144N Obligatory Double Negation in SOV languages:144S SOVNeg Order:144X Verb-Initial with Clause-Final Negative:144A Position of Negative Word With Respect to Subject, Object, and Verb:90G Double-headed relative clauses:90E Correlative relative clauses:144V Verb-Initial with Preverbal Negative:144I SNegVO Order:144R SONegV Order:143B Obligatory Double Negation:144M Multiple Negative Constructions in SOV Languages:144U Double negation in verb-initial languages:144G Optional Double Negation in SVO languages:144K SVONeg Order:144B Position of negative words relative to beginning and end of clause and with respect to adjacency to verb:144F Obligatory Double Negation in SVO languages:90D Internally-headed relative clauses:144E Multiple Negative Constructions in SVO Languages:144D The Position of Negative Morphemes in SVO Languages:81B Languages with two Dominant Orders of Subject, Object, and Verb:143E Preverbal Negative Morphemes:143C Optional Double Negation:90F Adjoined relative clauses:143A Order of Negative Morpheme and Verb:144W Verb-Initial with Negative that is Immediately Postverbal or between Subject and Object:144O Optional Double Negation in SOV languages:144Q SNegOV Order:144L The Position of Negative Morphemes in SOV Languages:144H NegSVO Order:144C Languages with different word order in negative clauses:144T The Position of Negative Morphemes in Verb-Initial Languages:143G Minor morphological means of signaling negation:143D Optional Triple Negation:39B Inclusive/Exclusive Forms in Pama-Nyungan:137B M in Second Person Singular:136B M in First Person Singular:109B Other Roles of Applied Objects:10B Nasal Vowels in West Africa:25B Zero Marking of A and P Arguments:21B Exponence of Tense-Aspect-Mood Inflection:108B Productivity of the Antipassive Construction:130B Cultural Categories of Languages with Identity of 'Finger' and 'Hand':58B Number of Possessive Nouns:79B Suppletion in Imperatives and Hortatives:",string:string:string:string:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:dateTime:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:,grammar
Health Nutrition and Population Statistics , World Bank , www.kaggle.com/theworldbank/health-nutrition-and-population-statistics , Fri Nov 18 2016 11:16:51 GMT+0530 (IST) , State of human health across the world ,2088, nutrition- health- demographics- ,Context HealthStats provides key health nutrition and population statistics gathered from a variety of international sources. Themes include population dynamics nutrition reproductive health health financing medical resources and usage immunization infectious diseases HIV/AIDS DALY population projections and lending. HealthStats also includes health nutrition and population statistics by wealth quintiles. Content This dataset includes 345 indicators such as immunization rates malnutrition prevalence and vitamin A supplementation rates across 263 countries around the world. Data was collected on a yearly basis from 1960-2016. Inspiration  In your opinion what are some of the more surprising indicators? Are there any you would consider adding? Is there a relationship between condom use and rates of children born with HIV? How do these rates compare over time? Which countries have the highest consumption of iodized salt? Has this indicator changed over time and if so in which countries? Are there any other indicators that seem to correlate with this one?   Acknowledgements Data was acquired from the World Bank and can be accessed in multiple formats here.,,,demography
Sentiment Lexicons for 81 Languages , Rachael Tatman , www.kaggle.com/rtatman/sentiment-lexicons-for-81-languages , Thu Sep 14 2017 01:29:05 GMT+0530 (IST) , Sentiment Polarity Lexicons (Positive vs. Negative) ,214, languages- linguistics- ,Context Sentiment analysis the task of automatically detecting whether a piece of text is positive or negative generally relies on a hand-curated list of words with positive sentiment (good great awesome) and negative sentiment (bad gross awful). This dataset contains both positive and negative sentiment lexicons for 81 languages. Content The sentiment lexicons in this dataset were generated via graph propagation based on a knowledge graph--a graphical representation of real-world entities and the links between them. The general intuition is that words which are closely linked on a  knowledge graph probably have similar sentiment polarities. For this project sentiments were generated based on English sentiment lexicons.  This dataset contains sentiment lexicons for the following languages  Afrikaans Albanian Arabic Aragonese Armenian Azerbaijani Basque Belarusian Bengali Bosnian Breton Bulgarian Catalan Chinese Croatian Czech Danish Dutch Esperanto Estonian Faroese Finnish French Galician Georgian German Greek Gujarati Haitian Creole Hebrew Hindi Hungarian Icelandic Ido Indonesian Interlingua Irish Italian Kannada Khmer Kirghiz Korean Kurdish Latin Latvian Lithuanian Luxembourgish Macedonian Malay Maltese Marathi Norwegian Norwegian Persian Polish Portuguese Romanian Romansh Russian Scottish Serbian Slovak Slovene Spanish Swahili Swedish Tagalog Tamil Telugu Thai Turkish Turkmen Ukrainian Urdu Uzbek Vietnamese Volapük Walloon Welsh Western Frisian Yiddish For more information and additional sentiment lexicons please visit the project’s website.   Acknowledgements This dataset was collected by Yanqing Chen and Steven Skiena. If you use it in your work please cite the following paper Chen Y. & Skiena S. (2014). Building Sentiment Lexicons for All Major Languages. In ACL (2) (pp. 383-389). It is distributed here under the GNU General Public License. Note that this is the full GPL which allows many free uses but does not allow its incorporation into any type of distributed proprietary software even in part or in translation. For commercial applications please contact the dataset creators. Inspiration  These word lists contain many words with similar meanings. Can you automatically detect which words are cognates? Can you use these sentiment lexicons to reverse-engineer the knowledge graphs that generated them? ,,,text analysis
The Counted: Killed by Police 2015-2016 , The Guardian , www.kaggle.com/the-guardian/the-counted , Sat Jan 07 2017 20:21:12 GMT+0530 (IST) , Use of deadly force by police officers in United States ,618, crime- ,The Counted is a project by the Guardian – and you – working to count the number of people killed by police and other law enforcement agencies in the United States throughout 2015 and 2016 to monitor their demographics and to tell the stories of how they died. The database will combine Guardian reporting with verified crowdsourced information to build a more comprehensive record of such fatalities. The Counted is the most thorough public accounting for deadly use of force in the US but it will operate as an imperfect work in progress – and will be updated by Guardian reporters and interactive journalists frequently. Any deaths arising directly from encounters with law enforcement will be included in the database. This will inevitably include but will likely not be limited to people who were shot tasered and struck by police vehicles as well those who died in police custody. Self-inflicted deaths during encounters with law enforcement or in police custody or detention facilities will not be included. The US government has no comprehensive record of the number of people killed by law enforcement. This lack of basic data has been glaring amid the protests riots and worldwide debate set in motion by the fatal police shooting of Michael Brown in August 2014. The Guardian agrees with those analysts campaign groups activists and authorities who argue that such accounting is a prerequisite for an informed public discussion about the use of force by police. Contributions of any information that may improve the quality of our data will be greatly welcomed as we work toward better accountability. Please contact us at thecounted@theguardian.com. CREDITS Research and Reporting Jon Swaine Oliver Laughland Jamiles Lartey Design and Production Kenan Davis Rich Harris Nadja Popovich Kenton Powell,uid:name:age:gender:raceethnicity:armed:month:day:year:streetaddress:city:state:latitude:longitude:,numeric:string:numeric:boolean:string:string:dateTime:numeric:numeric:string:string:string:string:string:,crime
London Police Records , Sohier Dane , www.kaggle.com/sohier/london-police-records , Tue Aug 15 2017 05:41:34 GMT+0530 (IST) , A snapshot of crime outcome and stop and search data ,118, crime- government- ,This dataset provides a complete snapshot of crime outcome and stop and search data as held by the Home Office from late 2014 through mid 2017 for London both the greater metro and the city. Content The core fields are as follows Reported by    The force that provided the data about the crime. Falls within   At present also the force that provided the data about the crime. This is currently being looked into and is likely to change in the near future. Longitude and Latitude The anonymised coordinates of the crime. LSOA code and LSOA name    References to the Lower Layer Super Output Area that the anonymised point falls into according to the LSOA boundaries provided by the Office for National Statistics. Crime type One of the crime types listed in the Police.UK FAQ. Last outcome category  A reference to whichever of the outcomes associated with the crime occurred most recently. For example this crime's 'Last outcome category' would be 'Offender fined'. Context    A field provided for forces to provide additional human-readable data about individual crimes. Currently for newly added CSVs this is always empty. For additional details including the steps taken to anonymize the data please see https//data.police.uk/about/#provenance. Acknowledgements This dataset was kindly released by the British Home Office under the Open Government License 3.0 at https//data.police.uk/data/. If you are looking for more data they cover much more than London! All major cities in England and Wales are available adding up to roughly 2gb of new data per month.,Crime ID:Month:Reported by:Falls within:Longitude:Latitude:Location:LSOA code:LSOA name:Outcome type:,string:dateTime:string:string:numeric:numeric:string:string:string:string:,crime
Foreign Exchange (FX) Prediction - USD/JPY , Team AI , www.kaggle.com/team-ai/foreign-exchange-fx-prediction-usdjpy , Sun Aug 13 2017 11:56:53 GMT+0530 (IST) , Jan 2017 Martket Data(Lightweight CSV) ,69, time series- finance- ,Context Coming Soon Content Coming Soon Acknowledgements Special Thanks to http//www.histdata.com/download-free-forex-data/ Inspiration 実際の取引にこの情報を使うときは十分ご注意ください。弊社およびコミュニティメンバーは損失の責任を取ることができません。,2017.01.31:23:00:113.147:113.173:113.135:113.162:,dateTime:dateTime:numeric:numeric:numeric:numeric:,banking
EURUSD - 15m - 2010-2016 , Michal Januszewski , www.kaggle.com/meehau/EURUSD , Wed Feb 22 2017 20:12:13 GMT+0530 (IST) , FOREX currency rates data for EURUSD 15 minute candles BID years 2010-2016 ,362, finance- money- ,Context I've always wanted to have a proper sample Forex currency rates dataset for testing purposes so I've created one. Content The data contains Forex EURUSD currency rates in 15-minute slices (OHLC - Open High Low Close and Volume). BID price only. Spread is not provided so be careful.  (Quick reminder Bid price + Spread = Ask price) The dates are in the yyyy-mm-dd hhmm format GMT. Volume is in Units. Acknowledgements Dukascopy Bank SA https//www.dukascopy.com/swiss/english/marketwatch/historical/ Inspiration Just would like to see if there is still an way to beat the current Forex market conditions with the prop traders' advanced automatic algorithms running in the wild.,Time:Open:High:Low:Close:Volume:,dateTime:numeric:numeric:numeric:numeric:numeric:,banking
Police Officer Deaths in the U.S. , FiveThirtyEight , www.kaggle.com/fivethirtyeight/police-officer-deaths-in-the-us , Sat Nov 05 2016 23:54:01 GMT+0530 (IST) , On-Duty Police Officer Deaths from 1971-2016 ,807, death- crime- ,Context This dataset contains data behind the story The Dallas Shooting Was Among The Deadliest For Police In U.S. History. The data are scraped from ODMP and capture information on all tracked on-duty police officer deaths in the U.S. broken down by cause from 1971 until 2016. Content This dataset tags every entry as human or canine. There are 10 variables  person dept Department eow End of watch cause Cause of death cause_short Shortened cause of death date Cleaned EOW year Year from EOW canine dept_name state  Inspiration Using the data can you determine the temporal trend of police officer deaths by cause? By state? By department? Acknowledgements The primary source of data is the Officer Down Memorial Page (ODMP) started in 1996 by a college student who is now a police officer and who continues to maintain the database. The original data and code can be found on the FiveThirtyEight GitHub.,,,crime
Arrests by Baltimore Police Department , Amandeep Rathee , www.kaggle.com/arathee2/arrests-by-baltimore-police-department , Wed Nov 23 2016 11:56:14 GMT+0530 (IST) , Data of 131k arrests made by the Baltimore Police Department ,555, crime- ,Context This data represents the top arrest charge of those processed at Baltimore's Central Booking & Intake Facility. This data does not contain those who have been processed through Juvenile Booking. Content The data set was created on October 18 2011. The data set was last updated on November 18 2016. It is updated on a monthly basis. Metadata  Arrest-ID Age Sex Race ArrestDate ArrestTime ArrestLocation IncidentOffense IncidentLocation Charge ChargeDescription District Post Neighborhood Location1(Location Coordinates)  Past Research I have done my own analysis on the data which can be found on the following GitHub repository. Feel free to give any suggestions regarding the data. Github Link Inspiration  How arrests vary across different gender race age ? Which area in Baltimore has most number of arrests made ? What are the top offences and/or charges made while making arrests ?  Acknowledgements The data is hosted on Data set Source Baltimore Police Depratment's website Baltimore Police Department,,,crime
Uber Pickups in New York City , FiveThirtyEight , www.kaggle.com/fivethirtyeight/uber-pickups-in-new-york-city , Mon Nov 14 2016 00:58:07 GMT+0530 (IST) , Trip data for over 20 million Uber (and other for-hire vehicle) trips in NYC ,7334, road transport- ,Uber TLC FOIL Response This directory contains data on over 4.5 million Uber pickups in New York City from April to September 2014 and 14.3 million more Uber pickups from January to June 2015. Trip-level data on 10 other for-hire vehicle (FHV) companies as well as aggregated data for 329 FHV companies is also included. All the files are as they were received on August 3 Sept. 15 and Sept. 22 2015.  FiveThirtyEight obtained the data from the NYC Taxi & Limousine Commission (TLC) by submitting a Freedom of Information Law request on July 20 2015. The TLC has sent us the data in batches as it continues to review trip data Uber and other HFV companies have submitted to it. The TLC's correspondence with FiveThirtyEight is included in the files TLC_letter.pdf TLC_letter2.pdf and TLC_letter3.pdf. TLC records requests can be made here. This data was used for four FiveThirtyEight stories Uber Is Serving New York’s Outer Boroughs More Than Taxis Are Public Transit Should Be Uber’s New Best Friend Uber Is Taking Millions Of Manhattan Rides Away From Taxis and Is Uber Making NYC Rush-Hour Traffic Worse?. The Data The dataset contains roughly four groups of files  Uber trip data from 2014 (April - September) separated by month with detailed location information Uber trip data from 2015 (January - June) with less fine-grained location information non-Uber FHV (For-Hire Vehicle) trips. The trip information varies by company but can include day of trip time of trip pickup location driver's for-hire license number and vehicle's for-hire license number. aggregate ride and vehicle statistics for all FHV companies (and occasionally for taxi companies)  Uber trip data from 2014 There are six files of raw data on Uber pickups in New York City from April to September 2014. The files are separated by month and each has the following columns  Date/Time  The date and time of the Uber pickup Lat  The latitude of the Uber pickup Lon  The longitude of the Uber pickup Base  The TLC base company code affiliated with the Uber pickup  These files are named  uber-raw-data-apr14.csv uber-raw-data-aug14.csv uber-raw-data-jul14.csv uber-raw-data-jun14.csv uber-raw-data-may14.csv uber-raw-data-sep14.csv  Uber trip data from 2015 Also included is the file uber-raw-data-janjune-15.csv This file has the following columns  Dispatching_base_num  The TLC base company code of the base that dispatched the Uber Pickup_date  The date and time of the Uber pickup Affiliated_base_num  The TLC base company code affiliated with the Uber pickup locationID  The pickup location ID affiliated with the Uber pickup  The Base codes are for the following Uber bases B02512  Unter B02598  Hinter B02617  Weiter B02682  Schmecken B02764  Danach-NY B02765  Grun B02835  Dreist B02836  Drinnen For coarse-grained location information from these pickups the file taxi-zone-lookup.csv shows the taxi Zone (essentially neighborhood) and Borough for each locationID. Non-Uber FLV trips The dataset also contains 10 files of raw data on pickups from 10 for-hire vehicle (FHV) companies. The trip information varies by company but can include day of trip time of trip pickup location driver's for-hire license number and vehicle's for-hire license number. These files are named  American_B01362.csv Diplo_B01196.csv Highclass_B01717.csv Skyline_B00111.csv Carmel_B00256.csv Federal_02216.csv Lyft_B02510.csv Dial7_B00887.csv Firstclass_B01536.csv Prestige_B01338.csv  Aggregate Statistics There is also a file other-FHV-data-jan-aug-2015.csv containing daily pickup data for 329 FHV companies from January 2015 through August 2015. The file Uber-Jan-Feb-FOIL.csv contains aggregated daily Uber trip statistics in January and February 2015.,DATE:TIME:PICK UP ADDRESS::,dateTime:dateTime:string:string:,roadways
NYC Transit Data , mrwagner , www.kaggle.com/monsieurwagner/nyctransit , Sat Jul 22 2017 06:22:54 GMT+0530 (IST) , Station locations performance metrics and turnstile data for early 2016 ,179, ,Context This dataset includes locations of NYC subway stops performance data for all transit modes and turnstile data. Content The stop and performance data were last update June 2017. The turnstile data is for every week in January-July 2016.  Acknowledgements All credit to the Metropolitan Transportation Authority of the State of New York and NYC Open Data. Data downloaded from the MTA's http//datamine.mta.info/ Inspiration This dataset is intended as an accompaniment to the new New York City Taxi Trip Duration challenge. I'm wondering if transit intensity or quality near where a taxi ride starts (or ends) affects how long a taxi ride will last.,INDICATOR_SEQ:PARENT_SEQ:AGENCY_NAME:INDICATOR_NAME:DESCRIPTION:CATEGORY:FREQUENCY:DESIRED_CHANGE:INDICATOR_UNIT:DECIMAL_PLACES:PERIOD_YEAR:PERIOD_MONTH:YTD_TARGET:YTD_ACTUAL:MONTHLY_TARGET:MONTHLY_ACTUAL:YYYY_MM:,numeric:numeric:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:dateTime:,rail and metro
Game of Thrones , Myles O'Neill , www.kaggle.com/mylesoneill/game-of-thrones , Fri May 20 2016 07:02:31 GMT+0530 (IST) , Explore deaths and battles from this fantasy world ,11422, literature- social groups- war- ,"Overview Game of Thrones is a hit fantasy tv show based on the equally famous book series ""A Song of Fire and Ice"" by George RR Martin. The show is well known for its vastly complicated political landscape large number of characters and its frequent character deaths. Data Sources This dataset combines three sources of data all of which are based on information from the book series.  Firstly there is battles.csv which contains Chris Albon's ""The War of the Five Kings"" Dataset which can be found here https//github.com/chrisalbon/war_of_the_five_kings_dataset . Its a great collection of all of the battles in the series. Secondly we have character-deaths.csv from Erin Pierce and Ben Kahle. This dataset was created as a part of their Bayesian Survival Analysis which can be found here http//allendowney.blogspot.com/2015/03/bayesian-survival-analysis-for-game-of.html Finally we have a more comprehensive character dataset with character-predictions.csv. This comes from the team at A Song of Ice and Data who scraped it from  http//awoiaf.westeros.org/ . It also includes their predictions on which character will die the methodology of which can be found here https//got.show/machine-learning-algorithm-predicts-death-game-of-thrones  What insights about the complicated political landscape of this fantasy world can you find in this data? Of course it goes without saying that this dataset contains spoilers ;)",,,books and comics
Education Statistics , World Bank , www.kaggle.com/theworldbank/education-statistics , Fri Nov 18 2016 11:00:42 GMT+0530 (IST) , Studies of education status indicators around the world ,1358, education- ,Context The World Bank EdStats All Indicator Query holds over 4000 internationally comparable indicators that describe education access progression completion literacy teachers population and expenditures. The indicators cover the education cycle from pre-primary to vocational and tertiary education. Content In addition to the above mentioned indicators this dataset also holds learning outcome data from international and regional learning assessments (e.g. PISA TIMSS PIRLS) equity data from household surveys and projection/attainment data to 2050. For further information please visit the EdStats website. Inspiration  In your opinion what are some of the more surprising indicators? Are there any you would consider adding? Which countries have the highest adult illiteracy rates? Have they changed over time and do rates vary based on age bracket? Do school enrollment rates have an impact on adult illiteracy rates? If so can you determine approximately how long a change in enrollment takes in order to impact illiteracy? Does this change vary among countries and if so can you point to changes in policies or NGO efforts that might play a role?  Acknowledgements Data was acquired from the World Bank and can be accessed in multiple formats here.,,,student performances
Behavioral Risk Factor Surveillance System , Centers for Disease Control and Prevention , www.kaggle.com/cdc/behavioral-risk-factor-surveillance-system , Thu Aug 24 2017 05:46:13 GMT+0530 (IST) , Public health surveys of 400k people from 2011-2015 ,157, mental health- public health- ,The objective of the BRFSS is to collect uniform state-specific data on preventive health practices and risk behaviors that are linked to chronic diseases injuries and preventable infectious diseases in the adult population. Factors assessed by the BRFSS include tobacco use health care coverage HIV/AIDS knowledge or prevention physical activity and fruit and vegetable consumption. Data are collected from a random sample of adults (one per household) through a telephone survey. The Behavioral Risk Factor Surveillance System (BRFSS) is the nation's premier system of health-related telephone surveys that collect state data about U.S. residents regarding their health-related risk behaviors chronic health conditions and use of preventive services. Established in 1984 with 15 states BRFSS now collects data in all 50 states as well as the District of Columbia and three U.S. territories. BRFSS completes more than 400000 adult interviews each year making it the largest continuously conducted health survey system in the world. Content  Each year contains a few hundred columns. Please see one of the annual code books for complete details. These CSV files were converted from a SAS data format using pandas; there may be some data artifacts as a result. If you like this dataset you might also like the data for 2001-2010.  Acknowledgements This dataset was released by the CDC. You can find the original dataset and additional years of data here.,_STATE:_GEOSTR:_DENSTR2:PRECALL:REPNUM:REPDEPTH:FMONTH:IDATE:IMONTH:IDAY:IYEAR:INTVID:DISPCODE:SEQNO:_PSU:NATTMPTS:NRECSEL:NRECSTR:CTELENUM:CELLFON:PVTRESID:NUMADULT:NUMMEN:NUMWOMEN:GENHLTH:PHYSHLTH:MENTHLTH:POORHLTH:HLTHPLN1:PERSDOC2:MEDCOST:CHECKUP1:BPHIGH4:BPMEDS:BLOODCHO:CHOLCHK:TOLDHI2:CVDINFR4:CVDCRHD4:CVDSTRK3:ASTHMA3:ASTHNOW:CHCSCNCR:CHCOCNCR:CHCCOPD:HAVARTH3:ADDEPEV2:CHCKIDNY:CHCVISON:DIABETE3:SMOKE100:SMOKDAY2:STOPSMK2:LASTSMK2:USENOW3:AGE:HISPANC2:MRACE:ORACE2:VETERAN3:MARITAL:CHILDREN:EDUCA:EMPLOY:INCOME2:WEIGHT2:HEIGHT3:CTYCODE1:NUMHHOL2:NUMPHON2:CPDEMO1:CPDEMO2:CPDEMO3:CPDEMO4:RENTHOM1:SEX:PREGNANT:FRUITJU1:FRUIT1:FVBEANS:FVGREEN:FVORANG:VEGETAB1:EXERANY2:EXRACT01:EXEROFT1:EXERHMM1:EXRACT02:EXEROFT2:EXERHMM2:STRENGTH:QLACTLM2:USEEQUIP:LMTJOIN3:ARTHDIS2:ARTHSOCL:JOINPAIN:SEATBELT:FLUSHOT5:FLSHTMY2:IMFVPLAC:PNEUVAC3:ALCDAY5:AVEDRNK2:DRNK3GE5:MAXDRNKS:HIVTST6:HIVTSTD3:HIVRISK3:PDIABTST:PREDIAB1:DIABAGE2:INSULIN:BLDSUGAR:FEETCHK2:DOCTDIAB:CHKHEMO3:FEETCHK:EYEEXAM:DIABEYE:DIABEDU:PAINACT2:QLMENTL2:QLSTRES2:QLHLTH2:SSBSUGAR:SSBFRUIT:SSBCALRI:PFPPREPR:PFPPRGNT:PFPPRVNT:TYPCNTR6:NOBCUSE4:FPCHLDF2:PFPVITMN:VIDFCLT3:VIREDIF3:VIPRFVS3:VINOCRE3:VIEYEXM3:VIINSUR3:VICTRCT3:VIGLUMA3:VIMACDG3:QLREST2:SLEPTIME:SLEPSNOR:SLEPDAY:SLEPDRIV:WRKHCF1:DIRCONT1:DRHPAD1:HAREHAB1:STREHAB1:CVDASPRN:ASPUNSAF:BPEATHBT:BPSALT:BPALCHOL:BPEXER:BPEATADV:BPSLTADV:BPALCADV:BPEXRADV:BPMEDADV:BPHI2MR:HASYMP1:HASYMP2:HASYMP3:HASYMP4:HASYMP5:HASYMP6:STRSYMP1:STRSYMP2:STRSYMP3:STRSYMP4:STRSYMP5:STRSYMP6:FIRSTAID:HADMAM:HOWLONG:PROFEXAM:LENGEXAM:HADPAP2:LASTPAP2:HADHYST2:PCPSAREC:PSATEST1:PSATIME:PCPSARSN:PCPSAADV:PCPSADIS:PCPSADEC:PROSTATE:BLDSTOOL:LSTBLDS3:HADSIGM3:HADSGCO1:LASTSIG3:SMCQUITL:SMCTRYQT:SMCCALQT:SMCPROGQ:SMCCNSLQ:SMCMEDQT:SMCTIMEQ:SMCPLANQ:SHSNWRK1:SHSNHOM1:SHSRIDEV:SHSINPUB:SHSHOMES:SHSVHICL:SHSALOW1:ASTHMAGE:ASATTACK:ASERVIST:ASDRVIST:ASRCHKUP:ASACTLIM:ASYMPTOM:ASNOSLEP:ASTHMED3:ASINHALR:ARTTODAY:ARTHWGT:ARTHEXER:ARTHEDU:TNSARCV:TNSARCNT:TNSASHT1:HPVADVC2:HPVADSHT:SHINGLE1:COPDTEST:COPDQOL:COPDDOC:COPDHOSP:COPDMEDS:GPWELPR3:GP3DYWTR:GP3DYFD1:GP3DYPRS:GPBATRAD:GPFLSLIT:GPEMRCM1:GPEMRIN1:GPVACPL1:GPMNDEVC:GPNOTEV1:VHCOMBAT:VHDRPTSD:VHDRTBI:VHCOUNSL:VHTAKLIF:VHSUICID:RRCLASS2:RRCOGNT2:RRATWRK2:RRHCARE3:RRPHYSM2:RREMTSM2:ADPLEASR:ADDOWN:ADSLEEP:ADENERGY:ADEAT1:ADFAIL:ADTHINK:ADMOVE:MISTMNT:ADANXEV:CIMEMLOS:CINOADLT:CIRBIAGE:CIHOWOFT:CIASSIST:CIINTFER:CIFAMCAR:CIHCPROF:CIMEDS:CIDIAGAZ:SCNTMONY:SCNTMEAL:SCNTPAID:SCNTWRK1:SCNTLPAD:SCNTLWK1:WHRTST9:HIVRDTS2:EMTSUPRT:LSATISFY:ACEDEPRS:ACEDRINK:ACEDRUGS:ACEPRISN:ACEDIVRC:ACEPUNCH:ACEHURT:ACESWEAR:ACETOUCH:ACETTHEM:ACEHVSEX:RCSBIRTH:RCSGENDR:RCHISLAT:RCSRACE:RCSBRACE:RCSRLTN2:CASTHDX2:CASTHNO2:FLUSHCH2:RCVFVCH4:CHIMRCVE:CALLBACK:ADLTCHLD:CTELNUM1:CELLFON2:CADULT:PVTRESD2:CSTATE:RSPSTATE:LANDLINE:PCTCELL:QSTVER:QSTLANG:MSCODE:_STSTR:_STRWT:_RAW:_WT2:_RAWRAKE:_WT2RAKE:_REGION:_IMPAGE:_IMPRACE:_IMPNPH:O_STATE:CRACEASC:_CRACE:_RAWCH:_WT2CH:CHILDAGE:_CLCPM01:_CLCPM02:_CLCPM03:_CLCPM04:_CLCPM05:_CLLCPWT:_LLCPM01:_LLCPM02:_LLCPM03:_LLCPM04:_LLCPM05:_LLCPM06:_LLCPM07:_LLCPM08:_LLCPM09:_LLCPM10:_LLCPM11:_LLCPM12:_LLCPWT:_RFHLTH:_HCVU651:_RFHYPE5:_CHOLCHK:_RFCHOL:_LTASTH1:_CASTHM1:_ASTHMS1:_DRDXAR1:_SMOKER3:_RFSMOK3:MRACEORG:MRACEASC:_PRACE:_MRACE:RACE2:_RACEG2:_RACEGR2:_RACE_G:_CNRACE:_CNRACEC:_AGEG5YR:_AGE65YR:_AGE_G:HTIN4:HTM4:WTKG3:_BMI5:_BMI5CAT:_RFBMI5:_CHLDCNT:_EDUCAG:_INCOMG:FTJUDA1_:FRUTDA1_:BEANDAY_:GRENDAY_:ORNGDAY_:VEGEDA1_:_MISFRTN:_MISVEGN:_FRTRESP:_VEGRESP:_FRUTSUM:_VEGESUM:_FRT16:_VEG23:_FRUITEX:_VEGETEX:_TOTINDA:METVAL1_:METVAL2_:MAXVO2_:FC60_:ACTINT1_:ACTINT2_:PADUR1_:PADUR2_:PAFREQ1_:PAFREQ2_:_MINACT1:_MINACT2:STRFREQ_:PAMISS_:PAMIN1_:PAMIN2_:PAMIN_:PAVIGM1_:PAVIGM2_:PAVIGMN_:_PACAT:_PAINDEX:_PA150R1:_PA300R1:_PA3002L:_PASTRNG:_PAREC:_PASTAER:_RFSEAT2:_RFSEAT3:_FLSHOT5:_PNEUMO2:DRNKANY5:DROCDY3_:_RFBING5:_DRNKDY4:_DRNKMO4:_RFDRHV4:_RFDRMN4:_RFDRWM4:_AIDTST3:HAVHPAD:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:,mental health
BRFSS 2001-2010 , Centers for Disease Control and Prevention , www.kaggle.com/cdc/brfss-20012010 , Thu Aug 24 2017 06:02:38 GMT+0530 (IST) , Behavioral Risk Factor Surveillance System for 2001-2010 ,118, mental health- public health- ,The objective of the BRFSS is to collect uniform state-specific data on preventive health practices and risk behaviors that are linked to chronic diseases injuries and preventable infectious diseases in the adult population. Factors assessed by the BRFSS include tobacco use health care coverage HIV/AIDS knowledge or prevention physical activity and fruit and vegetable consumption. Data are collected from a random sample of adults (one per household) through a telephone survey. The Behavioral Risk Factor Surveillance System (BRFSS) is the nation's premier system of health-related telephone surveys that collect state data about U.S. residents regarding their health-related risk behaviors chronic health conditions and use of preventive services. Established in 1984 with 15 states BRFSS now collects data in all 50 states as well as the District of Columbia and three U.S. territories. BRFSS completes more than 400000 adult interviews each year making it the largest continuously conducted health survey system in the world. Content  Each year contains a few hundred columns. Please see one of the annual code books for complete details. These CSV files were converted from a SAS data format using pandas; there may be some data artifacts as a result. If you like this data you might also enjoy the 2011-2015 batch. Please note that those years use a different format.  Acknowledgements This dataset was released by the CDC. You can find the original dataset manuals and additional years of data here.,_STATE:_GEOSTR:_DENSTR:LISTSTAT:PRECALL:REPNUM:REPDEPTH:_RECORD:FMONTH:IMONTH:IDAY:IYEAR:INTVID:DISPCODE:WINDDOWN:SEQNO:_PSU:NATTMPTS:NRECSEL:NRECSTR:NUMADULT:NUMMEN:NUMWOMEN:GENHLTH:PHYSHLTH:MENTHLTH:POORHLTH:HLTHPLAN:NOCOVR12:PERSDOC2:EXERANY2:BPHIGH2:BPMEDS:BLOODCHO:CHOLCHK:TOLDHI2:ASTHMA2:ASTHNOW:DIABETES:PAIN12MN:SYMTMMTH:LMTJOINT:JOINTRT:HAVARTH:TRTARTH:FLUSHOT:PNEUVAC2:SMOKE100:SMOKEDAY:STOPSMK2:ALCDAYS:AVEDRNK:DRNK2GE5:FIREARM3:AGE:HISPANC2:MRACE:ORACE2:MARITAL:CHILDREN:EDUCA:EMPLOY:INCOME2:WEIGHT:HEIGHT:CTYCODE:NUMHHOL2:NUMPHON2:CELLPHON:SEX:PREGNT2:QLACTLM2:USEEQUIP:JOBACTIV:MODPACT:MODPADAY:MODPATIM:VIGPACT:VIGPADAY:VIGPATIM:PSATEST:PSATIME:DIGRECEX:DRETIME:PROSTATE:PROSHIST:BLDSTOOL:LSTBLDS2:HADSIGM2:LASTSIG2:HIVTF1A:HIVTF1B:HIVOPT1A:HIVOPT1B:HIVTST3:HIVTSTDT:RSNTST3:WHRTST4:PCSAIDS2:DIABAGE2:INSULIN:DIABPILL:BLDSUGAR:FEETCHK2:FEETSORE:DOCTDIAB:CHKHEMO2:FEETCHK:EYEEXAM:DIABEYE:DIABEDU:SEXINTMN:SEXCONDM:CONDLAST:CONEFF2:NEWPARTN:HIVRISK:STDTREAT:STDCLIN:SEXBEHA2:SELCPTN3:SEX1PTN3:USECOND3:HLTHPRB2:LONGLMT2:QLPERSN2:QLROUTN2:PAINACT2:QLMENTL2:QLSTRES2:QLREST2:QLHLTH2:QLPCHEL2:QLPCLEV2:QLRCHEL2:QLRCLEV2:RSNOCOV2:PSTPLAN2:RSWOCOV2:PRIMCARE:MOSTCARE:FACILIT2:MEDCOST:CHECKUP:HADMAM:HOWLONG:WHYDONE:PROFEXAM:LENGEXAM:REASEXAM:HADPAP:LASTPAP:WHYPAP:HADHYST2:LASTDEN2:RMVTEETH:DENCLEAN:REASDENT:DENTLINS:ASTHMAGE:ASATTACK:ASERVIST:ASDRVIST:ASRCHKUP:ASACTLIM:ASYMPTOM:ASNOSLEP:ASTHMEDS:ASTHCHLD:ASKIDHAS:HASYMP1:HASYMP2:HASYMP3:HASYMP4:HASYMP5:HASYMP6:STRSYMP1:STRSYMP2:STRSYMP3:STRSYMP4:STRSYMP5:STRSYMP6:FIRSTAID:CVDFAT02:CVDFVG01:CVDEXR03:CVDFATR2:CVDFVEG:CVDEXRS2:CVDINFR2:CVDCRHD2:CVDSTRK2:HATTKAGE:STROKAGE:CVDREHAB:CVDASPRN:ASPUNSAF:WHYASPAN:WHYASPHA:WHYASPSK:FRUITJUI:FRUIT:GREENSAL:POTATOES:CARROTS:VEGETABL:LOSEWT:MAINTAIN:FEWCAL:PHYACT:WTDESIRE:DRADVICE:VITAMINS:MULTIVIT:FOLICACD:TAKEVIT:RECOMMEN:FIRSTSMK:REGSMK:LASTSMK:GETCARE:QUITSMOK:HOUSESMK:INDOORS:SMKPUBLC:SMKWORK:USEEVER2:USENOW2:CIGAR2:CIGARNOW:PIPESMK:PIPENOW:BIDISMK:BIDINOW:_QSTVER:MRACEORG:MRACEASC:_PRACE:_STSTR:_STRWT:_RAW:_WT2:_POSTSTR:_FINALWT:_REGION:_AGEG_:_SEXG_:_RACEG3_:_IMPAGE:_IMPNPH:_MSACODE:_AGEG5YR:_AGE65YR:RACE2:_RACEG2:_RACEGR2:_CNRACE:_CNRACEC:_BMI2:_BMI2CAT:_RFBMI2:_RFHYPE3:_CHOLCHK:_RFCHOL:_HASCJS:_CJSLMT:_CJSARTH:_SMOKER2:_RFSMOK2:_DRNKMO:_DRNKDAY:_RFBINGE:_RFDRHVY:_RFDRKMN:_RFDRKWM:_TOTINDA:_RFPAREC:_RFPAMOD:_RFPAVIG:_SMKLESS:_RFTOBAC:_FRTINDX:_FRTSERV:HTIN:HTM:WTKG:_MODPAMN:_VIGPAMN:DRNKANY2:_MRACE:IDATE:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:string:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:,mental health
IBM HR Analytics Employee Attrition & Performance , pavansubhash , www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset , Fri Mar 31 2017 12:25:16 GMT+0530 (IST) , Predict attrition of your valuable employees ,6273, employment- business- ,Uncover the factors that lead to employee attrition and explore important questions such as ‘show me a breakdown of distance from home by job role and attrition’ or ‘compare average monthly income by education and attrition’. This is a fictional data set created by IBM data scientists. Education     1 'Below College'     2 'College'     3 'Bachelor'     4 'Master'     5 'Doctor' EnvironmentSatisfaction     1 'Low'     2 'Medium'     3 'High'     4 'Very High' JobInvolvement          1 'Low'     2 'Medium'     3 'High'     4 'Very High' JobSatisfaction         1 'Low'     2 'Medium'     3 'High'     4 'Very High' PerformanceRating          1 'Low'     2 'Good'     3 'Excellent'     4 'Outstanding' RelationshipSatisfaction          1 'Low'     2 'Medium'     3 'High'     4 'Very High' WorkLifeBalance          1 'Bad'     2 'Good'     3 'Better'     4 'Best',,,trade and business
Cheltenham Crime Data , Mike Chirico , www.kaggle.com/mchirico/chtpd , Fri Oct 13 2017 16:08:48 GMT+0530 (IST) , Cheltenham Township Police Department incident dataset ,198, crime- ,Cheltenham PA Crime Data Cheltenham is a home rule township bordering North Philadelphia in Montgomery County.  It has a population of about 37000 people.  You can find out more about Cheltenham on wikipedia. Cheltenham's Facebook Groups. contains postings on crime and other events in the community. Getting Started Reading Data is a simple python script for getting started. If you prefer to use R there is an example Kernel  here. Proximity to Philadelphia This township borders on Philadelphia which may or may not influence crime in the community.  For Philadelphia crime patterns see the Philadelphia Crime Dataset.  Reference Data was obtained from socrata.com,incident_id:case_number:incident_datetime:incident_type_primary:incident_description:clearance_type:address_1:address_2:city:state:zip:country:latitude:longitude:created_at:updated_at:location:hour_of_day:day_of_week:parent_incident_type:,numeric:dateTime:dateTime:string:string:string:string:string:string:string:string:string:numeric:numeric:dateTime:dateTime:string:numeric:string:string:,crime
Exoplanet Hunting in Deep Space , WΔ , www.kaggle.com/keplersmachines/kepler-labelled-time-series-data , Wed Apr 12 2017 22:04:18 GMT+0530 (IST) , Kepler labelled time series data ,857, astronomy- space- ,The Search for New Earths GitHub The data describe the change in flux (light intensity) of several thousand stars. Each star has a binary label of 2 or 1. 2 indicated that that the star is confirmed to have at least one exoplanet in orbit; some observations are in fact multi-planet systems. As you can imagine planets themselves do not emit light but the stars that they orbit do. If said star is watched over several months or years there may be a regular 'dimming' of the flux (the light intensity). This is evidence that there may be an orbiting body around the star; such a star could be considered to be a 'candidate' system. Further study of our candidate system for example by a satellite that captures light at a different wavelength could solidify the belief that the candidate can in fact be 'confirmed'.  In the above diagram a star is orbited by a blue planet. At t = 1 the starlight intensity drops because it is partially obscured by the planet given our position. The starlight rises back to its original value at t = 2. The graph in each box shows the measured flux (light intensity) at each time interval.  Description Trainset  5087 rows or observations. 3198 columns or features. Column 1 is the label vector. Columns 2 - 3198 are the flux values over time. 37 confirmed exoplanet-stars and 5050 non-exoplanet-stars.  Testset  570 rows or observations. 3198 columns or features. Column 1 is the label vector. Columns 2 - 3198 are the flux values over time. 5 confirmed exoplanet-stars and 565 non-exoplanet-stars.  Acknowledgements The data presented here are cleaned and are derived from observations made by the NASA Kepler space telescope. The Mission is ongoing - for instance data from Campaign 12 was released on 8th March 2017. Over 99% of this dataset originates from Campaign 3. To boost the number of exoplanet-stars in the dataset confirmed exoplanets from other campaigns were also included. To be clear all observations from Campaign 3 are included. And in addition to this confirmed exoplanet-stars from other campaigns are also included. The datasets were prepared late-summer 2016. Campaign 3 was used because 'it was felt' that this Campaign is unlikely to contain any undiscovered (i.e. wrongly labelled) exoplanets. NASA open-sources the original Kepler Mission data and it is hosted at the Mikulski Archive. After being beamed down to Earth NASA applies de-noising algorithms to remove artefacts generated by the telescope. The data - in the .fits format - is stored online. And with the help of a seasoned astrophysicist anyone with an internet connection can embark on a search to find and retrieve the datafiles from the Archive. The cover image is copyright © 2011 by Dan Lessmann,LABEL:FLUX.1:FLUX.2:FLUX.3:FLUX.4:FLUX.5:FLUX.6:FLUX.7:FLUX.8:FLUX.9:FLUX.10:FLUX.11:FLUX.12:FLUX.13:FLUX.14:FLUX.15:FLUX.16:FLUX.17:FLUX.18:FLUX.19:FLUX.20:FLUX.21:FLUX.22:FLUX.23:FLUX.24:FLUX.25:FLUX.26:FLUX.27:FLUX.28:FLUX.29:FLUX.30:FLUX.31:FLUX.32:FLUX.33:FLUX.34:FLUX.35:FLUX.36:FLUX.37:FLUX.38:FLUX.39:FLUX.40:FLUX.41:FLUX.42:FLUX.43:FLUX.44:FLUX.45:FLUX.46:FLUX.47:FLUX.48:FLUX.49:FLUX.50:FLUX.51:FLUX.52:FLUX.53:FLUX.54:FLUX.55:FLUX.56:FLUX.57:FLUX.58:FLUX.59:FLUX.60:FLUX.61:FLUX.62:FLUX.63:FLUX.64:FLUX.65:FLUX.66:FLUX.67:FLUX.68:FLUX.69:FLUX.70:FLUX.71:FLUX.72:FLUX.73:FLUX.74:FLUX.75:FLUX.76:FLUX.77:FLUX.78:FLUX.79:FLUX.80:FLUX.81:FLUX.82:FLUX.83:FLUX.84:FLUX.85:FLUX.86:FLUX.87:FLUX.88:FLUX.89:FLUX.90:FLUX.91:FLUX.92:FLUX.93:FLUX.94:FLUX.95:FLUX.96:FLUX.97:FLUX.98:FLUX.99:FLUX.100:FLUX.101:FLUX.102:FLUX.103:FLUX.104:FLUX.105:FLUX.106:FLUX.107:FLUX.108:FLUX.109:FLUX.110:FLUX.111:FLUX.112:FLUX.113:FLUX.114:FLUX.115:FLUX.116:FLUX.117:FLUX.118:FLUX.119:FLUX.120:FLUX.121:FLUX.122:FLUX.123:FLUX.124:FLUX.125:FLUX.126:FLUX.127:FLUX.128:FLUX.129:FLUX.130:FLUX.131:FLUX.132:FLUX.133:FLUX.134:FLUX.135:FLUX.136:FLUX.137:FLUX.138:FLUX.139:FLUX.140:FLUX.141:FLUX.142:FLUX.143:FLUX.144:FLUX.145:FLUX.146:FLUX.147:FLUX.148:FLUX.149:FLUX.150:FLUX.151:FLUX.152:FLUX.153:FLUX.154:FLUX.155:FLUX.156:FLUX.157:FLUX.158:FLUX.159:FLUX.160:FLUX.161:FLUX.162:FLUX.163:FLUX.164:FLUX.165:FLUX.166:FLUX.167:FLUX.168:FLUX.169:FLUX.170:FLUX.171:FLUX.172:FLUX.173:FLUX.174:FLUX.175:FLUX.176:FLUX.177:FLUX.178:FLUX.179:FLUX.180:FLUX.181:FLUX.182:FLUX.183:FLUX.184:FLUX.185:FLUX.186:FLUX.187:FLUX.188:FLUX.189:FLUX.190:FLUX.191:FLUX.192:FLUX.193:FLUX.194:FLUX.195:FLUX.196:FLUX.197:FLUX.198:FLUX.199:FLUX.200:FLUX.201:FLUX.202:FLUX.203:FLUX.204:FLUX.205:FLUX.206:FLUX.207:FLUX.208:FLUX.209:FLUX.210:FLUX.211:FLUX.212:FLUX.213:FLUX.214:FLUX.215:FLUX.216:FLUX.217:FLUX.218:FLUX.219:FLUX.220:FLUX.221:FLUX.222:FLUX.223:FLUX.224:FLUX.225:FLUX.226:FLUX.227:FLUX.228:FLUX.229:FLUX.230:FLUX.231:FLUX.232:FLUX.233:FLUX.234:FLUX.235:FLUX.236:FLUX.237:FLUX.238:FLUX.239:FLUX.240:FLUX.241:FLUX.242:FLUX.243:FLUX.244:FLUX.245:FLUX.246:FLUX.247:FLUX.248:FLUX.249:FLUX.250:FLUX.251:FLUX.252:FLUX.253:FLUX.254:FLUX.255:FLUX.256:FLUX.257:FLUX.258:FLUX.259:FLUX.260:FLUX.261:FLUX.262:FLUX.263:FLUX.264:FLUX.265:FLUX.266:FLUX.267:FLUX.268:FLUX.269:FLUX.270:FLUX.271:FLUX.272:FLUX.273:FLUX.274:FLUX.275:FLUX.276:FLUX.277:FLUX.278:FLUX.279:FLUX.280:FLUX.281:FLUX.282:FLUX.283:FLUX.284:FLUX.285:FLUX.286:FLUX.287:FLUX.288:FLUX.289:FLUX.290:FLUX.291:FLUX.292:FLUX.293:FLUX.294:FLUX.295:FLUX.296:FLUX.297:FLUX.298:FLUX.299:FLUX.300:FLUX.301:FLUX.302:FLUX.303:FLUX.304:FLUX.305:FLUX.306:FLUX.307:FLUX.308:FLUX.309:FLUX.310:FLUX.311:FLUX.312:FLUX.313:FLUX.314:FLUX.315:FLUX.316:FLUX.317:FLUX.318:FLUX.319:FLUX.320:FLUX.321:FLUX.322:FLUX.323:FLUX.324:FLUX.325:FLUX.326:FLUX.327:FLUX.328:FLUX.329:FLUX.330:FLUX.331:FLUX.332:FLUX.333:FLUX.334:FLUX.335:FLUX.336:FLUX.337:FLUX.338:FLUX.339:FLUX.340:FLUX.341:FLUX.342:FLUX.343:FLUX.344:FLUX.345:FLUX.346:FLUX.347:FLUX.348:FLUX.349:FLUX.350:FLUX.351:FLUX.352:FLUX.353:FLUX.354:FLUX.355:FLUX.356:FLUX.357:FLUX.358:FLUX.359:FLUX.360:FLUX.361:FLUX.362:FLUX.363:FLUX.364:FLUX.365:FLUX.366:FLUX.367:FLUX.368:FLUX.369:FLUX.370:FLUX.371:FLUX.372:FLUX.373:FLUX.374:FLUX.375:FLUX.376:FLUX.377:FLUX.378:FLUX.379:FLUX.380:FLUX.381:FLUX.382:FLUX.383:FLUX.384:FLUX.385:FLUX.386:FLUX.387:FLUX.388:FLUX.389:FLUX.390:FLUX.391:FLUX.392:FLUX.393:FLUX.394:FLUX.395:FLUX.396:FLUX.397:FLUX.398:FLUX.399:FLUX.400:FLUX.401:FLUX.402:FLUX.403:FLUX.404:FLUX.405:FLUX.406:FLUX.407:FLUX.408:FLUX.409:FLUX.410:FLUX.411:FLUX.412:FLUX.413:FLUX.414:FLUX.415:FLUX.416:FLUX.417:FLUX.418:FLUX.419:FLUX.420:FLUX.421:FLUX.422:FLUX.423:FLUX.424:FLUX.425:FLUX.426:FLUX.427:FLUX.428:FLUX.429:FLUX.430:FLUX.431:FLUX.432:FLUX.433:FLUX.434:FLUX.435:FLUX.436:FLUX.437:FLUX.438:FLUX.439:FLUX.440:FLUX.441:FLUX.442:FLUX.443:FLUX.444:FLUX.445:FLUX.446:FLUX.447:FLUX.448:FLUX.449:FLUX.450:FLUX.451:FLUX.452:FLUX.453:FLUX.454:FLUX.455:FLUX.456:FLUX.457:FLUX.458:FLUX.459:FLUX.460:FLUX.461:FLUX.462:FLUX.463:FLUX.464:FLUX.465:FLUX.466:FLUX.467:FLUX.468:FLUX.469:FLUX.470:FLUX.471:FLUX.472:FLUX.473:FLUX.474:FLUX.475:FLUX.476:FLUX.477:FLUX.478:FLUX.479:FLUX.480:FLUX.481:FLUX.482:FLUX.483:FLUX.484:FLUX.485:FLUX.486:FLUX.487:FLUX.488:FLUX.489:FLUX.490:FLUX.491:FLUX.492:FLUX.493:FLUX.494:FLUX.495:FLUX.496:FLUX.497:FLUX.498:FLUX.499:FLUX.500:FLUX.501:FLUX.502:FLUX.503:FLUX.504:FLUX.505:FLUX.506:FLUX.507:FLUX.508:FLUX.509:FLUX.510:FLUX.511:FLUX.512:FLUX.513:FLUX.514:FLUX.515:FLUX.516:FLUX.517:FLUX.518:FLUX.519:FLUX.520:FLUX.521:FLUX.522:FLUX.523:FLUX.524:FLUX.525:FLUX.526:FLUX.527:FLUX.528:FLUX.529:FLUX.530:FLUX.531:FLUX.532:FLUX.533:FLUX.534:FLUX.535:FLUX.536:FLUX.537:FLUX.538:FLUX.539:FLUX.540:FLUX.541:FLUX.542:FLUX.543:FLUX.544:FLUX.545:FLUX.546:FLUX.547:FLUX.548:FLUX.549:FLUX.550:FLUX.551:FLUX.552:FLUX.553:FLUX.554:FLUX.555:FLUX.556:FLUX.557:FLUX.558:FLUX.559:FLUX.560:FLUX.561:FLUX.562:FLUX.563:FLUX.564:FLUX.565:FLUX.566:FLUX.567:FLUX.568:FLUX.569:FLUX.570:FLUX.571:FLUX.572:FLUX.573:FLUX.574:FLUX.575:FLUX.576:FLUX.577:FLUX.578:FLUX.579:FLUX.580:FLUX.581:FLUX.582:FLUX.583:FLUX.584:FLUX.585:FLUX.586:FLUX.587:FLUX.588:FLUX.589:FLUX.590:FLUX.591:FLUX.592:FLUX.593:FLUX.594:FLUX.595:FLUX.596:FLUX.597:FLUX.598:FLUX.599:FLUX.600:FLUX.601:FLUX.602:FLUX.603:FLUX.604:FLUX.605:FLUX.606:FLUX.607:FLUX.608:FLUX.609:FLUX.610:FLUX.611:FLUX.612:FLUX.613:FLUX.614:FLUX.615:FLUX.616:FLUX.617:FLUX.618:FLUX.619:FLUX.620:FLUX.621:FLUX.622:FLUX.623:FLUX.624:FLUX.625:FLUX.626:FLUX.627:FLUX.628:FLUX.629:FLUX.630:FLUX.631:FLUX.632:FLUX.633:FLUX.634:FLUX.635:FLUX.636:FLUX.637:FLUX.638:FLUX.639:FLUX.640:FLUX.641:FLUX.642:FLUX.643:FLUX.644:FLUX.645:FLUX.646:FLUX.647:FLUX.648:FLUX.649:FLUX.650:FLUX.651:FLUX.652:FLUX.653:FLUX.654:FLUX.655:FLUX.656:FLUX.657:FLUX.658:FLUX.659:FLUX.660:FLUX.661:FLUX.662:FLUX.663:FLUX.664:FLUX.665:FLUX.666:FLUX.667:FLUX.668:FLUX.669:FLUX.670:FLUX.671:FLUX.672:FLUX.673:FLUX.674:FLUX.675:FLUX.676:FLUX.677:FLUX.678:FLUX.679:FLUX.680:FLUX.681:FLUX.682:FLUX.683:FLUX.684:FLUX.685:FLUX.686:FLUX.687:FLUX.688:FLUX.689:FLUX.690:FLUX.691:FLUX.692:FLUX.693:FLUX.694:FLUX.695:FLUX.696:FLUX.697:FLUX.698:FLUX.699:FLUX.700:FLUX.701:FLUX.702:FLUX.703:FLUX.704:FLUX.705:FLUX.706:FLUX.707:FLUX.708:FLUX.709:FLUX.710:FLUX.711:FLUX.712:FLUX.713:FLUX.714:FLUX.715:FLUX.716:FLUX.717:FLUX.718:FLUX.719:FLUX.720:FLUX.721:FLUX.722:FLUX.723:FLUX.724:FLUX.725:FLUX.726:FLUX.727:FLUX.728:FLUX.729:FLUX.730:FLUX.731:FLUX.732:FLUX.733:FLUX.734:FLUX.735:FLUX.736:FLUX.737:FLUX.738:FLUX.739:FLUX.740:FLUX.741:FLUX.742:FLUX.743:FLUX.744:FLUX.745:FLUX.746:FLUX.747:FLUX.748:FLUX.749:FLUX.750:FLUX.751:FLUX.752:FLUX.753:FLUX.754:FLUX.755:FLUX.756:FLUX.757:FLUX.758:FLUX.759:FLUX.760:FLUX.761:FLUX.762:FLUX.763:FLUX.764:FLUX.765:FLUX.766:FLUX.767:FLUX.768:FLUX.769:FLUX.770:FLUX.771:FLUX.772:FLUX.773:FLUX.774:FLUX.775:FLUX.776:FLUX.777:FLUX.778:FLUX.779:FLUX.780:FLUX.781:FLUX.782:FLUX.783:FLUX.784:FLUX.785:FLUX.786:FLUX.787:FLUX.788:FLUX.789:FLUX.790:FLUX.791:FLUX.792:FLUX.793:FLUX.794:FLUX.795:FLUX.796:FLUX.797:FLUX.798:FLUX.799:FLUX.800:FLUX.801:FLUX.802:FLUX.803:FLUX.804:FLUX.805:FLUX.806:FLUX.807:FLUX.808:FLUX.809:FLUX.810:FLUX.811:FLUX.812:FLUX.813:FLUX.814:FLUX.815:FLUX.816:FLUX.817:FLUX.818:FLUX.819:FLUX.820:FLUX.821:FLUX.822:FLUX.823:FLUX.824:FLUX.825:FLUX.826:FLUX.827:FLUX.828:FLUX.829:FLUX.830:FLUX.831:FLUX.832:FLUX.833:FLUX.834:FLUX.835:FLUX.836:FLUX.837:FLUX.838:FLUX.839:FLUX.840:FLUX.841:FLUX.842:FLUX.843:FLUX.844:FLUX.845:FLUX.846:FLUX.847:FLUX.848:FLUX.849:FLUX.850:FLUX.851:FLUX.852:FLUX.853:FLUX.854:FLUX.855:FLUX.856:FLUX.857:FLUX.858:FLUX.859:FLUX.860:FLUX.861:FLUX.862:FLUX.863:FLUX.864:FLUX.865:FLUX.866:FLUX.867:FLUX.868:FLUX.869:FLUX.870:FLUX.871:FLUX.872:FLUX.873:FLUX.874:FLUX.875:FLUX.876:FLUX.877:FLUX.878:FLUX.879:FLUX.880:FLUX.881:FLUX.882:FLUX.883:FLUX.884:FLUX.885:FLUX.886:FLUX.887:FLUX.888:FLUX.889:FLUX.890:FLUX.891:FLUX.892:FLUX.893:FLUX.894:FLUX.895:FLUX.896:FLUX.897:FLUX.898:FLUX.899:FLUX.900:FLUX.901:FLUX.902:FLUX.903:FLUX.904:FLUX.905:FLUX.906:FLUX.907:FLUX.908:FLUX.909:FLUX.910:FLUX.911:FLUX.912:FLUX.913:FLUX.914:FLUX.915:FLUX.916:FLUX.917:FLUX.918:FLUX.919:FLUX.920:FLUX.921:FLUX.922:FLUX.923:FLUX.924:FLUX.925:FLUX.926:FLUX.927:FLUX.928:FLUX.929:FLUX.930:FLUX.931:FLUX.932:FLUX.933:FLUX.934:FLUX.935:FLUX.936:FLUX.937:FLUX.938:FLUX.939:FLUX.940:FLUX.941:FLUX.942:FLUX.943:FLUX.944:FLUX.945:FLUX.946:FLUX.947:FLUX.948:FLUX.949:FLUX.950:FLUX.951:FLUX.952:FLUX.953:FLUX.954:FLUX.955:FLUX.956:FLUX.957:FLUX.958:FLUX.959:FLUX.960:FLUX.961:FLUX.962:FLUX.963:FLUX.964:FLUX.965:FLUX.966:FLUX.967:FLUX.968:FLUX.969:FLUX.970:FLUX.971:FLUX.972:FLUX.973:FLUX.974:FLUX.975:FLUX.976:FLUX.977:FLUX.978:FLUX.979:FLUX.980:FLUX.981:FLUX.982:FLUX.983:FLUX.984:FLUX.985:FLUX.986:FLUX.987:FLUX.988:FLUX.989:FLUX.990:FLUX.991:FLUX.992:FLUX.993:FLUX.994:FLUX.995:FLUX.996:FLUX.997:FLUX.998:FLUX.999:FLUX.1000:FLUX.1001:FLUX.1002:FLUX.1003:FLUX.1004:FLUX.1005:FLUX.1006:FLUX.1007:FLUX.1008:FLUX.1009:FLUX.1010:FLUX.1011:FLUX.1012:FLUX.1013:FLUX.1014:FLUX.1015:FLUX.1016:FLUX.1017:FLUX.1018:FLUX.1019:FLUX.1020:FLUX.1021:FLUX.1022:FLUX.1023:FLUX.1024:FLUX.1025:FLUX.1026:FLUX.1027:FLUX.1028:FLUX.1029:FLUX.1030:FLUX.1031:FLUX.1032:FLUX.1033:FLUX.1034:FLUX.1035:FLUX.1036:FLUX.1037:FLUX.1038:FLUX.1039:FLUX.1040:FLUX.1041:FLUX.1042:FLUX.1043:FLUX.1044:FLUX.1045:FLUX.1046:FLUX.1047:FLUX.1048:FLUX.1049:FLUX.1050:FLUX.1051:FLUX.1052:FLUX.1053:FLUX.1054:FLUX.1055:FLUX.1056:FLUX.1057:FLUX.1058:FLUX.1059:FLUX.1060:FLUX.1061:FLUX.1062:FLUX.1063:FLUX.1064:FLUX.1065:FLUX.1066:FLUX.1067:FLUX.1068:FLUX.1069:FLUX.1070:FLUX.1071:FLUX.1072:FLUX.1073:FLUX.1074:FLUX.1075:FLUX.1076:FLUX.1077:FLUX.1078:FLUX.1079:FLUX.1080:FLUX.1081:FLUX.1082:FLUX.1083:FLUX.1084:FLUX.1085:FLUX.1086:FLUX.1087:FLUX.1088:FLUX.1089:FLUX.1090:FLUX.1091:FLUX.1092:FLUX.1093:FLUX.1094:FLUX.1095:FLUX.1096:FLUX.1097:FLUX.1098:FLUX.1099:FLUX.1100:FLUX.1101:FLUX.1102:FLUX.1103:FLUX.1104:FLUX.1105:FLUX.1106:FLUX.1107:FLUX.1108:FLUX.1109:FLUX.1110:FLUX.1111:FLUX.1112:FLUX.1113:FLUX.1114:FLUX.1115:FLUX.1116:FLUX.1117:FLUX.1118:FLUX.1119:FLUX.1120:FLUX.1121:FLUX.1122:FLUX.1123:FLUX.1124:FLUX.1125:FLUX.1126:FLUX.1127:FLUX.1128:FLUX.1129:FLUX.1130:FLUX.1131:FLUX.1132:FLUX.1133:FLUX.1134:FLUX.1135:FLUX.1136:FLUX.1137:FLUX.1138:FLUX.1139:FLUX.1140:FLUX.1141:FLUX.1142:FLUX.1143:FLUX.1144:FLUX.1145:FLUX.1146:FLUX.1147:FLUX.1148:FLUX.1149:FLUX.1150:FLUX.1151:FLUX.1152:FLUX.1153:FLUX.1154:FLUX.1155:FLUX.1156:FLUX.1157:FLUX.1158:FLUX.1159:FLUX.1160:FLUX.1161:FLUX.1162:FLUX.1163:FLUX.1164:FLUX.1165:FLUX.1166:FLUX.1167:FLUX.1168:FLUX.1169:FLUX.1170:FLUX.1171:FLUX.1172:FLUX.1173:FLUX.1174:FLUX.1175:FLUX.1176:FLUX.1177:FLUX.1178:FLUX.1179:FLUX.1180:FLUX.1181:FLUX.1182:FLUX.1183:FLUX.1184:FLUX.1185:FLUX.1186:FLUX.1187:FLUX.1188:FLUX.1189:FLUX.1190:FLUX.1191:FLUX.1192:FLUX.1193:FLUX.1194:FLUX.1195:FLUX.1196:FLUX.1197:FLUX.1198:FLUX.1199:FLUX.1200:FLUX.1201:FLUX.1202:FLUX.1203:FLUX.1204:FLUX.1205:FLUX.1206:FLUX.1207:FLUX.1208:FLUX.1209:FLUX.1210:FLUX.1211:FLUX.1212:FLUX.1213:FLUX.1214:FLUX.1215:FLUX.1216:FLUX.1217:FLUX.1218:FLUX.1219:FLUX.1220:FLUX.1221:FLUX.1222:FLUX.1223:FLUX.1224:FLUX.1225:FLUX.1226:FLUX.1227:FLUX.1228:FLUX.1229:FLUX.1230:FLUX.1231:FLUX.1232:FLUX.1233:FLUX.1234:FLUX.1235:FLUX.1236:FLUX.1237:FLUX.1238:FLUX.1239:FLUX.1240:FLUX.1241:FLUX.1242:FLUX.1243:FLUX.1244:FLUX.1245:FLUX.1246:FLUX.1247:FLUX.1248:FLUX.1249:FLUX.1250:FLUX.1251:FLUX.1252:FLUX.1253:FLUX.1254:FLUX.1255:FLUX.1256:FLUX.1257:FLUX.1258:FLUX.1259:FLUX.1260:FLUX.1261:FLUX.1262:FLUX.1263:FLUX.1264:FLUX.1265:FLUX.1266:FLUX.1267:FLUX.1268:FLUX.1269:FLUX.1270:FLUX.1271:FLUX.1272:FLUX.1273:FLUX.1274:FLUX.1275:FLUX.1276:FLUX.1277:FLUX.1278:FLUX.1279:FLUX.1280:FLUX.1281:FLUX.1282:FLUX.1283:FLUX.1284:FLUX.1285:FLUX.1286:FLUX.1287:FLUX.1288:FLUX.1289:FLUX.1290:FLUX.1291:FLUX.1292:FLUX.1293:FLUX.1294:FLUX.1295:FLUX.1296:FLUX.1297:FLUX.1298:FLUX.1299:FLUX.1300:FLUX.1301:FLUX.1302:FLUX.1303:FLUX.1304:FLUX.1305:FLUX.1306:FLUX.1307:FLUX.1308:FLUX.1309:FLUX.1310:FLUX.1311:FLUX.1312:FLUX.1313:FLUX.1314:FLUX.1315:FLUX.1316:FLUX.1317:FLUX.1318:FLUX.1319:FLUX.1320:FLUX.1321:FLUX.1322:FLUX.1323:FLUX.1324:FLUX.1325:FLUX.1326:FLUX.1327:FLUX.1328:FLUX.1329:FLUX.1330:FLUX.1331:FLUX.1332:FLUX.1333:FLUX.1334:FLUX.1335:FLUX.1336:FLUX.1337:FLUX.1338:FLUX.1339:FLUX.1340:FLUX.1341:FLUX.1342:FLUX.1343:FLUX.1344:FLUX.1345:FLUX.1346:FLUX.1347:FLUX.1348:FLUX.1349:FLUX.1350:FLUX.1351:FLUX.1352:FLUX.1353:FLUX.1354:FLUX.1355:FLUX.1356:FLUX.1357:FLUX.1358:FLUX.1359:FLUX.1360:FLUX.1361:FLUX.1362:FLUX.1363:FLUX.1364:FLUX.1365:FLUX.1366:FLUX.1367:FLUX.1368:FLUX.1369:FLUX.1370:FLUX.1371:FLUX.1372:FLUX.1373:FLUX.1374:FLUX.1375:FLUX.1376:FLUX.1377:FLUX.1378:FLUX.1379:FLUX.1380:FLUX.1381:FLUX.1382:FLUX.1383:FLUX.1384:FLUX.1385:FLUX.1386:FLUX.1387:FLUX.1388:FLUX.1389:FLUX.1390:FLUX.1391:FLUX.1392:FLUX.1393:FLUX.1394:FLUX.1395:FLUX.1396:FLUX.1397:FLUX.1398:FLUX.1399:FLUX.1400:FLUX.1401:FLUX.1402:FLUX.1403:FLUX.1404:FLUX.1405:FLUX.1406:FLUX.1407:FLUX.1408:FLUX.1409:FLUX.1410:FLUX.1411:FLUX.1412:FLUX.1413:FLUX.1414:FLUX.1415:FLUX.1416:FLUX.1417:FLUX.1418:FLUX.1419:FLUX.1420:FLUX.1421:FLUX.1422:FLUX.1423:FLUX.1424:FLUX.1425:FLUX.1426:FLUX.1427:FLUX.1428:FLUX.1429:FLUX.1430:FLUX.1431:FLUX.1432:FLUX.1433:FLUX.1434:FLUX.1435:FLUX.1436:FLUX.1437:FLUX.1438:FLUX.1439:FLUX.1440:FLUX.1441:FLUX.1442:FLUX.1443:FLUX.1444:FLUX.1445:FLUX.1446:FLUX.1447:FLUX.1448:FLUX.1449:FLUX.1450:FLUX.1451:FLUX.1452:FLUX.1453:FLUX.1454:FLUX.1455:FLUX.1456:FLUX.1457:FLUX.1458:FLUX.1459:FLUX.1460:FLUX.1461:FLUX.1462:FLUX.1463:FLUX.1464:FLUX.1465:FLUX.1466:FLUX.1467:FLUX.1468:FLUX.1469:FLUX.1470:FLUX.1471:FLUX.1472:FLUX.1473:FLUX.1474:FLUX.1475:FLUX.1476:FLUX.1477:FLUX.1478:FLUX.1479:FLUX.1480:FLUX.1481:FLUX.1482:FLUX.1483:FLUX.1484:FLUX.1485:FLUX.1486:FLUX.1487:FLUX.1488:FLUX.1489:FLUX.1490:FLUX.1491:FLUX.1492:FLUX.1493:FLUX.1494:FLUX.1495:FLUX.1496:FLUX.1497:FLUX.1498:FLUX.1499:FLUX.1500:FLUX.1501:FLUX.1502:FLUX.1503:FLUX.1504:FLUX.1505:FLUX.1506:FLUX.1507:FLUX.1508:FLUX.1509:FLUX.1510:FLUX.1511:FLUX.1512:FLUX.1513:FLUX.1514:FLUX.1515:FLUX.1516:FLUX.1517:FLUX.1518:FLUX.1519:FLUX.1520:FLUX.1521:FLUX.1522:FLUX.1523:FLUX.1524:FLUX.1525:FLUX.1526:FLUX.1527:FLUX.1528:FLUX.1529:FLUX.1530:FLUX.1531:FLUX.1532:FLUX.1533:FLUX.1534:FLUX.1535:FLUX.1536:FLUX.1537:FLUX.1538:FLUX.1539:FLUX.1540:FLUX.1541:FLUX.1542:FLUX.1543:FLUX.1544:FLUX.1545:FLUX.1546:FLUX.1547:FLUX.1548:FLUX.1549:FLUX.1550:FLUX.1551:FLUX.1552:FLUX.1553:FLUX.1554:FLUX.1555:FLUX.1556:FLUX.1557:FLUX.1558:FLUX.1559:FLUX.1560:FLUX.1561:FLUX.1562:FLUX.1563:FLUX.1564:FLUX.1565:FLUX.1566:FLUX.1567:FLUX.1568:FLUX.1569:FLUX.1570:FLUX.1571:FLUX.1572:FLUX.1573:FLUX.1574:FLUX.1575:FLUX.1576:FLUX.1577:FLUX.1578:FLUX.1579:FLUX.1580:FLUX.1581:FLUX.1582:FLUX.1583:FLUX.1584:FLUX.1585:FLUX.1586:FLUX.1587:FLUX.1588:FLUX.1589:FLUX.1590:FLUX.1591:FLUX.1592:FLUX.1593:FLUX.1594:FLUX.1595:FLUX.1596:FLUX.1597:FLUX.1598:FLUX.1599:FLUX.1600:FLUX.1601:FLUX.1602:FLUX.1603:FLUX.1604:FLUX.1605:FLUX.1606:FLUX.1607:FLUX.1608:FLUX.1609:FLUX.1610:FLUX.1611:FLUX.1612:FLUX.1613:FLUX.1614:FLUX.1615:FLUX.1616:FLUX.1617:FLUX.1618:FLUX.1619:FLUX.1620:FLUX.1621:FLUX.1622:FLUX.1623:FLUX.1624:FLUX.1625:FLUX.1626:FLUX.1627:FLUX.1628:FLUX.1629:FLUX.1630:FLUX.1631:FLUX.1632:FLUX.1633:FLUX.1634:FLUX.1635:FLUX.1636:FLUX.1637:FLUX.1638:FLUX.1639:FLUX.1640:FLUX.1641:FLUX.1642:FLUX.1643:FLUX.1644:FLUX.1645:FLUX.1646:FLUX.1647:FLUX.1648:FLUX.1649:FLUX.1650:FLUX.1651:FLUX.1652:FLUX.1653:FLUX.1654:FLUX.1655:FLUX.1656:FLUX.1657:FLUX.1658:FLUX.1659:FLUX.1660:FLUX.1661:FLUX.1662:FLUX.1663:FLUX.1664:FLUX.1665:FLUX.1666:FLUX.1667:FLUX.1668:FLUX.1669:FLUX.1670:FLUX.1671:FLUX.1672:FLUX.1673:FLUX.1674:FLUX.1675:FLUX.1676:FLUX.1677:FLUX.1678:FLUX.1679:FLUX.1680:FLUX.1681:FLUX.1682:FLUX.1683:FLUX.1684:FLUX.1685:FLUX.1686:FLUX.1687:FLUX.1688:FLUX.1689:FLUX.1690:FLUX.1691:FLUX.1692:FLUX.1693:FLUX.1694:FLUX.1695:FLUX.1696:FLUX.1697:FLUX.1698:FLUX.1699:FLUX.1700:FLUX.1701:FLUX.1702:FLUX.1703:FLUX.1704:FLUX.1705:FLUX.1706:FLUX.1707:FLUX.1708:FLUX.1709:FLUX.1710:FLUX.1711:FLUX.1712:FLUX.1713:FLUX.1714:FLUX.1715:FLUX.1716:FLUX.1717:FLUX.1718:FLUX.1719:FLUX.1720:FLUX.1721:FLUX.1722:FLUX.1723:FLUX.1724:FLUX.1725:FLUX.1726:FLUX.1727:FLUX.1728:FLUX.1729:FLUX.1730:FLUX.1731:FLUX.1732:FLUX.1733:FLUX.1734:FLUX.1735:FLUX.1736:FLUX.1737:FLUX.1738:FLUX.1739:FLUX.1740:FLUX.1741:FLUX.1742:FLUX.1743:FLUX.1744:FLUX.1745:FLUX.1746:FLUX.1747:FLUX.1748:FLUX.1749:FLUX.1750:FLUX.1751:FLUX.1752:FLUX.1753:FLUX.1754:FLUX.1755:FLUX.1756:FLUX.1757:FLUX.1758:FLUX.1759:FLUX.1760:FLUX.1761:FLUX.1762:FLUX.1763:FLUX.1764:FLUX.1765:FLUX.1766:FLUX.1767:FLUX.1768:FLUX.1769:FLUX.1770:FLUX.1771:FLUX.1772:FLUX.1773:FLUX.1774:FLUX.1775:FLUX.1776:FLUX.1777:FLUX.1778:FLUX.1779:FLUX.1780:FLUX.1781:FLUX.1782:FLUX.1783:FLUX.1784:FLUX.1785:FLUX.1786:FLUX.1787:FLUX.1788:FLUX.1789:FLUX.1790:FLUX.1791:FLUX.1792:FLUX.1793:FLUX.1794:FLUX.1795:FLUX.1796:FLUX.1797:FLUX.1798:FLUX.1799:FLUX.1800:FLUX.1801:FLUX.1802:FLUX.1803:FLUX.1804:FLUX.1805:FLUX.1806:FLUX.1807:FLUX.1808:FLUX.1809:FLUX.1810:FLUX.1811:FLUX.1812:FLUX.1813:FLUX.1814:FLUX.1815:FLUX.1816:FLUX.1817:FLUX.1818:FLUX.1819:FLUX.1820:FLUX.1821:FLUX.1822:FLUX.1823:FLUX.1824:FLUX.1825:FLUX.1826:FLUX.1827:FLUX.1828:FLUX.1829:FLUX.1830:FLUX.1831:FLUX.1832:FLUX.1833:FLUX.1834:FLUX.1835:FLUX.1836:FLUX.1837:FLUX.1838:FLUX.1839:FLUX.1840:FLUX.1841:FLUX.1842:FLUX.1843:FLUX.1844:FLUX.1845:FLUX.1846:FLUX.1847:FLUX.1848:FLUX.1849:FLUX.1850:FLUX.1851:FLUX.1852:FLUX.1853:FLUX.1854:FLUX.1855:FLUX.1856:FLUX.1857:FLUX.1858:FLUX.1859:FLUX.1860:FLUX.1861:FLUX.1862:FLUX.1863:FLUX.1864:FLUX.1865:FLUX.1866:FLUX.1867:FLUX.1868:FLUX.1869:FLUX.1870:FLUX.1871:FLUX.1872:FLUX.1873:FLUX.1874:FLUX.1875:FLUX.1876:FLUX.1877:FLUX.1878:FLUX.1879:FLUX.1880:FLUX.1881:FLUX.1882:FLUX.1883:FLUX.1884:FLUX.1885:FLUX.1886:FLUX.1887:FLUX.1888:FLUX.1889:FLUX.1890:FLUX.1891:FLUX.1892:FLUX.1893:FLUX.1894:FLUX.1895:FLUX.1896:FLUX.1897:FLUX.1898:FLUX.1899:FLUX.1900:FLUX.1901:FLUX.1902:FLUX.1903:FLUX.1904:FLUX.1905:FLUX.1906:FLUX.1907:FLUX.1908:FLUX.1909:FLUX.1910:FLUX.1911:FLUX.1912:FLUX.1913:FLUX.1914:FLUX.1915:FLUX.1916:FLUX.1917:FLUX.1918:FLUX.1919:FLUX.1920:FLUX.1921:FLUX.1922:FLUX.1923:FLUX.1924:FLUX.1925:FLUX.1926:FLUX.1927:FLUX.1928:FLUX.1929:FLUX.1930:FLUX.1931:FLUX.1932:FLUX.1933:FLUX.1934:FLUX.1935:FLUX.1936:FLUX.1937:FLUX.1938:FLUX.1939:FLUX.1940:FLUX.1941:FLUX.1942:FLUX.1943:FLUX.1944:FLUX.1945:FLUX.1946:FLUX.1947:FLUX.1948:FLUX.1949:FLUX.1950:FLUX.1951:FLUX.1952:FLUX.1953:FLUX.1954:FLUX.1955:FLUX.1956:FLUX.1957:FLUX.1958:FLUX.1959:FLUX.1960:FLUX.1961:FLUX.1962:FLUX.1963:FLUX.1964:FLUX.1965:FLUX.1966:FLUX.1967:FLUX.1968:FLUX.1969:FLUX.1970:FLUX.1971:FLUX.1972:FLUX.1973:FLUX.1974:FLUX.1975:FLUX.1976:FLUX.1977:FLUX.1978:FLUX.1979:FLUX.1980:FLUX.1981:FLUX.1982:FLUX.1983:FLUX.1984:FLUX.1985:FLUX.1986:FLUX.1987:FLUX.1988:FLUX.1989:FLUX.1990:FLUX.1991:FLUX.1992:FLUX.1993:FLUX.1994:FLUX.1995:FLUX.1996:FLUX.1997:FLUX.1998:FLUX.1999:FLUX.2000:FLUX.2001:FLUX.2002:FLUX.2003:FLUX.2004:FLUX.2005:FLUX.2006:FLUX.2007:FLUX.2008:FLUX.2009:FLUX.2010:FLUX.2011:FLUX.2012:FLUX.2013:FLUX.2014:FLUX.2015:FLUX.2016:FLUX.2017:FLUX.2018:FLUX.2019:FLUX.2020:FLUX.2021:FLUX.2022:FLUX.2023:FLUX.2024:FLUX.2025:FLUX.2026:FLUX.2027:FLUX.2028:FLUX.2029:FLUX.2030:FLUX.2031:FLUX.2032:FLUX.2033:FLUX.2034:FLUX.2035:FLUX.2036:FLUX.2037:FLUX.2038:FLUX.2039:FLUX.2040:FLUX.2041:FLUX.2042:FLUX.2043:FLUX.2044:FLUX.2045:FLUX.2046:FLUX.2047:FLUX.2048:FLUX.2049:FLUX.2050:FLUX.2051:FLUX.2052:FLUX.2053:FLUX.2054:FLUX.2055:FLUX.2056:FLUX.2057:FLUX.2058:FLUX.2059:FLUX.2060:FLUX.2061:FLUX.2062:FLUX.2063:FLUX.2064:FLUX.2065:FLUX.2066:FLUX.2067:FLUX.2068:FLUX.2069:FLUX.2070:FLUX.2071:FLUX.2072:FLUX.2073:FLUX.2074:FLUX.2075:FLUX.2076:FLUX.2077:FLUX.2078:FLUX.2079:FLUX.2080:FLUX.2081:FLUX.2082:FLUX.2083:FLUX.2084:FLUX.2085:FLUX.2086:FLUX.2087:FLUX.2088:FLUX.2089:FLUX.2090:FLUX.2091:FLUX.2092:FLUX.2093:FLUX.2094:FLUX.2095:FLUX.2096:FLUX.2097:FLUX.2098:FLUX.2099:FLUX.2100:FLUX.2101:FLUX.2102:FLUX.2103:FLUX.2104:FLUX.2105:FLUX.2106:FLUX.2107:FLUX.2108:FLUX.2109:FLUX.2110:FLUX.2111:FLUX.2112:FLUX.2113:FLUX.2114:FLUX.2115:FLUX.2116:FLUX.2117:FLUX.2118:FLUX.2119:FLUX.2120:FLUX.2121:FLUX.2122:FLUX.2123:FLUX.2124:FLUX.2125:FLUX.2126:FLUX.2127:FLUX.2128:FLUX.2129:FLUX.2130:FLUX.2131:FLUX.2132:FLUX.2133:FLUX.2134:FLUX.2135:FLUX.2136:FLUX.2137:FLUX.2138:FLUX.2139:FLUX.2140:FLUX.2141:FLUX.2142:FLUX.2143:FLUX.2144:FLUX.2145:FLUX.2146:FLUX.2147:FLUX.2148:FLUX.2149:FLUX.2150:FLUX.2151:FLUX.2152:FLUX.2153:FLUX.2154:FLUX.2155:FLUX.2156:FLUX.2157:FLUX.2158:FLUX.2159:FLUX.2160:FLUX.2161:FLUX.2162:FLUX.2163:FLUX.2164:FLUX.2165:FLUX.2166:FLUX.2167:FLUX.2168:FLUX.2169:FLUX.2170:FLUX.2171:FLUX.2172:FLUX.2173:FLUX.2174:FLUX.2175:FLUX.2176:FLUX.2177:FLUX.2178:FLUX.2179:FLUX.2180:FLUX.2181:FLUX.2182:FLUX.2183:FLUX.2184:FLUX.2185:FLUX.2186:FLUX.2187:FLUX.2188:FLUX.2189:FLUX.2190:FLUX.2191:FLUX.2192:FLUX.2193:FLUX.2194:FLUX.2195:FLUX.2196:FLUX.2197:FLUX.2198:FLUX.2199:FLUX.2200:FLUX.2201:FLUX.2202:FLUX.2203:FLUX.2204:FLUX.2205:FLUX.2206:FLUX.2207:FLUX.2208:FLUX.2209:FLUX.2210:FLUX.2211:FLUX.2212:FLUX.2213:FLUX.2214:FLUX.2215:FLUX.2216:FLUX.2217:FLUX.2218:FLUX.2219:FLUX.2220:FLUX.2221:FLUX.2222:FLUX.2223:FLUX.2224:FLUX.2225:FLUX.2226:FLUX.2227:FLUX.2228:FLUX.2229:FLUX.2230:FLUX.2231:FLUX.2232:FLUX.2233:FLUX.2234:FLUX.2235:FLUX.2236:FLUX.2237:FLUX.2238:FLUX.2239:FLUX.2240:FLUX.2241:FLUX.2242:FLUX.2243:FLUX.2244:FLUX.2245:FLUX.2246:FLUX.2247:FLUX.2248:FLUX.2249:FLUX.2250:FLUX.2251:FLUX.2252:FLUX.2253:FLUX.2254:FLUX.2255:FLUX.2256:FLUX.2257:FLUX.2258:FLUX.2259:FLUX.2260:FLUX.2261:FLUX.2262:FLUX.2263:FLUX.2264:FLUX.2265:FLUX.2266:FLUX.2267:FLUX.2268:FLUX.2269:FLUX.2270:FLUX.2271:FLUX.2272:FLUX.2273:FLUX.2274:FLUX.2275:FLUX.2276:FLUX.2277:FLUX.2278:FLUX.2279:FLUX.2280:FLUX.2281:FLUX.2282:FLUX.2283:FLUX.2284:FLUX.2285:FLUX.2286:FLUX.2287:FLUX.2288:FLUX.2289:FLUX.2290:FLUX.2291:FLUX.2292:FLUX.2293:FLUX.2294:FLUX.2295:FLUX.2296:FLUX.2297:FLUX.2298:FLUX.2299:FLUX.2300:FLUX.2301:FLUX.2302:FLUX.2303:FLUX.2304:FLUX.2305:FLUX.2306:FLUX.2307:FLUX.2308:FLUX.2309:FLUX.2310:FLUX.2311:FLUX.2312:FLUX.2313:FLUX.2314:FLUX.2315:FLUX.2316:FLUX.2317:FLUX.2318:FLUX.2319:FLUX.2320:FLUX.2321:FLUX.2322:FLUX.2323:FLUX.2324:FLUX.2325:FLUX.2326:FLUX.2327:FLUX.2328:FLUX.2329:FLUX.2330:FLUX.2331:FLUX.2332:FLUX.2333:FLUX.2334:FLUX.2335:FLUX.2336:FLUX.2337:FLUX.2338:FLUX.2339:FLUX.2340:FLUX.2341:FLUX.2342:FLUX.2343:FLUX.2344:FLUX.2345:FLUX.2346:FLUX.2347:FLUX.2348:FLUX.2349:FLUX.2350:FLUX.2351:FLUX.2352:FLUX.2353:FLUX.2354:FLUX.2355:FLUX.2356:FLUX.2357:FLUX.2358:FLUX.2359:FLUX.2360:FLUX.2361:FLUX.2362:FLUX.2363:FLUX.2364:FLUX.2365:FLUX.2366:FLUX.2367:FLUX.2368:FLUX.2369:FLUX.2370:FLUX.2371:FLUX.2372:FLUX.2373:FLUX.2374:FLUX.2375:FLUX.2376:FLUX.2377:FLUX.2378:FLUX.2379:FLUX.2380:FLUX.2381:FLUX.2382:FLUX.2383:FLUX.2384:FLUX.2385:FLUX.2386:FLUX.2387:FLUX.2388:FLUX.2389:FLUX.2390:FLUX.2391:FLUX.2392:FLUX.2393:FLUX.2394:FLUX.2395:FLUX.2396:FLUX.2397:FLUX.2398:FLUX.2399:FLUX.2400:FLUX.2401:FLUX.2402:FLUX.2403:FLUX.2404:FLUX.2405:FLUX.2406:FLUX.2407:FLUX.2408:FLUX.2409:FLUX.2410:FLUX.2411:FLUX.2412:FLUX.2413:FLUX.2414:FLUX.2415:FLUX.2416:FLUX.2417:FLUX.2418:FLUX.2419:FLUX.2420:FLUX.2421:FLUX.2422:FLUX.2423:FLUX.2424:FLUX.2425:FLUX.2426:FLUX.2427:FLUX.2428:FLUX.2429:FLUX.2430:FLUX.2431:FLUX.2432:FLUX.2433:FLUX.2434:FLUX.2435:FLUX.2436:FLUX.2437:FLUX.2438:FLUX.2439:FLUX.2440:FLUX.2441:FLUX.2442:FLUX.2443:FLUX.2444:FLUX.2445:FLUX.2446:FLUX.2447:FLUX.2448:FLUX.2449:FLUX.2450:FLUX.2451:FLUX.2452:FLUX.2453:FLUX.2454:FLUX.2455:FLUX.2456:FLUX.2457:FLUX.2458:FLUX.2459:FLUX.2460:FLUX.2461:FLUX.2462:FLUX.2463:FLUX.2464:FLUX.2465:FLUX.2466:FLUX.2467:FLUX.2468:FLUX.2469:FLUX.2470:FLUX.2471:FLUX.2472:FLUX.2473:FLUX.2474:FLUX.2475:FLUX.2476:FLUX.2477:FLUX.2478:FLUX.2479:FLUX.2480:FLUX.2481:FLUX.2482:FLUX.2483:FLUX.2484:FLUX.2485:FLUX.2486:FLUX.2487:FLUX.2488:FLUX.2489:FLUX.2490:FLUX.2491:FLUX.2492:FLUX.2493:FLUX.2494:FLUX.2495:FLUX.2496:FLUX.2497:FLUX.2498:FLUX.2499:FLUX.2500:FLUX.2501:FLUX.2502:FLUX.2503:FLUX.2504:FLUX.2505:FLUX.2506:FLUX.2507:FLUX.2508:FLUX.2509:FLUX.2510:FLUX.2511:FLUX.2512:FLUX.2513:FLUX.2514:FLUX.2515:FLUX.2516:FLUX.2517:FLUX.2518:FLUX.2519:FLUX.2520:FLUX.2521:FLUX.2522:FLUX.2523:FLUX.2524:FLUX.2525:FLUX.2526:FLUX.2527:FLUX.2528:FLUX.2529:FLUX.2530:FLUX.2531:FLUX.2532:FLUX.2533:FLUX.2534:FLUX.2535:FLUX.2536:FLUX.2537:FLUX.2538:FLUX.2539:FLUX.2540:FLUX.2541:FLUX.2542:FLUX.2543:FLUX.2544:FLUX.2545:FLUX.2546:FLUX.2547:FLUX.2548:FLUX.2549:FLUX.2550:FLUX.2551:FLUX.2552:FLUX.2553:FLUX.2554:FLUX.2555:FLUX.2556:FLUX.2557:FLUX.2558:FLUX.2559:FLUX.2560:FLUX.2561:FLUX.2562:FLUX.2563:FLUX.2564:FLUX.2565:FLUX.2566:FLUX.2567:FLUX.2568:FLUX.2569:FLUX.2570:FLUX.2571:FLUX.2572:FLUX.2573:FLUX.2574:FLUX.2575:FLUX.2576:FLUX.2577:FLUX.2578:FLUX.2579:FLUX.2580:FLUX.2581:FLUX.2582:FLUX.2583:FLUX.2584:FLUX.2585:FLUX.2586:FLUX.2587:FLUX.2588:FLUX.2589:FLUX.2590:FLUX.2591:FLUX.2592:FLUX.2593:FLUX.2594:FLUX.2595:FLUX.2596:FLUX.2597:FLUX.2598:FLUX.2599:FLUX.2600:FLUX.2601:FLUX.2602:FLUX.2603:FLUX.2604:FLUX.2605:FLUX.2606:FLUX.2607:FLUX.2608:FLUX.2609:FLUX.2610:FLUX.2611:FLUX.2612:FLUX.2613:FLUX.2614:FLUX.2615:FLUX.2616:FLUX.2617:FLUX.2618:FLUX.2619:FLUX.2620:FLUX.2621:FLUX.2622:FLUX.2623:FLUX.2624:FLUX.2625:FLUX.2626:FLUX.2627:FLUX.2628:FLUX.2629:FLUX.2630:FLUX.2631:FLUX.2632:FLUX.2633:FLUX.2634:FLUX.2635:FLUX.2636:FLUX.2637:FLUX.2638:FLUX.2639:FLUX.2640:FLUX.2641:FLUX.2642:FLUX.2643:FLUX.2644:FLUX.2645:FLUX.2646:FLUX.2647:FLUX.2648:FLUX.2649:FLUX.2650:FLUX.2651:FLUX.2652:FLUX.2653:FLUX.2654:FLUX.2655:FLUX.2656:FLUX.2657:FLUX.2658:FLUX.2659:FLUX.2660:FLUX.2661:FLUX.2662:FLUX.2663:FLUX.2664:FLUX.2665:FLUX.2666:FLUX.2667:FLUX.2668:FLUX.2669:FLUX.2670:FLUX.2671:FLUX.2672:FLUX.2673:FLUX.2674:FLUX.2675:FLUX.2676:FLUX.2677:FLUX.2678:FLUX.2679:FLUX.2680:FLUX.2681:FLUX.2682:FLUX.2683:FLUX.2684:FLUX.2685:FLUX.2686:FLUX.2687:FLUX.2688:FLUX.2689:FLUX.2690:FLUX.2691:FLUX.2692:FLUX.2693:FLUX.2694:FLUX.2695:FLUX.2696:FLUX.2697:FLUX.2698:FLUX.2699:FLUX.2700:FLUX.2701:FLUX.2702:FLUX.2703:FLUX.2704:FLUX.2705:FLUX.2706:FLUX.2707:FLUX.2708:FLUX.2709:FLUX.2710:FLUX.2711:FLUX.2712:FLUX.2713:FLUX.2714:FLUX.2715:FLUX.2716:FLUX.2717:FLUX.2718:FLUX.2719:FLUX.2720:FLUX.2721:FLUX.2722:FLUX.2723:FLUX.2724:FLUX.2725:FLUX.2726:FLUX.2727:FLUX.2728:FLUX.2729:FLUX.2730:FLUX.2731:FLUX.2732:FLUX.2733:FLUX.2734:FLUX.2735:FLUX.2736:FLUX.2737:FLUX.2738:FLUX.2739:FLUX.2740:FLUX.2741:FLUX.2742:FLUX.2743:FLUX.2744:FLUX.2745:FLUX.2746:FLUX.2747:FLUX.2748:FLUX.2749:FLUX.2750:FLUX.2751:FLUX.2752:FLUX.2753:FLUX.2754:FLUX.2755:FLUX.2756:FLUX.2757:FLUX.2758:FLUX.2759:FLUX.2760:FLUX.2761:FLUX.2762:FLUX.2763:FLUX.2764:FLUX.2765:FLUX.2766:FLUX.2767:FLUX.2768:FLUX.2769:FLUX.2770:FLUX.2771:FLUX.2772:FLUX.2773:FLUX.2774:FLUX.2775:FLUX.2776:FLUX.2777:FLUX.2778:FLUX.2779:FLUX.2780:FLUX.2781:FLUX.2782:FLUX.2783:FLUX.2784:FLUX.2785:FLUX.2786:FLUX.2787:FLUX.2788:FLUX.2789:FLUX.2790:FLUX.2791:FLUX.2792:FLUX.2793:FLUX.2794:FLUX.2795:FLUX.2796:FLUX.2797:FLUX.2798:FLUX.2799:FLUX.2800:FLUX.2801:FLUX.2802:FLUX.2803:FLUX.2804:FLUX.2805:FLUX.2806:FLUX.2807:FLUX.2808:FLUX.2809:FLUX.2810:FLUX.2811:FLUX.2812:FLUX.2813:FLUX.2814:FLUX.2815:FLUX.2816:FLUX.2817:FLUX.2818:FLUX.2819:FLUX.2820:FLUX.2821:FLUX.2822:FLUX.2823:FLUX.2824:FLUX.2825:FLUX.2826:FLUX.2827:FLUX.2828:FLUX.2829:FLUX.2830:FLUX.2831:FLUX.2832:FLUX.2833:FLUX.2834:FLUX.2835:FLUX.2836:FLUX.2837:FLUX.2838:FLUX.2839:FLUX.2840:FLUX.2841:FLUX.2842:FLUX.2843:FLUX.2844:FLUX.2845:FLUX.2846:FLUX.2847:FLUX.2848:FLUX.2849:FLUX.2850:FLUX.2851:FLUX.2852:FLUX.2853:FLUX.2854:FLUX.2855:FLUX.2856:FLUX.2857:FLUX.2858:FLUX.2859:FLUX.2860:FLUX.2861:FLUX.2862:FLUX.2863:FLUX.2864:FLUX.2865:FLUX.2866:FLUX.2867:FLUX.2868:FLUX.2869:FLUX.2870:FLUX.2871:FLUX.2872:FLUX.2873:FLUX.2874:FLUX.2875:FLUX.2876:FLUX.2877:FLUX.2878:FLUX.2879:FLUX.2880:FLUX.2881:FLUX.2882:FLUX.2883:FLUX.2884:FLUX.2885:FLUX.2886:FLUX.2887:FLUX.2888:FLUX.2889:FLUX.2890:FLUX.2891:FLUX.2892:FLUX.2893:FLUX.2894:FLUX.2895:FLUX.2896:FLUX.2897:FLUX.2898:FLUX.2899:FLUX.2900:FLUX.2901:FLUX.2902:FLUX.2903:FLUX.2904:FLUX.2905:FLUX.2906:FLUX.2907:FLUX.2908:FLUX.2909:FLUX.2910:FLUX.2911:FLUX.2912:FLUX.2913:FLUX.2914:FLUX.2915:FLUX.2916:FLUX.2917:FLUX.2918:FLUX.2919:FLUX.2920:FLUX.2921:FLUX.2922:FLUX.2923:FLUX.2924:FLUX.2925:FLUX.2926:FLUX.2927:FLUX.2928:FLUX.2929:FLUX.2930:FLUX.2931:FLUX.2932:FLUX.2933:FLUX.2934:FLUX.2935:FLUX.2936:FLUX.2937:FLUX.2938:FLUX.2939:FLUX.2940:FLUX.2941:FLUX.2942:FLUX.2943:FLUX.2944:FLUX.2945:FLUX.2946:FLUX.2947:FLUX.2948:FLUX.2949:FLUX.2950:FLUX.2951:FLUX.2952:FLUX.2953:FLUX.2954:FLUX.2955:FLUX.2956:FLUX.2957:FLUX.2958:FLUX.2959:FLUX.2960:FLUX.2961:FLUX.2962:FLUX.2963:FLUX.2964:FLUX.2965:FLUX.2966:FLUX.2967:FLUX.2968:FLUX.2969:FLUX.2970:FLUX.2971:FLUX.2972:FLUX.2973:FLUX.2974:FLUX.2975:FLUX.2976:FLUX.2977:FLUX.2978:FLUX.2979:FLUX.2980:FLUX.2981:FLUX.2982:FLUX.2983:FLUX.2984:FLUX.2985:FLUX.2986:FLUX.2987:FLUX.2988:FLUX.2989:FLUX.2990:FLUX.2991:FLUX.2992:FLUX.2993:FLUX.2994:FLUX.2995:FLUX.2996:FLUX.2997:FLUX.2998:FLUX.2999:FLUX.3000:FLUX.3001:FLUX.3002:FLUX.3003:FLUX.3004:FLUX.3005:FLUX.3006:FLUX.3007:FLUX.3008:FLUX.3009:FLUX.3010:FLUX.3011:FLUX.3012:FLUX.3013:FLUX.3014:FLUX.3015:FLUX.3016:FLUX.3017:FLUX.3018:FLUX.3019:FLUX.3020:FLUX.3021:FLUX.3022:FLUX.3023:FLUX.3024:FLUX.3025:FLUX.3026:FLUX.3027:FLUX.3028:FLUX.3029:FLUX.3030:FLUX.3031:FLUX.3032:FLUX.3033:FLUX.3034:FLUX.3035:FLUX.3036:FLUX.3037:FLUX.3038:FLUX.3039:FLUX.3040:FLUX.3041:FLUX.3042:FLUX.3043:FLUX.3044:FLUX.3045:FLUX.3046:FLUX.3047:FLUX.3048:FLUX.3049:FLUX.3050:FLUX.3051:FLUX.3052:FLUX.3053:FLUX.3054:FLUX.3055:FLUX.3056:FLUX.3057:FLUX.3058:FLUX.3059:FLUX.3060:FLUX.3061:FLUX.3062:FLUX.3063:FLUX.3064:FLUX.3065:FLUX.3066:FLUX.3067:FLUX.3068:FLUX.3069:FLUX.3070:FLUX.3071:FLUX.3072:FLUX.3073:FLUX.3074:FLUX.3075:FLUX.3076:FLUX.3077:FLUX.3078:FLUX.3079:FLUX.3080:FLUX.3081:FLUX.3082:FLUX.3083:FLUX.3084:FLUX.3085:FLUX.3086:FLUX.3087:FLUX.3088:FLUX.3089:FLUX.3090:FLUX.3091:FLUX.3092:FLUX.3093:FLUX.3094:FLUX.3095:FLUX.3096:FLUX.3097:FLUX.3098:FLUX.3099:FLUX.3100:FLUX.3101:FLUX.3102:FLUX.3103:FLUX.3104:FLUX.3105:FLUX.3106:FLUX.3107:FLUX.3108:FLUX.3109:FLUX.3110:FLUX.3111:FLUX.3112:FLUX.3113:FLUX.3114:FLUX.3115:FLUX.3116:FLUX.3117:FLUX.3118:FLUX.3119:FLUX.3120:FLUX.3121:FLUX.3122:FLUX.3123:FLUX.3124:FLUX.3125:FLUX.3126:FLUX.3127:FLUX.3128:FLUX.3129:FLUX.3130:FLUX.3131:FLUX.3132:FLUX.3133:FLUX.3134:FLUX.3135:FLUX.3136:FLUX.3137:FLUX.3138:FLUX.3139:FLUX.3140:FLUX.3141:FLUX.3142:FLUX.3143:FLUX.3144:FLUX.3145:FLUX.3146:FLUX.3147:FLUX.3148:FLUX.3149:FLUX.3150:FLUX.3151:FLUX.3152:FLUX.3153:FLUX.3154:FLUX.3155:FLUX.3156:FLUX.3157:FLUX.3158:FLUX.3159:FLUX.3160:FLUX.3161:FLUX.3162:FLUX.3163:FLUX.3164:FLUX.3165:FLUX.3166:FLUX.3167:FLUX.3168:FLUX.3169:FLUX.3170:FLUX.3171:FLUX.3172:FLUX.3173:FLUX.3174:FLUX.3175:FLUX.3176:FLUX.3177:FLUX.3178:FLUX.3179:FLUX.3180:FLUX.3181:FLUX.3182:FLUX.3183:FLUX.3184:FLUX.3185:FLUX.3186:FLUX.3187:FLUX.3188:FLUX.3189:FLUX.3190:FLUX.3191:FLUX.3192:FLUX.3193:FLUX.3194:FLUX.3195:FLUX.3196:FLUX.3197:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,astronomy
Periodic Table of the Elements , Jake Waitze , www.kaggle.com/jwaitze/tablesoftheelements , Thu Feb 16 2017 20:31:39 GMT+0530 (IST) , Elements activity series and electromotive potentials ,246, chemistry- physics- ,"Context Observations of particles much smaller than us and various understandings of those particles have propelled mankind forward in ways once impossible to imagine. ""The elements"" are what we call the sequential patterns in which some of these particles manifest themselves. As a chemistry student and a coder I wanted to do what came naturally to me and make my class a bit easier by coding/automating my way around some of the tedious work involved with calculations. Unfortunately it seems that chemical-related datasets are not yet a thing which have been conveniently formatted into downloadable databases (as far as my research went). I decided that the elements would be a good place to start data collection so I did that and I'd like to see if this is useful to others as well. Other related data sets I'd like to coalesce are some large amount of standard entropies and enthalpies of various compounds and many of the data sets from the CRC Handbook of Chemistry and Physics. I also think as many diagrams as possible should be documented in a way that can be manipulated and read via code. Content Included here are three data sets. Each data set I have included is in three different formats (CSV JSON Excel) for a total of nine files. Table of the Elements  This is the primary data set. 118 elements in sequential order 72 features  Reactivity Series  33 rows (in order of reactivity - most reactive at the top) 3 features (symbol name ion)  Electromotive Potentials  284 rows (in order from most negative potential to most positive) 3 features (oxidant reductant potential)  Acknowledgements All of the data was scraped from 120 pages on Wikipedia using scripts. The links to those scripts are available in the dataset descriptions. Extra If you are interested in trying the chemistry calculations code I made for completing some of my repetitive class work it's publicly available on my GitHub. (Chemistry Calculations Repository) I plan to continue updating that as time goes on.",oxidant:reductant:potential:,string:string:numeric:,chemistry
Emoji sentiment , Jose Berengueres , www.kaggle.com/harriken/emoji-sentiment , Sun Oct 01 2017 15:26:54 GMT+0530 (IST) , Are people that use emoji happier? ,193, linguistics- internet- ,Are people that use emoji happier? paper --> https//arxiv.org/abs/1710.00888 At ASONAM2017 PydataDubai vol 1.0 @ AWOK PyDataBCN2017 @ EASDE we have presented the paper Happiness inside a job?... Many people in the various audiences asked why we avoid using emojis to predict and profile employees. The answer is that  we prefer to use  links of likes because they are more authentic than words or emojis. In the same way that google page rank is more effective when it looks at links between pages rather than content inside the pages. ... Still people keep asking about it. But there is one thing emoji are good at estimating author sentiment and that is just possible thanks to the unique characteristics of the dataset at hand. Previous research has traditionally analyzed emoji sentiment from the point of view of the reader of the content not the author. Here we analyze emoji sentiment from the author point of view and present a benchmark that was built from an employee happiness dataset where emoji happen to be annotated with daily happiness of the author of the comment. We also found out that people that use emoji are happier!? muuch happier... But the question is what did we miss? Content The main table contains columns named after emoji hex codes a 1 means the emoji appears one time in the comment (row). This dataset is an expanded version of this one but has different formats columns and one different table that is why we decided to release it as separate dataset. as he scripts are not compatible. Other stuff The R script written on MAC OS does not work in the kaggle platform (because numbers become factors and other little changes in how the code is interpreted...) the full working script (tested on R studio MAC OS) can be found at https//github.com/orioli/emoji-writer-sentiment Thank you to Lewis Michel,:emoji:s.writer:s.reader:sd:count:description:diff:,string:string:numeric:numeric:numeric:numeric:string:numeric:,mail and messaging
German Federal Elections 2017 , Jens Laufer , www.kaggle.com/jenslaufer/german-election-2017 , Sat Sep 30 2017 18:32:14 GMT+0530 (IST) , Results  in the different areas ,169, politics- ,Context The dataset reflects the votes for the different areas in Germany for the 2017 federal  elections. See German Federal Election 2017 for more details Content The data was aquired from govdata.de which is state website offering interesting datasets. The original dataset was not easy to use therefore I did some reshaping without changing the  data Acknowledgements The dataset is originally from https//www.govdata.de/web/guest/apps/-/details/bundestagswahl-2017 Inspiration The data is interesting as it reflects the votes for all areas in Germany,:area_id:area_names:state:registered.voters:total_votes:invalid_first_votes:invalid_second_votes:valid_first_votes:valid_second_votes:,numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:,elections
U.S. Incomes by Occupation and Gender , Jean-Phillipe , www.kaggle.com/jonavery/incomes-by-career-and-gender , Fri Sep 23 2016 05:21:52 GMT+0530 (IST) , Analyze gender gap and differences in industry's incomes ,1843, gender- employment- income- ,Many people say the gender gap in income levels is overstated in the United States where some say that inequality in the labor force is a thing of the past. Is there a gender gap at all? Is it stronger in some industries than in others? This dataset retrieved from the Bureau of Labor Statistics shows the median weekly incomes for 535 different occupations. The data encompasses information for all working American citizens as of January 2015. The incomes are broken into male and female statistics preceded by the total median income when including both genders. The data has been re-formatted from the original PDF-friendly arrangement to make it easier to clean and analyze. Analysis thus far has found that there is indeed a sizable gender gap between male and female incomes. Use of this dataset should cite the Bureau of Labor Statistics as per their copyright information  The Bureau of Labor Statistics (BLS) is a Federal government agency and everything that we publish both in hard copy and electronically is in the public domain except for previously copyrighted photographs and illustrations. You are free to use our public domain material without specific permission although we do ask that you cite the Bureau of Labor Statistics as the source. ,Occupation:All_workers:All_weekly:M_workers:M_weekly:F_workers:F_weekly:,string:numeric:numeric:numeric:numeric:numeric:numeric:,income
Six Degrees of Francis Bacon , Rachael Tatman , www.kaggle.com/rtatman/six-degrees-of-francis-bacon , Wed Aug 30 2017 02:49:29 GMT+0530 (IST) , An early modern social network ,301, europe- north america- history- sociology- networks- ,Overview Six Degrees of Francis Bacon is a digital reconstruction of the early modern social network (EMSN). Historians and literary critics have long studied the way that early modern people associated with each other and participated in various kinds of formal and informal groups. By data-mining existing scholarship that describes relationships between early modern persons documents and institutions we have created a unified systematized representation of the way people in early modern England were connected. Contents This dataset contains information on 171419 relationships between 15824 early modern figures (including of course the titular Francis Bacon). The individuals have been separated into 109 distinct labelled groups and the relationships fall under one of 64 labelled categories. This dataset contains the following files  SDFB_groups.csv a list of the groups of individuals in the dataset SDFB_people.csv a list of all individuals in the dataset SDFB_relationships_100000000_100020000.csv This and the following “relationships” files contain information on relationships between specific individuals SDFB_relationships_100020001_100040000.csv SDFB_relationships_100040001_100060000.csv SDFB_relationships_100060001_100080000.csv SDFB_relationships_100080001_100100000.csv SDFB_relationships_100100001_100120000.csv SDFB_relationships_100120001_100140000.csv SDFB_relationships_100140001_100160000.csv SDFB_relationships_100160001_100180000.csv SDFB_relationships_greater_than_100180000.csv SDFB_RelationshipTypes.csv the types of relationships found in the database table-of-contents.csv a table of contents for the files  Acknowledgements Please cite Six Degrees of Francis Bacon as follows SDFB Team Six Degrees of Francis Bacon Reassembling the Early Modern Social Network. www.sixdegreesoffrancisbacon.com (August 29 2017). Inspiration This dataset is an excellent place to explore network analysis and visualization. Each individual is a node and each relationship an edge.   Can you visualize this social network?  Who is the most central figure in this social network?  Do different groups have different degrees of connectivity? Plexity? ,SDFB Group ID:Name:Description:Start Year Type:Start Year:End Year Type:End Year:Members List (Name with SDFB Person ID):,numeric:string:string:string:numeric:string:numeric:string:,history
U.S. Pollution Data , BrendaSo , www.kaggle.com/sogun3/uspollution , Fri Nov 04 2016 23:02:56 GMT+0530 (IST) , Pollution in the U.S. since 2000 ,3167, environment- pollution- ,Context This dataset deals with pollution in the U.S. Pollution in the U.S. has been well documented by the U.S. EPA but it is a pain to download all the data and arrange them in a format that interests data scientists. Hence I gathered four major pollutants (Nitrogen Dioxide Sulphur Dioxide Carbon Monoxide and Ozone) for every day from 2000 - 2016 and place them neatly in a csv file.  Content There is a total of 28 fields  State Code  The code allocated by US EPA to each state County code  The code of counties in a specific state allocated by US EPA Site Num  The site number in a specific county allocated by US EPA Address Address of the monitoring site State  State of monitoring site County  County of monitoring site City  City of the monitoring site Date Local  Date of monitoring  The four pollutants (NO2 O3 SO2 and O3) each has 5 specific columns. For instance for NO2  NO2 Units  The units measured for NO2 NO2 Mean  The arithmetic mean of concentration of NO2 within a given day NO2 AQI  The calculated air quality index of NO2 within a given day NO2 1st Max Value  The maximum value obtained for NO2 concentration in a given day NO2 1st Max Hour  The hour when the maximum NO2 concentration was recorded in a given day  Observations totaled to over 1.4 million. Acknowledgements All the data is scraped from the database of U.S. EPA  https//aqsdr1.epa.gov/aqsweb/aqstmp/airdata/download_files.html  Inspiration I did a related project with some of my friends in college and decided to open source our dataset so that data scientists don't need to rescrape the U.S. EPA site for historical pollution data. However I want to make this dataset bigger potentially covering more information and more countries. Please contact me if interested.,,,air pollution
1 million Sudoku games , Bryan Park , www.kaggle.com/bryanpark/sudoku , Thu Dec 29 2016 06:55:15 GMT+0530 (IST) , 1 million numpy array pairs of Sudoku games and solutions ,1113, games- ,"Context Sudoku is a popular number puzzle that requires you to fill blanks in a 9X9 grid with digits so that each column each row and each of the nine 3×3 subgrids contains all of the digits from 1 to 9. Sudoku-solving has gained much attention from various fields. As a deep learning researcher I was inclined to investigate the possibilities of neural networks solving Sudoku. This dataset was prepared for that. Content There are dozens of source codes to generate Sudoku games available. I picked one of them and ran the code. It took approximately 6 hours to generate 1 million games ( + solutions). A Sudoku puzzle is represented as a 9x9 Python numpy array. The blanks were replaced with 0's. You can easily load and explore the data by running this. import numpy as np quizzes = np.load('sudoku_quizzes.npy') # shape = (1000000 9 9) solutions = np.load('sudoku_solutions.npy') # shape = (1000000 9 9) for quiz solution in zip(quizzes[10] solutions[10])     print(quiz)     print(solution)  ** Updates for Version 3. ** I converted NumPy arrays to csv so they are easily accessible irrespective of language. In each line a Sudoku quiz and its corresponding solution are separated by a comma. You can restore the csv file content to Numpy arrays if needed as follows import numpy as np quizzes = np.zeros((1000000 81) np.int32) solutions = np.zeros((1000000 81) np.int32) for i line in enumerate(open('sudoku.csv' 'r').read().splitlines()[1])     quiz solution = line.split("""")     for j q_s in enumerate(zip(quiz solution))         q s = q_s         quizzes[i j] = q         solutions[i j] = s quizzes = quizzes.reshape((-1 9 9)) solutions = solutions.reshape((-1 9 9))  Acknowledgements I'm grateful to Arel Cordero who wrote and shared this great Sudoku generation code. https//www.ocf.berkeley.edu/~arel/sudoku/main.html. Inspiration  Check  https//github.com/Kyubyong/sudoku to see if CNNs can crack Sudoku puzzles. Also reinforcement learning can be a promising alternative to this task. Feel free to challenge Sudoku puzzles. ",quizzes:solutions:,numeric:numeric:,game strategies
Hospital General Information , Centers for Medicare & Medicaid Services , www.kaggle.com/cms/hospital-general-information , Thu Aug 10 2017 02:15:35 GMT+0530 (IST) , General information & quality ratings for almost all US hospitals ,1057, healthcare- hospitals- public health- human medicine- ,"Context There are all sorts of reasons why you'd want to know a hospital's quality rating.  Your mom is having her second hip replacement. Her first one went terribly and you're nervous about how she'll do. Which hospital would you suggest she have her surgery? You're selecting a health plan on your state's Exchange but your top two choices partner with different hospitals. How will you decide which plan to pick? Your brother has Cystic Fibrosis and has to go to the ER frequently. He hates waiting. Which hospitals/states provide care in the timeliest manner? Your in-laws moved to Florida recently to retire and have been trying to convince you to move there too. You're looking for any way possible to show them that your state is better. Does your state have better hospitals?  Every hospital in the United States of America that accepts publicly insured patients (Medicaid or MediCare) is required to submit quality data quarterly to the Centers for Medicare & Medicaid Services (CMS). There are very few hospitals that do not accept publicly insured patients so this is quite a comprehensive list. Content This file contains general information about all hospitals that have been registered with Medicare including their addresses type of hospital and ownership structure. It also contains information about the quality of each hospital in the form of an overall rating (1-5 where 5 is the best possible rating & 1 is the worst) and whether the hospital scored above same as or below the national average for a variety of measures.  This data was updated by CMS on July 25 2017. CMS' overall rating includes 60 of the 100 measures for which data is collected & reported on Hospital Compare website (https//www.medicare.gov/hospitalcompare/search.html). Each of the measures have different collection/reporting dates so it is impossible to specify exactly which time period this dataset covers.  For more information about the timeframes for each measure see  https//www.medicare.gov/hospitalcompare/Data/Data-Updated.html# For more information about the data itself APIs and a variety of formats see https//data.medicare.gov/Hospital-Compare Acknowledgements Attention Works of the U.S. Government are in the public domain and permission is not required to reuse them. An attribution to the agency as the source is appreciated. Your materials however should not give the false impression of government endorsement of your commercial products or services. See 42 U.S.C. 1320b-10.  Inspiration Which hospital types & hospital ownerships are most common? Which hospital types & ownerships are associated with better than average ratings/mortality/readmission/etc? What is the average hospital rating by state? Which hospital types & hospital ownerships are more likely to have not submitted proper data (""Not Available"" & ""Results are not available for this reporting period"")? Which parts of the country have the highest & lowest density of religious hospitals?",State:Provider ID:Hospital Name:Address:City:,string:numeric:string:string:string:,health infrastructure
Spelling Variation on Urban Dictionary , Rachael Tatman , www.kaggle.com/rtatman/spelling-variation-on-urban-dictionary , Thu Jul 27 2017 01:31:58 GMT+0530 (IST) , A gr8t dataset of wrods used on Urban Dictionary ,25, languages- popular culture- literature- linguistics- ,Context Urban Dictionary is an online dictionary of informal language that anyone can add to. As a result a lot of the user-provided dictionary entries contain interesting variant spellings. While some are (presumably) typos others are new linguistic innovations. Content This dataset contains 716 variant spellings found in text scraped from Urban Dictionary as well as the standard spellings of those words (in UK English). Acknowledgements If you use this dataset in your work please cite the following paper Saphra N. & Lopez A. (2016). Evaluating Informal-Domain Word Representations With UrbanDictionary. ACL 2016 94. URL http//www.anthology.aclweb.org/W/W16/W16-2517.pdf Inspiration  What’s the average edit distances between a variant spelling and the standard spelling? Does this differ by part of speech? (You can find part of speech using the Natural Language Toolkit pos_tag function which is available in Python kernels.) Can you automatically classify whether a variant spelling is a typo or an intentional innovation (like gr8t)?  Can you come up with an edit distance metric that takes into account how close letters are to each other on a standard keyboard? Does that help you identify typos? Can you build an Standard English to Urban Dictionary “translator”? ,variant_spelling:standard_spelling:,string:string:,literature
Kickstarter Project Statistics , Cathie So , www.kaggle.com/socathie/kickstarter-project-statistics , Tue Nov 01 2016 11:07:42 GMT+0530 (IST) , 4000 live projects plus 4000 most backed projects ,3293, finance- ,"Crowdfunding has become one of the main sources of initial capital for small businesses and start-up companies that are looking to launch their first products. Websites like Kickstarter and Indiegogo provide a platform for millions of creators to present their innovative ideas to the public. This is a win-win situation where creators could accumulate initial fund while the public get access to cutting-edge prototypical products that are not available in the market yet. At any given point Indiegogo has around 10000 live campaigns while Kickstarter has 6000. It has become increasingly difficult for projects to stand out of the crowd. Of course advertisements via various channels are by far the most important factor to a successful campaign. However for creators with a smaller budget this leaves them wonder ""How do we increase the probability of success of our campaign starting from the very moment we create our project on these websites?"" Data Sources All of my raw data are scraped from Kickstarter.com.  First 4000 live projects that are currently campaigning on Kickstarter (live.csv) Last updated 2016-10-29 5pm PDT amt.pledged amount pledged (float) blurb project blurb (string) by project creator (string) country abbreviated country code (string of length 2) currency currency type of amt.pledged (string of length 3) end.time campaign end time (string ""YYYY-MM-DDThhmmss-TZD"") location mostly city (string) pecentage.funded unit % (int) state mostly US states (string of length 2) and others (string) title project title (string) type type of location (string County/Island/LocalAdmin/Suburb/Town/Zip) url project url after domain (string) Top 4000 most backed projects ever on Kickstarter (most_backed.csv) Last updated 2016-10-30 10pm PDT amt.pledged blurb by category project category (string) currency goal original pledge goal (float) location num.backers total number of backers (int) num.backers.tier number of backers corresponds to the pledge amount in pledge.tier (int[len(pledge.tier)]) pledge.tier pledge tiers in USD (float[]) title  url  See more at http//datapolymath.paperplane.io/",:amt.pledged:blurb:by:country:currency:end.time:location:percentage.funded:,numeric:numeric:string:string:string:string:dateTime:string:numeric:,online information
Virtual Reality Driving Simulator Dataset , Sasan Jafarnejad , www.kaggle.com/sasanj/virtual-reality-driving-simulator-dataset , Wed Aug 16 2017 19:36:11 GMT+0530 (IST) , Dataset from drivers driving a virtual reality driving simulator. ,54, ,Context We developed this platform to be able to study driver behavior in a controlled environment and perform various experiments economically and with greater flexibility. VehicularLab - University of Luxembourg Content More information will become available with the publication of the corresponding article that is currently submitted to IEEE VNC 2017. Acknowledgements To be acknowledged! Inspiration This dataset can be used to discover differences in individuals driving behavior.,id:timestamp:session_id:user_id:pc_throttle:pc_brake:pc_steering:pc_rpm:pc_speed:pc_pos_x:pc_pos_y:pc_pos_z:pc_laptime:pc_race_state:pc_lap_number:pc_lap_distance:vr_pos_x:vr_pos_y:vr_pos_z:vr_rotation_x:vr_rotation_y:vr_rotation_z:logitech_acceleration:logitech_brake:logitech_steering:,numeric:dateTime:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Solar Flares from RHESSI Mission , Kheirallah Samaha , www.kaggle.com/khsamaha/solar-flares-rhessi , Thu Feb 09 2017 18:13:46 GMT+0530 (IST) , Reuven Ramaty High Energy Solar Spectroscopic Imager ,192, astronomy- space- ,"Context Reuven Ramaty High Energy Solar Spectroscopic Imager (RHESSI originally High Energy Solar Spectroscopic Imager or HESSI) is a NASA solar flare observatory. It is the sixth mission in the Small Explorer program selected in October 1997 and launched on 5 February 2002. Its primary mission is to explore the physics of particle acceleration and energy release in solar flares. HESSI was renamed to RHESSI on 29 March 2002 in honor of Reuven Ramaty a pioneer in the area of high energy solar physics. RHESSI is the first space mission named after a NASA scientist. RHESSI was built by Spectrum Astro for Goddard Space Flight Center and is operated by the Space Sciences Laboratory in Berkeley California. The principal investigator from 2002 to 2012 was Robert Lin who was succeeded by Säm Krucker. useful links https//en.wikipedia.org/wiki/Reuven_Ramaty_High_Energy_Solar_Spectroscopic_Imager https//hesperia.gsfc.nasa.gov/hessi/objectives.htm Content Ramaty High Energy Solar Spectroscopic Imager (RHESSI) Notes  Note that only events with non-zero position and energy range not equal to 3-6 keV are confirmed as solar sources. Events which have no position and show up mostly in the front detectors but were not able to be imaged  are flagged as ""PS"". Events which do not have valid position are only confirmed to be non-solar if the NS flag is set. Peak Rate  peak counts/second in energy range 6-12 keV averaged over active collimators including background. Total Counts  counts in energy range 6-12 keV integrated over duration of flare summed over all subcollimators  including background. Energy  the highest energy band in which the flare was observed. Electron Kev (kilo electron volt) https//en.wikipedia.org/wiki/Electronvolt Radial Distance  distance from Sun center Quality Codes Qn where n is the total number of data gap SAA particle eclipse or decimation flags set for event.  n ranges from 0 to 11.  Use care when analyzing the data when the quality is not zero. Active_Region A number for the closest active region if available radial_offset the offset of the flare position from the spin axis of the spacecraft in arcsec. This is used i spectroscopy. peak_c/s peak count rate in corrected counts. Flare Flag Codes    a0 - In attenuator state 0 (None) sometime during flare   a1 - In attenuator state 1 (Thin) sometime during flare   a2 - In attenuator state 2 (Thick) sometime during flare   a3 - In attenuator state 3 (Both) sometime during flare   An - Attenuator state (0=None 1=Thin 2=Thick 3=Both) at peak of flare   DF - Front segment counts were decimated sometime during flare   DR - Rear segment counts were decimated sometime during flare   ED - Spacecraft eclipse (night) sometime during flare   EE - Flare ended in spacecraft eclipse (night)   ES - Flare started in spacecraft eclipse (night)   FE - Flare ongoing at end of file   FR - In Fast Rate Mode   FS - Flare ongoing at start of file   GD - Data gap during flare   GE - Flare ended in data gap   GS - Flare started in data gap   MR - Spacecraft in high-latitude zone during flare   NS - Non-solar event   PE - Particle event Particles are present   PS - Possible Solar Flare; in front detectors but no position   Pn - Position Quality P0 = Position is NOT valid P1 = Position is valid   Qn - Data Quality Q0 = Highest Quality Q11 = Lowest Quality   SD - Spacecraft was in SAA sometime during flare   SE - Flare ended when spacecraft was in SAA   SS - Flare started when spacecraft was in SAA Acknowledgements What is a solar flare? A Solar flare is the rapid release of a large amount of energy stored in the solar atmosphere. During a flare gas is heated to 10 to 20 million degrees Kelvin (K) and radiates soft X rays and longer-wavelength emission. Unable to penetrate the Earth's atmosphere the X rays can only be detected from space. Instruments on Skylab SMM the Japanese/US Yohkoh mission and other spacecraft have recorded many flares in X rays over the last twenty years or so. Ground-based observatories have recorded the visible and radio outputs. These data form the basis of our current understanding of a solar flare. But there are many possible mechanisms for heating the gas and observations to date have not been able to differentiate between them. HESSI's new approach Researchers believe that much of the energy released during a flare is used to accelerate to very high energies electrons (emitting primarily X-rays) and protons and other ions (emitting primarily gamma rays). The new approach of the HESSI mission is to combine for the first time high-resolution imaging in hard X-rays and gamma rays with high-resolution spectroscopy so that a detailed energy spectrum can be obtained at each point of the image. This new approach will enable researchers to find out where these particles are accelerated and to what energies. Such information will advance understanding of the fundamental high-energy processes at the core of the solar flare problem. https//hesperia.gsfc.nasa.gov/hessi/objectives.htm Inspiration  Explore Know something new Predict the solar flare Respect the Sun and value it and Take care of the environments.  Thanks",flare:start.date:start.time:total.counts:x.pos.asec:peak:end:duration.s:peak.c/s:energy.kev:y.pos.asec:active.region.ar:flag.1:flag.2:flag.3:flag.4:flag.5:radial:,numeric:dateTime:dateTime:numeric:string:dateTime:string:numeric:numeric:string:numeric:numeric:string:string:string:string:string:numeric:,astronomy
National Health and Nutrition Examination Survey , Centers for Disease Control and Prevention , www.kaggle.com/cdc/national-health-and-nutrition-examination-survey , Fri Jan 27 2017 01:41:45 GMT+0530 (IST) , NHANES datasets from 2013-2014 ,1512, human medicine- health- ,Context The National Health and Nutrition Examination Survey (NHANES) is a program of studies designed to assess the health and nutritional status of adults and children in the United States. The survey is unique in that it combines interviews and physical examinations. NHANES is a major program of the National Center for Health Statistics (NCHS). NCHS is part of the Centers for Disease Control and Prevention (CDC) and has the responsibility for producing vital and health statistics for the Nation. The NHANES program began in the early 1960s and has been conducted as a series of surveys focusing on different population groups or health topics. In 1999 the survey became a continuous program that has a changing focus on a variety of health and nutrition measurements to meet emerging needs. The survey examines a nationally representative sample of about 5000 persons each year. These persons are located in counties across the country 15 of which are visited each year. The NHANES interview includes demographic socioeconomic dietary and health-related questions. The examination component consists of medical dental and physiological measurements as well as laboratory tests administered by highly trained medical personnel. To date thousands of research findings have been published using the NHANES data. Content The 2013-2014 NHANES datasets include the following components  Demographics dataset  A complete variable dictionary can be found here Examinations dataset which contains  Blood pressure Body measures Muscle strength - grip test Oral health - dentition Taste & smell A complete variable dictionary can be found here Dietary data - total nutrient intake first day   A complete variable dictionary can be found here Laboratory dataset which includes  Albumin & Creatinine - Urine Apolipoprotein B Blood Lead Cadmium Total Mercury Selenium and Manganese Blood mercury inorganic ethyl and methyl Cholesterol - HDL Cholesterol - LDL & Triglycerides Cholesterol - Total Complete Blood Count with 5-part Differential - Whole Blood Copper Selenium & Zinc - Serum Fasting Questionnaire Fluoride - Plasma Fluoride - Water Glycohemoglobin Hepatitis A Hepatitis B Surface Antibody Hepatitis B core antibody surface antigen and Hepatitis D antibody Hepatitis C RNA (HCV-RNA) and Hepatitis C Genotype Hepatitis E IgG & IgM Antibodies Herpes Simplex Virus Type-1 & Type-2 HIV Antibody Test Human Papillomavirus (HPV) - Oral Rinse Human Papillomavirus (HPV) DNA - Vaginal Swab Roche Cobas & Roche Linear Array Human Papillomavirus (HPV) DNA Results from Penile Swab Samples Roche Linear Array Insulin Iodine - Urine Perchlorate Nitrate & Thiocyanate - Urine Perfluoroalkyl and Polyfluoroalkyl Substances (formerly Polyfluoroalkyl Chemicals - PFC) Personal Care and Consumer Product Chemicals and Metabolites Phthalates and Plasticizers Metabolites - Urine Plasma Fasting Glucose Polycyclic Aromatic Hydrocarbons (PAH) - Urine Standard Biochemistry Profile Tissue Transglutaminase Assay (IgA-TTG) & IgA Endomyseal Antibody Assay (IgA EMA) Trichomonas - Urine Two-hour Oral Glucose Tolerance Test Urinary Chlamydia Urinary Mercury Urinary Speciated Arsenics Urinary Total Arsenic Urine Flow Rate Urine Metals Urine Pregnancy Test Vitamin B12  A complete data dictionary can be found here Questionnaire dataset which includes information on Acculturation Alcohol Use Blood Pressure & Cholesterol Cardiovascular Health Consumer Behavior Current Health Status Dermatology Diabetes Diet Behavior & Nutrition Disability Drug Use Early Childhood Food Security Health Insurance Hepatitis Hospital Utilization & Access to Care Housing Characteristics Immunization Income Medical Conditions Mental Health - Depression Screener Occupation Oral Health Osteoporosis Pesticide Use Physical Activity Physical Functioning Preventive Aspirin Use Reproductive Health Sexual Behavior Sleep Disorders Smoking - Cigarette Use Smoking - Household Smokers Smoking - Recent Tobacco Use Smoking - Secondhand Smoke Exposure Taste & Smell Weight History Weight History - Youth A complete variable dictionary can be found here Medication dataset which includes prescription medications A complete variable dictionary can be found here  Acknowledgements Original data and additional documents related to the datasets or NHANES can be found here.,SEQN:SDDSRVYR:RIDSTATR:RIAGENDR:RIDAGEYR:RIDAGEMN:RIDRETH1:RIDRETH3:RIDEXMON:RIDEXAGM:DMQMILIZ:DMQADFC:DMDBORN4:DMDCITZN:DMDYRSUS:DMDEDUC3:DMDEDUC2:DMDMARTL:RIDEXPRG:SIALANG:SIAPROXY:SIAINTRP:FIALANG:FIAPROXY:FIAINTRP:MIALANG:MIAPROXY:MIAINTRP:AIALANGA:DMDHHSIZ:DMDFMSIZ:DMDHHSZA:DMDHHSZB:DMDHHSZE:DMDHRGND:DMDHRAGE:DMDHRBR4:DMDHREDU:DMDHRMAR:DMDHSEDU:WTINT2YR:WTMEC2YR:SDMVPSU:SDMVSTRA:INDHHIN2:INDFMIN2:INDFMPIR:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,diseases and epidemics
Results from Running Events in Porto Portugal , Pedro Lima , www.kaggle.com/pvlima/results-from-running-events-in-porto , Sun Jun 18 2017 22:19:09 GMT+0530 (IST) , Collection of results from running events in Porto Portugal between 2011-2017 ,31, running- ,Context Collection of results from running events in Porto Portugal.  Content Each row corresponds to the race name and year runner name official time (clock time) net time place age class sex and country. Data collected from the website runporto.com.,place:,numeric:,sports events
LCS 2017 Summer Split Fantasy Player & Team Stats , danielwatabe , www.kaggle.com/danielwatabe/lcs-2017-summer-split-fantasy-player-team-stats , Wed Oct 11 2017 22:05:35 GMT+0530 (IST) , LCS Summer 2017 Fantasy Stats ,22, video games- ,"As the Summer Split Regular Season comes to a close. We can look back on which players and teams performed well in terms of fantasy points.  Next to the Column Names. In the parenthesis is how many points are awarded.  For example in team stats Dragon Kills(+1) gives 1 point per dragon killed. Baron Kills gives 2 points.  In player stats ""10+K/A(+2)"" means +2 points when Kill+Assists is greater than 10 in a match. In player stats ""3K(+2)4K(+5)5k(+10)"" means +2 points per triple kill +5 points per quadra and +10 points per penta These are the point breakdowns according to the Fantasy LCS website ""LCS Players are scored accordingly  2 points per kill -0.5 points per death 1.5 points per assist 0.01 points per creep kill 2 points for a triple kill 5 points for a quadra kill (doesn't also count as a triple kill) 10 points for a penta kill (doesn't also count as a quadra kill) 2 points if a player attains 10 or more assists or kills in a game (this bonus only applies once)  LCS Teams are scored accordingly  2 points per win  2 points per Baron Nashor killed 1 point per Dragon killed 2 points per First Blood earned 1 point per Tower destroyed 2 points if the team wins in less than 30 minutes""  Source http//fantasy.na.lolesports.com/en-US/stats","Name:Role:Team:Results:Total Points:Avg Points Per Game:Game Played:Kill(+2):D(-0.5):A(+1.5):CS(+0.01):10+K/A(+2):3K(+2),4K(+5),5k(+10):",string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:,video games
Press Release by Govt. of India , Rajanand Ilangovan / இராஜ்ஆனந்த் இளங்கோவன் , www.kaggle.com/rajanand/press-release , Mon Oct 02 2017 09:14:48 GMT+0530 (IST) , 10000 records of press release from 2003. ,46, india- government- linguistics- ,I have used a web scrapper written in R to scrape the data from pib.nic.in website. Acknowledgements This dataset was scrapped from Press Information Bureau Government of India's website. Banner Photo by Patrick Tomasso on Unsplash.,pr_id:pr_datetime:pr_issued_by:pr_title:pr_content:,numeric:string:string:string:string:,online information
Automobile Dataset , Ramakrishnan Srinivasan , www.kaggle.com/toramky/automobile-dataset , Wed May 24 2017 10:15:13 GMT+0530 (IST) , Dataset consist of various characteristic of an auto ,777, automobiles- ,"Context This dataset consist of data From 1985 Ward's Automotive Yearbook. Here are the sources Sources  1) 1985 Model Import Car and Truck Specifications 1985 Ward's Automotive Yearbook.  2) Personal Auto Manuals Insurance Services Office 160 Water Street New York NY 10038  3) Insurance Collision Report Insurance Institute for Highway Safety Watergate 600 Washington DC 20037 Content This data set consists of three types of entities (a) the specification of an auto in terms of various characteristics (b) its assigned insurance risk rating (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then if it is more risky (or less) this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is risky -3 that it is probably pretty safe.  The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small station wagons sports/speciality etc...) and represents the average loss per car per year.  Note Several of the attributes in the database could be used as a ""class"" attribute. Inspiration Please bring it on whatever inferences you can get it.",symboling:normalized-losses:make:fuel-type:aspiration:num-of-doors:body-style:drive-wheels:engine-location:wheel-base:length:width:height:curb-weight:engine-type:num-of-cylinders:engine-size:fuel-system:bore:stroke:compression-ratio:horsepower:peak-rpm:city-mpg:highway-mpg:price:,numeric:numeric:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:string:string:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,Insurance
Meta Kaggle , Kaggle , www.kaggle.com/kaggle/meta-kaggle , Thu Jul 21 2016 02:40:29 GMT+0530 (IST) , Kaggle's public data on competitions users submission scores and kernels ,3184, statistics- telecommunications- ,We aren't saying this dataset is the Rosetta Stone of machine learning competitions but we do think there is a lot to learn from (and a lot of fun to be had by) releasing some of our most interesting tables on Kaggle community and competition activity. Strategizing to become a Master? Wondering who where and what goes in to a winning team? Deciding between evaluation metrics for your next data science project? We hope the scripts published here will enrich and entertain Kagglers spark some lively conversations and act as a resource for the larger machine learning community.  This data (available through Kaggle Scripts as CSV files and a SQLite database) contains the tables listed below. Note that this data is not a complete dump rows columns and tables have been filtered out and it is a small subset of the data that we can release publicly. Over time we'll add more of the tables that we can release publicly to it. ,Id:Name:Title:OrderId:,numeric:string:string:numeric:,online information
NYC Rat Sightings , City of New York , www.kaggle.com/new-york-city/nyc-rat-sightings , Mon Sep 18 2017 21:15:20 GMT+0530 (IST) , ~102k Observations Around New York ,104, government agencies- animals- government- ,Context Rats in New York City are prevalent as in many densely populated areas. For a long time the exact number of rats in New York City was unknown and a common urban legend was that there were up to four times as many rats as people. In 2014 however scientists more accurately measured the entire city's rat population to be approximately only 25% of the number of humans; i.e. there were approximately 2 million rats to New York's 8.4 million people at the time of the study.[1][2] Content New York City rodent complaints can be made online or by dialing 3-1-1 and the New York City guide Preventing Rats on Your Property discusses how the New York City Health Department inspects private and public properties for rats. Property owners that fail inspections receive a Commissioner's Order and have five days to correct the problem. If after five days the property fails a second inspection the owner receives a Notice of Violation and can be fined. The property owner is billed for any clean-up or extermination carried out by the Health Department. Data is from 2010-Sept 16th 2017 and includes date location (lat/lon) type of structure borough and community board. Acknowledgements Data was produced by the City of New York via their 311 portal. Inspiration  Where and when are rats most seen? Can you predict rat sightings from previous data? Are there any trends in rat sightings? ,Unique Key:Created Date:Closed Date:Agency:Agency Name:Complaint Type:Descriptor:Location Type:Incident Zip:Incident Address:Street Name:Cross Street 1:Cross Street 2:Intersection Street 1:Intersection Street 2:Address Type:City:Landmark:Facility Type:Status:Due Date:Resolution Action Updated Date:Community Board:Borough:X Coordinate (State Plane):Y Coordinate (State Plane):Park Facility Name:Park Borough:School Name:School Number:School Region:School Code:School Phone Number:School Address:School City:School State:School Zip:School Not Found:School or Citywide Complaint:Vehicle Type:Taxi Company Borough:Taxi Pick Up Location:Bridge Highway Name:Bridge Highway Direction:Road Ramp:Bridge Highway Segment:Garage Lot Name:Ferry Direction:Ferry Terminal Name:Latitude:Longitude:Location:,numeric:dateTime:dateTime:string:string:string:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:dateTime:dateTime:string:string:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:string:,zoological
FEM simulations , David , www.kaggle.com/daalgi/fem-simulations , Mon Oct 09 2017 12:52:53 GMT+0530 (IST) , Data to build a regression surrogate model of a complex numerical model ,29, data analysis- regression analysis- ,Context Engineers use numerical models to analyze the behavior of the systems they are studying. By means of numerical models you can prove whether a design is safe or not instead of making a prototype and testing it. This gives you great flexibility to modify parameters and to find a cheaper design that satisfies all the safety requirements. But when the models are too complex the numerical simulations can easily last from a few hours to a few days. In addition during the optimization process you might need a few tens of trials. So in order to simplify the process we can build a simple 'surrogate' model that yields similar results to the original one. Here's when Machine Learning comes in! Content The dataset contains the data of about 6000 numerical simulations (finite element models FEM). It must be pointed out that there is no noise in the data that is if we run again the simulations we'd get the same results. There are 9 input parameters and 4 output results. Inputs (continuous and positive values) (1) load parameters ecc N gammaG. (2) material parameters Esoil Econc. (3) geometry parameters Dbot H1 H2 H3. Outputs (continuous values) (1)  stress related results Mr_t Mt_t Mr_c Mt_c. Acknowledgements The parametric numerical model was self-made. Inspiration The data comes from deterministic numerical simulations. Under this circumstance is there any way we can find a regression model that gives accurate results? Let's say something like 5% error (True_value / Predicted_value within the range of [0.95 1.05]). What would be the most appropriate regression algorithms? What accuracy can we expect?,Sample:ecc:N:gammaG:Esoil:Econc:Dbot:H1:H2:H3:Mr_t:Mt_t:Mr_c:Mt_c:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Pakistan Suicide Bombing Attacks , Zeeshan-ul-hassan Usmani , www.kaggle.com/zusmani/pakistansuicideattacks , Tue Oct 10 2017 13:03:35 GMT+0530 (IST) , Most Authentic Count of Suicide Bombing Attacks in Pakistan (1995-2016) ,699, crime- ,Context Pakistan Suicide Bombing Attacks (1995-2016) Suicide bombing is an operational method in which the very act of the attack is dependent upon the death of the perpetrator. Though only 3% of all terrorist attacks around the world can be classified as suicide bombing attacks these account for 48% of the casualties. Explosions and suicide bombings have become the modus operandi of terrorist organizations throughout the world. The world is full of unwanted explosives brutal bombings accidents and violent conflicts and there is a need to understand the impact of these explosions on one’s surroundings the environment and most importantly on human bodies. From 1980 to 2001 (excluding 9/11/01) the average number of deaths per incident for suicide bombing attacks was 13. This number is far above the average of less than one death per incident across all types of terrorist attacks over the same time period. Suicide bombers unlike any other device or means of destruction can think and therefore detonate the charge at an optimal location with perfect timing to cause maximum carnage and destruction. Suicide bombers are adaptive and can quickly change targets if forced by security risk or the availability of better targets.  Suicide attacks are relatively inexpensive to fund and technologically primitive as IEDs can be readily constructed.  World has seen more than 3600 suicide bombing attacks in over 40 countries since 1982. Suicide Bombing has wreaked havoc in Pakistan in the last decade or so. From only a couple of attacks before 2000 it kept escalating after the US Operation Enduring Freedom in Afghanistan promiscuously killing hundreds of people each year towering as one of the most prominent security threats that every single Pakistani faces today. The conundrum of suicide bombing in Pakistan has obliterated 6982 clean-handed civilians and injured another 17624 in a total of 475 attacks since 1995. More than 94% of these attacks have taken place after year 2006. From 2007 to 2013 the country witnessed a suicide bombing attack on every 6th day that increased to every 4th day in 2013. Counting the dead and the injured each attack victimizes 48 people in Pakistan.  Pakistan Body Count (www.PakistanBodyCount.org) is the oldest and most accurate running tally of suicide bombings in Pakistan. The given database (PakistanSuicideAttacks.CSV) has been populated by using majority of the data from Pakistan Body Count and building up on it by canvassing open source newspapers media reports think tank analyses and personal contacts in media and law enforcement agencies. We provide a count of the people killed and injured in suicide attacks including the ones who died later in hospitals or homes due to injuries caused or aggravated by these attacks (second and tertiary blast injuries) making it the most authentic source for suicide attacks related data in this region. We will keep releasing the updates every quarter at this page. Content Geography Pakistan Time period 1995-2016  Unit of analysis Attack Dataset The dataset contains detailed information of 475 suicide bombing attacks in Pakistan that killed an estimated 6982 and injured 17624 people.  Variables The dataset contains Serial No Incident Date Islamic Date (based on Islamic lunar calendar) approximate Time Long-Lat City Province Location Location Sensitivity & Type Target type and Sect Open/Close Space (as it will change the impact of blast waves due to reflection) min and max number of people killed and injured number of suicide bombers amount of explosive being used and the name of hospitals where victims went for treatment. Sources Unclassified media articles hospital reports think tank analysis and reports and government official press releases. Acknowledgements & References Pakistan Body Count has been leveraged extensively in scholarly publications reports media articles and books. The website and the dataset has been collected and curated by the founder Zeeshan-ul-hassan Usmani.  Users are allowed to use copy distribute and cite the dataset as follows “Zeeshan-ul-hassan Usmani Pakistan Body Count Pakistan Suicide Bombing Attacks Dataset Kaggle Dataset Repository Jan 25 2017.” Past Work  Zeeshan-ul-hassan Usmani and Daniel Kirk “Simulation of Suicide Bombing – Using Computers to Save Lives” I-Universe New York NY April 2011 Zeeshan-ul-hassan Usmani and Daniel Kirk “Modeling and Simulation of Explosion Effectiveness as a Function of Blast and Crowd Characteristics” The Journal of Defense Modeling and Simulation Applications Methodology Technology Sage Publications with Society of Simulation Vol. 6 No. 2 pp. 79-95 Vista CA USA October 2009 Muhammad Irfan and Zeeshan-ul-hassan Usmani “Suicide Terrorism and its New Target –Pakistan” in Wars Insurgencies and Terrorist Attacks A Psychosocial Perspective from The Muslim World by Unaiza Niaz Oxford University Press Canada July 2010  Sana Rasheed Data Science for Suicide Bombings I-Universe New York NY December 2016  Zeeshan-ul-hassan Usmani and Sana Rasheed “Terrorism What Data Sciences Can Do?” 20th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2014 Data Framework Track) at Bloomberg  New York NY USA (August 24-27 2014) Zeeshan-ul-hassan Usmani “Suicide Bombing Forecaster – Novel Techniques to Predict Patterns of Suicide Bombing in Pakistan” 2012 Conference on Homeland Security part of 2012 Autumn Simulation Multi-Conference San Diego CA USA October 28 – 31 2012 Zeeshan-ul-hassan Usmani “BlastSim – Simulation to Save Lives” IEEE/SIC Winter Simulation Conference PhD Colloquium Austin Texas December 13-16 2009 Zeeshan-ul-hassan Usmani Fawzi Alghamdi and Daniel Kirk “BlastSim – Multi-agent Simulation of Suicide Bombing“ IEEE Symposium Computational Intelligence for Security and Defense Applications (CISDA) Ottawa Canada July 8-10 2009 Zeeshan-ul-hassan Usmani Eyosias Imana and Daniel Kirk “Virtual Iraq – Simulation of Insurgent Attacks” IEEE Workshop on Computational Intelligence in Virtual Environments (CIVE) March 30-April 2 2009  Zeeshan-ul-hassan Usmani Eyosias Imana and Daniel Kirk “Random Walk in Extreme Conditions – An Agent Based Simulation of Suicide Bombing” IEEE Symposium on Intelligent Agents March 2009 Zeeshan-ul-hassan Usmani Eyosias Imana and Daniel Kirk “Escaping Death – Geometrical Recommendations for High Value Targets” IEEE International Joint Conferences on Computer Information and Systems Sciences and Engineering (CIS2E 08) Bridgeport CT December 5–13 2008 Zeeshan-ul-hassan Usmani and Daniel Kirk “Extreme Conditions for Intelligent Agents” IEEE 2008 WI-IAT Doctoral Workshop Sydney Australia December 9-12 2008  Zeeshan-ul-hassan Usmani Andrew English & Richard Griffith “The Effects of a Suicide Bombing Crowd Formations” Inter-service/Industry Training Simulation and Education Conference (I/ITSEC) Orlando FL Nov 26-29 2007  Inspiration Some ideas worth exploring  How many people got killed and injured per year? Visualize suicide attacks on timeline Find out any correlation with number of suicide bombing attacks with drone attacks Find out any correlation with suicide bombing attacks with influencing events given in the dataset Can we predict the next suicide bombing attack? Find the correlation between blast/explosive weight and number of people killed and injured Find the impact of holiday type on number of blast victims Find the correlation between Islamic date and blast day/time/size/number of victims Find the Top 10 locations of blasts Find the names of hospitals sorted by number of victims   Questions? For detailed visit www.PakistanBodyCount.org  Or contact Pakistan Body Count staff at info@pakistanbodycount.org ,S#:Date:Islamic Date:Blast Day Type:Holiday Type:Time:City:Latitude:Longitude:Province:Location:Location Category:Location Sensitivity:Open/Closed Space:Influencing Event/Event:Target Type:Targeted Sect if any:Killed Min:Killed Max:Injured Min:Injured Max:No. of Suicide Blasts:Explosive Weight (max):Hospital Names:Temperature(C):Temperature(F):,numeric:string:string:string:string:dateTime:string:numeric:numeric:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:string:string:numeric:numeric:,crime
Austin 311 Calls , Jacob Boysen , www.kaggle.com/jboysen/austin-calls , Fri Aug 18 2017 23:15:59 GMT+0530 (IST) , 463k Public Complaints 2013-17 ,47, government agencies- ,Context 311 calls are a good snapshot of public complaints and provide interesting analytical data to predict future resource allocation by policymakers. Content Date time location description handling office and status are included. Acknowledgements This dataset was compiled by the City of Austin and published on Google Cloud Public Data. Inspiration  Any notable trends in location or volume of certain calls? Can you predict future 311 calls?  Dataset Description Use this dataset with BigQuery You can use Kernels to analyze share and discuss this data on Kaggle but if you’re looking for real-time updates and bigger data check out the data on BigQuery too.,city:close_date:complaint_description:complaint_type:council_district_code:county:created_date:incident_address:incident_zip:last_update_date:latitude:location:longitude:map_page:map_tile:owning_department:source:state_plane_x_coordinate:state_plane_y_coordinate:status:status_change_date:street_name:street_number:unique_key:,string:dateTime:string:string:numeric:string:dateTime:string:numeric:dateTime:numeric:string:numeric:string:string:string:string:numeric:numeric:string:dateTime:string:numeric:string:,
ATP Men's Tour , Jordan Goblet , www.kaggle.com/jordangoblet/atp-tour-20002016 , Tue Sep 27 2016 15:06:45 GMT+0530 (IST) , Results of the ATP tour competitions since 2000 ,1451, tennis- ,Results for the men's ATP tour date back to January 2000 including Grand Slams Masters Series Masters Cup and International Series competitions. Historical head-to-head betting odds go back to 2001. See here for more details about the metadata  http//www.tennis-data.co.uk/notes.txt Source - http//www.tennis-data.co.uk/data.php There is a lot you can do with this data set. The ultimate goal is obviously to predict the outcome of the game or to build an efficient betting strategy based on your model(s).  You can also  compare the betting agencies (Bet365 Bet&Win Ladbrokes Pinnacles...) in terms of predictions quality or measure the progress of these betting agencies over the years discover if it's possible to predict specific events (3 sets match retirement walk over...) or the evolution of players. ,,,game strategies
2016 US Election , Ben Hamner , www.kaggle.com/benhamner/2016-us-election , Fri Jul 01 2016 09:42:24 GMT+0530 (IST) , Explore data related to the 2016 US Election ,16141, politics- ,"This contains data relevant for the 2016 US Presidential Election including up-to-date primary results.   Exploration Ideas  What candidates within the Republican party have results that are the most anti-correlated? Which Republican candidate is Hillary Clinton most correlated with based on county voting patterns? What about Bernie Sanders? What insights can you discover by mapping this data?  Do you have answers or other exploration ideas? Add your ideas to this forum post and share your insights through Kaggle Scripts! Do you think that we should augment this dataset with more data sources? Submit a pull request to this repo or let us know here! Data Description The 2016 US Election dataset contains several main files and folders at the moment. You may download the entire archive via the ""Download Data"" link at the top of the page or interact with the data in Kaggle Scripts through the ../input directory. Original Data Sources  Primary Results from CNN New Hampshire County-Level Results County Shapefiles County QuickFacts ",fips:area_name:state_abbreviation:PST045214:PST040210:PST120214:POP010210:AGE135214:AGE295214:AGE775214:SEX255214:RHI125214:RHI225214:RHI325214:RHI425214:RHI525214:RHI625214:RHI725214:RHI825214:POP715213:POP645213:POP815213:EDU635213:EDU685213:VET605213:LFE305213:HSG010214:HSG445213:HSG096213:HSG495213:HSD410213:HSD310213:INC910213:INC110213:PVY020213:BZA010213:BZA110213:BZA115213:NES010213:SBO001207:SBO315207:SBO115207:SBO215207:SBO515207:SBO415207:SBO015207:MAN450207:WTN220207:RTN130207:RTN131207:AFN120207:BPS030214:LND110210:POP060210:,numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,elections
Movement coordination in trawling bats , Rob Harrand , www.kaggle.com/tentotheminus9/movement-coordination-in-trawling-bats , Thu Aug 24 2017 18:20:54 GMT+0530 (IST) , Explore how bats interact during flight ,24, ,Context This dataset comes from a study into the movement of bats by researchers at the University of Bristol UK. I found it whilst exploring the open datasets at the Movebank Data Repository a site dedicated to animal tracking data. Content The datasets contain information on the position and timestamps for multiple bats. The type of movement (individual or paired) is also included. See the readme.txt file for much more information. Acknowledgements I did not create this data. Full citations are below Data Holderied M Giuggioli L McKetterick TJ (2015) Data from Delayed response and biosonar perception explain movement coordination in trawling bats. Movebank Data Repository. doi10.5441/001/1.62h1f7k9 Associated paper (open access) Giuggioli L McKetterick TJ Holderied M (2015) Delayed response and biosonar perception explain movement coordination in trawling bats. PLOS Computational Biology. doi10.1371/journal.pcbi.1004089.t001,event-id:visible:timestamp:location-long:location-lat:comments:sensor-type:individual-taxon-canonical-name:tag-local-identifier:individual-local-identifier:study-name:,numeric:boolean:dateTime:numeric:numeric:string:string:string:numeric:numeric:string:,zoological
Austin Bike Share Trips , Jacob Boysen , www.kaggle.com/jboysen/austin-bike , Thu Aug 10 2017 03:06:19 GMT+0530 (IST) , Information on 649k Bike Rides Across Austin ,132, cycling- ,Context Bike shares are becoming a popular alternative means of transportation. The City of Austin makes data available on >649k bike trips over 2013-2017. Content This data includes information on bike trip start location stop location duration type of bike share user. Bike station location data is also provided. Dataset Description Use this dataset with BigQuery You can use Kernels to analyze share and discuss this data on Kaggle but if you’re looking for real-time updates and bigger data check out the data on BigQuery too. *austin_bikeshare_trips.csv*  bikeid integer id of bike  checkout_time HHMMSS see start time for date stamp duration_minutes int minutes of trip duration end_station_id integer id of end station end_station_name string of end station name month month integer start_station_id integer id of start station start_station_name string of start station name start_time YYYY-MM-DD HHMMSS subscriber_type membership typ e.g. walk up annual other bike share etc trip_id unique trip id int year year of trip int  *austin_bikeshare_stations.csv*  latitude geospatial latitude precision to 5 places location (lat long) longitude geospatial longitude precision to 5 places name station name str station_id unique station id int status station status (active closed moved ACL-only)  Acknowledgements This dataset is available from Google Public Data. Inspiration  What stations are most popular? At certain times? What are the average user trip?  Can you predict station usage to improve the ability of bike share employees to supply high-use stations? ,latitude:location:longitude:name:station_id:status:,numeric:string:numeric:string:numeric:string:,roadways
Indoor Positioning , liwste , www.kaggle.com/liwste/indoor-positioning , Mon Mar 13 2017 01:24:09 GMT+0530 (IST) , Dataset of bluetooth beacons readings indoor ,206, networks- ,Context I am interested in indoor positioning technology and had been playing with blue-tooth beacons. Typically blue-tooth beacons have accuracy of a range between 1 to 4 meters. I am thinking of maybe using machine learning can produce results of greater accuracy compared to using traditional filtering methods e.g. kalman filters particle filters. Content 3 Kontakt blue-tooth beacons are mounted in a 2.74 meters wide x 4.38 meters long (width x length) room. The 3 beacons are transmitting at a transmit power of -12dbm. A Sony Xperia E3 smartphone with blue-tooth turned on is used as a receiver to the record the data. Recordings are done on several positions in the room of an interval of 30-60 seconds in the same position. Beacons location #  Beacon                       X(meters)         Y(meters) BeaconA                        0.10                   1.80 BeaconB                        2.74                   2.66 BeaconC                        1.22                   4.54  Fields  The distance in meters between beacon A and the device calculated by using the rssi of this blue-tooth beacon. The distance in meters between beacon B and the device calculated by using the rssi of this blue-tooth beacon. The distance in meters between beacon C and the device calculated by using the rssi of this blue-tooth beacon. X coordinate in centimeters rounded to the nearest centimeter measured using a measuring tape with +/-1cm accuracy. Y coordinate in centimeters rounded to the nearest centimeter measured using a measuring tape with +/-1cm accuracy. Date and time of the recording.  Acknowledgements The data is collected solely by me. Inspiration To try and improve on the accuracy of indoor position using blue-tooth beacons which typically have accuracy of range between 1 meters to 4 meters.,Distance A:Distance B:Distance C:Position X:Position Y:Date:Time:,numeric:numeric:numeric:numeric:numeric:dateTime:string:,gadgets
US Stocks Fundamentals (XBRL) , usfundamentals , www.kaggle.com/usfundamentals/us-stocks-fundamentals , Tue Sep 06 2016 23:56:53 GMT+0530 (IST) , Fundamental data for 12129 companies based on XBRL ,3254, finance- ,This dataset contains US stocks fundamental data such as income statement balance sheet and cash flows.  12129 companies 8526 unique indicators ~20 indicators comparable across most companies Five years of data yearly  The data is provided by http//usfundamentals.com.,company_id:name_latest:names_previous:,numeric:string:string:,stock data
Datascience Universities across US , SrihariRao , www.kaggle.com/sriharirao/datascience-universities-across-us , Sun Sep 25 2016 00:34:59 GMT+0530 (IST) , Contains datascience programs offered and location data by university. ,1301, education- data- information technology- ,Contains DataScience programs offered by universities along with program details world ranking and a lot lot more. Happy exploring !!!,SCHOOL:STATE:CITY:NOC:PROGRAM:TYPE:DEPARTMENT:DELIVERY:DURATION:PREREQ:LINK:LOC_LAT:LOC_LONG:WORLD_RANK:COUNTRY:TEACHING:INTERNATIONAL:RESEARCH:CITATIONS:INCOME:TOTAL_SCORE:NUM_STUDENTS:STUDENT_STAFF_RATIO:INTERNATIONAL_STUDENTS:F_M_RATIO:YEAR:timesData:,string:string:string:numeric:string:string:string:string:string:string:string:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:numeric:numeric:,universities and colleges
Cycle Share Dataset , Pronto Cycle Share , www.kaggle.com/pronto/cycle-share-dataset , Mon Nov 07 2016 08:06:29 GMT+0530 (IST) , Bicycle Trip Data from Seattle's Cycle Share System ,1601, cycling- road transport- ,"Context The Pronto Cycle Share system consists of 500 bikes and 54 stations located in Seattle. Pronto provides open data on individual trips stations and daily weather. Content There are 3 datasets that provide data on the stations trips and weather from 2014-2016.  Station dataset station_id station ID number name name of station lat station latitude long station longitude install_date date that station was placed in service install_dockcount number of docks at each station on the installation date modification_date date that station was modified resulting in a change in location or dock count current_dockcount number of docks at each station on 8/31/2016 decommission_date date that station was placed out of service Trip dataset trip_id numeric ID of bike trip taken starttime day and time trip started in PST stoptime day and time trip ended in PST bikeid ID attached to each bike tripduration time of trip in seconds  from_station_name name of station where trip originated to_station_name name of station where trip terminated  from_station_id ID of station where trip originated to_station_id ID of station where trip terminated usertype ""Short-Term Pass Holder"" is a rider who purchased a 24-Hour or 3-Day Pass; ""Member"" is a rider who purchased a Monthly or an Annual Membership gender gender of rider  birthyear birth year of rider Weather dataset contains daily weather information in the service area  Acknowledgements The original datasets can be downloaded here. Inspiration Some ideas worth exploring  What is the most popular bike route? How are bike uses or routes affected by user characteristics station features and weather? ",station_id:name:lat:long:install_date:install_dockcount:modification_date:current_dockcount:decommission_date:,string:string:numeric:numeric:dateTime:numeric:dateTime:numeric:string:,roadways
Historical Sales and Active Inventory , JamesS , www.kaggle.com/flenderson/sales-analysis , Thu Dec 08 2016 07:13:20 GMT+0530 (IST) , Records of sold and unsold products and their characteristics ,2000, business- product- ,"Context Attached is a set of products in which we are trying to determine which products we should continue to sell and which products to remove from our inventory. The file contains BOTH historical sales data AND active inventory which can be discerned with the column titled ""File Type"".  We suspect that data science applied to the set--such as a decision tree analysis or logistic regression or some other machine learning model---can help us generate a value (i.e. probability score) for each product that can be used as the main determinant evaluating the inventory. Each row in the file represents one product.  It is important to note that we have MANY products in our inventory and very few of them tend to sell (only about 10% sell each year) and many of the products only have a single sale in the course of a year. Content The file contains historical sales data (identified with the column titled File_Type) along with current active inventory that is in need of evaluation (i.e. File Type = ""Active""). The historical data shows sales for the past 6 months. The binary target (1 = sale 0 = no sale in past six months) is likely the primary target that should drive the analysis.  The other columns contain numeric and categorical attributes that we deem relevant to sales.  Note that some of the historical sales SKUs are ALSO included in the active inventory.  A few comments about the attributes included as we realize we may have some attributes that are unnecessary or may need to be explained.   SKU_number This is the unique identifier for each product. Order Just a sequential counter. Can be ignored. SoldFlag 1 = sold in past 6 mos. 0 = Not sold MarketingType = Two categories of how we market the product. This should probably be ignored or better yet each type should be considered independently.  New_Release_Flag = Any product that has had a future release (i.e.  Release Number > 1)  Inspiration (1) What is the best model to use that will provide us with a probability estimate of a sale for each SKU? We are mainly interested in a relative unit that we can continuously update based on these attributes (and others that we add as we are able).  (2) Is it possible to provide a scored file (i.e. a probability score for each SKU in the file) and to provide an evaluation of the accuracy of the selected model?  (3) What are the next steps we should take? Thanks very much for any suggestions you may provide.",Order:File_Type:SKU_number:SoldFlag:SoldCount:MarketingType:ReleaseNumber:New_Release_Flag:StrengthFactor:PriceReg:ReleaseYear:ItemCount:LowUserPrice:LowNetPrice:,numeric:string:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,trade and business
PLAYERUNKNOWN'S BATTLEGROUNDS Player Statistics , JustinMoore , www.kaggle.com/lazyjustin/pubgplayerstats , Tue Aug 01 2017 20:33:34 GMT+0530 (IST) , Player statistics for PUBG. 150 features per player. ,183, video games- games- ,Context Grab your pans... Player statistics for approximately 85000 of the top PUBG players (as tracked by https//pubgtracker.com/). All statistics were gathered using aggregate region filters (all regions) and feature labels are subdivided by server type solo duo and squad. 87898 players with 150 numerical game-play features per player (+2 for player name and PUBG Tracker ID). Content Features include KD ratios wins losses damage wins top 10's and movement characteristics (walking/riding distance etc...) Acknowledgements Special thanks to pubgtracker.com for their support and aid with gathering this data. More information can be found here https//pubgtracker.com/ PLAYERUNKNOWN'S BATTLEGROUNDS is a registered trademark trademark or service mark of Bluehole Inc. and its affiliates https//www.playbattlegrounds.com/main.pu Inspiration As a gamer addicted to PUBG it was a blast putting this data set together. Some great project ideas include a. Visualizations of player skill vs. specific strategies b. Unsupervised clustering of players based on strategy (for matchmaking or team building) c. Prediction of features based on player skill and/or strategies,player_name:tracker_id:solo_KillDeathRatio:solo_WinRatio:solo_TimeSurvived:solo_RoundsPlayed:solo_Wins:solo_WinTop10Ratio:solo_Top10s:solo_Top10Ratio:solo_Losses:solo_Rating:solo_BestRating:solo_DamagePg:solo_HeadshotKillsPg:solo_HealsPg:solo_KillsPg:solo_MoveDistancePg:solo_RevivesPg:solo_RoadKillsPg:solo_TeamKillsPg:solo_TimeSurvivedPg:solo_Top10sPg:solo_Kills:solo_Assists:solo_Suicides:solo_TeamKills:solo_HeadshotKills:solo_HeadshotKillRatio:solo_VehicleDestroys:solo_RoadKills:solo_DailyKills:solo_WeeklyKills:solo_RoundMostKills:solo_MaxKillStreaks:solo_WeaponAcquired:solo_Days:solo_LongestTimeSurvived:solo_MostSurvivalTime:solo_AvgSurvivalTime:solo_WinPoints:solo_WalkDistance:solo_RideDistance:solo_MoveDistance:solo_AvgWalkDistance:solo_AvgRideDistance:solo_LongestKill:solo_Heals:solo_Revives:solo_Boosts:solo_DamageDealt:solo_DBNOs:duo_KillDeathRatio:duo_WinRatio:duo_TimeSurvived:duo_RoundsPlayed:duo_Wins:duo_WinTop10Ratio:duo_Top10s:duo_Top10Ratio:duo_Losses:duo_Rating:duo_BestRating:duo_DamagePg:duo_HeadshotKillsPg:duo_HealsPg:duo_KillsPg:duo_MoveDistancePg:duo_RevivesPg:duo_RoadKillsPg:duo_TeamKillsPg:duo_TimeSurvivedPg:duo_Top10sPg:duo_Kills:duo_Assists:duo_Suicides:duo_TeamKills:duo_HeadshotKills:duo_HeadshotKillRatio:duo_VehicleDestroys:duo_RoadKills:duo_DailyKills:duo_WeeklyKills:duo_RoundMostKills:duo_MaxKillStreaks:duo_WeaponAcquired:duo_Days:duo_LongestTimeSurvived:duo_MostSurvivalTime:duo_AvgSurvivalTime:duo_WinPoints:duo_WalkDistance:duo_RideDistance:duo_MoveDistance:duo_AvgWalkDistance:duo_AvgRideDistance:duo_LongestKill:duo_Heals:duo_Revives:duo_Boosts:duo_DamageDealt:duo_DBNOs:squad_KillDeathRatio:squad_WinRatio:squad_TimeSurvived:squad_RoundsPlayed:squad_Wins:squad_WinTop10Ratio:squad_Top10s:squad_Top10Ratio:squad_Losses:squad_Rating:squad_BestRating:squad_DamagePg:squad_HeadshotKillsPg:squad_HealsPg:squad_KillsPg:squad_MoveDistancePg:squad_RevivesPg:squad_RoadKillsPg:squad_TeamKillsPg:squad_TimeSurvivedPg:squad_Top10sPg:squad_Kills:squad_Assists:squad_Suicides:squad_TeamKills:squad_HeadshotKills:squad_HeadshotKillRatio:squad_VehicleDestroys:squad_RoadKills:squad_DailyKills:squad_WeeklyKills:squad_RoundMostKills:squad_MaxKillStreaks:squad_WeaponAcquired:squad_Days:squad_LongestTimeSurvived:squad_MostSurvivalTime:squad_AvgSurvivalTime:squad_WinPoints:squad_WalkDistance:squad_RideDistance:squad_MoveDistance:squad_AvgWalkDistance:squad_AvgRideDistance:squad_LongestKill:squad_Heals:squad_Revives:squad_Boosts:squad_DamageDealt:squad_DBNOs:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,video games
Weekly Dairy Product Prices , Sohier Dane , www.kaggle.com/sohier/weekly-dairy-product-prices , Wed Aug 30 2017 03:56:17 GMT+0530 (IST) , USDA data on bulk dairy production since 2010 ,132, finance- agriculture- ,We don't always think about industrial scale food but cheese blocks the size of a small car are important. The Mandatory Price Reporting Act of 2010 (pdf) was passed on September 27 2010 the act required USDA to release dairy product sales information on or before Wednesday at 300 pm EST (unless affected by a Federal Holiday). The act also required the establishment of an electronic mandatory price reporting system for dairy products reported under Public Law 106-532. These dairy statistics will continue to be collected on a weekly basis AMS-Dairy Programs will collect analyze aggregate and publish dairy product sales information for selected dairy commodities. Acknowledgements This data is released by the US Department of Agriculture. You can find the original dataset here.  Inspiration  Can you predict changes in moisture content for 40 pound blocks of cheese? ,Week Ending Date:Report Date:Date:Weighted Prices:Sales:,dateTime:dateTime:dateTime:numeric:numeric:,
Animal Bites , Rachael Tatman , www.kaggle.com/rtatman/animal-bites , Fri Sep 15 2017 22:51:38 GMT+0530 (IST) , Data on over 9000 bites including rabies tests ,211, human medicine- animals- crime- violence- ,Context In the United States animal bites are often reported to law enforcement (such as animal control). The main concern with an animal bite is that the animal may be rabid. This dataset includes information on over 9000 animal bites which occurred near Louisville Kentucky from 1985 to 2017 and includes information on whether the animal was quarantined after the bite occurred and whether that animal was rabid. Content Attributes of animal bite incidents reported to and investigated by Louisville Metro Department of Public Health and Wellness.  Personal/identifying data has been removed. This dataset is a single .csv with the following fields.  bite_date The date the bite occurred SpeciesIDDesc The species of animal that did the biting BreedIDDesc Breed (if known) GenderIDDesc Gender (of the animal) color color of the animal vaccination_yrs how many years had passed since the last vaccination vaccination_date the date of the last vaccination victim_zip the zipcode of the victim AdvIssuedYNDesc whether advice was issued WhereBittenIDDesc Where on the body the victim was bitten quarantine_date whether the animal was quarantined DispositionIDDesc whether the animal was released from quarantine head_sent_date the date the animal’s head was sent to the lab release_date the date the animal was released     ResultsIDDesc results from lab tests (for rabies)  Acknowledgements Attributes of animal bite incidents reported to and investigated by Louisville Metro Department of Public Health and Wellness. This data is in the public domain. Inspiration  Which animals are most likely to bite humans? Are some dog breeds more likely to bite? What factors are most strongly associated with a positive rabies ID?  ,bite_date:SpeciesIDDesc:BreedIDDesc:GenderIDDesc:color:vaccination_yrs:vaccination_date:victim_zip:AdvIssuedYNDesc:WhereBittenIDDesc:quarantine_date:DispositionIDDesc:head_sent_date:release_date:ResultsIDDesc:,dateTime:string:string:string:string:numeric:dateTime:numeric:string:string:dateTime:string:string:string:string:,zoological
US Adult Income , John Olafenwa , www.kaggle.com/johnolafenwa/us-census-data , Fri Jul 14 2017 19:09:37 GMT+0530 (IST) , Data set of adult income ,958, income- economics- ,"US Adult Census data relating income to social factors such as Age Education race etc. The Us Adult income dataset was extracted  by Barry Becker from the 1994 US Census Database. The data set consists of anonymous information such as occupation age native country race capital gain capital loss education work class and more. Each row is labelled as either having a salary greater than "">50K"" or ""<=50K"". This Data set is split into two CSV files named adult-training.txt and adult-test.txt. The goal here is to train a binary classifier on the training dataset to predict the column income_bracket which has two possible values "">50K"" and ""<=50K""  and evaluate the accuracy of the classifier with the test dataset.  Note that the dataset is made up of categorical and continuous features. It also contains missing values  The categorical columns are workclass education marital_status occupation relationship race gender native_country The continuous columns are age education_num capital_gain capital_loss hours_per_week This Dataset was obtained from the UCI repository it can be found  on https//archive.ics.uci.edu/ml/datasets/census+income  http//mlr.cs.umass.edu/ml/machine-learning-databases/adult/ USAGE This dataset is well suited to developing and testing wide linear classifiers deep neutral network classifiers and a combination of both. For more info on Combined Deep and Wide Model classifiers refer to the Research Paper by Google https//arxiv.org/abs/1606.07792 Refer to this kernel for sample usage  https//www.kaggle.com/johnolafenwa/wage-prediction Complete Tutorial is available from  http//johnolafenwa.blogspot.com.ng/2017/07/machine-learning-tutorial-1-wage.html?m=1 ",|1x3 Cross validator:,numeric:,income
Detailed NFL Play-by-Play Data 2015 , Max Horowitz , www.kaggle.com/maxhorowitz/nflplaybyplay2015 , Mon Oct 03 2016 07:46:14 GMT+0530 (IST) , An NFL dataset generated by the nflscrapR R-package & primed for analysis ,3154, american football- ,"Introduction The lack of publicly available National Football League (NFL) data sources has been a major obstacle in the creation of modern reproducible research in football analytics.  While clean play-by-play data is available via open-source software packages in other sports (e.g. nhlscrapr for hockey; PitchF/x data in baseball; the NBA API for basketball) the equivalent datasets are not freely available for researchers interested in the statistical analysis of the NFL.  To solve this issue a group of Carnegie Mellon University statistical researchers led by recent graduate Maksim Horowitz built and released nflscrapR an R package which uses an API maintained by the NFL to scrape clean parse and output clean datasets at the individual play player game and season levels.  These datasets allow for the advancement of NFL research in the public domain by allowing analysts to develop from a common source in order to create reproducible NFL research similar to what is being done currently in other professional sports.  2015 NFL Play-by-Play Dataset The dataset made available on Kaggle contains all the regular season plays from the 2015-2016 NFL season.  The dataset contain 46129 rows and 63 columns.  Each play is broken down into great detail containing information on; game situation players involved and results.  Detailed information about the dataset can be found in the nflscrapR documentation. Downloading and Installing nflscrapR Use the following code in your R console # Must install the devtools package using the below code install.packages('devtools') library(devtools) # For now you must install nflscrapR from github if (!is.element(""nflscrapR"" installed.packages())) {     # Print Installing nflscrapR     devtoolsinstall_github(repo = ""maksimhorowitz/nflscrapR"") }  library(nflscrapR) ",,,football
Insect Light Trap , University of Copenhagen , www.kaggle.com/University-of-Copenhagen/insect-light-trap , Wed Jul 12 2017 05:22:49 GMT+0530 (IST) , The University of Copenhagen’s Zoological Museum zapped insects for 18 years ,140, biology- environment- ,Context The University of Copenhagen’s Zoological Museum placed a light trap on their roof and for 18 years they documented the types of insects being caught.  The data was collected as part of a study to determine insect responses to recent climate change. Content This file contains the raw data from the light trapping study ordered by Order (Lepidoptera/Coleoptera) family name (species) year date1 (start) date2 (end) and number of individuals Acknowledgements Original publication Thomsen PF Jørgensen PS Bruun HH Pedersen J Riis-Nielsen T Jonko K Słowińska I Rahbek C Karsholt O (2016) Resource specialists lead local insect community turnover associated with temperature – analysis of an 18-year full-seasonal record of moths and beetles. Journal of Animal Ecology 85(1) 251–261. http//dx.doi.org/10.1111/1365-2656.12452 The original dataset can be found at http//datadryad.org/resource/doi10.5061/dryad.s4945/1 Inspiration Climate change is on everyone's mind for one reason or another and insects are susceptible to climate change just like humans. Using these data can you determine which species have become more or less prevalent over the 18 years of collection?,order:family:name:year:date1:date2:individuals:,string:string:string:numeric:dateTime:dateTime:numeric:,zoological
India Water Quality Data , Venkat Ramakrishnan , www.kaggle.com/venkatramakrishnan/india-water-quality-data , Sat Dec 31 2016 17:52:01 GMT+0530 (IST) , Government data related to the water quality of India ,1170, water technology- ,Context There has been increased interest among the public about the Environment and living conditions in India.  Especially after since many manufacturing units are being planned people are worried about how it will affect the underground water quality and the environment.  Government of India under the Ministry of Drinking Water and Sanitation has released the Water Quality Affected Data for 2009 2010 2011 and 2012.  The objective here is to analyze this data alongside with Forest Industries Habitation and development projects data in the same area (panchayat) to figure out whether there is any connection between the development effort and the quality of water getting affected.  This effort will identify such associations and create awareness such that people and the Govt. can act in time to avoid further deterioration of the water resources. Content Currently there is this data set of areas with affected water quality for the years 2009 2010 2011 and 2012.   Further datasets are expected for subsequent years.  These datasets identify the state district and specific localities in which water quality degradation has been reported in that particular year.  Focus should be on the area (Panchayat/Village) rather than the district or the state as a whole and observations should be made if there are any associations between the other sets of data available for the same area (from industrial habitation manufacturing and other sources which I intend to add here also). Acknowledgements My deep gratitude to the Government of India for making this data available through the Open Data initiative. Inspiration  Let's explore if there are any repetitive patterns of water quality degradation in the same area for multiple years. As a whole which areas in India has a lot of water quality degradation issues over the years (heat maps) Which chemical is predominantly present in most of the water quality issues (heat maps). And why (from the associations with other developmental data like industry manufacturing development initiatives housing habitation etc.) As a whole for the country is the water quality degrading or upgrading (number of instances reported of water quality getting affected)? Let's explore if there are any associations between the water quality data and the other developmental data.  If there is then what is the extent (visualisation) and how can we address it (prescriptive). Let's predict if there are GOING TO BE water quality issues in areas that are not affected right now based on the developmental and water quality data that is available right now. Prevention is better than cure!  It would be great if we could have water quality and industrial/development experts in this analysis so that they can contribute their valuable inputs!,State Name:District Name:Block Name:Panchayat Name:Village Name:Habitation Name:Quality Parameter:Year:,string:string:string:string:string:string:string:dateTime:,water pollution
National Institute of the Korean Language Corpus , Rachael Tatman , www.kaggle.com/rtatman/national-institute-of-the-korean-language-corpus , Sat Oct 07 2017 02:41:05 GMT+0530 (IST) , Korean frequency lists for NLP ,31, languages- asia- linguistics- ,Context How frequently a word occurs in a language is an important piece of information for natural language processing and linguists. In natural language processing very frequent words tend to be less informative than less frequent one and are often removed during preprocessing.  This dataset contains frequency information on Korean which is spoken by 80 million people. For each item both the frequency (number of times it occurs in the corpus) and its relative rank to other lemmas is provided. Content This dataset contains six sub-files with frequency information. The files have been renamed in English but no changes have been made to the file contents. The files and their headers are listed below.  The text in this dataset is UTF-8.  Frequency by Jamo (letter) 순위 Rank 빈도 Frequency 위치 Location 자모 Jamo (Hangul letter) Frequency 순위 Rank 빈도 Frequency  항목 Location 범주 Category Frequency by Syllable 순위 Rank 빈도 Frequency 음절 Syllable Borrowings 순위 Rank 빈도 Frequency 항목 Item 풀이 Root Non Standard Words 순위 Rank 빈도 Frequency 어휘 Vocabulary 풀이 Notes  품사 Part of Speech Frequency (Longer version) 순위 Rank 빈도 Frequency  항목 Location 범주 Category  Acknowledgements This dataset was collected and made available by the National Institute of Korean Language. The dataset and additional documentation (in Korean) can be found here.  This dataset is distributed under a Korean Open Government Liscence type 4. It may be redistributed with attribution without derivatives and not for commercial purposes. Inspiration  What are the most frequent jamo (Hangul characters) in Korean? Least frequent? What qualities do borrowed words have? Is there a relationship between word length and frequency?  You may also like  English word frequency Japanese lemma frequency List of simplified Chinese characters ordered by frequency rank Stopword lists for African languages ,순위:빈도:항목:풀이::,numeric:numeric:string:string:string:,text analysis
Celebrity Deaths , HugoDarwood , www.kaggle.com/hugodarwood/celebrity-deaths , Sat Jan 14 2017 14:18:12 GMT+0530 (IST) , All wikipedia-listed celebrity deaths from 2006 ,2179, biographical dictionaries- celebrity- death- ,Context I created this dataset to investigate the claim that 2016 had an unnaturally large number of celebrity deaths. Content Points listed by Name Age Cause of death and Reason for fame Acknowledgements Lifted from https//en.wikipedia.org/wiki/Deaths_in_2016 for all years,age:birth_year:cause_of_death:death_month:death_year:famous_for:name:nationality:fame_score:,numeric:numeric:string:string:numeric:string:string:string:numeric:,demography
Agricuture  Crops Production In india , SrinivasRao , www.kaggle.com/srinivas1/agricuture-crops-production-in-india , Mon Aug 14 2017 00:31:38 GMT+0530 (IST) , Various Crops Cultivation/Production ,301, india- business- agriculture- ,Context Agricuture Production in India from 2001-2014 Content This Dataset Describes the Agricuture Crops Cultivation/Production in india. This is from https//data.gov.in/ fully Licensed Acknowledgements This Dataset can solves the problems of various crops Cultivation/production in india. Columns cropstring crop name Varietystringcrop subsidary name state stringCrops Cultivation/production Place QuantityIntegerno of Quintals/Hectars productionIntegerno of years Production SeasonDateTimemedium(no of days)long(no of days) UnitString  Tons CostInteger cost of cutivation and Production Recommended ZoneString place(StateMandalVillage) Inspiration Across The Globe India Is The Second Largest Country having People more than 1.3 Billion. Many People Are Dependent On The Agricuture And it is the Main Resource. In Agricuturce Cultivation/Production Having More Problems.  I want to solve the Big problem in india and usefull to  many more people,Crop:State:Cost of Cultivation (`/Hectare) A2+FL:Cost of Cultivation (`/Hectare) C2:Cost of Production (`/Quintal) C2:Yield (Quintal/ Hectare) :,string:string:numeric:numeric:numeric:numeric:,
News Aggregator Dataset , UCI Machine Learning , www.kaggle.com/uciml/news-aggregator-dataset , Tue Nov 01 2016 03:52:55 GMT+0530 (IST) , Headlines and categories of 400k news stories from 2014 ,1563, news agencies- linguistics- ,This dataset contains headlines URLs and categories for 422937 news stories collected by a web aggregator between March 10th 2014 and August 10th 2014. News categories included in this dataset include business; science and technology; entertainment; and health. Different news articles that refer to the same news item (e.g. several articles about recently released employment statistics) are also categorized together. Content The columns included in this dataset are  ID  the numeric ID of the article TITLE  the headline of the article URL  the URL of the article PUBLISHER  the publisher of the article CATEGORY  the category of the news item; one of -- b  business -- t  science and technology -- e  entertainment -- m  health STORY  alphanumeric ID of the news story that the article discusses HOSTNAME  hostname where the article was posted TIMESTAMP  approximate timestamp of the article's publication given in Unix time (seconds since midnight on Jan 1 1970)  Acknowledgments This dataset comes from the UCI Machine Learning Repository. Any publications that use this data should cite the repository as follows Lichman M. (2013). UCI Machine Learning Repository [http//archive.ics.uci.edu/ml]. Irvine CA University of California School of Information and Computer Science. This specific dataset can be found in the UCI ML Repository at this URL Inspiration What kinds of questions can we explore using this dataset? Here are a few possibilities  can we predict the category (business entertainment etc.) of a news article given only its headline? can we predict the specific story that a news article refers to given only its headline? ,,,news
Saturday Night Live , Hendrik Hilleckes , www.kaggle.com/hhllcks/snldb , Wed Oct 18 2017 20:14:53 GMT+0530 (IST) , Over 40 seasons of hilarious data ,556, popular culture- film- ,"Context I was thinking about a dataset that I could provide and when I was reading through the LiveFromNewYork subreddit I got the idea what about a Saturday Night Live dataset? Wouldn't it be fun to analyze the data about a TV show that airs since the 70s? Content I aim to improve the dataset over time and update the files with more data. But I think that I have enough already so that people can work with it. There are files for the following objects  season episode title actor actor_title (mapping of actors and titles) rating (episode rating from IMDb.com)  Acknowledgements A lot of the data comes from http//www.snlarchives.net where Joel Navaroli (@snlmedia) created a great snl archive. You can find everything about SNL there. Want to know about the 5th sketch in the 3rd episode in season 13? Go there to find out! I got the ratings from IMDb.com.  I used Scrapy to get the data from the websites. Inspiration Since SNL is such a long running TV show I thought it would be interesting to see how it developed over time. There are also some prejudices around like ""there was a big slump from season X to Y"". Do the user ratings reflect that? I provided an example analysis so that everyone can get started easily with the data. Source You can find everything about the dataset in the GitHub repository http//www.github.com/hhllcks/snldb",aid:type:url:gender:,string:string:string:string:,TV shows
Brazilian Motor Insurance Market , Rodrigo Domingos , www.kaggle.com/rodrigodomingos/brazilian-insurance-motor-market , Wed Jan 11 2017 14:46:34 GMT+0530 (IST) , An introduction to the Brazilian motor insurance market trends ,316, automobiles- ,Context The Brazilian government compiles motor insurance data from ago/2000 to ago/2016 and makes it available for public consumption. Content There's information about the performance of Brazilian insurance motor like Premium claim and commission. Acknowledgements SUSEP is a governmental office responsible for collect house and share this information http//www2.susep.gov.br/menuestatistica/SES/principal.aspx Inspiration This information can answer questions about performance and trends regarding to Brazilian motor line of business and make user able to gain insight about this market. I know this data well but my inspiration to share this data on Kaggle is to discuss and see different points of view.,Coenti:Noenti:Cogrupo:Nogrupo:,numeric:string:string:string:,Insurance
HMO Capitation DataSet , Kingsley Samuel , www.kaggle.com/kelvinkins/hmo-capitation-dataset , Fri Oct 06 2017 21:25:28 GMT+0530 (IST) , Capitation Data of staff patients of a company between 2017-09-01 and 2017-10-01 ,25, ,Context This dataset is a capitation list containing the list of staff of a company eligible for treatment for the specified period of time. With this dataset One can study how much a company spends on her staff on a monthly basis how often staffs are added to the health insurance scheme and how often staffs are withdrawn from the scheme. Content The datasets contains the following column with about 103385 rows which is the data of two months 2017-09-01 and 2017-10-01  ID_capitation Hospital_ID CapitationAmount ValueDate CompanyID PatientUniqueID CapitationType  Inspiration How can we eradicate fraud from this system because capitation Fee are still being paid on some ghost staffs.,ID_capitation:Hospital_ID:CapitationAmount:ValueDate:CompanyID:PatientUniqueID:CapitationType:,numeric:numeric:numeric:dateTime:numeric:string:string:,Insurance
Las Vegas TripAdvisor Reviews , Chris Crawford , www.kaggle.com/crawford/las-vegas-tripadvisor-reviews , Tue Aug 29 2017 01:30:08 GMT+0530 (IST) , 500 reviews from hotels on the Las Vegas Strip ,101, cities- hotels- ,Context This dataset includes quantitative and categorical features from online reviews from 21 hotels located in Las Vegas Strip extracted from TripAdvisor. All the 504 reviews were collected between January and August of 2015. Content The dataset contains 504 records and 20 tuned features  24 per hotel (two per each month randomly selected) regarding the year of 2015.  The CSV contains a header with the names of the columns corresponding to the features. Acknowledgements Lichman M. (2013). UCI Machine Learning Repository http//archive.ics.uci.edu/ml. Irvine CA University of California School of Information and Computer Science Downloaded form UCI Machine Learning Repository Inspiration Do machine learning algorithms take into account what happens in Vegas stays in Vegas?,User country:,string:,online reviews and ratings
MovieLens 20M Dataset , GroupLens , www.kaggle.com/grouplens/movielens-20m-dataset , Tue Nov 08 2016 05:54:23 GMT+0530 (IST) , Over 20 Million Movie Ratings and Tagging Activities Since 1995 ,1640, film- ,Context The datasets describe ratings and free-text tagging activities from MovieLens a movie recommendation service. It contains 20000263 ratings and 465564 tag applications across 27278 movies. These data were created by 138493 users between January 09 1995 and March 31 2015. This dataset was generated on October 17 2016. Users were selected at random for inclusion. All selected users had rated at least 20 movies.  Content No demographic information is included. Each user is represented by an id and no other information is provided. The data are contained in six files. tag.csv that contains tags applied to movies by users  userId movieId tag timestamp  rating.csv that contains ratings of movies by users  userId movieId rating timestamp  movie.csv that contains movie information  movieId title genres  link.csv that contains identifiers that can be used to link to other sources  movieId imdbId tmbdId  genome_scores.csv that contains movie-tag relevance data  movieId tagId relevance  genome_tags.csv that contains tag descriptions  tagId tag  Acknowledgements The original datasets can be found here. To acknowledge use of the dataset in publications please cite the following paper F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5 4 Article 19 (December 2015) 19 pages. DOI=http//dx.doi.org/10.1145/2827872 Inspiration Some ideas worth exploring  Which genres receive the highest ratings? How does this change over time? Determine the temporal trends in the genres/tagging activity of the movies released ,,,movies
Hazardous Air Pollutants , US Environmental Protection Agency , www.kaggle.com/epa/hazardous-air-pollutants , Sat Jul 01 2017 00:16:19 GMT+0530 (IST) , A summary of daily Hazardous Air Pollutants from 1990 to 2017 ,132, environment- pollution- ,Context Hazardous air pollutants also known as toxic air pollutants or air toxics are those pollutants that are known or suspected to cause cancer or other serious health effects such as reproductive effects or birth defects or adverse environmental effects. The Environmental Protection Agency (EPA) tracks 187 air pollutants. See https//www.epa.gov/haps/ for more information. Content The daily summary file contains data for every monitor (sampled parameter) in the Environmental Protection Agency (EPA) database for each day. This file will contain a daily summary record that is 1. The aggregate of all sub-daily measurements taken at the monitor. 2. The single sample value if the monitor takes a single daily sample (e.g. there is only one sample with a 24-hour duration). In this case the mean and max daily sample will have the same value. Fields Descriptions 1. State Code The Federal Information Processing Standards (FIPS) code of the state in which the monitor resides.  County Code The FIPS code of the county in which the monitor resides. Site Num A unique number within the county identifying the site. Parameter Code The AQS code corresponding to the parameter measured by the monitor. POC This is the “Parameter Occurrence Code” used to distinguish different instruments that measure the same parameter at the same site. Latitude The monitoring site’s angular distance north of the equator measured in decimal degrees. Longitude The monitoring site’s angular distance east of the prime meridian measured in decimal degrees. Datum The Datum associated with the Latitude and Longitude measures. Parameter Name The name or description assigned in AQS to the parameter measured by the monitor. Parameters may be pollutants or non-pollutants. Sample Duration The length of time that air passes through the monitoring device before it is analyzed (measured). So it represents an averaging period in the atmosphere (for example a 24-hour sample duration draws ambient air over a collection filter for 24 straight hours). For continuous monitors it can represent an averaging time of many samples (for example a 1-hour value may be the average of four one-minute samples collected during each quarter of the hour). Pollutant Standard A description of the ambient air quality standard rules used to aggregate statistics. (See description at beginning of document.) Date Local The calendar date for the summary. All daily summaries are for the local standard day (midnight to midnight) at the monitor. Units of Measure The unit of measure for the parameter. QAD always returns data in the standard units for the parameter. Submitters are allowed to report data in any unit and EPA converts to a standard unit so that we may use the data in calculations. Event Type Indicates whether data measured during exceptional events are included in the summary. A wildfire is an example of an exceptional event; it is something that affects air quality but the local agency has no control over. No Events means no events occurred. Events Included means events occurred and the data from them is included in the summary. Events Excluded means that events occurred but data form them is excluded from the summary. Concurred Events Excluded means that events occurred but only EPA concurred exclusions are removed from the summary. If an event occurred for the parameter in question the data will have multiple records for each monitor. Observation Count The number of observations (samples) taken during the day. Observation Percent The percent representing the number of observations taken with respect to the number scheduled to be taken during the day. This is only calculated for monitors where measurements are required (e.g. only certain parameters). Arithmetic Mean The average (arithmetic mean) value for the day. 1st Max Value The highest value for the day. 1st Max Hour The hour (on a 24-hour clock) when the highest value for the day (the previous field) was taken. AQI The Air Quality Index for the day for the pollutant if applicable. Method Code  An internal system code indicating the method (processes equipment and protocols) used in gathering and measuring the sample. The method name is in the next column. Method Name A short description of the processes equipment and protocols used in gathering and measuring the sample. Local Site Name The name of the site (if any) given by the State local or tribal air pollution control agency that operates it. Address The approximate street address of the monitoring site. State Name The name of the state where the monitoring site is located. County Name The name of the county where the monitoring site is located. City Name The name of the city where the monitoring site is located. This represents the legal incorporated boundaries of cities and not urban areas. CBSA Name The name of the core bases statistical area (metropolitan area) where the monitoring site is located. Date of Last Change The date the last time any numeric values in this record were updated in the AQS data system.  Acknowledgements These data came from the EPA and are current up to May 01 2017. You can use Kernels to analyze share and discuss this data on Kaggle but if you’re looking for real-time updates and bigger data check out the data on BigQuery too https//cloud.google.com/bigquery/public-data/epa. Inspiration People exposed to toxic air pollutants at sufficient concentrations and durations may have an increased chance of getting cancer or experiencing other serious health effects. These health effects can include damage to the immune system as well as neurological reproductive (e.g. reduced fertility) developmental respiratory and other health problems. In addition to exposure from breathing air toxics some toxic air pollutants such as mercury can deposit onto soils or surface waters where they are taken up by plants and ingested by animals and are eventually magnified up through the food chain. Like humans animals may experience health problems if exposed to sufficient quantities of air toxics over time. Use this dataset to find out where the highest concentrations of hazardous air pollutants are for each state. You could also use the GPS locations to find out where the EPA has the most monitoring stations and identify places that could use more.,state_code:county_code:site_num:parameter_code:poc:latitude:longitude:datum:parameter_name:sample_duration:pollutant_standard:date_local:units_of_measure:event_type:observation_count:observation_percent:arithmetic_mean:first_max_value:first_max_hour:aqi:method_code:method_name:local_site_name:address:state_name:county_name:city_name:cbsa_name:date_of_last_change:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:dateTime:string:string:numeric:numeric:numeric:numeric:numeric:string:numeric:string:string:string:string:string:string:string:dateTime:,
UFO Sightings around the world , Cam Nugent , www.kaggle.com/camnugent/ufo-sightings-around-the-world , Tue Aug 15 2017 21:16:17 GMT+0530 (IST) , 80000+ documented close encounters from the past 70 years ,380, history- linguistics- ,"Context Extraterrestrials visitors little green men UFOs swap gas.  What do they want? Where do they come from? Do they like cheeseburgers? This dataset will likely not help you answer these questions. It does contain over 80000 records of UFO sightings dating back as far as 1949. With the latitude and longitude data it is possible to assess the global distribution of UFO sightings (patterns could aid in planetary defence if invasion proves to be imminent). The dates and times along with the duration of the UFO's stay and description of the craft also lend themselves to predictions. Can we find patterns in their arrival times and durations? Do aliens work on weekends? Help defend the planet and learn about your fellow earthlings (and when they are most likely to see ET). Content Date_time - standardized date and time of sighting city - location of UFO sighting state/province - the US state or Canadian province appears blank for other locations country - Country of UFO sighting UFO_shape - a one word description of the ""spacecraft"" length_of_encounter_seconds - standardized to seconds length of the observation of the UFO described_duration _of_encounter - raw description of the length of the encounter (shows uncertainty to previous column) description - text description of the UFO encounter. Warning column is messy with some curation it could lend itself to some natural language processing and sentiment analysis. date_documented - when was the UFO sighting reported latitude - latitude longitude - longitude Note there are missing data in the columns. I've left it as is because depending on what the user is interested in the missing values in any one column may or may not matter. Acknowledgements I found these data here https//github.com/planetsig/ufo-reports  Full credit to them for the curation I added some column headers and just described what I've seen Inspiration Some great ways to use these data would be  A global plot of the locations of recorded UFO sightings. Can the duration of the UFO visit be predicted from the other data? Is there a pattern to the appearances? At certain times of day on certain days of the week or days of the year? (i.e. are people on their way home from the pub more likely to see little green men?) Are certain shapes of UFO more likely to be seen in different geographical regions. ",Date_time:city:state/province:country:UFO_shape:length_of_encounter_seconds:described_duration_of_encounter:description:date_documented:latitude:longitude:,dateTime:string:string:string:string:numeric:string:string:dateTime:numeric:numeric:,astronomy
My Complete Genome , Zeeshan-ul-hassan Usmani , www.kaggle.com/zusmani/mygenome , Mon Jan 30 2017 20:54:43 GMT+0530 (IST) , 6000 Base-Pairs of Phenotype SNPs - Complete Raw Data ,568, human genetics- ,Context Zeeshan-ul-hassan Usmani’s Genome Phenotype SNPs Raw Data Genomics is a branch of molecular biology that involves structure function variation evolution and mapping of genomes. There are several companies offering next generation sequencing of human genomes from complete 3 billion base-pairs to a few thousand Phenotype SNPs. I’ve used 23andMe (using Illumina HumanOmniExpress-24) for my DNA’s Phenotype SNPs. I am sharing the entire raw dataset here for the international research community for following reasons  I am a firm believer in open dataset transparency and the right to learn research explores and educate. I do not want to restrict the knowledge flow for mere privacy concerns. Hence I am offering my entire DNA raw data for the world to use for research without worrying about privacy. I call it copyleft dataset.  Most of available test datasets for research come from western world and we don’t see much from under-developing countries. I thought to share my data to bridge the gap and I expect others to follow the trend.  I would be the happiest man on earth if a life can be saved knowledge can be learned an idea can be explore or a fact can be found using my DNA data. Please use it the way you will  Content Name Zeeshan-ul-hassan Usmani Age 38 Years Country of Birth Pakistan Country of Ancestors  India (Utter Pradesh - UP) File GenomeZeeshanUsmani.csv Size 15 MB Sources 23andMe Personalized Genome Report The research community is still progressively working in this domain and it is agreed upon by professionals that genomics is still in its infancy. You now have the chance to explore this novel domain via the dataset and become one of the few genomics early adopters. The data-set is a complete genome extracted from www.23andme.com and is represented as a sequence of SNPs represented by the following symbols A (adenine) C (cytosine) G (guanine) T (thymine) D (base deletions) I (base insertions) and '_' or '-' if the SNP for particular location is not accessible. It contains Chromosomes 1-22 X Y and mitochondrial DNA. A complete list of the exact SNPs (base pairs) available and their data-set index can be found at  https//api.23andme.com/res/txt/snps.b4e00fe1db50.data For more information about how the data-set was extracted follow https//api.23andme.com/docs/reference/#genomes  Moreover for a more detailed understanding of the data-set content please acquaint yourself with the description of https//api.23andme.com/docs/reference/#genotypes Acknowledgements Users are allowed to use copy distribute and cite the dataset as follows “Zeeshan-ul-hassan Usmani Genome Phenotype SNPS Raw Data File by 23andMe Kaggle Dataset Repository Jan 25 2017.” Useful Links You may use the following human genome database sites for help  GenBank - https//www.ncbi.nlm.nih.gov/genbank/ The Human Genome Project - https//www.genome.gov/hgp/ Genomes OnLine Database (GOLD) - https//gold.jgi.doe.gov Complete Genomics - http//www.completegenomics.com/public-data/  Inspiration Some ideas worth exploring  Is the individual in question more susceptible to cancer? Does he tend to gain weight?  Where is his place of origin?  Which gene determines certain biological feature (cancer susceptibility fat generation rate hair color etc. How does this phenotype SNPs compare with other similar datasets from the western-world? What would be the likely cause of death for this person? What are the most likely diseases/illnesses this person is going to face in lifetime? What is unique about this dataset? What else you can extract from this dataset when it comes to personal trait intelligence level ancestry and body makeup?  Sample Reports Please check out following reports to understand what can be done with this data Ancestry –  https//www.23andme.com/published-report/eeb4f9bbd6b5474f/?share_id=f6c5562848e84586 Weight Report -  https//you.23andme.com/published/reports/65c9af9f8223456d/?share_id=0126f129e4f3458b,# This data file generated by 23andMe at: Wed Jan 25 11:45:20 2017:,string:,genomics
Stack Overflow Developer Survey 2017 , Stack Overflow , www.kaggle.com/stackoverflow/so-survey-2017 , Thu Jun 15 2017 19:45:47 GMT+0530 (IST) , A look into the lives of over 64000 Stack Overflow developers ,614, information technology- internet- ,Every year Stack Overflow conducts a massive survey of people on the site covering all sorts of information like programming languages salary code style and various other information. This year they amassed more than 64000 responses fielded from 213 countries. Data The data is made up of two files  1. survey_results_public.csv - CSV file with main survey results one respondent per row and one column per answer  2. survey_results_schema.csv - CSV file with survey schema i.e. the questions that correspond to each column name m Acknowledgements Data is directly taken from StackOverflow and licensed under the ODbL license.,Respondent:Professional:ProgramHobby:Country:University:EmploymentStatus:FormalEducation:MajorUndergrad:HomeRemote:CompanySize:CompanyType:YearsProgram:YearsCodedJob:YearsCodedJobPast:DeveloperType:WebDeveloperType:MobileDeveloperType:NonDeveloperType:CareerSatisfaction:JobSatisfaction:ExCoderReturn:ExCoderNotForMe:ExCoderBalance:ExCoder10Years:ExCoderBelonged:ExCoderSkills:ExCoderWillNotCode:ExCoderActive:PronounceGIF:ProblemSolving:BuildingThings:LearningNewTech:BoringDetails:JobSecurity:DiversityImportant:AnnoyingUI:FriendsDevelopers:RightWrongWay:UnderstandComputers:SeriousWork:InvestTimeTools:WorkPayCare:KinshipDevelopers:ChallengeMyself:CompetePeers:ChangeWorld:JobSeekingStatus:HoursPerWeek:LastNewJob:AssessJobIndustry:AssessJobRole:AssessJobExp:AssessJobDept:AssessJobTech:AssessJobProjects:AssessJobCompensation:AssessJobOffice:AssessJobCommute:AssessJobRemote:AssessJobLeaders:AssessJobProfDevel:AssessJobDiversity:AssessJobProduct:AssessJobFinances:ImportantBenefits:ClickyKeys:JobProfile:ResumePrompted:LearnedHiring:ImportantHiringAlgorithms:ImportantHiringTechExp:ImportantHiringCommunication:ImportantHiringOpenSource:ImportantHiringPMExp:ImportantHiringCompanies:ImportantHiringTitles:ImportantHiringEducation:ImportantHiringRep:ImportantHiringGettingThingsDone:Currency:Overpaid:TabsSpaces:EducationImportant:EducationTypes:SelfTaughtTypes:TimeAfterBootcamp:CousinEducation:WorkStart:HaveWorkedLanguage:WantWorkLanguage:HaveWorkedFramework:WantWorkFramework:HaveWorkedDatabase:WantWorkDatabase:HaveWorkedPlatform:WantWorkPlatform:IDE:AuditoryEnvironment:Methodology:VersionControl:CheckInCode:ShipIt:OtherPeoplesCode:ProjectManagement:EnjoyDebugging:InTheZone:DifficultCommunication:CollaborateRemote:MetricAssess:EquipmentSatisfiedMonitors:EquipmentSatisfiedCPU:EquipmentSatisfiedRAM:EquipmentSatisfiedStorage:EquipmentSatisfiedRW:InfluenceInternet:InfluenceWorkstation:InfluenceHardware:InfluenceServers:InfluenceTechStack:InfluenceDeptTech:InfluenceVizTools:InfluenceDatabase:InfluenceCloud:InfluenceConsultants:InfluenceRecruitment:InfluenceCommunication:StackOverflowDescribes:StackOverflowSatisfaction:StackOverflowDevices:StackOverflowFoundAnswer:StackOverflowCopiedCode:StackOverflowJobListing:StackOverflowCompanyPage:StackOverflowJobSearch:StackOverflowNewQuestion:StackOverflowAnswer:StackOverflowMetaChat:StackOverflowAdsRelevant:StackOverflowAdsDistracting:StackOverflowModeration:StackOverflowCommunity:StackOverflowHelpful:StackOverflowBetter:StackOverflowWhatDo:StackOverflowMakeMoney:Gender:HighestEducationParents:Race:SurveyLong:QuestionsInteresting:QuestionsConfusing:InterestedAnswers:Salary:ExpectedSalary:,numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:dateTime:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:,Online forums 
1000 parallel sentences , Bryan Park , www.kaggle.com/bryanpark/parallelsents , Sun Dec 25 2016 17:34:04 GMT+0530 (IST) , 1000 parallel sentences of Korean English Japanese Spanish and Indonesian ,54, languages- linguistics- ,Context A few years ago I investigated a Korean corpus in order to find the most frequent 1000 words. Subsequently I asked native speakers to translate those words and their example sentences into English Japanese Spanish and Indonesian. I've totally forgotten this data since then but it flashed on me this might be helpful for some people. Undoubtedly 1000 sentences are a pretty small corpus but it is also true that parallel corpora are hard to get. Content It's a csv file. As you expect the first line is the heading.  ID Id of the headword. It is arranged by alphabetical order. HEADWORD 1000 most frequent Korean words. POS Part of speech. ENGLISH English meaning or equivalent. JAPANESE Japanese meaning or equivalent. SPANISH Spanish meaning or equivalent. INDONESIAN Indonesian meaning or equivalent. EXAMPLE (KO) An example sentence EXAMPLE (EN) English translation EXAMPLE (JA) Japanese translation EXAMPLE (ES) Spanish translation EXAMPLE (ID) Indonesian translation  Inspiration For now I'm not sure how this small corpus can be used. Hopefully this will be helpful for some pilot linguistic project.,ID:HEADWORD:POS:ENGLISH:JAPANESE:SPANISH:INDONESIAN:EXAMPLE (KO):EXAMPLE (EN):EXAMPLE (JA):EXAMPLE (ES):EXAMPLE (ID):,numeric:string:string:string:string:string:string:string:string:string:string:string:,text analysis
Default of Credit Card Clients Dataset , UCI Machine Learning , www.kaggle.com/uciml/default-of-credit-card-clients-dataset , Thu Nov 03 2016 09:09:18 GMT+0530 (IST) , Default Payments of Credit Card Clients in Taiwan from 2005 ,5066, finance- ,Dataset Information This dataset contains information on default payments demographic factors credit data history of payment and bill statements of credit card clients in Taiwan from April 2005 to September 2005.  Content There are 25 variables  ID ID of each client LIMIT_BAL Amount of given credit in NT dollars (includes individual and family/supplementary credit SEX Gender (1=male 2=female) EDUCATION (1=graduate school 2=university 3=high school 4=others 5=unknown 6=unknown) MARRIAGE Marital status (1=married 2=single 3=others) AGE Age in years PAY_0 Repayment status in September 2005 (-1=pay duly 1=payment delay for one month 2=payment delay for two months ... 8=payment delay for eight months 9=payment delay for nine months and above) PAY_2 Repayment status in August 2005 (scale same as above) PAY_3 Repayment status in July 2005 (scale same as above) PAY_4 Repayment status in June 2005 (scale same as above) PAY_5 Repayment status in May 2005 (scale same as above) PAY_6 Repayment status in April 2005 (scale same as above) BILL_AMT1 Amount of bill statement in September 2005 (NT dollar) BILL_AMT2 Amount of bill statement in August 2005 (NT dollar) BILL_AMT3 Amount of bill statement in July 2005 (NT dollar) BILL_AMT4 Amount of bill statement in June 2005 (NT dollar) BILL_AMT5 Amount of bill statement in May 2005 (NT dollar) BILL_AMT6 Amount of bill statement in April 2005 (NT dollar) PAY_AMT1 Amount of previous payment in September 2005 (NT dollar) PAY_AMT2 Amount of previous payment in August 2005 (NT dollar) PAY_AMT3 Amount of previous payment in July 2005 (NT dollar) PAY_AMT4 Amount of previous payment in June 2005 (NT dollar) PAY_AMT5 Amount of previous payment in May 2005 (NT dollar) PAY_AMT6 Amount of previous payment in April 2005 (NT dollar) default.payment.next.month Default payment (1=yes 0=no)  Inspiration Some ideas for exploration  How does the probability of default payment vary by categories of different demographic variables? Which variables are the strongest predictors of default payment?  Acknowledgements Any publications based on this dataset should acknowledge the following  Lichman M. (2013). UCI Machine Learning Repository [http//archive.ics.uci.edu/ml]. Irvine CA University of California School of Information and Computer Science. The original dataset can be found here at the UCI Machine Learning Repository.,,,banking
Devanagari Character Dataset , Ashok Kumar Pant , www.kaggle.com/ashokpant/devanagari-character-dataset , Fri Jun 23 2017 00:43:18 GMT+0530 (IST) , Devanagari (Nepali) Handwritten Character Dataset ,105, ,Context This dataset is created as a part of my dissertation work for the fulfillment of the Master's degree in Computer Science (Tribhuvan University Nepal 2012). Content The dataset contains three individual categories. Samples are collected from 40 individuals (persons) from different fields and cropped for character boundary.  Numerals (288 samples per class 10 classes)  Vowels (221 samples per class 12 classes)  Consonants (205 samples per class 36 classes)  Citation Please cite in your publications if it helps your research @inproceedings{pant2012off   title={Off-line Nepali handwritten character recognition using Multilayer Perceptron and Radial Basis Function neural networks}   author={Pant Ashok Kumar and Panday Sanjeeb Prasad and Joshi Shashidhar Ram}   booktitle={2012 Third Asian Himalayas International Conference on Internet}   pages={1--5}   year={2012}   organization={IEEE} } ,Numerals::,numeric:numeric:,Written script
When do children learn words? , Rachael Tatman , www.kaggle.com/rtatman/when-do-children-learn-words , Thu Jul 27 2017 22:34:47 GMT+0530 (IST) , How common 731 Norwegian words are & when children learn them ,130, languages- europe- linguistics- ,Context When children are born they don’t know any words. By the time they’re three most children know 200 words or more. These words aren’t randomly selected from the language they’re learning however. A two-year-old is much more likely to know the word “bottle” than the word “titration”. What words do children learn first and what qualities do those words have? This dataset was collected to explore this question. Content The main dataset includes information for 732 Norwegian words. A second table also includes measures of how frequently each word is used in Norwegian both on the internet (as observed in the Norwegian Web as Corpus dataset) and when an adult is talking to a child. The latter is commonly called “child directed speech” and is abbreviated as “CDS”.           Main data   ID_CDI_I Word ID from the Norwegian adaptation of the MacArthur-Bates Communicative Development Inventories version 1 ID_CDI_II Word ID from the Norwegian adaptation of the MacArthur-Bates Communicative Development Inventories version 2 Word_NW The word in Norwegian Word_CDI The form of the word found in the Norwegian adaptation of the MacArthur-Bates Communicative Development Inventories Translation the English translation of the Norwegian word AoA how old a child generally is was when they this this word in months (Estimated from the MacArthur-Bates Communicative Development Inventories) VSoA how many other words a child generally knows when they learn this word (rounded up to the nearest 10) Lex_cat the specific part of speech of the word Broad_lex the broad part of speech of the word Freq a measure of how commonly this word occurs in Norwegian CDS_Freq a measure of how commonly this word occurs when a Norwegian adult is talking to a Norwegian child   Norwegian CDS Frequency   Word_CDI The word from as found in the Norwegian adaptation of the MacArthur-Bates Communicative Development Inventories Translation The English translation of the Norwegian word Freq_NoWaC How often this word is used on the internet Freq_CDS How often this word is used when talking to children (based on two Norwegian CHILDES corpora)  Acknowledgements This dataset was collected by Pernille Hansen. If you use this data please cite the following paper  Hansen (2016). What makes a word easy to acquire? The effects of word class frequency imageability and phonological neighbourhood density on lexical development. First Language. Advance online publication. doi 10.1177/0142 723716679956 http//dx.doi.org/10.1177/0142723716679956  Inspiration  How well can you predict which words a child will learn first? Are some sounds or letters found more often than chance in words learned early? Can you build topic models on earlier-acquired and later-acquired words? Which topics are over-represented in words learned very early? ,ID_CDI_I:ID_CDI_II:Word_NW:Word_CDI:Translation:AoA:VSoA:Lex_cat:Broad_lex:Freq:CDS_freq:,string:string:string:string:string:numeric:numeric:string:string:numeric:numeric:,text analysis
Oklahoma Earthquakes and Saltwater Injection Wells , ChrisM! , www.kaggle.com/ksuchris2000/oklahoma-earthquakes-and-saltwater-injection-wells , Tue Sep 26 2017 23:13:05 GMT+0530 (IST) , Earthquakes in Oklahoma region and Oil and Gas fluid byproduct data. ,58, ,"Context Beginning in 2009 the frequency of earthquakes in the U.S. State of Oklahoma rapidly increased from an average of fewer than two 3.0+ magnitude earthquakes per year since 1978 to hundreds per year in 2014 2015 and 2016. Thousands of earthquakes have occurred in Oklahoma and surrounding areas in southern Kansas and North Texas since 2009. Scientific studies attribute the rise in earthquakes to the disposal of wastewater produced during oil extraction that has been injected deeply into the ground. (Wikipedia) Injection wells are utilized to dispose of fluid created as a byproduct of oil and gas production activities. Likewise hydraulic fracturing ie ""fracking"" produces large byproducts of water. This byproduct is then injected deep back into the earth via disposal/injection wells.  Content This dataset contains two data files. One detailing ""active"" saltwater injection wells in Oklahoma as of September 2017. The second file lists earthquakes in the Oklahoma region (Oklahoma and surrounding states) since 1977.  Acknowledgements Data was gathered from Oklahoma Corporation Commission and The United States Geological Survey.  Inspiration  Is there a correlation between earthquakes and injection well activity?  Can the data be used as a predictor of general proximity and/or time of future earthquakes ? ",API#:Operator:Operator ID:WellType:WellName:WellNumber:OrderNumbers:Approval Date:County:Sec:Twp:Rng:QQQQ:LAT:LONG:PSI:BBLS:ZONE::,numeric:string:numeric:string:string:numeric:numeric:dateTime:string:numeric:string:string:string:numeric:numeric:numeric:numeric:string:string:,disasters
Elementary school admission Romania 2014 , Gabriel Preda , www.kaggle.com/gpreda/elementary-school-admission-romania-2014 , Sun Jul 23 2017 17:11:14 GMT+0530 (IST) , Show elementary school admission patterns at county level for Romania in 2014 ,37, europe- education- ,Context data.gov.ro hosts datasets with public administrative data from Romania government much like data.gov for US relevant data.  The main file from this datasource http//data.gov.ro/dataset/inscrierea-in-invatamantul-primar-2014 originates from data.gov.ro and contains the anonymized information for the pupils registering in elementary school 1st grade in Romania in 2014. Starting from this data I wanted to represent the registration data geographically to have a sense of the geographical distribution of pupils registration in 1st grade. I therefore added few other files to this dataset from different sources    school information (to be able to connect pupils information with geographical data) - 1 file;   census information (in order to show the percent of the entire regional population registering in 1st grade in 2014) - 2 files.  Content The dataset contains 4 sources of data elementary_school_registration_2014.csv The original source of this data is to be found here (Romanian page) http//data.gov.ro/dataset/inscrierea-in-invatamantul-primar-2014 This represents the registration information for pupils in 1st grade for elementary school in Romania. The data is anonymized and shows   an unique code for each child; sex; social environment ('U' stands for Urban and 'R' for country-side);  the citizenship; the ethnic group (similar with mother tongue); the type of the registration application; the admission stage (I-1 I-2 I-3); the educational alternative (traditional or different schooling options available in Romania like special education for challenged pupils or Montessori progressive etc.); teaching language an unique code for identifying every school (SIRUES); disability (handicap) flag; orphan or institutionalized child flag; single parent flag; attendance of after-school option.  school_network.csv Origin of this data source is http//eprofu.ro/docs/tehnic/institutii/retea-scolara.xls. This file is used to connect SIRUES code from the main file in the datasource with the geographical information. The file contains  the 'judet' information (is an administrative unit in Romania larger than a municipality and smaller than a region much like a county in US); the name of the school; the unique code SIRUES (this can be used to merge with the pupils registration file); the type of school; the school category; the education form; the teaching language.  ro_judete_poligon.geojson This file original source is http//www.geo-spatial.org - shows geospatial information for Romanian counties (judet) in geojson format. It also includes the census information starting from 1948 until 2011 (last Romanian census). The detail of county geographical information is very high and therefore this geojson will be used only to extract the census information. romania.geojson This geojson file source is https//github.com/codeforamerica/click_that_hood/blob/master/public/data/romania.geojson It is used to display the county borders (contains less points than ro_judete_poligon.geojson),unique_code:,numeric:,demography
Aviation Accident Database & Synopses , Kheirallah Samaha , www.kaggle.com/khsamaha/aviation-accident-database-synopses , Tue Jan 10 2017 20:52:37 GMT+0530 (IST) , The NTSB aviation accident dataset ,2039, aviation- ,Content The NTSB aviation accident database contains information from 1962 and later about civil aviation accidents and selected incidents within the United States its territories and possessions and in international waters. Acknowledgements Generally a preliminary report is available online within a few days of an accident. Factual information is added when available and when the investigation is completed the preliminary report is replaced with a final description of the accident and its probable cause. Full narrative descriptions may not be available for dates before 1993 cases under revision or where NTSB did not have primary investigative responsibility. Inspiration Hope it will teach us how to improve the quality and safety of traveling by Airplane.,,,accidents
World Bank Youth Unemployment Rates , Sovann Tong , www.kaggle.com/sovannt/world-bank-youth-unemployment , Sat Nov 05 2016 12:48:51 GMT+0530 (IST) , Youth Unemployment rates by country from 2010-2014 ,2004, employment- finance- ,"Context  A data driven look into answering the common question while travelling overseas  ""how easy is it to get a job in your country?"" Content This dataset contains youth unemployment rates (% of total labor force ages 15-24) (modeled ILO estimate) Latest data available from 2010 to 2014. Acknowledgements International Labour Organization. http//data.worldbank.org/indicator/SL.UEM.TOTL.ZS Released under Open license.",Country Name:Country Code:2010:2011:2012:2013:2014:,string:string:numeric:numeric:numeric:numeric:numeric:,
Storm Prediction Center , JeffTennis , www.kaggle.com/jtennis/spctornado , Tue Nov 22 2016 19:42:55 GMT+0530 (IST) , Historic tornado data 1950 to 2015 ,897, climate- , Database of tornado activity from 1950 to 2015 Created by National Weather service and available at http//www.spc.noaa.gov/gis/svrgis/ Enhance understanding of where tornados happen indicators of damage and weather conditions associated with tornados (temp/El Nino La Nina)  Metadata available at http//www.spc.noaa.gov/wcm/data/SPC_severe_database_description.pdf,,,disasters
H-1B Visa Petitions 2011-2016 , Sharan Naribole , www.kaggle.com/nsharan/h-1b-visa , Tue Feb 28 2017 14:33:27 GMT+0530 (IST) , 3 million records of H-1B Visa Petitions ,4374, law- international relations- ,Context The H-1B is an employment-based non-immigrant visa category for temporary foreign workers in the United States. For a foreign national to apply for H1-B visa an US employer must offer a job and petition for H-1B visa with the US immigration department. This is the most common visa status applied for and held by international students once they complete college/ higher education (Masters PhD) and work in a full-time position. The Office of Foreign Labor Certification (OFLC) generates program data that is useful information about the immigration programs including the H1-B visa. The disclosure data updated annually is available at this link. However the raw data available is messy and might not be suitable for rapid analysis. A set of data transformations were performed making the data more accessible for quick exploration. To learn more about the transformations performed please read this blog and  R Notebook. Content The columns in the dataset include UPDATE Credit Jagan Gurumurthy The CASE_STATUS field denotes the status of the application after LCA processing. Certified applications are filed with USCIS for H-1B approval. CASE_STATUS CERTIFIED does not mean the applicant got his/her H-1B visa approved it just means that he/she is eligible to file an H-1B. For more details on this update read this discussion.  CASE_STATUS Status associated with the last significant event or decision. Valid values include “Certified” “Certified-Withdrawn” Denied” and “Withdrawn”. EMPLOYER_NAME Name of employer submitting labor condition application. SOC_NAME Occupational name associated with the SOC_CODE. SOC_CODE is the occupational code associated with the job being requested for temporary labor condition as classified by the Standard Occupational Classification (SOC) System. JOB_TITLE Title of the job FULL_TIME_POSITION Y = Full Time Position; N = Part Time Position PREVAILING_WAGE Prevailing Wage for the job being requested for temporary labor condition. The wage is listed at annual scale in USD. The prevailing wage for a job position is defined as the average wage paid to similarly employed workers in the requested occupation in the area of intended employment. The prevailing wage is based on the employer’s minimum requirements for the position.  YEAR Year in which the H-1B visa petition was filed WORKSITE City and State information of the foreign worker's intended area of employment lon longitude of the Worksite lat latitude of the Worksite  Acknowledgements  The Office of Foreign Labor Certification (OFLC) for publishing the annual disclosure data with the purpose of performing in-depth longitudinal research and analysis. Transformations performed on raw dataset are described in this GitHub repo particularly this R Notebook.  Inspiration Is the number of petitions with Data Engineer job title increasing over time? Which part of the US has the most Hardware Engineer jobs? Which industry has the most number of Data Scientist positions? Which employers file the most petitions each year? More Information  About LCA Processing http//redbus2us.com/what-is-h1b-lca-why-file-it-salary-processing-times-dol/ Raw dataset description https//www.foreignlaborcert.doleta.gov/docs/Performance_Data/Disclosure/FY15-FY16/H-1B_FY16_Record_Layout.pdf H-1B process http//www.immi-usa.com/h1b-application-process-step-by-step-guide/ ,:CASE_STATUS:EMPLOYER_NAME:SOC_NAME:JOB_TITLE:FULL_TIME_POSITION:PREVAILING_WAGE:YEAR:,numeric:string:string:string:string:string:numeric:numeric:,
Pantheon Project: Historical Popularity Index , Massachusetts Institute of Technology , www.kaggle.com/mit/pantheon-project , Thu Mar 02 2017 02:30:18 GMT+0530 (IST) , Record of every historical figure with Wikipedia biography in 25+ languages ,139, biographical dictionaries- history- internet- ,Context You were not born with the ability to fly cure disease or communicate at long distances but you were born in a society that endows you with these capacities. These capacities are the result of information that has been generated by humans and that humans have been able to embed in tangible and digital objects. This information is all around you. It is the way in which the atoms in an airplane are arranged or the way in which your cell-phone whispers dance instructions to electromagnetic waves. Pantheon is a project celebrating the cultural information that endows our species with these fantastic capacities. To celebrate our global cultural heritage we are compiling analyzing and visualizing datasets that can help us understand the process of global cultural development. Dive in visualize and enjoy. Content The Pantheon 1.0 data measures the global popularity of historical characters using two measures. The simpler of the two measures which we denote as L is the number of different Wikipedia language editions that have an article about a historical character. The more sophisticated measure which we name the Historical Popularity Index (HPI) corrects L by adding information on the age of the historical character the concentration of page views among different languages the coefficient of variation in page views and the number of page views in languages other than English. Acknowledgements Pantheon is a project developed by the Macro Connections group at the Massachusetts Institute of Technology Media Lab. Inspiration Which historical figures have a biography in the most languages? Who received the most Wikipedia page views? Which occupations or industries are the most popular? What country has the most individuals with a historical popularity index over twenty?,article_id:full_name:sex:birth_year:city:state:country:continent:latitude:longitude:occupation:industry:domain:article_languages:page_views:average_views:historical_popularity_index:,numeric:string:string:numeric:string:string:string:string:numeric:numeric:string:string:string:numeric:numeric:numeric:numeric:,
Google Text Normalization Challenge , Google Natural Language Understanding Research , www.kaggle.com/google-nlu/text-normalization , Wed Apr 26 2017 22:52:42 GMT+0530 (IST) , Text-to-speech synthesis text normalization data from Sproat & Jaitly 2016 ,969, languages- linguistics- ,"Challenge Description This dataset and accompanying paper present a challenge to the community given a large corpus of written text aligned to its normalized spoken form train an RNN to learn the correct normalization function. That is a date written ""31 May 2014"" is spoken as ""the thirty first of may twenty fourteen."" We present a dataset of general text where the normalizations were generated using an existing text normalization component of a text-to-speech (TTS) system. This dataset was originally released open-source here and is reproduced on Kaggle for the community. The Data The data in this directory are the English language training development and test data used in Sproat and Jaitly (2016). The following divisions of data were used  Training      output_1 through output_21 (corresponding to output-000[0-8]?-of-00100 in the original dataset) Runtime eval  output_91 (corresponding to output-0009[0-4]-of-00100 in the original dataset) Test data     output_96 (corresponding to output-0009[5-9]-of-00100 in the original dataset)  In practice for the results reported in the paper only the first 100002 lines of output-00099-of-00100 were used (for English). Lines with """" in two columns are the end of sentence marker otherwise there are three columns the first of which is the ""semiotic class"" (Taylor 2009) the second is the input token and the third is the output following the paper cited above. All text is from Wikipedia. All data were extracted on 2016/04/08 and run through the Google Kestrel TTS text normalization system (Ebden and Sproat 2015) so that the notion of ""token"" ""semiotic class"" and reference output are all Kestrel's notion. Our Research In this paper we present our own experiments with this data set with a variety of different RNN architectures. While some of the architectures do in fact produce very good results when measured in terms of overall accuracy the errors that are produced are problematic since they would convey completely the wrong message if such a system were deployed in a speech application. On the other hand we show that a simple FST-based filter can mitigate those errors and achieve a level of accuracy not achievable by the RNN alone.  Though our conclusions are largely negative on this point we are actually not arguing that the text normalization problem is intractable using an pure RNN approach merely that it is not going to be something that can be solved merely by having huge amounts of annotated text data and feeding that to a general RNN model. And with open-source data we provide a novel data set for sequence-to-sequence modeling in the hopes that the the community can find better solutions.  Disclaimer This is not an official Google product. References Ebden Peter and Sproat Richard. 2015. The Kestrel TTS text normalization system. Natural Language Engineering. 21(3). Richard Sproat and Navdeep Jaitly. 2016. RNN Approaches to Text Normalization A Challenge. Released on arXiv.org https//arxiv.org/abs/1611.00068 Taylor Paul. 2009. Text-to-Speech Synthesis. Cambridge University Press Cambridge.",Semiotic Class:Input Token:Output Token:,string:string:string:,text analysis
30 Years of European Solar Generation , Sohier Dane , www.kaggle.com/sohier/30-years-of-european-solar-generation , Fri Sep 15 2017 02:16:44 GMT+0530 (IST) , Hourly energy potential for 1986-2015 ,176, energy- ,This dataset contains hourly estimates of an area's energy potential for 1986-2015 as a percentage of a power plant's maximum output. The overall scope of EMHIRES is to allow users to assess the impact of meteorological and climate variability on the generation of solar power in Europe and not to mime the actual evolution of solar power production in the latest decades. For this reason the hourly solar power generation time series are released for meteorological conditions of the years 1986-2015 (30 years) without considering any changes in the solar installed capacity. Thus the installed capacity considered is fixed as the one installed at the end of 2015. For this reason data from EMHIRES should not be compared with actual power generation data other than referring to the reference year 2015.  Content  The data is available at both the national level and the NUTS 2 level. The NUTS 2 system divides the EU into 276 statistical units. Please see the manual for the technical details of how these estimates were generated.  This product is intended for policy analysis over a wide area and is not the best for estimating the output from a single system. Please don't use it commercially.  Acknowledgements This dataset was kindly made available by the European Commission's STETIS program. You can find the original dataset here. Inspiration  How clean is the dataset? Older solar estimates used to contain impossible values around sunset (ie more energy than the sun releases) or negative sunlight. What does a typical year look like? One common approach is to stitch together 12 months of raw data using the 12 most typical months per this ISO standard.  If you like If you like this dataset you might also enjoy  - 30 years of European wind  - Google's Project Sunroof ,time_step:AT11:AT21:AT12:AT31:AT32:AT22:AT33:AT34:AT13:BE21:BE31:BE32:BE33:BE22:BE34:BE35:BE23:BE10:BE24:BE25:BG32:BG33:BG31:BG34:BG41:BG42:CZ06:CZ03:CZ08:CZ01:CZ05:CZ04:CZ02:CZ07:DEA5:DE30:DE40:DE91:DE50:DED1:DE71:DEE1:DEA4:DED2:DEA1:DE13:DE72:DEE2:DE60:DE92:DE12:DE73:DEB1:DEA2:DED3:DE93:DEE3:DE80:DE25:DEA3:DE22:DE21:DE24:DE23:DEB3:DEF0:DE27:DE11:DEG0:DEB2:DE14:DE26:DE94:ES61:ES24:ES12:ES13:ES41:ES42:ES51:ES30:ES52:ES43:ES11:ES53:ES23:ES22:ES21:ES62:FI20:FI1C:FI1D:FI1B:FI19:FR42:FR61:FR72:FR25:FR26:FR52:FR24:FR21:FR83:FR43:FR23:FR10:FR81:FR63:FR41:FR62:FR30:FR51:FR22:FR53:FR82:FR71:EL51:EL30:EL63:EL53:EL62:EL54:EL52:EL43:EL42:EL65:EL64:EL61:EL41:HU33:HU23:HU32:HU31:HU21:HU10:HU22:CH02:CH03:CH05:CH01:CH07:CH06:CH04:IE01:IE02:ITF1:ITF5:ITF6:ITF3:ITH5:ITH4:ITI4:ITC3:ITC4:ITI3:ITF2:ITC1:ITF4:ITG2:ITG1:ITI1:ITH2:ITI2:ITC2:ITH3:NL13:NL23:NL12:NL22:NL11:NL42:NL41:NL32:NL21:NL31:NL34:NL33:NO04:NO02:NO01:NO03:NO05:PL51:PL61:PL31:PL43:PL11:PL21:PL12:PL52:PL32:PL34:PL63:PL22:PL33:PL62:PL41:PL42:PT18:PT15:PT16:PT17:PT11:RO32:RO12:RO21:RO11:RO31:RO22:RO41:RO42:SE32:SE31:SE12:SE33:SE21:SE11 :SE22:SE23:SK01:SK03:SK04:SK02:UKH2:UKJ1:UKD6:UKK3:UKD1:UKF1:UKK4:UKK2:UKH1:UKE1:UKL2:UKM2:UKH3:UKK1:UKD3:UKJ3:UKG1:UKM6:UKI3UKI4:UKJ4:UKD4:UKF2:UKF3:UKD7:UKM5:UKE2:UKN0:UKC2:UKI5UKI6:UKG2:UKM3:UKE3:UKJ2:UKC1:UKG3:UKL1:UKE4:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,renewable energy
Journalists Killed Worldwide Since 1992 , Committee to Protect Journalists , www.kaggle.com/cpjournalists/journalists-killed-worldwide-since-1992 , Sun Nov 13 2016 08:50:34 GMT+0530 (IST) , Journalist Deaths from 1992-2016 ,811, news agencies- journalism- death- crime- ,"Context CPJ began compiling detailed records on journalist deaths in 1992. CPJ applies strict journalistic standards when investigating a death. One important aspect of their research is determining whether a death was work-related. As a result they classify deaths as ""motive confirmed"" or ""motive unconfirmed."" Content The dataset contains 18 variables  Type CPJ classified deaths as motive confirmed or motive confirmed as well as Media Workers Date Name Sex Country_killed Organization Nationality Medium Job Coverage Freelance Local_Foreign Source_fire Type_death Impunity_for_murder Taken_captive Threatened Tortured  Acknowledgements The original dataset can be found here. Inspiration Some ideas for exploring the dataset  What is the trend in journalist deaths over time and how does this differ by type of death job coverage and country? Are there differences by sex and/or nationality? ",Type:Date:Name:Sex:Country_killed:Organization:Nationality:Medium:Job:Coverage:Freelance:Local_Foreign:Source_fire:Type_death:Impunity_for_murder:Taken_captive:Threatened:Tortured:,string:dateTime:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:,crime
Trump Financial Disclosure 2016 , Sohier Dane , www.kaggle.com/sohier/trump-financial-disclosure-2016 , Tue Jul 11 2017 02:36:52 GMT+0530 (IST) , Donald Trump's 2016 Form 278e ,56, presidents- finance- politics- ,Context All US presidential candidates are required to fill out form 278e a general disclosure of their assets debts and sources of income. This is an unpacked version of the pdf of Trump's form that was made available by the Federal Election Commission in mid 2016. It contains some information about his financial interests but not enough to paint a complete picture of his net worth. It may be possible to use some of these forms to identify his foreign business partners. Acknowledgements This dataset unpacked from the original pdf and kindly made available by Quartz. Please see their original article for the full background on what this form does and does not contain. You might also like  Trump's World Trump's Tweets Trump Campaign Expenditures ,,,politics
Water Consumption in a Median Size City , Marco Molina , www.kaggle.com/marcomolina/water-consumption-in-a-median-size-city , Thu Sep 15 2016 12:34:37 GMT+0530 (IST) , This dataset contains water consumption per capita from late 2000s to 2016. ,1200, water technology- ,The dataset contains the following variables water consumption per user (cubic meters) from 2009 to 2016 land use type of user (e.g. industrial housing public infrastructure etc.) zip code and others. The challenge is to treat NAs in a way that do not distort the overall dataset. You should also check whether there are any missing values. If so can you ﬁll them in and do you understand why they are missing? This dataset is property of a local water provider called AguaH and its part of a research developed between 2014 and 2016.,,,
Tree Census in New York City , NYC Parks and Recreation , www.kaggle.com/nycparks/tree-census , Mon Jul 17 2017 22:27:32 GMT+0530 (IST) , What tree species are thriving on the streets of each NYC borough? ,535, plants- forestry- ,Context New York City’s trees shade us in the summer beautify our neighborhoods help reduce noise and support urban wildlife. Beyond these priceless benefits our urban forest provides us a concrete return on the financial investment we put into it. This return includes stormwater interception energy conservation air pollutant removal and carbon dioxide storage. Our publicly owned trees are as much of an asset to us as our streets sewers bridges and public buildings. Content This dataset includes a record for every tree in New York City and includes the tree's location by borough and latitude/longitude species by Latin name and common names size health and issues with the tree's roots trunk and branches. Acknowledgements The 2015 2005 and 1995 tree censuses were conducted by NYC Parks and Recreation staff TreesCount! program staff and hundreds of volunteers.,recordid:address:house_number:street:zip_original:cb_original:site:species:diameter:status:wires:sidewalk_condition:support_structure:borough:x:y:longitude:latitude:cb_new:zip_new:censustract_2010:censusblock_2010:nta_2010:segmentid:spc_common:spc_latin:location:,numeric:string:numeric:string:numeric:numeric:string:string:numeric:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:string:string:string:,botanical
CalCOFI , Sohier Dane , www.kaggle.com/sohier/calcofi , Thu Aug 24 2017 00:54:53 GMT+0530 (IST) , Over 60 years of oceanographic data ,53, ecology- oceanography- ,Context The CalCOFI data set represents the longest (1949-present) and most complete (more than 50000 sampling stations) time series of oceanographic and larval fish data in the world. It includes abundance data on the larvae of over 250 species of fish; larval length frequency data and egg abundance data on key commercial species; and oceanographic and plankton data. The physical chemical and biological data collected at regular time and space intervals quickly became valuable for documenting climatic cycles in the California Current and a range of biological responses to them. CalCOFI research drew world attention to the biological response to the dramatic Pacific-warming event in 1957-58 and introduced the term “El Niño” into the scientific literature.  The California Cooperative Oceanic Fisheries Investigations (CalCOFI) are a unique partnership of the California Department of Fish & Wildlife NOAA Fisheries Service and Scripps Institution of Oceanography. The organization was formed in 1949 to study the ecological aspects of the sardine population collapse off California. Today our focus has shifted to the study of the marine environment off the coast of California the management of its living resources and monitoring the indicators of El Nino and climate change. CalCOFI conducts quarterly cruises off southern & central California collecting a suite of hydrographic and biological data on station and underway.  Data collected at depths down to 500 m include temperature salinity oxygen phosphate silicate nitrate and nitrite chlorophyll transmissometer PAR C14 primary productivity phytoplankton biodiversity zooplankton biomass and zooplankton biodiversity.  Content Each table has several dozen columns. Please see this page for the table details.,Cst_Cnt:Btl_Cnt:Sta_ID:Depth_ID:Depthm:T_degC:Salnty:O2ml_L:STheta:O2Sat:Oxy_µmol/Kg:BtlNum:RecInd:T_prec:T_qual:S_prec:S_qual:P_qual:O_qual:SThtaq:O2Satq:ChlorA:Chlqua:Phaeop:Phaqua:PO4uM:PO4q:SiO3uM:SiO3qu:NO2uM:NO2q:NO3uM:NO3q:NH3uM:NH3q:C14As1:C14A1p:C14A1q:C14As2:C14A2p:C14A2q:DarkAs:DarkAp:DarkAq:MeanAs:MeanAp:MeanAq:IncTim:LightP:R_Depth:R_TEMP:R_POTEMP:R_SALINITY:R_SIGMA:R_SVA:R_DYNHT:R_O2:R_O2Sat:R_SIO3:R_PO4:R_NO3:R_NO2:R_NH4:R_CHLA:R_PHAEO:R_PRES:R_SAMP:DIC1:DIC2:TA1:TA2:pH2:pH1:DIC Quality Comment:,numeric:numeric:string:string:numeric:numeric:numeric:string:numeric:string:string:string:numeric:numeric:string:numeric:string:numeric:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:string:numeric:string:string:numeric:string:string:numeric:string:string:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:numeric:string:string:string:string:string:string:string:string:,zoological
Mannanafnaskrá , Sohier Dane , www.kaggle.com/sohier/icelandic-names , Mon Sep 11 2017 21:44:25 GMT+0530 (IST) , The legally binding list of Icelandic names ,6, linguistics- ,Trying to name a child? Looking for something a little different? Something that will force a preschool's database to support unicode? Look no farther! From Aðdal to Ösp to Ben this list has you covered. The Icelandic Naming committee maintains an official register of approved Icelandic given names and is the governing body of introduction of new given names into the culture of Iceland. In many cases parents use the database as a guide when choosing a name. If the name they have in mind is not in the register they can fill out a special form and request whether the name will be considered allowable by law. If the committee rules positively on a request the name will be added to the Personal Names Register. If the committee denies the request the child may not be allowed to get an Icelandic passport with that name. The register is stored and maintained at Registers Iceland and is accessible through the national portal Ísland.is. Note on the column headers Drengir = boys Millinöfn = girls Stúlkur = either.,Drengir:Millinöfn:Stúlkur:,string:string:string:,
Academic Scores for NCAA Athletic Programs , NCAA , www.kaggle.com/ncaa/academic-scores , Thu Feb 16 2017 20:00:22 GMT+0530 (IST) , Survey of team's program eligibility and retention by year and institution ,363, sports- education- ,Context College presidents across the nation recognized a need to track how student-athletes are doing academically prior to graduation. Starting in 2003 colleges and universities in NCAA Division I — the largest and highest profile athletics programs — implemented a comprehensive academic reform package designed to improve the academic success and graduation of all student-athletes. The centerpiece of the academic reform package was the development of a real-time academic measurement for sports teams known as the Academic Progress Rate (APR). The APR includes student-athlete eligibility retention and graduation as factors in a formula that yields a single number providing a much clearer picture of the current academic culture on each Division I sports team in the country. Since its inception the APR has become an important measure of student-athlete academic success. For high APR scores the NCAA recognizes member institutions for ensuring that student-athletes succeed in the classroom. If however low APR scores are earned consistently member institutions can be subjected to penalties including scholarship reductions and the loss of eligibility to compete in championships. Content This study was created by the National Collegiate Athletic Association (NCAA) to provide public access to team-level APR scores eligibility rates retention rates and athlete counts on Division I athletic programs starting with the 2003-2004 season through the 2013-2014 season Inspiration Which sport or school has the highest academic score? Which schools' scores have increased or decreased significantly in the past decade? Are men's or women's team academic performance better? What about public and private colleges?,SCHOOL_ID:SCHOOL_NAME:SCHOOL_TYPE:ACADEMIC_YEAR:SPORT_CODE:SPORT_NAME:NCAA_DIVISION:NCAA_SUBDIVISION:NCAA_CONFERENCE:FOURYEAR_ATHLETES:FOURYEAR_SCORE:FOURYEAR_ELIGIBILITY:FOURYEAR_RETENTION:2014_ATHLETES:2014_SCORE:2014_ELIGIBILITY:2014_RETENTION:2013_ATHLETES:2013_SCORE:2013_ELIGIBILITY:2013_RETENTION:2012_ATHLETES:2012_SCORE:2012_ELIGIBILITY:2012_RETENTION:2011_ATHLETES:2011_SCORE:2011_ELIGIBILITY:2011_RETENTION:2010_ATHLETES:2010_SCORE:2010_ELIGIBILITY:2010_RETENTION:2009_ATHLETES:2009_SCORE:2009_ELIGIBILITY:2009_RETENTION:2008_ATHLETES:2008_SCORE:2008_ELIGIBILITY:2008_RETENTION:2007_ATHLETES:2007_SCORE:2007_ELIGIBILITY:2007_RETENTION:2006_ATHLETES:2006_SCORE:2006_ELIGIBILITY:2006_RETENTION:2005_ATHLETES:2005_SCORE:2005_ELIGIBILITY:2005_RETENTION:2004_ATHLETES:2004_SCORE:2004_ELIGIBILITY:2004_RETENTION:,numeric:string:numeric:numeric:numeric:string:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,student performances
DACA Recipients , Anu , www.kaggle.com/anupamakhan/daca-recipients-as-of-sept-4-2017 , Tue Oct 10 2017 22:07:10 GMT+0530 (IST) , Aggregate data as of Sept 4 2017 ,44, politics- demographics- ,"Context Aggregate data from US Citizenship and Immigration Services on Deferred Action for Childhood Arrivals program as of Sept 4 2017 https//www.uscis.gov/tools/reports-studies/immigration-forms-data/data-set-form-i-821d-deferred-action-childhood-arrivals Content  Country of birth approximate active DACA recipients  Notes  This table refers to individuals who were granted Deferred Action for Childhood Arrivals (DACA) as of September 4 2017.  The number of individuals who were ever granted DACA as of September 4 2017 was approximately 800000. This total excludes persons who applied for an initial grant of DACA and were not approved as well as initial DACA requestors that were approved at first but later had their initial request denied or terminated. Nearly 40000 DACA recipients have adjusted to lawful permanent resident (LPR) status leaving about 760000 who are not LPRs.  About 70000 individuals who were granted DACA either failed to renew at the end of their 2-year validity period or were denied on renewal leaving approximately 690000 active DACA recipients as of September 4 2017. Totals do not add due to rounding. Countries  with fewer than 10 active DACA recipients are included in other. Not available  data are not available in electronic systems. Source  U.S. Citizenship and Immigration Services""                               State of Residence  Notes  This table refers to individuals who were  granted Deferred Action for Childhood Arrivals (DACA) as of September 4 2017.  The number of individuals who were ever granted DACA as of September 4 2017 was approximately 800000. This total excludes persons who applied for an initial grant of DACA and were not approved as well as initial DACA requestors that were approved at first but later had their initial request denied or terminated. Nearly 40000 DACA recipients have adjusted to lawful permanent resident (LPR) status leaving about 760000 who are not LPRs.  About 70000 individuals who were granted for DACA either failed to renew at the end of their 2-year validity period or were denied on renewal leaving approximately 690000 active DACA recipients as of September 4 2017. State of residence at the time of most recent application. Totals do not add due to rounding. Territories with less than 10 residents are included in other. Not available  data are not available in electronic systems. Source  U.S. Citizenship and Immigration Services CLAIMS3 and ELIS Systems.""                                 Core-based Statistical Areas  Notes  This table refers to individuals who were granted Deferred Action for Childhood Arrivals (DACA) as of September 4 2017.  The number of individuals who were ever granted DACA as of September 4 2017 was approximately 800000. This total excludes persons who applied for an initial grant of DACA and were not approved as well as initial DACA requestors that were approved at first but later had their initial request denied or terminated. Nearly 40000 DACA recipients have adjusted to lawful permanent resident (LPR) status leaving about 760000 who are not LPRs.  About 70000 individuals who were granted DACA either failed to renew at the end of their 2-year validity period or were denied on renewal leaving approximately 690000 active DACA recipients as of September 4 2017. Core Based Statistical Areas (CBSA) at the time of most recent application.  CBSAs are defined  by the Office of Management and Budget. Totals may not add due to rounding. CBSAs with fewer than 1000 residents are included in other. Not available  data are not available in electronic systems. Source  U.S. Citizenship and Immigration Services CLAIMS3 and ELIS Systems.""                                                 Age and Sex  Notes  These tables refer to individuals who were  granted Deferred Action for Childhood Arrivals (DACA) as of September 4 2017. The number of individuals who were ever granted DACA as of September 4 2017 was approximately 800000. This total excludes persons who applied for an initial grant of DACA and were not approved as well as initial DACA requestors that were approved at first but later had their initial request denied or terminated.  Nearly 40000 DACA recipients have adjusted to lawful permanent resident (LPR) status leaving about 760000 who are not LPRs.  About 70000 individuals who were granted DACA either failed to renew at the end of their 2-year validity period or were denied on renewal leaving approximately 690000 active DACA recipients as of September 4 2017. Age as of September 4 2017 and marital status as of the time of most recent application. Totals do not add due to rounding. Interquartile range is the range between the 25th percentile and the 75th percentile.  About half of the active DACA recipients are 20 to 27 years old. Not available  data are not available in electronic systems. Source  U.S. Citizenship and Immigration Services CLAIMS3 and ELIS Systems.""                                     Marital status  Notes  This table refers to individuals who were granted Deferred Action for Childhood Arrivals (DACA) as of September 4 2017.  The number of individuals who were ever granted DACA as of September 4 2017 was approximately 800000. This total excludes persons who applied for an initial grant of DACA and were not approved as well as initial DACA requestors that were approved at first but later had their initial request denied or terminated.  Nearly 40000 DACA recipients have adjusted to lawful permanent resident (LPR) status leaving about 760000 who are not LPRs.  About 70000 individuals who were granted DACA either failed to renew at the end of their 2-year validity period or were denied on renewal leaving approximately 690000 active DACA recipients as of September 4 2017. Marital status at time of most recent application. Not available  data are not available in electronic systems.  Inspiration I converted this data set from the published PDF so I could practice making choropleth maps.  Acknowledgements I got the CBSA topojson from here https//discourse.looker.com/t/custom-topojson-for-2014-core-based-statistical-areas-cbsa/2028",Age as of 9/4/2017:Number (rounded):Percent:,string:numeric:numeric:,demography
Tsunami Causes and Waves , NOAA , www.kaggle.com/noaa/seismic-waves , Fri Feb 03 2017 09:45:19 GMT+0530 (IST) , Cause magnitude and intensity of every tsunami since 2000 BC ,743, oceans- ,"Context Tsunami is a Japanese word that translates to ""harbor wave"". It is a wave or a series of waves generated by an impulsive vertical displacement of the surface of the ocean or other body of water. Tsunamis have been responsible for over 500000 fatalities throughout the world — almost half from the 2004 Indian Ocean earthquake and tsunami! Content The NOAA/WDS tsunami database is a listing of historical tsunami source events and runup locations throughout the world from 2000 B.C. to the present. The events were gathered from scientific and scholarly sources regional and worldwide catalogs tide gauge data deep ocean sensor data individual event reports and unpublished works. There are currently over 2000 source events in the database with event validities greater than one and over 13000 runup locations where tsunami effects were observed. Acknowledgements NOAA's National Centers for Environmental Information (NCEI) and the World Data Service for Geophysics compiled and published this tsunami database for tsunami warning centers engineers oceanographers seismologists and the general public.",SOURCE_ID:YEAR:MONTH:DAY:HOUR:MINUTE:CAUSE:VALIDITY:FOCAL_DEPTH:PRIMARY_MAGNITUDE:REGION_CODE:COUNTRY:STATE/PROVINCE:LOCATION:LATITUDE:LONGITUDE:MAXIMUM_HEIGHT:MAGNITUDE_ABE:MAGNITUDE_IIDA:INTENSITY_SOLOVIEV:WARNING_STATUS:MISSING:MISSING_ESTIMATE:INJURIES:INJURY_ESTIMATE:FATALITIES:FATALITY_ESTIMATE:DAMAGE_MILLIONS_DOLLARS:DAMAGE_ESTIMATE:HOUSES_DAMAGED:HOUSE_DAMAGE_ESTIMATE:HOUSES_DESTROYED:HOUSE_DESTRUCTION_ESTIMATE:ALL_MISSING:MISSING_TOTAL:ALL_INJURIES:INJURY_TOTAL:ALL_FATALITIES:FATALITY_TOTAL:ALL_DAMAGE_MILLIONS:DAMAGE_TOTAL:ALL_HOUSES_DAMAGED:HOUSE_DAMAGE_TOTAL:ALL_HOUSES_DESTROYED:HOUSE_DESTRUCTION_TOTAL:,numeric:numeric:numeric:numeric:string:string:numeric:numeric:string:numeric:numeric:string:string:string:numeric:numeric:numeric:string:string:numeric:string:string:string:string:string:string:numeric:string:numeric:string:string:string:string:string:string:string:string:string:numeric:string:numeric:string:string:string:string:,disasters
Solar Radiation Prediction , LenitoPipito , www.kaggle.com/dronio/SolarEnergy , Sun May 21 2017 23:49:42 GMT+0530 (IST) , Task from NASA Hackathon ,612, space- energy- ,"Context Space Apps Moscow was held on April 29th & 30th. Thank you to the 175 people who joined the International Space Apps Challenge at this location! Content The dataset contains such columns as ""wind direction"" ""wind speed"" ""humidity"" and temperature. The response parameter that is to be predicted is ""Solar_radiation"". It contains measurements for the past 4 months and you have to predict the level of solar radiation. Just imagine that you've got solar energy batteries and you want to know will it  be reasonable to use them in future? Acknowledgements Thanks NASA for the dataset. Inspiration Predict the level of solar radiation. Here are some intersecting dependences that i have figured out 1. Humidity & Solar_radiation. 2.Temeperature & Solar_radiation. The best result of accuracy  I could get using cross-validation was only 55%.",UNIXTime:Data:Time:Radiation:Temperature:Pressure:Humidity:WindDirection(Degrees):Speed:TimeSunRise:TimeSunSet:,numeric:dateTime:dateTime:numeric:numeric:numeric:numeric:numeric:numeric:dateTime:dateTime:,astronomy
NEWS SUMMARY , Kondalarao Vonteru , www.kaggle.com/sunnysai12345/news-summary , Thu Aug 10 2017 10:00:27 GMT+0530 (IST) , Generating short length descriptions of news articles. ,214, journalism- india- linguistics- ,Context I am currently working on summarizing chat context where it helps an agent in understanding previous context quickly. It interests me to apply the deep learning models to existing datasets and how they perform on them. I believe news articles are rich in grammar and vocabulary which allows us to gain greater insights. Content The dataset consists of 4515 examples and contains Author_name Headlines Url of Article Short text Complete Article. I gathered the summarized news from Inshorts and only scraped the news articles from Hindu Indian times and Guardian.  Time period ranges from febrauary to august 2017. Acknowledgements I would like to thank the authors of Inshorts for their amazing work Inspiration  Generating short length descriptions(headlines) from text(news articles). Summarizing large amount of information which can be represented in compressed space  Purpose When I was working on the summarization task I didn't find any open source data-sets to work on I believe there are people just like me who are working on these tasks and I hope it helps them. Contributions It will be really helpful if anyone found nice insights from this data and can share their work. Thankyou...!!! For those who are interested here is the link for the github code which includes the scripts for scraping. https//github.com/sunnysai12345/News_Summary,author:date:headlines:read_more:text:ctext:,string:dateTime:string:string:string:string:,news
COMBO-17 Galaxy Dataset , Megan Risdal , www.kaggle.com/mrisdal/combo17-galaxy-dataset , Mon Apr 17 2017 07:47:20 GMT+0530 (IST) , Galaxies with brightness measurements in 17 visible bands ,80, astronomy- space- ,This dataset was obtained here and their description is reproduced below. Astronomical background Galaxies are fundamental structures in the Universe.  Our Sun lives in the Milky Way Galaxy we can see as a patchy band of light across the sky.  The components of a typical galaxy are a vast number of stars (total mass ~106-1011 Mo where Mo is the unit of a solar mass) a complex interstellar medium of gas and dust from which stars form (typically 1-100% of the stellar component mass) a single supermassive black hole at the center (typically <1% of the stellar component mass) and a poorly understood component called Dark Matter with mass ~5-10-times all the other components combined. Over the ~14 billion years since the Big Bang  the rate at which galaxies convert interstellar matter into stars has not been constant and thus the brightness and color of galaxies change with cosmic time.  This phenomenon has several names in the astronomical community the history of star formation in the Universe chemical evolution of galaxies or simply galaxy evolution.  A major effort over several decades has been made to quantify and understand galaxy evolution using telescopes at all wavelengths. The traditional tool for such studies has been optical spectroscopy which easily reveals signatures of star formation in nearby galaxies.  However to study star formation in the galaxies recently emerged after the Big Bang we must examine extremely faint galaxies which are too faint for spectroscopy even using the biggest available telescopes.  A feasible alternative is to obtain images of faint galaxies at random locations in the sky in narrow spectral bands and thereby construct crude spectra.  First statistical analysis of such multiband photometric datasets are used to classify galaxies stars and quasars.  Second for the galaxies multivariate regression is made to develop photometric estimates of redshift which is a measure both of distance from us and age since the Big Bang.  Third one can examine galaxy colors as a function of redshift (after various corrections are made) to study the evolution of star formation. The present dataset is taken after these first two steps are complete. Contents Wolf et al. (2004) provide the first public catalog of a large dataset (63501 objects) with brightness measurements in 17 bands in the visible band.  (Note that the Sloan Digital Sky Survey provides a much larger dataset of 108 objects with measurements in 5 bands.)  We provide here a subset of their catalog with 65 columns of information on 3462 galaxies.  These are objects in the Chandra Deep Field South field which Wolf and colleagues have classified as `Galaxies'.  The column headings are formally described in their Table 3 and the columns we provide are summarized here with brief commentary Col 1  Nr object number Col 2-3 Total R (red band) magnitude and its error.  This was the band at which the basic catalog was constructed.  Magnitudes are inverted logarithmic measures of brightness.  A  galaxy with R=21 is 100-times brighter than one with R=26.  The error is the standard deviation derived from detailed knowledge of the measurement process.  This dataset is an excellent example of astronomical datasets where each variable is accompanied by heteroscedastic measurement errors of known variances.  Col 4-5  ApDRmag is the difference between the total and aperture magnitude in the R band.  This is a rough measure of the size of the galaxy in the image where ApDRmag=0 corresponds to a point source.  Negative values are not physically meaningful.  mu_max is the central surface brightness of the object in the R band.  The difference between Rmag and mu_max should also be an indicator of galaxy size. Col 6-9 Mcz and MCzml are two redshift estimates.  Mcz is the preferred value.  e.Mcz is its estimated error and chi2red is the reduced chi-squared value of the least-squares fit of the 17-band magnitudes to the best-fit template galaxy spectrum.  Galaxies with large e.Mcz or chi2red might be omitted as unreliable. Col 10-29 These give the absolute magnitudes (i.e. intrinsic luminosities) of the galaxy in 10 bands with their measurement errors.  They are based on the measured magnitudes and the redshifts and represent the intrinsic luminosities of the galaxies; a galaxy with M=-15 is 100-times less luminous than one with M=-20.    These magnitudes are not all independent of each others but the are important for representing intrinsic properties of the galaxies.  Below is one of several redshift-stratified plots of the B-band absolute magnitude (abscissa) against the difference of magnitude (i.e. ratio of luminosities) between the 2800A ultraviolet and blue band which is a sensitive indicator of star formation.  A redshift-dependent bimodal distribution is seen.  Col 30-55  Observed brightnesses in 13 bands in sequence from 420 nm in the ultraviolet to 915 nm in the far red.  These are given in linear variables with units of photon flux densities photons/m2/s/nm.  Again each measurement is accompanied by a measurement error which can be used to distinguish measurement from intrinsic dispersions in the distributions. Col 56-65 Observed brightnesses in 5 traditional broad spectral bands UBVRI.  These are largely redundant with the 13 bands in the previous columns.  Statistical exercises  Examine basic characteristics of the survey which are not of scientific interest.  These include the absence of high-redshift (i.e. distant) high-absolute-magnitude (i.e. faint) galaxies; the dropoff in flux with redshift; the dropoff in image size with redshift. Study these two populations as a function of redshift to investigate the evolution of star formation.  ,Nr:Rmag:e.Rmag:ApDRmag:mumax:Mcz:e.Mcz:MCzml:chi2red:UjMAG:e.UjMAG:BjMAG:e.BjMAG:VjMAG:e.VjMAG:usMAG:e.usMAG:gsMAG:e.gsMAG:rsMAG:e.rsMAG:UbMAG:e.UbMAG:BbMAG:e.BbMAG:VnMAG:e.VbMAG:S280MAG:e.S280MA:W420FE:e.W420FE:W462FE:e.W462FE:W485FD:e.W485FD:W518FE:e.W518FE:W571FS:e.W571FS:W604FE:e.W604FE:W646FD:e.W646FD:W696FE:e.W696FE:W753FE:e.W753FE:W815FS:e.W815FS:W856FD:e.W856FD:W914FD:e.W914FD:W914FE:e.W914FE:UFS:e.UFS:BFS:e.BFS:VFD:e.VFD:RFS:e.RFS:IFD:e.IFD:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,astronomy
Trump Financial Disclosure 2017 , Sohier Dane , www.kaggle.com/sohier/trump-financial-disclosure-2017 , Tue Jul 11 2017 04:30:37 GMT+0530 (IST) , Donald Trump's 2017 Form 278e ,115, finance- politics- ,Context This is a general disclosure of Donald Trump's assets debts and sources of income. Because the forms are only meant to reveal on potential conflicts of interests a filer might have they provide far less specificity than tax returns would. This is an unpacked version of the pdf of Trump's form that was made available by the Federal Election Commission June 16th 2017. It contains some information about his financial interests but not enough to paint a complete picture of his net worth. It may be possible to use some of these forms to identify his foreign business partners. Acknowledgements This dataset was kindly extracted from the original PDF and made publicly available by the Center for Responsive Politics. Inspiration Previous work on similar disclosures by Trump has often focused on identifying his foreign business ties. Are you able to find any new ones? You might also like  Trump's 2016 Financial Disclosure Trump's World Trump's Tweets Trump Campaign Expenditures ,ID #:Page:Description:Underlying Assets:Location:EIF:attached schedule+2016:2016 Value Min:2016 Value Max:Income Type:2016 Income Exact:2016 Income Min:2016 Income Max:,numeric:numeric:string:string:string:string:numeric:string:string:string:string:string:string:,politics
Interest Rate Records , Sohier Dane , www.kaggle.com/sohier/interest-rate-records , Sat Aug 19 2017 01:52:10 GMT+0530 (IST) , Historic H15 Release Data from the Federal Reserve ,203, finance- government- banking- ,The H15 Release from the federal reserve provides daily interest rate information for a variety of core interest rates such as T bills and the federal funds rate. For some rates this dataset extends all the way back to 1954. The rates included are  time_period federal_funds 1_month_nonfinancial_commercial_paper 2_month_nonfinancial_commercial_paper 3_month_nonfinancial_commercial_paper 1_month_financial_commercial_paper 2_month_financial_commercial_paper 3_month_financial_commercial_paper prime_rate discount_rate 4_week_treasury_bill 3_month_treasury_bill 6_month_treasury_bill 1_year_treasury_bill 1_month_treasury_constant_maturity 3_month_treasury_constant_maturity 6_month_treasury_constant_maturity 1_year_treasury_constant_maturity 2_year_treasury_constant_maturity 3_year_treasury_constant_maturity 5_year_treasury_constant_maturity 7_year_treasury_constant_maturity 10_year_treasury_constant_maturity 20_year_treasury_constant_maturity 30_year_treasury_constant_maturity 5_year_inflation_indexed_treasury_constant_maturity 7_year_inflation_indexed_treasury_constant_maturity 10_year_inflation_indexed_treasury_constant_maturity 20_year_inflation_indexed_treasury_constant_maturity 30_year_inflation_indexed_treasury_constant_maturity inflation_indexed_long_term_average  Please see https//www.federalreserve.gov/releases/h15/ for notices caveats and newly released data.,time_period:federal_funds:1_month_nonfinancial_commercial_paper:2_month_nonfinancial_commercial_paper:3_month_nonfinancial_commercial_paper:1_month_financial_commercial_paper:2_month_financial_commercial_paper:3_month_financial_commercial_paper:prime_rate:discount_rate:4_week_treasury_bill:3_month_treasury_bill:6_month_treasury_bill:1_year_treasury_bill:1_month_treasury_constant_maturity:3_month_treasury_constant_maturity:6_month_treasury_constant_maturity:1_year_treasury_constant_maturity:2_year_treasury_constant_maturity:3_year_treasury_constant_maturity:5_year_treasury_constant_maturity:7_year_treasury_constant_maturity:10_year_treasury_constant_maturity:20_year_treasury_constant_maturity:30_year_treasury_constant_maturity:5_year_inflation_indexed_treasury_constant_maturity:7_year_inflation_indexed_treasury_constant_maturity:10_year_inflation_indexed_treasury_constant_maturity:20_year_inflation_indexed_treasury_constant_maturity:30_year_inflation_indexed_treasury_constant_maturity:inflation_indexed_long_term_average:,dateTime:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,banking
UK Government Wine Cellar Reports , Sohier Dane , www.kaggle.com/sohier/uk-government-wine-cellar-reports , Wed Sep 06 2017 22:47:55 GMT+0530 (IST) , Stores and consumption for 2014-2016 ,24, alcohol- ,This dataset does not have a description yet.,Country/Region:Vintage:Product Name:Grade:,string:numeric:string:string:,
Crime in Baltimore , Sohier Dane , www.kaggle.com/sohier/crime-in-baltimore , Wed Sep 13 2017 21:52:08 GMT+0530 (IST) , Crime data for 2012-2017 ,182, crime- ,All BPD data on Open Baltimore is preliminary data and subject to change. The information presented through Open Baltimore represents Part I victim based crime data. The data do not represent statistics submitted to the FBI's Uniform Crime Report (UCR); therefore any comparisons are strictly prohibited. For further clarification of UCR data please visit http//www.fbi.gov/about-us/cjis/ucr/ucr. Please note that this data is preliminary and subject to change. Prior month data is likely to show changes when it is refreshed on a monthly basis. All data is geocoded to the approximate latitude/longitude location of the incident and excludes those records for which an address could not be geocoded. Any attempt to match the approximate location of the incident to an exact address is strictly prohibited. Acknowledgements This dataset was kindly made available by the City of Baltimore. You can find the original dataset which is updated regularly here.,CrimeDate:CrimeTime:CrimeCode:Location:Description:Inside/Outside:Weapon:Post:District:Neighborhood:Longitude:Latitude:Location 1:Premise:Total Incidents:,dateTime:dateTime:string:string:string:string:string:numeric:string:string:numeric:numeric:string:string:numeric:,crime
NY State Lotto Winning Numbers , Sohier Dane , www.kaggle.com/sohier/ny-state-lotto-winning-numbers , Wed Sep 13 2017 23:02:11 GMT+0530 (IST) , Winning numbers since 2001 ,39, money- ,Winning numbers from the New York State Lotto since 2001. Acknowledgements This dataset was kindly made available by the state of New York. You can find the original dataset here. Inspiration  Some other state lotteries have proven to be predictable and ended up being gamed. It's extremely unlikely that any real patterns exist in a large and long running lotto like New York's but can you find any? ,Draw Date:Winning Numbers:Bonus #:Extra #:,dateTime:string:numeric:string:,
UK Traffic Counts , Sohier Dane , www.kaggle.com/sohier/uk-traffic-counts , Wed Aug 30 2017 00:03:13 GMT+0530 (IST) , Details of traffic in England and Wales ,166, road transport- ,Data are available for each junction to junction link on the major road network (motorways and A roads). Data are also available for the sample of points on the minor road network (B C and unclassified roads) that are counted each year and these counts are used to produce estimates of traffic growth on minor roads. The data are produced for every year and are in three formats a) the raw manual count data collected by trained enumerators; b) Annual Average Daily Flows (AADFs) for count points on major roads and minor roads; and c) traffic figures for major roads only. Explanatory notes (metadata) are available for each dataset and in one combined note. A description of how annual road traffic estimates are produced is available at https//www.gov.uk/government/uploads/system/uploads/attachment_data/file/270083/contents-page.pdf This dataset was kindly released by the British Department of Transportation. You can find the original dataset here.,AADFYear:CP:Estimation_method:Estimation_method_detailed:ONS GOR Name:ONS LA Name:Road:RCat:iDir:S Ref E:S Ref N:S Ref Latitude:S Ref Longitude:A-Junction:B-Junction:LenNet:LenNet_miles:FdPC:Fd2WMV:FdCar:FdBUS:FdLGV:FdHGVR2:FdHGVR3:FdHGVR4:FdHGVA3:FdHGVA5:FdHGVA6:FdHGV:FdAll_MV:,numeric:numeric:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,roadways
Medicare's Doctor Comparison Scores , Sohier Dane , www.kaggle.com/sohier/medicares-doctor-comparison-scores , Wed Aug 30 2017 04:14:39 GMT+0530 (IST) , The 2017 Physican Compare Database ,121, public health- human medicine- ,The Physician Compare website was created by the Centers for Medicare & Medicaid Services (CMS) in December 2010 as required by the Affordable Care Act (ACA) of 2010 to help patients assess and find doctors and hospitals. This dataset contains the information supplied to patients via that website including patient satisfaction surveys and performance scores across over 100 metrics. Acknowledgements This dataset was kindly released by the Centers for Medicare & Medicaid Services. You can find the original copy of the dataset here.,Organization legal name or 'doing business as' name:Group PAC ID:State:Participating in PQRS:Measure Identifier:Measure Title:Inverse Measure:Measure Performance Rate:Footnote:Reporting Mechanism:Reported on PC Live Site:,string:numeric:string:string:string:string:string:numeric:string:string:string:,health infrastructure
Baltimore 911 Calls , Sohier Dane , www.kaggle.com/sohier/baltimore-911-calls , Wed Aug 30 2017 00:09:38 GMT+0530 (IST) , Records of 2.8 million calls from 2015 onwards ,105, crime- ,This dataset records the time location priority and reason for calls to 911 in the city of Baltimore. Acknowledgements This dataset was kindly made available by the City of Baltimore. They update the data daily; you can find the original version here. Inspiration  The study discussed in this Atlantic article reviewing 911 calls in Milwaukuee found that that incidents of police violence lead to large drops in the number of 911 calls. Does this hold true for Baltimore as well? ,:callDateTime:priority:district:description:callNumber:incidentLocation:location:,numeric:dateTime:string:string:string:string:string:string:,
Seattle Police Department 911 Incident Response , Sohier Dane , www.kaggle.com/sohier/seattle-police-department-911-incident-response , Wed Aug 30 2017 00:57:37 GMT+0530 (IST) , 1.4 million responses from 2009 onwards ,83, crime- ,This dataset records police responses to 911 calls in the city of Seattle. Acknowledgements This dataset was kindly made available by the City of Seattle. They update the data daily; you can find the original version here. Inspiration  The study discussed in this Atlantic article reviewing 911 calls in Milwaukuee found that that incidents of police violence lead to large drops in the number of 911 calls. Does this hold true for Seattle as well? This dataset technically only contains the responses to 911 calls rather than the calls themselves but it should be feasible to use the responses as a decent proxy for calls. ,CAD CDW ID:CAD Event Number:General Offense Number:Event Clearance Code:Event Clearance Description:Event Clearance SubGroup:Event Clearance Group:Event Clearance Date:Hundred Block Location:District/Sector:Zone/Beat:Census Tract:Longitude:Latitude:Incident Location:Initial Type Description:Initial Type Subgroup:Initial Type Group:At Scene Time:,numeric:numeric:numeric:numeric:string:string:string:dateTime:string:string:string:numeric:numeric:numeric:string:string:string:string:string:,
Allen-Unger Global Commodity Prices , Sohier Dane , www.kaggle.com/sohier/allenunger-global-commodity-prices , Fri Sep 22 2017 23:09:32 GMT+0530 (IST) , Price Time Series Between 965 and 1983 ,47, history- economics- ,Context Are you tired of hearing your elders talk about how much cheaper things were back in their day? Would you like to one-up them by talking about how much cheaper goods were a thousand years before they were born? Of course you would! You might also have an interest in an unusually comprehensive set of historic prices that cover long time spans. English port wine prices for example stretch from 1209 through 1869. Content Each commodity contains prices in the local currency and standardized silver units that allow for broader comparisons. Please note that this dataset has been consolidated into a single file from the original thousand or so csvs so the format is slightly different. Acknowledgements This dataset was kindly made available by Robert Allen and Richard Unger. You can find the original dataset here. Inspiration  Can you identify goods or locations that remained largely unaffected by the industrial revolution?  If you like If you enjoyed this dataset you might also like the millennium of macroeconomic data dataset.,Item Year:Original Value:Standard Value:Original Currency:Standard Currency:Orignal Measure:Standard Measure:Sources:Notes:Location:Commodity:Variety:,numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:,commodity prices
World Countries and Continents Details , folaraz , www.kaggle.com/folaraz/world-countries-and-continents-details , Thu Oct 05 2017 14:02:23 GMT+0530 (IST) , World exploration for data scientist ,80, data analysis- geography- demographics- ,Context Can you tell geographical stories about the world using data science? Content World countries with their corresponding continents  official english names official french names DialITULanguages and so on. Acknowledgements This data was gotten from https//old.datahub.io/  Inspiration Exploration of the world countries   - Can we graphically visualize countries that speak a particular language?  - We can also integrate this dataset into others to enhance our exploration. - The dataset has now been updated to include longitude and latitudes of countries in the world.,name:official_name_en:official_name_fr:ISO3166-1-Alpha-2:ISO3166-1-Alpha-3:M49:ITU:MARC:WMO:DS:Dial:FIFA:FIPS:GAUL:IOC:ISO4217-currency_alphabetic_code:ISO4217-currency_country_name:ISO4217-currency_minor_unit:ISO4217-currency_name:ISO4217-currency_numeric_code:is_independent:Capital:Continent:TLD:Languages:Geoname ID:EDGAR:,string:string:string:string:string:numeric:string:string:string:string:numeric:string:string:numeric:string:string:string:numeric:string:numeric:string:string:string:string:string:numeric:string:,geographical information
American Time Use Survey , US Bureau of Labor Statistics , www.kaggle.com/bls/american-time-use-survey , Thu Jun 15 2017 22:02:54 GMT+0530 (IST) , Multi-Year Survey Microdata Files from 2003-2015 ,987, time series- demographics- ,Context The American Time Use Survey (ATUS) is the Nation’s first federally administered continuous survey on time use in the United States. The goal of the survey is to measure how people divide their time among life’s activities. In ATUS individuals are randomly selected from a subset of households that have completed their eighth and final month of interviews for the Current Population Survey (CPS). ATUS respondents are interviewed only one time about how they spent their time on the previous day where they were and whom they were with. The survey is sponsored by the Bureau of Labor Statistics and is conducted by the U.S. Census Bureau. The major purpose of ATUS is to develop nationally representative estimates of how people spend their time. Many ATUS users are interested in the amount of time Americans spend doing unpaid nonmarket work which could include unpaid childcare eldercare housework and volunteering. The survey also provides information on the amount of time people spend in many other activities such as religious activities socializing exercising and relaxing. In addition to collecting data about what people did on the day before the interview ATUS collects information about where and with whom each activity occurred and whether the activities were done for one’s job or business. Demographic information—including sex race age educational attainment occupation income marital status and the presence of children in the household—also is available for each respondent. Although some of these variables are updated during the ATUS interview most of this information comes from earlier CPS interviews as the ATUS sample is drawn from a subset of households that have completed month 8 of the CPS.  The user guide can be found here. Content There are 8 datasets containing microdata from 2003-2015  Respondent file The Respondent file contains information about ATUS respondents including their labor force status and earnings. Roster file The Roster file contains information about household members and nonhousehold children (under 18) of ATUS respondents. It includes information such as age and sex. Activity file The Activity file contains information about how ATUS respondents spent their diary day. It includes information such as activity codes activity start and stop times and locations. Because Activity codes have changed somewhat between 2003 and 2015 this file uses activity codes that appear in the 2003-2015 ATUS Coding Lexicon (PDF). Activity summary file The Activity summary file contains information about the total time each ATUS respondent spent doing each activity on the diary day. Because Activity codes have changed somewhat between 2003 and 2015 this file uses activity codes that appear in the 2003-2015 ATUS Coding Lexicon (PDF). Who file The Who file includes codes that indicate who was present during each activity. CPS 2003-2015 file The ATUS-CPS file contains information about each household member of all individuals selected to participate in ATUS. The information on the ATUS-CPS file was collected 2 to 5 months before the ATUS interview. Eldercare Roster file The ATUS Eldercare Roster file contains information about people for whom the respondent provided care. Eldercare data have been collected since 2011. Replicate weights file The Replicate weights file contains miscellaneous ATUS weights.  The ATUS interview data dictionary can be found here. The ATUS Current Population Survey (CPS) data dictionary can be found here. The ATUS occupation and industry codes can be found here. The ATUS activity lexicon can be found here. Acknowledgements The original datasets can be found here. Inspiration How do daily activities differ by  labor force status income household composition geographical region disability status ,tucaseid:tuactivity_n:tuactdur24:tucc5:tucc5b:trtcctot_ln:trtcc_ln:trtcoc_ln:tustarttim:tustoptime:trcodep:trtier1p:trtier2p:tucc8:tucumdur:tucumdur24:tuactdur:tr_03cc57:trto_ln:trtonhh_ln:trtohh_ln:trthh_ln:trtnohh_ln:tewhere:tucc7:trwbelig:trtec_ln:tuec24:tudurstop:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:dateTime:dateTime:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,demography
Alcohol and Drug Consumption of German Teens , Fabiola , www.kaggle.com/fabiolabusch/alcohol-and-drug-consumption-of-german-teens , Fri Sep 15 2017 04:12:43 GMT+0530 (IST) , Do modern teens prefer weed over cigarettes? ,137, alcohol- public health- children- health- illegal drugs- ,Context The data was collected by social science research institutes 1973 bis 1993 Institut für Jugendforschung GmbH (IJF) München; 1997 GfM-GETAS/WBA GmbH Hamburg 2001 bis 2015 forsa Gesellschaft für Sozialforschung und statistische Analysen mbH Dortmund und Berlin.  Long term studies regarding the alcohol and (illegal) drug consumption habits of 12 to 25 year old German teens were taken. The motivations and influences in drug consumption were studied. The aim was to develop preventional means and ways of communication with drug consuming teenagers. Content Young Germans between 12 and 25 years were asked about their drug consumptions in the last 12 months. The survey was taken from the 70's until today. Different datasets were provided and for some years features are missing. Acknowledgements The data is provided by German Bundeszentrale für gesundheitliche Aufklärung (Ministry of Health Education) and can be accessed at http//www.gbe-bund.de. Photo by Stas Svechnikov on Unsplash. Inspiration While growing up in the late 2000's in Germany I had the impression that teenagers smoke less cigarettes and drink less alcohol than they used to in the 90's. Instead they consumed more cannabis. I wonder if I was right ...,:12_lt26_mf:12_lt16_mf:16_lt18_mf:18_lt22_mf:22_lt26_mf:12_lt26_m:12_lt16_m:16_lt18_m:18_lt22_m:22_lt26_m:12_lt26_f:12_lt16_f:16_lt18_f:18_lt22_f:22_lt26_f:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,drugs and addiction
Computer Parts Dataset (CPU GPU HDD...) , ilias sekkaf , www.kaggle.com/iliassekkaf/computerparts , Sat Sep 30 2017 19:08:40 GMT+0530 (IST) , How did computer specifications and performance evolve over time? ,243, computers- computer architecture- internet- ,Contents Contains specifications release dates and release prices of computer parts. Context CPUs  Status  End of Life if Product End of Life notification has been published Active if this specific part is active Pre Active if orders may be taken but not scheduled nor shipped. Execute Disable Bit hardware-based security feature that can reduce exposure to viruses and malicious-code attacks Thermal Monitoring Technologies protect the processor package and the system from thermal failure through several thermal management features.  Idle States are used to save power when the processor is idle.   Intel® My WiFi Technology enables wireless connection of an UltrabookTM or laptop to WiFi-enabled devices such as printers stereos etc. Intel® 64 architecture delivers 64-bit computing on server workstation desktop and mobile platforms when combined with supporting software. Intel 64 architecture improves performance by allowing systems to address more than 4 GB of both virtual and physical memory. Intel® VT-x with Extended Page Tables reduces the memory and power overhead costs and increases battery life through hardware optimization of page table management. Intel® Virtualization Technology allows one hardware platform to function as multiple “virtual” platforms. It offers improved manageability by limiting downtime and maintaining productivity by isolating computing activities into separate partitions. Intel® Hyper-Threading Technology delivers two processing threads per physical core. Highly threaded applications can get more work done in parallel completing tasks sooner. Intel® Turbo Boost Technology dynamically increases the processor's frequency as needed by taking advantage of thermal and power headroom to give you a burst of speed when you need it and increased energy efficiency when you don’t. T (Junction Temperature) is the maximum  temperature allowed. Socket` the component that provides the mechanical and electrical connections between the processor and motherboard.   PCI Express (PCIe) Configurations the available PCIe lane configurations that can be used to link the PCH PCIe lanes to PCIe devices. PCI Express Revision the version supported by the processor.  OpenGL indicates support for a cross-language multi-platform API for rendering 2D and 3D vector graphics. DirectX indicates support for a specific version of Microsoft’s collection of API’s for handling multimedia compute tasks Max Resolution   the maximum resolution supported by the processor for a device with an integrated flat panel (24bits per pixel & 60Hz). System or device display resolution is dependent on multiple system design factors Max Resolution (DP)  the maximum resolution supported by the processor via the DP interface (24bits per pixel & 60Hz). System or device display resolution is dependent on multiple system design factors Max Resolution (HDMI) the maximum resolution supported by the processor via the HDMI interface (24bits per pixel & 60Hz). System or device display resolution is dependent on multiple system design factors; actual resolution may be lower on your system. 4K support indicates the product's support of 4K resolution defined here as minimum 3840 x 2160. Graphics Output defines the interfaces available to communicate with display devices. The maximum amount of memory accessible to processor graphics. Processor graphics operates on the same physical memory as the CPU (subject to OS driver and other system limitations). Graphics max dynamic frequency  to the maximum opportunistic graphics render clock frequency (in MHz) that can be supported using Intel® HD Graphics with Dynamic Frequency feature. Graphics Base frequency  the rated/guaranteed graphics render clock frequency in MHz. Processor Graphics indicates graphics processing circuitry integrated into the processor ECC Memory Supported ECC memory is a type of system memory that can detect and correct common kinds of internal data corruption. Max Memory bandwidth is the maximum rate at which data can be read from or stored into a semiconductor memory by the processor (in GB/s). The number of memory channels refers to the bandwidth operation for real world application. Channel Type Single Channel Dual Channel Triple Channel and Flex Mode. Max memory size the maximum memory capacity supported by the processor. “Conflict free” defined by the U.S. Securities and Exchange Commission rules to mean products that do not contain conflict minerals (tin tantalum tungsten and/or gold) that directly or indirectly finance or benefit armed groups in the Democratic Republic of the Congo (DRC) or adjoining countries. Thermal Design Power (TDP) represents the average power in watts the processor dissipates when operating at Base Frequency with all cores active under an Intel-defined high-complexity workload.  CPU Cache is an area of fast memory located on the processor.  Max turbo frequency is the maximum single core frequency at which the processor is capable of operating using Intel® Turbo Boost Technology. Frequency is measured GHz Processor Base Frequency describes the rate at which the processor's transistors open and close. A Thread or thread of execution is a software term for the basic ordered sequence of instructions that can be passed through or processed by a single CPU core.  Cores  a hardware term that describes the number of independent central processing units  Embedded In essence an embedded processor is a CPU chip used in a system which is not a general-purpose workstation laptop or desktop computer. More information Lithography  the semiconductor technology used to manufacture an integrated circuit and is reported in nanometer (nm)    GPUs  Architecture   the GPU architecture used on the graphics card Best_Resolution   the best Screensize for  reducing bottleneck to a minimum      Boost_Clock   the MHz speed of the graphics card        Core_Speed   the speed of the graphics card        DVI_Connection   How many DVI connections does the graphics cardhave   Dedicated   is the graphics card dedicated    Direct_X   What Direct X can the graphics card support        DisplayPort_Connection   How many DisplayPort connections does the  graphics card   have    HDMI_Connection   How many HDMI connections does the graphics card have  Integrated   is the Graphics card integrated L2_Cache   the L2 Cache of graphics card  Max_Power   What power in watts is required to run the graphics card Memory   the memory of graphics card    Memory_Bandwidth   the memory Bandwidth  Memory_Bus   the memory bus of graphics card Memory_Speed   the memory speed of the graphic card's RAM        Memory_Type   the memory type of the graphics card     Notebook_GPU   Is it for Notebooks or Desktop   Open_GL   What Open GL can the graphics card support PSU   What Power Supply is needed to run the graphics card Pixel_Rate   the number of pixels per second the GPU can produce Power_Connector   What Power Connector is needed to run the graphics card   Process   What nm technology does the GPU use        ROPs   How many Raster Operation Pipelines does the GPU have     Release_Date    Release_Price   the release price of the GPU Resolution_WxH   Maximum supported resolution SLI_Crossfire   does the GPU support SLI or Crossfire Technology Shader   What Shader Model can the graphics card support  TMUs   How many texture mapping units does the GPU have    Texture_Rate   How many texture pixels per second can the GPU produce      VGA_Connection   How many VGA connections does GPU have   Inspiration  How did performance over price ratio evolve over time?  How about general computing power?   Are there any manufacturers that are known for some specific range of performance & price?   Acknowledgements The data given here belongs Mainly to Intel Game-Debate and the companies involved in producing the part. I do not own the data I uploaded it solely for informative purposes under their original license.,Architecture:Best_Resolution:Boost_Clock:Core_Speed:DVI_Connection:Dedicated:Direct_X:DisplayPort_Connection:HDMI_Connection:Integrated:L2_Cache:Manufacturer:Max_Power:Memory:Memory_Bandwidth:Memory_Bus:Memory_Speed:Memory_Type:Name:Notebook_GPU:Open_GL:PSU:Pixel_Rate:Power_Connector:Process:ROPs:Release_Date:Release_Price:Resolution_WxH:SLI_Crossfire:Shader:TMUs:Texture_Rate:VGA_Connection:,string:string:string:string:numeric:string:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:numeric:string:string:string:string:numeric:dateTime:string:string:string:numeric:numeric:string:numeric:,gadgets
The Interview Attendance Problem , VishnuRaghavan , www.kaggle.com/vishnusraghavan/the-interview-attendance-problem , Wed Aug 23 2017 12:04:40 GMT+0530 (IST) , Predict which candidates will attend the intervew ,190, strategy- business- management- unsolved problems in neuroscience- ,Context The data pertains to the recruitment industry in India for the years 2014-2016 and deals with candidate interview attendance for various clients. The details are largely self explanatory.  Content The data have been collected by me and my fellow researchers over a period of over 2 years between september 2014-January 2017. The details of the data are as follows  Date of interview This date refers to the day the candidates were scheduled for the interview. The formats vary. Name of the client The clients that gave the recruitment vendor the requisite mandate Industry Vertical This refers to the vertical the client belongs(Note Candidates can jump across verticals in their job hunt) Location Refers to the current location of the candidate Job location Refers to the place where the candidate will be placed Interview location Where the interview has been scheduled Candidate Native Location The candidate's hometown. Position to be closed Niche refers to rare skill sets while routine refers to more common skill sets Nature of Skill Set This refers to the skill the client has and specifies the same Interview Type There are three types of interview- Walkin drives- these are unscheduled. Candidates are either contacted or they come to the interview on their own volition Scheduled- Here the candidates profiles are screened by the client and subsequent to this the vendor fixes an appointment between the client and the candidate. The third one is a scheduled walkin. Here the number of candidates is larger and the candidates are informed beforehand of a tentative date to ascertain their availability. The profiles are screened as in a scheduled interview. In a sense it bears features of both a walk-in and a scheduled interview Candidate ID This is a substitute to keep the candidates identity a secret 12.Gender Whether the candidate is male or female Marital Status Whether the candidate is married or Single Observed Attendance Whether the candidate attended the interview. This is binary and will form our dependent variable 15 Expected Attendance Whether the candidate was expected to attend the interview. Here the it is either yes no or uncertain  There are a set of questions that are asked by a recruiter while scheduling the candidate. The answers to these determine whether expected attendance is yes no or uncertain. Acknowledgements A great measure of thanks goes to my colleaues in research and work.   Dr Rajendra Desai Associate Professor St Joseph's College of Management Bangalore Marcia Akshaya Leo HR recruiter Chennai Dr Rashmi Nakra Professor St Josephs College of Management Bangalore Prima Student St Josephs College of Management Bangalore Trupthi Student St Josephs College of Management Bangalore  Inspiration A few pointers We have already attempted Naive Bayes with decent results  We would like to know if we can predict whether a candidate will attend interviews or not with other algorithms Also whether any of the present set of variables can be modified to yield better results Whether we can find additional variables from the internet and whether we can derive variables from the existing set of variables. ,Date of Interview:Client name:Industry:Location:Position to be closed:Nature of Skillset:Interview Type:Name(Cand ID):Gender:Candidate Current Location:Candidate Job Location:Interview Venue:Candidate Native location:Have you obtained the necessary permission to start at the required time:Hope there will be no unscheduled meetings:Can I Call you three hours before the interview and follow up on your attendance for the interview:Can I have an alternative number/ desk number. I assure you that I will not trouble you too much:Have you taken a printout of your updated resume. Have you read the JD and understood the same:Are you clear with the venue details and the landmark.:Has the call letter been shared:Expected Attendance:Observed Attendance:Marital Status::,string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:,trade and business
NIPS Papers , Ben Hamner , www.kaggle.com/benhamner/nips-papers , Sun Dec 04 2016 20:22:54 GMT+0530 (IST) , Titles authors abstracts and extracted text for all NIPS papers (1987-2016) ,1079, linguistics- artificial intelligence- ,Neural Information Processing Systems (NIPS) is one of the top machine learning conferences in the world. It covers topics ranging from deep learning and computer vision to cognitive science and reinforcement learning.  This dataset includes the title authors abstracts and extracted text for all NIPS papers to date (ranging from the first 1987 conference to the current 2016 conference). I've extracted the paper text from the raw PDF files and are releasing that both in CSV files and as a SQLite database. The code to scrape and create this dataset is on GitHub. Here's a quick RMarkdown exploratory overview of what's in the data.  We encourage you to explore this data and share what you find through Kaggle Kernels!,id:name:,numeric:string:,artificial intelligence
World Glacier Inventory , National Snow and Ice Data Center , www.kaggle.com/nsidcorg/glacier-inventory , Thu Feb 09 2017 02:37:07 GMT+0530 (IST) , Name location altitude and area of every glacier on the planet ,187, environment- climate- ,Content The World Glacier Inventory contains information for over 130000 glaciers. Inventory parameters include geographic location area length orientation elevation and classification. The WGI is based primarily on aerial photographs and maps with most glaciers having one data entry only. The data set can be viewed as a snapshot of the glacier distribution in the second half of the twentieth century. It was founded on the original WGI from the World Glacier Monitoring Service. Acknowledgements The National Snow & Ice Data Center continues to work with the World Glacier Monitoring Service to update the glacier inventory database.,Glacier ID:Political Unit:Continent:Basin Code:Location Code:Glacier Code:Glacier Name:Latitude:Longitude:Primary Class:Glacier Source:Basin Count:Glacier Form:Glacier Activity:Activity Start:Activity End:Minimum Elevation:Minimum Elevation Exposed:Mean Elevation:Mean Elevation Accumulation:Mean Elevation Ablation:Maximum Elevation:Snow Line Elevation:Snow Line Accuracy:Glacier Area:Area Accuracy:Area Exposed:Mean Width:Mean Length:Maximum Length:Maximum Length Exposed:Maximum Length Ablation:Mean Depth:Depth Accuracy:Accumulation Orientation:Ablation Orientation:Topographic Map Year:Topographic Map Scale:Photograph Year:,string:string:string:string:string:numeric:string:numeric:numeric:numeric:numeric:string:numeric:numeric:string:string:numeric:string:numeric:string:string:numeric:string:string:numeric:numeric:string:string:string:numeric:string:string:string:string:string:string:numeric:numeric:string:,geographical information
Hard Drive Test Data , Backblaze , www.kaggle.com/backblaze/hard-drive-test-data , Sat Nov 05 2016 11:09:40 GMT+0530 (IST) , Daily Snapshot of Each Operational Hard Drive in 2016 ,549, computer science- electrical components- ,Context Each day Backblaze takes a snapshot of each operational hard drive that includes basic hard drive information (e.g. capacity failure) and S.M.A.R.T. statistics reported by each drive. This dataset contains data from the first two quarters in 2016. Content This dataset contains basic hard drive information and 90 columns or raw and normalized values of 45 different S.M.A.R.T. statistics. Each row represents a daily snapshot of one hard drive.  date Date in yyyy-mm-dd format serial_number Manufacturer-assigned serial number of the drive model Manufacturer-assigned model number of the drive capacity_bytes Drive capacity in bytes failure Contains a “0” if the drive is OK. Contains a “1” if this is the last day the drive was operational before failing. 90 variables that begin with 'smart' Raw and Normalized values for 45 different SMART stats as reported by the given drive  Inspiration Some items to keep in mind as you process the data  S.M.A.R.T. statistic can vary in meaning based on the manufacturer and model. It may be more informative to compare drives that are similar in model and manufacturer Some S.M.A.R.T. columns can have out-of-bound values When a drive fails the 'failure' column is set to 1 on the day of failure and starting the day after the drive will be removed from the dataset. Each day new drives are also added. This means that total number of drives each day may vary.  S.M.A.R.T. 9 is the number of hours a drive has been in service. To calculate a drive's age in days divide this number by 24.  Given the hints above below are a couple of questions to help you explore the dataset  What is the median survival time of a hard drive? How does this differ by model/manufacturer? Can you calculate the probability that a hard drive will fail given the hard drive information and statistics in the dataset?  Acknowledgement The original collection of data can be found here. When using this data Backblaze asks that you cite Backblaze as the source; you accept that you are solely responsible for how you use the data; and you do not sell this data to anyone.,date:serial_number:model:failure:smart_1_normalized:smart_1_raw:smart_2_normalized:smart_2_raw:smart_3_normalized:smart_3_raw:smart_4_normalized:smart_4_raw:smart_5_normalized:smart_5_raw:smart_7_normalized:smart_7_raw:smart_8_normalized:smart_8_raw:smart_9_normalized:smart_9_raw:smart_10_normalized:smart_10_raw:smart_11_normalized:smart_11_raw:smart_12_normalized:smart_12_raw:smart_13_normalized:smart_13_raw:smart_15_normalized:smart_15_raw:smart_22_normalized:smart_22_raw:smart_183_normalized:smart_183_raw:smart_184_normalized:smart_184_raw:smart_187_normalized:smart_187_raw:smart_188_normalized:smart_188_raw:smart_189_normalized:smart_189_raw:smart_190_normalized:smart_190_raw:smart_191_normalized:smart_191_raw:smart_192_normalized:smart_192_raw:smart_193_normalized:smart_193_raw:smart_194_normalized:smart_194_raw:smart_195_normalized:smart_195_raw:smart_196_normalized:smart_196_raw:smart_197_normalized:smart_197_raw:smart_198_normalized:smart_198_raw:smart_199_normalized:smart_199_raw:smart_200_normalized:smart_200_raw:smart_201_normalized:smart_201_raw:smart_220_normalized:smart_220_raw:smart_222_normalized:smart_222_raw:smart_223_normalized:smart_223_raw:smart_224_normalized:smart_224_raw:smart_225_normalized:smart_225_raw:smart_226_normalized:smart_226_raw:smart_240_normalized:smart_240_raw:smart_241_normalized:smart_241_raw:smart_242_normalized:smart_242_raw:smart_250_normalized:smart_250_raw:smart_251_normalized:smart_251_raw:smart_252_normalized:smart_252_raw:smart_254_normalized:smart_254_raw:smart_255_normalized:smart_255_raw:capacity_bytes:,dateTime:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:numeric:,gadgets
Severe Weather Data Inventory , NOAA , www.kaggle.com/noaa/severe-weather-data-inventory , Mon Oct 24 2016 21:04:45 GMT+0530 (IST) , Detections of hail storm cells based on NEXRAD radar data during 2015 ,582, climate- ,Severe Weather Data Inventory Context The Severe Weather Data Inventory (SWDI) is an integrated database of severe weather records for the United States. Severe weather is a phenomenon that risks the physical well-being of people and property. In fact the frozen precipitation resulting from fast updrafts during strong thunderstorms can lead to serious damage and harm. Each year the U.S. sees approximately $1 billion in property and crop damage due to severe weather incidents.  Frequency Event-level Period 2015  Content The records in SWDI come from a variety of sources in the National Climatic Data Center archive and cover a number of weather phenomena. This extract from 2015 covers hail detections including the probability of a weather event as well as the size and severity of hail -- all of which help understand potential damage to property and injury to people. Records are event-level records. Individual storm cells with a high probability of yielding hail are included in this dataset -- a total of n = 10824080. Inspiration Think about the geospatial and spatial statistical techniques that can be applied to this data to uncover patterns in storms.  How often does serious severe weather happen?  Where do these severe weather events normally occur? What correlations exist between severe weather and other environmental phenomena?  Acknowledgements This data is a product of NOAA's National Centers for Environmental Information (NCEI).  The dataset is generated by a variety of products that have been submitted to NOAA's weather and climate archives at NCEI. The datasets and methods are described at http//www.ncdc.noaa.gov/swdi/. SWDI provides a uniform way to access data from a variety of sources but it does not provide any additional quality control beyond the processing which took place when the data were archived. The data sources in SWDI will not provide complete severe weather coverage of a geographic region or time period due to a number of factors (eg reports for a location or time period not provided to NOAA). The absence of SWDI data for a particular location and time should not be interpreted as an indication that no severe weather occurred at that time and location. Furthermore much of the data in SWDI is automatically derived from radar data and represents probable conditions for an event rather than a confirmed occurrence. License Public Domain License,,,weather and climate
Daily Sea Ice Extent Data , National Snow and Ice Data Center , www.kaggle.com/nsidcorg/daily-sea-ice-extent-data , Fri Jun 09 2017 02:08:16 GMT+0530 (IST) , Total sea ice extent from 1978 to present ,964, environment- climate- ,Context The National Snow and Ice Data Center (NSIDC) supports research into our world’s frozen realms the snow ice glaciers frozen ground and climate interactions that make up Earth’s cryosphere. NSIDC manages and distributes scientific data creates tools for data access supports data users performs scientific research and educates the public about the cryosphere.  Content The dataset provides the total extent for each day for the entire time period (1978-2015). There are 7 variables  Year Month Day Extent unit is 10^6 sq km Missing unit is 10^6 sq km Source Source data product web site http//nsidc.org/data/nsidc-0051.html hemisphere  Acknowledgements The original datasets can be found here and here. Inspiration  Can you visualize the change in sea ice over time? Do changes in sea ice differ between the two hemispheres? ,Year:Month:Day:Extent:Missing:Source Data:hemisphere:,numeric:numeric:numeric:numeric:numeric:string:string:,weather and climate
Global Historical Climatology Network , NOAA , www.kaggle.com/noaa/global-historical-climatology-network , Mon Oct 24 2016 20:53:05 GMT+0530 (IST) , Land and ocean temperature anomalies ,744, climate- history- ,"Global Historical Climatology Network-Monthly (GHCN-M) Context The Global Historical Climatology Network (GHCN) is an integrated database of climate summaries from land surface stations across the globe. This data set contains gridded mean temperature anomalies or departures from a reference value or long-term average from the Global Historical Climatology Network-Monthly (GHCN-M) version 3.2.1 temperature data set. The gridded anomalies were produced from GHCN-M bias corrected data. Each month of data consists of 2592 gridded data points produced on a 5° by 5° basis for the entire globe (72 longitude by 36 latitude grid boxes).  Frequency Monthly Period 1880 to 2016  Content Gridded data for every month from January 1880 to the most recent month is available. The data are temperature anomalies in degrees Celsius. Each gridded value was multiplied by 100 and written to file as an integer. Missing values are represented by the value -9999. The data are formatted by year month latitude and longitude. There are 72 longitude grid values per line -- each grid is labeled as a concatenation of ""lon"" ""w"" or ""e"" then the degree. The latitude is captured in the ""lat"" field where the value indicates the lower bound of a grid cell (e.g. 85 indicates 85-90N whereas -90 indicates 85-90S). Longitude values are written from 180°W to 180°E and latitude values from 90°N to 90°S. This dataset permits the quantification of changes in the mean monthly temperature and precipitation for the earth's surface. Changes in the observing system itself have been carefully removed to allow for the true climate variability at the earth's surface to be represented in the data. Many surface weather stations undergo minor relocations through their history of observation. Stations may also be subject to changes in instrumentation as measurement technology evolves. Further the land use/land cover in the vicinity of an observing site may also change with time. Such modifications to an observing site have the potential to alter a thermometer's microclimate exposure characteristics and/or change the bias of measurements the impact of which can be a systematic shift in the mean level of temperature readings that is unrelated to true climate variations. The process of removing such ""non-climatic"" artifacts in a climate time series is called homogenization. In version 3 of the GHCN-Monthly temperature data the apparent impacts of documented and undocumented inhomogeneities are detected and removed through automated pairwise comparisons of mean monthly temperature series as detailed in Menne and Williams [2009]. Inspiration This granular dataset permits extensive historical analysis of the earth’s climate to answer questions about climate change including how different regions of the planet have been affected by changes in temperature over time. Get started by forking the kernel Mapping Historical Temperature Anomalies with R.  Acknowledgements This data is a product of NOAA's National Centers for Environmental Information (NCEI). It was compiled through the aggregation and analysis of many thousands of weather station records. The compete description of the processes and methods used may be found at https//www.ncdc.noaa.gov/ghcnm/v3.php. The Global Historical Climatology Network-Monthly (GHCN-M) temperature dataset was first developed in the early 1990s (Vose et al. 1992). A second version was released in 1997 following extensive efforts to increase the number of stations and length of the data record (Peterson and Vose 1997). Methods for removing inhomogeneities from the data record associated with non-climatic influences such as changes in instrumentation station environment and observing practices that occur over time were also included in the version 2 release (Peterson and Easterling 1994; Easterling and Peterson 1995). Since that time efforts have focused on continued improvements in dataset development methods including new quality control processes and advanced techniques for removing data inhomogeneities (Menne and Williams 2009). License Public Domain License",,,weather and climate
State Election Results 1971 - 2012 , Sohier Dane , www.kaggle.com/sohier/state-election-results-1971-2012 , Tue Oct 03 2017 05:10:05 GMT+0530 (IST) , Results for 72000 elections ,75, politics- political science- ,Context This dataset contains results of general elections to the lower house of the state legislatures in the United States over the last fifty years up to 2012. This dataset was created by the Princeton Gerrymandering Project as part of their effort to analyze and combat partisan gerrymandering. The Supreme Court will be hearing a very important case on this issue on October 3rd 2017. Regardless of who wins this dataset will be of interest to anyone hoping to defeat (or achieve!) a gerrymandering attempt. Content Each row represents one election from the perspective of the winner. For example the first row of the data should be read as a victory for a Democrat who was not the incumbent. Acknowledgements This dataset was kindly made available by the Princeton Gerrymandering Project. You can find their copy detailed discussion of the data and their code here.,State:District:Year:Party:Incumbent:Dem Votes:GOP Votes:Other Votes:,string:numeric:numeric:string:numeric:numeric:numeric:numeric:,elections
Hurricanes and Typhoons 1851-2014 , NOAA , www.kaggle.com/noaa/hurricane-database , Fri Jan 20 2017 23:45:43 GMT+0530 (IST) , Location wind and pressure of tropical cyclones in Atlantic and Pacific Oceans ,797, weather- ,Context The National Hurricane Center (NHC) conducts a post-storm analysis of each tropical cyclone in the Atlantic basin (i.e. North Atlantic Ocean Gulf of Mexico and Caribbean Sea) and and the North Pacific Ocean to determine the official assessment of the cyclone's history. This analysis makes use of all available observations including those that may not have been available in real time. In addition NHC conducts ongoing reviews of any retrospective tropical cyclone analyses brought to its attention and on a regular basis updates the historical record to reflect changes introduced. Content The NHC publishes the tropical cyclone historical database in a format known as HURDAT short for HURricane DATabase. These databases (Atlantic HURDAT2 and NE/NC Pacific HURDAT2) contain six-hourly information on the location maximum winds central pressure and (starting in 2004) size of all known tropical cyclones and subtropical cyclones.,ID:Name:Date:Time:Event:Status:Latitude:Longitude:Maximum Wind:Minimum Pressure:Low Wind NE:Low Wind SE:Low Wind SW:Low Wind NW:Moderate Wind NE:Moderate Wind SE:Moderate Wind SW:Moderate Wind NW:High Wind NE:High Wind SE:High Wind SW:High Wind NW:,string:string:numeric:numeric:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,disasters
El Nino Dataset , UCI Machine Learning , www.kaggle.com/uciml/el-nino-dataset , Mon Nov 07 2016 02:32:18 GMT+0530 (IST) , Meteorological readings taken from a series of buoys in the equatorial Pacific ,544, oceans- climate- ,Context This dataset contains oceanographic and surface meteorological readings taken from a series of buoys positioned throughout the equatorial Pacific. This data was collected with the Tropical Atmosphere Ocean (TAO) array which consists of nearly 70 moored buoys spanning the equatorial Pacific measuring oceanographic and surface meteorological variables critical for improved detection understanding and prediction of seasonal-to-interannual climate variations originating in the tropics.  Content The data consists of the following variables date latitude longitude zonal winds (west<0 east>0) meridional winds (south<0 north>0) relative humidity air temperature sea surface temperature and subsurface temperatures down to a depth of 500 meters. Data taken from the buoys from as early as 1980 for some locations. Other data that was taken in various locations are rainfall solar radiation current levels and subsurface temperatures.  The latitude and longitude in the data showed that the bouys moved around to different locations. The latitude values stayed within a degree from the approximate location. Yet the longitude values were sometimes as far as five degrees off of the approximate location.  There are missing values in the data. Not all buoys are able to measure currents rainfall and solar radiation so these values are missing dependent on the individual buoy. The amount of data available is also dependent on the buoy as certain buoys were commissioned earlier than others.  All readings were taken at the same time of day.  Acknowledgement This dataset is part of the UCI Machine Learning Repository and the original source can be found here. The original owner is the NOAA Pacific Marine Environmental Laboratory.   Inspiration  How can the data be used to predict weather conditions throughout the world?  How do the variables relate to each other?  Which variables have a greater effect on the climate variations?  Does the amount of movement of the buoy effect the reliability of the data? ,Observation: Year: Month: Day: Date:,numeric:numeric:numeric:numeric:dateTime:,weather and climate
Carbon Emissions , Jason McNeill , www.kaggle.com/txtrouble/carbon-emissions , Sun Nov 06 2016 08:33:26 GMT+0530 (IST) , Carbon emissions from electicity production ,809, environment- energy- ,Monthly/Annual carbon dioxide emissions from electricity generation from the Energy Information Administration. Data is broken down by fuel type. http//www.eia.gov/electricity/data.cfm#elecenv,MSN:YYYYMM:Value:Column_Order:Description:Unit:,string:numeric:numeric:numeric:string:string:,energy production
Ocean Ship Logbooks (1750-1850) , CWILOC , www.kaggle.com/cwiloc/climate-data-from-ocean-ships , Wed Aug 19 2015 03:23:00 GMT+0530 (IST) , Explore changing climatology with data from early shipping logs ,2705, environment- climate- shipping- ,"In the mid-eighteenth to nineteenth centuries navigating the open ocean was an imprecise and often dangerous feat. In order to calculate their daily progress and avoid running/sailing into the unknown a ship's crew kept a detailed logbook with data on winds waves and any remarkable weather. Handwritten in archived logbooks these rich datasets were nearly impossible to study until the European Union funded their digitization in 2001. You can visit the EU project website for detailed information on the countries and ships included. We're hosting the full 1750-1850 dataset on Kaggle to promote the exploration of this unique and invaluable climatology resource.  Data Description This data comes from the Climatological Database for the World's Oceans 1750-1850 (CLIWOC) version 1.5 data release. The primary data file is CLIWOC15.csv. The columns in this table are described on this page (scroll down to the table that starts with ""Field abbreviation""). It includes 280280 observational records of ship locations weather data and other associated information. The ancillary data files are described on the above site.",RecID:InstAbbr:InstName:InstPlace:InstLand:NumberEntry:NameArchiveSet:ArchivePart:Specification:LogbookIdent:LogbookLanguage:EnteredBy:DASnumber:ImageNumber:VoyageFrom:VoyageTo:ShipName:ShipType:Company:OtherShipInformation:Nationality:Name1:Rank1:Name2:Rank2:Name3:Rank3:ZeroMeridian:StartDay:TimeGen:ObsGen:ReferenceCourse:ReferenceWindDirection:DistUnits:DistToLandmarkUnits:DistTravelledUnits:LongitudeUnits:VoyageIni:UnitsOfMeasurement:Calendar:Year:Month:Day:DayOfTheWeek:PartDay:TimeOB:Watch:Glasses:UTC:CMG:ShipSpeed:Distance:drLatDeg:drLatMin:drLatSec:drLatHem:drLongDeg:drLongMin:drLongSec:drLongHem:LatDeg:LatMin:LatSec:LatHem:LongDeg:LongMin:LongSec:LongHem:Lat3:Lon3:LatInd:LonInd:PosCoastal:EncName:EncNat:EncRem:Anchored:AnchorPlace:LMname1:LMdirection1:LMdistance1:LMname2:LMdirection2:LMdistance2:LMname3:LMdirection3:LMdistance3:EstError:ApplError:WindDirection:AllWindDirections:WindForce:WindForceScale:AllWindForces:WindScale:Weather:ShapeClouds:DirClouds:Clearness:PrecipitationDescriptor:CloudFrac:Gusts:Rain:Fog:Snow:Thunder:Hail:SeaIce:Duplicate:Release:SSTReading:SSTReadingUnits:StateSea:CurrentDir:CurrentSpeed:TairReading:AirThermReadingUnits:ProbTair:BaroReading:AirPressureReadingUnits:BarometerType:BarTempReading:BarTempReadingUnits:HumReading:HumidityUnits:HumidityMethod:PumpWater:WaterAtThePumpUnits:LifeOnBoard:LifeOnBoardMemo:Cargo:CargoMemo:ShipAndRig:ShipAndRigMemo:Biology:BiologyMemo:WarsAndFights:WarsAndFightsMemo:Illustrations:TrivialCorrection:OtherRem:,numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:string:numeric:numeric:numeric:numeric:string:string:numeric:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:string:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:numeric:string:,weather and climate
Landslides After Rainfall 2007-2016 , NASA , www.kaggle.com/nasa/landslide-events , Thu Jan 19 2017 21:28:33 GMT+0530 (IST) , Location and cause of landslide events around the world ,299, mountains- geology- climate- ,Context Landslides are one of the most pervasive hazards in the world causing more than 11500 fatalities in 70 countries since 2007. Saturating the soil on vulnerable slopes intense and prolonged rainfall is the most frequent landslide trigger. Content The Global Landslide Catalog (GLC) was developed with the goal of identifying rainfall-triggered landslide events around the world regardless of size impacts or location. The GLC considers all types of mass movements triggered by rainfall which have been reported in the media disaster databases scientific reports or other sources. Acknowledgements The GLC has been compiled since 2007 at NASA Goddard Space Flight Center.,id:date:time:continent_code:country_name:country_code:state/province:population:city/town:distance:location_description:latitude:longitude:geolocation:hazard_type:landslide_type:landslide_size:trigger:storm_name:injuries:fatalities:source_name:source_link:,numeric:dateTime:string:string:string:string:string:numeric:string:numeric:string:numeric:numeric:string:string:string:string:string:string:string:numeric:string:string:,disasters
United States Droughts by County , United States Drought Monitor , www.kaggle.com/us-drought-monitor/united-states-droughts-by-county , Tue Nov 08 2016 06:56:20 GMT+0530 (IST) , Weekly data on extent and severity of drought in each US county (2000-present) ,493, geography- climate- ,"The United States Drought Monitor collects weekly data on drought conditions around the U.S. Acknowledgements All data was downloaded from the United States Drought Monitor webpage. The U.S. Drought Monitor is jointly produced by the National Drought Mitigation Center at the University of Nebraska-Lincoln the United States Department of Agriculture and the National Oceanic and Atmospheric Administration. Map courtesy of NDMC-UNL. The Data The data contains weekly observations about the extent and severity of drought in each county of the United States. The dataset contains the following fields  releaseDate when this data was released on the USDM website FIPS the FIPS code for this county county the county name state the state the county is in NONE percentage of the county that is not in drought D0 percentage of the county that is in abnormally dry conditions D1 percentage of the county that is in moderate drought D2 percentage of the county that is in severe drought D3 percentage of the county that is in extreme drought D4 percentage of the county that is in exceptional drought validStart the starting date of the week that these observations represent validEnd the ending date of the week that these observations represent domStatisticFormatID seems to always be 1  Note the drought categories are cumulative if an area is in D3 then it is also in D2 D1 and D0. This means that for every observation D4 <= D3 <= D2 <= D1 <= D0. County Info To make some analyses slightly easier I've also included *county_info_2016.csv* which contains physical size information about each county. This file contains the following fields  USPS     United States Postal Service State Abbreviation GEOID    FIPS code ANSICODE     American National Standards Institute code NAME     Name ALAND    Land Area (square meters) - Created for statistical purposes only AWATER   Water Area (square meters) - Created for statistical purposes only ALAND_SQMI   Land Area (square miles) - Created for statistical purposes only AWATER_SQMI  Water Area (square miles) - Created for statistical purposes only INTPTLAT     Latitude (decimal degrees) First character is blank or ""-"" denoting North or South latitude respectively INTPTLONG    Longitude (decimal degrees) First character is blank or ""-"" denoting East or West longitude respectively ",USPS:GEOID:ANSICODE:NAME:ALAND:AWATER:ALAND_SQMI:AWATER_SQMI:INTPTLAT:INTPTLONG                                                                                                               :,string:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:,disasters
Air Quality Annual Summary , US Environmental Protection Agency , www.kaggle.com/epa/air-quality , Fri Jun 30 2017 04:52:18 GMT+0530 (IST) , A summary of air quality from 1987 to 2017 ,285, environment- climate- ,Context The Environmental Protection Agency (EPA) creates air quality trends using measurements from monitors located across the country. All of this data comes from EPA’s Air Quality System (AQS). Data collection agencies report their data to the EPA via this system and it calculates several types of aggregate (summary) data for EPA internal use.  Content Field descriptions  State Code The FIPS code of the state in which the monitor resides. County Code The FIPS code of the county in which the monitor resides. Site NumA unique number within the county identifying the site. Parameter Code The AQS code corresponding to the parameter measured by the monitor. POC This is the “Parameter Occurrence Code” used to distinguish different instruments that measure the same parameter at the same site. Latitude The monitoring site’s angular distance north of the equator measured in decimal degrees. Longitude The monitoring site’s angular distance east of the prime meridian measured in decimal degrees. Datum The Datum associated with the Latitude and Longitude measures. Parameter Name The name or description assigned in AQS to the parameter measured by the monitor. Parameters may be pollutants or non-pollutants. Sample Duration The length of time that air passes through the monitoring device before it is analyzed (measured). So it represents an averaging period in the atmosphere (for example a 24-hour sample duration draws ambient air over a collection filter for 24 straight hours). For continuous monitors it can represent an averaging time of many samples (for example a 1-hour value may be the average of four one-minute samples collected during each quarter of the hour). Pollutant StandardA description of the ambient air quality standard rules used to aggregate statistics. (See description at beginning of document.) Metric Used The base metric used in the calculation of the aggregate statistics presented in the remainder of the row. For example if this is Daily Maximum then the value in the Mean column is the mean of the daily maximums. Method Name A short description of the processes equipment and protocols used in gathering and measuring the sample. Year The year the annual summary data represents. Units of Measure The unit of measure for the parameter. QAD always returns data in the standard units for the parameter. Submitters are allowed to report data in any unit and EPA converts to a standard unit so that we may use the data in calculations. Event Type Indicates whether data measured during exceptional events are included in the summary. A wildfire is an example of an exceptional event; it is something that affects air quality but the local agency has no control over. No Events means no events occurred. Events Included means events occurred and the data from them is included in the summary. Events Excluded means that events occurred but data form them is excluded from the summary. Concurred Events Excluded means that events occurred but only EPA concurred exclusions are removed from the summary. If an event occurred for the parameter in question the data will have multiple records for each monitor. Observation Count The number of observations (samples) taken during the year. Observation Percent The percent representing the number of observations taken with respect to the number scheduled to be taken during the year. This is only calculated for monitors where measurements are required (e.g. only certain parameters). Completeness Indicator An indication of whether the regulatory data completeness criteria for valid summary data have been met by the monitor for the year. Y means yes N means no or that there are no regulatory completeness criteria for the parameter. Valid Day Count The number of days during the year where the daily monitoring criteria were met if the calculation of the summaries is based on valid days. Required Day Count  The number of days during the year which the monitor was scheduled to take samples if measurements are required. Exceptional Data Count The number of data points in the annual data set affected by exceptional air quality events (things outside the norm that affect air quality). Null Data Count The count of scheduled samples when no data was collected and the reason for no data was reported. Primary Exceedance Count The number of samples during the year that exceeded the primary air quality standard. Secondary Exceedance Count The number of samples during the year that exceeded the secondary air quality standard. Certification Indicator An indication whether the completeness and accuracy of the information on the annual summary record has been certified by the submitter. Certified means the submitter has certified the data (due May 01 the year after collection). Certification not required means that the parameter does not require certification or the deadline has not yet passed. Uncertified (past due) means that certification is required but is overdue. Requested but not yet concurred means the submitter has completed the process but EPA has not yet acted to certify the data. Requested but denied means the submitter has completed the process but EPA has denied the request for cause. Was certified but data changed means the data was certified but data was replaced and the process has not been repeated. Num Obs Below MDL The number of samples reported during the year that were below the method detection limit (MDL) for the monitoring instrument. Sometimes these values are replaced by 1/2 the MDL in summary calculations. Arithmetic Mean The average (arithmetic mean) value for the year. Arithmetic Standard Dev The standard deviation about the mean of the values for the year. 1st Max Value The highest value for the year. 1st Max DateTime The date and time (on a 24-hour clock) when the highest value for the year (the previous field) was taken. 2nd Max Value The second highest value for the year. 2nd Max DateTime The date and time (on a 24-hour clock) when the second highest value for the year (the previous field) was taken. 3rd Max Value The third highest value for the year. 3rd Max DateTime The date and time (on a 24-hour clock) when the third highest value for the year (the previous field) was taken. 4th Max Value The fourth highest value for the year. 4th Max DateTime The date and time (on a 24-hour clock) when the fourth highest value for the year (the previous field) was taken. 1st Max Non Overlapping Value For 8-hour CO averages the highest value of the year. 1st NO Max DateTime The date and time (on a 24-hour clock) when the first maximum non overlapping value for the year (the previous field) was taken. 2nd Max Non Overlapping Value For 8-hour CO averages the second highest value of the year that does not share any hours with the 8-hour period of the first max non overlapping value. 2nd NO Max DateTime The date and time (on a 24-hour clock) when the second maximum non overlapping value for the year (the previous field) was taken. 99th Percentile The value from this monitor for which 99 per cent of the rest of the measured values for the year are equal to or less than. 98th Percentile The value from this monitor for which 98 per cent of the rest of the measured values for the year are equal to or less than. 95th Percentile The value from this monitor for which 95 per cent of the rest of the measured values for the year are equal to or less than. 90th Percentile The value from this monitor for which 90 per cent of the rest of the measured values for the year are equal to or less than. 75th Percentile The value from this monitor for which 75 per cent of the rest of the measured values for the year are equal to or less than. 50th Percentile The value from this monitor for which 50 per cent of the rest of the measured values for the year are equal to or less than (i.e. the median). 10th Percentile The value from this monitor for which 10 per cent of the rest of the measured values for the year are equal to or less than. Local Site Name The name of the site (if any) given by the State local or tribal air pollution control agency that operates it. Address The approximate street address of the monitoring site. State Name The name of the state where the monitoring site is located. County Name The name of the county where the monitoring site is located. City Name The name of the city where the monitoring site is located. This represents the legal incorporated boundaries of cities and not urban areas. CBSA Name The name of the core bases statistical area (metropolitan area) where the monitoring site is located. Date of Last Change The date the last time any numeric values in this record were updated in the AQS data system.  Acknowledgements These data come from the EPA. You can use Kernels to analyze share and discuss this data on Kaggle but if you’re looking for real-time updates and bigger data check out the data on Google BigQuery too https//cloud.google.com/bigquery/public-data/epa Inspiration Within these data are tons of ways for you to learn about air pollution and how it can affect our health and environment. You can also compare key air emissions to gross domestic product vehicle miles traveled population and energy consumption back to 1970. Best of all you can check out air trends where you live!,state_code:county_code:site_num:parameter_code:poc:latitude:longitude:datum:parameter_name:sample_duration:pollutant_standard:metric_used:method_name:year:units_of_measure:event_type:observation_count:observation_percent:completeness_indicator:valid_day_count:required_day_count:exceptional_data_count:null_data_count:primary_exceedance_count:secondary_exceedance_count:certification_indicator:num_obs_below_mdl:arithmetic_mean:arithmetic_standard_dev:first_max_value:first_max_datetime:second_max_value:second_max_datetime:third_max_value:third_max_datetime:fourth_max_value:fourth_max_datetime:first_max_non_overlapping_value:first_no_max_datetime:second_max_non_overlapping_value:second_no_max_datetime:ninety_nine_percentile:ninety_eight_percentile:ninety_five_percentile:ninety_percentile:seventy_five_percentile:fifty_percentile:ten_percentile:local_site_name:address:state_name:county_name:city_name:cbsa_name:date_of_last_change:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:numeric:string:string:numeric:numeric:string:numeric:numeric:numeric:numeric:string:numeric:string:numeric:numeric:numeric:numeric:dateTime:numeric:dateTime:numeric:dateTime:numeric:dateTime:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:dateTime:,air pollution
Carbon Dioxide Levels in Atmosphere , UC San Diego , www.kaggle.com/ucsandiego/carbon-dioxide , Fri Mar 10 2017 21:11:10 GMT+0530 (IST) , Atmospheric carbon dioxide data from Mauna Loa Observatory since 1958 ,476, environment- climate- ,Context The carbon dioxide record from Mauna Loa Observatory known as the “Keeling Curve” is the world’s longest unbroken record of atmospheric carbon dioxide concentrations. Scientists make atmospheric measurements in remote locations to sample air that is representative of a large volume of Earth’s atmosphere and relatively free from local influences. Content This dataset includes a monthly observation of atmospheric carbon dioxide (or CO2) concentrations from the Mauna Loa Observatory (Hawaii) at a latitude of 19.5 longitude of -155.6 and elevation of 3397 meters.   Columns 1-3 Provide the date in the following redundant formats year month and decimal date Column 4 Monthly CO2 concentrations in parts per million (ppm) measured on the 08A calibration scale and collected at 2400 hours on the fifteenth of each month. Column 5 The fifth column provides the same data after a seasonal adjustment which involves subtracting from the data a 4-harmonic fit with a linear gain factor to remove the seasonal cycle from carbon dioxide measurements Column 6 The sixth column provides the data with noise removed generated from a stiff cubic spline function plus 4-harmonic functions with linear gain Column 7 The seventh column is the same data with the seasonal cycle removed.  Acknowledgements The carbon dioxide data was collected and published by the University of California's Scripps Institution of Oceanography under the supervision of Charles David Keeling with support from the US Department of Energy Earth Networks and the National Science Foundation. Inspiration How have atmospheric carbon dioxide levels changed in the past sixty years? How do carbon dioxide concentrations change seasonally? What do you think causes this seasonal cycle? When will the carbon dioxide levels exceed 450 parts per million?,Year:Month:Decimal Date:Carbon Dioxide (ppm):Seasonally Adjusted CO2 (ppm):Carbon Dioxide Fit (ppm):Seasonally Adjusted CO2 Fit (ppm):,numeric:numeric:numeric:numeric:numeric:numeric:numeric:,air pollution
MRI and Alzheimers , Jacob Boysen , www.kaggle.com/jboysen/mri-and-alzheimers , Wed Aug 16 2017 22:48:10 GMT+0530 (IST) , Magnetic Resonance Imaging Comparisons of Demented and Nondemented Adults ,306, ,Context The Open Access Series of Imaging Studies (OASIS) is a project aimed at making MRI data sets of the brain freely available to the scientific community. By compiling and freely distributing MRI data sets we hope to facilitate future discoveries in basic and clinical neuroscience. OASIS is made available by the Washington University Alzheimer’s Disease Research Center Dr. Randy Buckner at the Howard Hughes Medical Institute (HHMI)( at Harvard University the Neuroinformatics Research Group (NRG) at Washington University School of Medicine and the Biomedical Informatics Research Network (BIRN). Content  Cross-sectional MRI Data in Young Middle Aged Nondemented and Demented Older Adults This set consists of a cross-sectional collection of 416 subjects aged 18 to 96.  For each subject 3 or 4 individual T1-weighted MRI scans obtained in single scan sessions are included.  The subjects are all right-handed and include both men and women.  100 of the included subjects over the age of 60 have been clinically diagnosed with very mild to moderate Alzheimer’s disease (AD).  Additionally a reliability data set is included containing 20 nondemented subjects imaged on a subsequent visit within 90 days of their initial session. Longitudinal MRI Data in Nondemented and Demented Older Adults  This set consists of a longitudinal collection of 150 subjects aged 60 to 96. Each subject was scanned on two or more visits separated by at least one year for a total of 373 imaging sessions. For each subject 3 or 4 individual T1-weighted MRI scans obtained in single scan sessions are included. The subjects are all right-handed and include both men and women. 72 of the subjects were characterized as nondemented throughout the study. 64 of the included subjects were characterized as demented at the time of their initial visits and remained so for subsequent scans including 51 individuals with mild to moderate Alzheimer’s disease. Another 14 subjects were characterized as nondemented at the time of their initial visit and were subsequently characterized as demented at a later visit.  Acknowledgements When publishing findings that benefit from OASIS data please include the following grant numbers in the acknowledgements section and in the associated Pubmed Central submission P50 AG05681 P01 AG03991 R01 AG021910 P20 MH071616 U24 RR0213 Inspiration Can you predict dementia? Alzheimer’s?,ID:M/F:Hand:Age:Educ:SES:MMSE:CDR:eTIV:nWBV:ASF:Delay:,string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:,diagnostics
Master's Degrees  Programs (mastersportal.eu) , Anas Aboureada , www.kaggle.com/anasfullstack/mastersportal-programs , Mon Oct 02 2017 12:41:05 GMT+0530 (IST) , Discovering thousands of Master's degrees worldwide! ,194, universities and colleges- education- ,Context I was searching for a master degree program in data-science when I found this awesome website mastersportal So I just scrapped it to take my time analysing all master programs available around the world. Content This dataset contains 60442 different master's degree programs from 99 countries around the world.,country_name:country_code:university_name:university_rank:program_name:program_type:deadline:duration:language:tution_1_currency:tution_1_money:tution_1_type:tution_2_currency:tution_2_money:tution_2_type:tuition_price_specification:start_date:ielts_score:structure:academic_req:facts:city:program_url:,string:string:string:string:string:string:dateTime:string:string:string:numeric:string:string:numeric:string:string:dateTime:numeric:string:string:string:string:string:,universities and colleges
Human Development Report 2015 , United Nations Development Program , www.kaggle.com/undp/human-development , Wed Jan 25 2017 20:30:59 GMT+0530 (IST) , Countries ranked by human development gender inequality and poverty ,1225, demographics- international relations- ,Content The Human Development Index (HDI) is a summary measure of achievements in key dimensions of human development a long and healthy life access to knowledge and a decent standard of living. The HDI is the geometric mean of normalized indices for each of the three dimensions. The health dimension is assessed by life expectancy at birth the education dimension is measured by mean of years of education for adults aged 25 years and more and expected years of education for children and the standard of living dimension is measured by gross national income per capita. The Inequality-Adjusted Human Development Index (IHDI) adjusts the HDI for inequality in the distribution of each dimension across the population. The Gender Development Index (GDI) measures gender inequalities in achievement in three basic dimensions of human development health measured by female and male life expectancy at birth; education measured by female and male expected years of education for children and female and male mean years of education for adults ages 25 and older; and command over economic resources measured by female and male estimated earned income. The Gender Inequality Index (GII) reflects gender-based disadvantage in three dimensions—reproductive health empowerment and the labour market—for as many countries as data of reasonable quality allow. It shows the loss in potential human development due to inequality between female and male achievements in these dimensions. The Multidimensional Poverty Index (MPI) identifies multiple deprivations at the household level in education health and standard of living as indicators of poverty. It uses micro data from household surveys and — unlike the IHDI — all the indicators needed to construct the measure must come from the same survey.,GDI Rank:Country:Gender Development Index (GDI):Human Development Index (Female):Human Development Index (Male):Life Expectancy at Birth (Female):Life Expectancy at Birth (Male):Expected Years of Education (Female):Expected Years of Education (Male):Mean Years of Education (Female):Mean Years of Education (Male):Estimated Gross National Income per Capita (Female):Estimated Gross National Income per Capita (Male):,numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,demography
Sample Insurance Portfolio , SachGupta , www.kaggle.com/sachgupta/sample-insurance-portfolio , Wed May 24 2017 05:47:33 GMT+0530 (IST) , The sample insurance file contains 36634 records in Florida for 2012 ,301, finance- ,Context  Aggregate and visualize data how you want—from tabular to graphical and geographic forms—for more profitable underwriting. Perform sophisticated multi-dimensional analysis to supply any data combination and permutation. Respond to claims quickly and improve customer satisfaction with real-time and historical access to catastrophe and hazard data  Content The sample insurance file contains 36634 records in Florida for 2012 from a sample company that implemented an agressive growth plan in 2012.  There are total insured value (TIV) columns containing TIV from 2011 and 2012 so this dataset is great for testing out the comparison feature.  This file has address information that you can choose to geocode or you can use the existing latitude/longitude in the file.,policyID:statecode:county:eq_site_limit:hu_site_limit:fl_site_limit:fr_site_limit:tiv_2011:tiv_2012:eq_site_deductible:hu_site_deductible:fl_site_deductible:fr_site_deductible:point_latitude:point_longitude:line:construction:point_granularity:,numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:numeric:,geographical information
Deadly traffic accidents in the UK (2015) , Karolina Wullum , www.kaggle.com/kwullum/deadly-traffic-accidents-in-the-uk-2015 , Mon Sep 18 2017 19:23:03 GMT+0530 (IST) ,  ,76, road transport- ,The dataset is taken from data.gov.uk and contains all traffic-related deaths in the UK in 2015. Source https//data.gov.uk/dataset/road-accidents-safety-data/resource/ceb00cff-443d-4d43-b17a-ee13437e9564,Accident_Index:Location_Easting_OSGR:Location_Northing_OSGR:Longitude:Latitude:Police_Force:Accident_Severity:Number_of_Vehicles:Number_of_Casualties:Date:Day_of_Week:Time:Local_Authority_(District):Local_Authority_(Highway):1st_Road_Class:1st_Road_Number:Road_Type:Speed_limit:Junction_Detail:Junction_Control:2nd_Road_Class:2nd_Road_Number:Pedestrian_Crossing-Human_Control:Pedestrian_Crossing-Physical_Facilities:Light_Conditions:Weather_Conditions:Road_Surface_Conditions:Special_Conditions_at_Site:Carriageway_Hazards:Urban_or_Rural_Area:Did_Police_Officer_Attend_Scene_of_Accident:LSOA_of_Accident_Location:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:dateTime:numeric:dateTime:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:,accidents
Death Metal , zjf , www.kaggle.com/zhangjuefei/death-metal , Fri Jan 13 2017 04:23:43 GMT+0530 (IST) , Death metal bands and albums ,376, music- ,"Context Metal-Archives.com (MA for short) is an encyclopedia website which includes information of nearly all heavy bands and albums on the earth. This information is collected and submitted by metalheads from all around the world. This dataset includes all ""death metal"" bands and albums on MA (by Nov. 2016). It's the search result by genre key word ""death metal""  which includes all bands which  contain phrase ""death metal"" in their genre. (e.g. ""technical death metal"" ""brutal death metal"" ""melodic death metal"" ... ) The banner of dataset is the cover art of New Jersey-based death metal band Disma's debut full-length album ""Towards the Megalith"" (2011 Profound Lore Records). It's beautiful but not quite typical for this dataset's theme. But 1900+ resolution picture about death metal is rare so I've chosen this one. Content There are three csv files included in the dataset bands.csv contains 37723 bands. Each record is consisted of 8 fields   id sequential integer id.  name the band's name which can contains non-english character punctuations numbers and other weird characters. country country the band is from. ""International""  means the members of the band are from multiple countries. status band's current activity-status 'Unknown' 'Split-up' 'Active' 'Changed name' 'On hold' and 'Disputed'. from_in the year in which the band formed. genre the description of the band's genre. It's irregular so you'd better not deem it as category but short text. theme the description of the band's lyric theme.  active the time-span in which the band is active.  albums.csv contains 28069 albums. Each record is consisted of 4 fields  id sequential integer id.  band foreign key to band's id in bands.csv. title album title. year the album's release year.  reviews.csv  contains 21510 reviews. Each record is consisted of 5 fields  id sequential integer id.  album foreign key to album's id in albums.csv. title the review's title. score the score for that album. Float number from 0.0 to 1.0 (from negative to positive).  content the review's text.  Notice  This dataset only contains full-length studio albums (excluding EPs singles live albums split albums and others). All commas in dataset are replaced by ""|"" to make comma available for fields separator.  NA value is ""N/A"".  All text is in utf-8 encoding.  Acknowledgements Metal-Archives! \m/ Inspiration  Statistical analysis Emotional analysis (reviews) Genre classification (by NLP of title and/or theme) Score prediction (by NLP of review's content) ",id:band:title:year:,numeric:numeric:string:numeric:,text analysis
Canadian Disaster Database , criticalhits , www.kaggle.com/criticalhits/canadian-disaster-database , Sat Sep 30 2017 02:46:38 GMT+0530 (IST) , Over 1000 Disasters Affecting Canadians At-Home or Abroad Since 1900 ,76, north america- time series- geography- ,"Context The Canadian Disaster Database The Canadian Disaster Database (CDD) contains detailed disaster information on more than 1000 natural technological and conflict events (excluding war) that have happened since 1900 at home or abroad and that have directly affected Canadians.  Content Data description copied from https//www.publicsafety.gc.ca/cnt/rsrcs/cndn-dsstr-dtbs/index-en.aspx Dataset date range 1900 - present The CDD tracks ""significant disaster events"" which conform to the Emergency Management Framework for Canada definition of a ""disaster"" and meet one or more of the following criteria  10 or more people killed   100 or more people affected/injured/infected/evacuated or homeless   an appeal for national/international assistance   historical significance   significant damage/interruption of normal processes such that the community affected cannot recover on its own    The database describes where and when a disaster occurred the number of injuries evacuations and fatalities as well as a rough estimate of the costs.  As much as possible the CDD contains primary data that is valid current and supported by reliable and traceable sources including federal institutions provincial/territorial governments non-governmental organizations and media sources.   Data is updated and reviewed on a semi-annual basis. Data Field Description      Disaster Type The type of disaster (e.g. flood earthquake etc.) that occurred.  Date of Event The date a specific event took place.  Specific Location The city town or region where a specific event took place.  Description of Event A brief description of a specific event including pertinent details that may not be captured in other data fields (e.g. amount of precipitation temperatures neighbourhoods etc.)  Fatalities The number of people killed due to a specific event.  Injured/Infected The number of people injured or infected due to a specific event.  Evacuees The number of individuals evacuated by the government of Canada due to a specific event.  Latitude & Longitude The exact geographic location of a specific event.  Province/Territory The province or territory where a specific event took place.  Estimated Total Cost A roll-up of all the costs listed within the financial data fields for a specific event.  DFAA Payments The amount in dollars paid out by Disaster Financial Assistance Arrangements (Public Safety Canada) due to a specific event.  Insurance Payments The amount in dollars paid out by insurance companies due to a specific event.  Provincial/Territorial Costs/Payments The amount in dollars paid out by a Province or Territory due to a specific event.  Utility Costs/Losses The amount of people whose utility services (power water etc.) were interrupted/affected by a specific event.  Magnitude A measure of the size of an earthquake related to the amount of energy released.  Other Federal Institution Costs The amount in dollars paid out by other federal institutions.     Acknowledgements Data gathered from http//cdd.publicsafety.gc.ca Terms of use for commercial and non-comerical reproduction https//www.publicsafety.gc.ca/cnt/ntcs/trms-en.aspx Inspiration This dataset provides valuable insight to natural and non-natrual disasters which have affected Canada.  Possible explorations * Where do different types of disasters occur more frequently?  * Which Province / Location in Canada has been hit the hardest in terms of fatalities number of injuries estimated total cost etc.? Spatial-temporal correlations between natural/artifical distasters *  I think that this can be used to produce some interesting data visualizations. Some of the questions I look forward to answering include  Can any spatial-temporal correlations between disasters be found in this dataset? Which locations in Canada have been hit the hardest in terms of people injured fatalities financial impact etc. ",EVENT CATEGORY,EVENT GROUP,disasters
Spotify's Worldwide Daily Song Ranking , Eduardo , www.kaggle.com/edumucelli/spotifys-worldwide-daily-song-ranking , Mon Aug 21 2017 01:32:54 GMT+0530 (IST) , The 200 daily most streamed songs in 53 countries ,386, music- ,"Context Music streaming is ubiquitous. Currently Spotify plays an important part on that. This dataset enable us to explore how artists and songs' popularity varies in time. Content This dataset contains the daily ranking of the 200 most listened songs in 53 countries from 2017 by Spotify users. It contains more than 2 million rows which comprises 4682 artists 11932 songs for a total count of one hundred five billion streams count. The data spans from 1st January 2017 to 17th August 2017 and will be kept up-to-date on following versions. It has been collected from Spotify's regional chart data. Inspiration  Can you predict what is the rank position or the number of streams a song will have in the future? How long does songs ""resist"" on the top 3 5 10 20 ranking? What are the signs of a song that gets into the top rank to stay? Do continents share same top ranking artists or songs? Are people listening to the very same top ranking songs on countries far away from each other? How long time does a top ranking song takes to get into the ranking of neighbor countries?  Example To start out you can take a look into a simple Kernel I have made in order to read the data filter data from a song plot is temporal tendency per country than make a simple forecast of the its streams count here. Crawler The crawler used to collect this data can be found here.",Position:Track Name:Artist:Streams:URL:Date:Region:,numeric:string:string:numeric:string:dateTime:string:,music
Forest Cover Type Dataset , UCI Machine Learning , www.kaggle.com/uciml/forest-cover-type-dataset , Thu Nov 03 2016 10:52:44 GMT+0530 (IST) , Tree types found in the Roosevelt National Forest in Colorado ,994, plants- ,Context This dataset contains tree observations from four areas of the Roosevelt National Forest in Colorado. All observations are cartographic variables (no remote sensing) from 30 meter x 30 meter sections.  Content There are seven tree types each represented by an integer variable 1 - Spruce/Fir  2 - Lodgepole Pine  3 - Ponderosa Pine  4 - Cottonwood/Willow  5 - Aspen  6 - Douglas-fir  7 - Krummholz   Remaining data fields include Elevation Elevation in meters  Aspect Aspect in degrees azimuth  Slope Slope in degrees  Horizontal Distance To Hydrology Horz Dist to nearest surface water features Vertical Distance To Hydrology  Vert Dist to nearest surface water features  Horizontal Distance To Roadways Horz Dist to nearest roadway  Hillshade 9am (0 to 255 index) Hillshade index at 9am summer solstice  Hillshade Noon (0 to 255 index) Hillshade index at noon summer solstice  Hillshade 3pm (0 to 255 index) Hillshade index at 3pm summer solstice  Horizontal Distance To Fire Points Horz Dist to nearest wildfire ignition points  Wilderness Area (4 binary columns 0 = absence or 1 = presence) Wilderness area designation  Soil Type (40 binary columns 0 = absence or 1 = presence) Soil Type designation  Cover Type (7 types integers 1 to 7) Forest Cover Type designation   The wilderness areas are 1 - Rawah Wilderness Area  2 - Neota Wilderness Area  3 - Comanche Peak Wilderness Area  4 - Cache la Poudre Wilderness Area   The soil types are 1 Cathedral family - Rock outcrop complex extremely stony  2 Vanet - Ratake families complex very stony  3 Haploborolis - Rock outcrop complex rubbly  4 Ratake family - Rock outcrop complex rubbly  5 Vanet family - Rock outcrop complex complex rubbly  6 Vanet - Wetmore families - Rock outcrop complex stony  7 Gothic family  8 Supervisor - Limber families complex  9 Troutville family very stony  10 Bullwark - Catamount families - Rock outcrop complex rubbly  11 Bullwark - Catamount families - Rock land complex rubbly. 12 Legault family - Rock land complex stony  13 Catamount family - Rock land - Bullwark family complex rubbly  14 Pachic Argiborolis - Aquolis complex  15 unspecified in the USFS Soil and ELU Survey  16 Cryaquolis - Cryoborolis complex  17 Gateview family - Cryaquolis complex  18 Rogert family very stony  19 Typic Cryaquolis - Borohemists complex  20 Typic Cryaquepts - Typic Cryaquolls complex  21 Typic Cryaquolls - Leighcan family till substratum complex  22 Leighcan family till substratum extremely bouldery  23 Leighcan family till substratum - Typic Cryaquolls complex  24 Leighcan family extremely stony  25 Leighcan family warm extremely stony  26 Granile - Catamount families complex very stony  27 Leighcan family warm - Rock outcrop complex extremely stony  28 Leighcan family - Rock outcrop complex extremely stony  29 Como - Legault families complex extremely stony  30 Como family - Rock land - Legault family complex extremely stony  31 Leighcan - Catamount families complex extremely stony  32 Catamount family - Rock outcrop - Leighcan family complex extremely stony  33 Leighcan - Catamount families - Rock outcrop complex extremely stony  34 Cryorthents - Rock land complex extremely stony  35 Cryumbrepts - Rock outcrop - Cryaquepts complex  36 Bross family - Rock land - Cryumbrepts complex extremely stony  37 Rock outcrop - Cryumbrepts - Cryorthents complex extremely stony  38 Leighcan - Moran families - Cryaquolls complex extremely stony  39 Moran family - Cryorthents - Leighcan family complex extremely stony  40 Moran family - Cryorthents - Rock land complex extremely stony Acknowledgement This dataset is part of the UCI Machine Learning Repository and the original source can be found here. The original database owners are Jock A. Blackard Dr. Denis J. Dean and Dr. Charles W. Anderson of the Remote Sensing and GIS Program at Colorado State University.  Inspiration  Can you build a model that predicts what types of trees grow in an area based on the surrounding characteristics? A past Kaggle competition project on this topic can be found here. What kinds of trees are most common in the Roosevelt National Forest? Which tree types can grow in more diverse environments? Are there certain tree types that are sensitive to an environmental factor such as elevation or soil type? ,,,botanical
Tobacco Use and Mortality 2004-2015 , National Health Service , www.kaggle.com/nhs/tobacco-use , Wed Jan 18 2017 18:35:17 GMT+0530 (IST) , Hospital admissions prescriptions and fatalities in England ,902, human medicine- ,Context Conditions that could be caused by smoking resulted in 1.7 million admissions to hospitals in England for adults aged 35 and over in 2014-2015 -- an average of 4700 admissions per day! These figures refer to admissions with a primary diagnosis of a disease that can be caused by smoking but for which smoking may or may not have actually been the cause. Content The Statistics on Smoking in England report aims to present a broad picture of health issues relating to smoking in England and covers topics such as smoking prevalence habits behaviours and attitudes smoking-related health issues and mortality and associated costs.  Acknowledgements This report contains data and information previously published by the Health and Social Care Information Centre (HSCIC) Department of Health the Office for National Statistics and Her Majesty’s Revenue and Customs.,Year:,string:,drugs and addiction
Tweets Targeting Isis , ActiveGalaXy , www.kaggle.com/activegalaxy/isis-related-tweets , Sat Jul 30 2016 05:29:27 GMT+0530 (IST) , General tweets about Isis & related words ,888, crime- internet- ,"Context The image at the top of the page is a frame from today's (7/26/2016) Isis #TweetMovie from twitter a ""normal"" day when two Isis operatives murdered a priest saying mass in a French church. (You can see this in the center left).  A selection of data from this site is being made available here to Kaggle users.   UPDATE An excellent study by Audrey Alexander titled Digital Decay? is now available which traces the ""change over time among English-language Islamic State sympathizers on Twitter. Intent This data set is intended to be a counterpoise to the How Isis Uses Twitter data set.  That data set contains 17k tweets alleged to originate with ""100+ pro-ISIS fanboys"".  This new set contains 122k tweets collected on two separate days 7/4/2016 and 7/11/2016 which contained any of the following terms with no further editing or selection  isis  isil  daesh  islamicstate  raqqa  Mosul ""islamic state""  This is not a perfect counterpoise as it almost surely contains a small number of pro-Isis fanboy tweets.  However unless some entity such as Kaggle is willing to expend significant resources on a service something like an expert level Mechanical Turk or Zooniverse a high quality counterpoise is out of reach.   A counterpoise provides a balance or backdrop against which to measure a primary object in this case the original pro-Isis data. So if anyone wants to discriminate between pro-Isis tweets and other tweets concerning Isis you will need to model the original pro-Isis data or signal against the counterpoise which is  signal + noise.  Further background and some analysis can be found in this forum thread. This data comes from postmodernnews.com/token-tv.aspx which daily collects about 25MB of Isis tweets for the purposes of graphical display. PLEASE NOTE This server is not currently active. Data Details There are several differences between the format of this data set and the pro-ISIS fanboy dataset.  1. All the twitter t.co tags have been expanded where possible  2. There are no ""description location followers numberstatuses"" data columns.    I have also included my version of the original pro-ISIS fanboy set.  This version has all the t.co links expanded where possible. ",,,social media
Human Resources Data Set , Dr. Rich , www.kaggle.com/rhuebner/human-resources-data-set , Sun Jul 23 2017 23:48:22 GMT+0530 (IST) , Dataset used for learning data visualization and basic regression ,898, employment- business- ,Context HR data can be hard to come by and HR professionals generally lag behind with respect to analytics and data visualization competency. Thus Dr. Carla Patalano and I set out to create our own HR-related dataset which is used in one of our graduate MSHRM courses called HR Metrics and Analytics at New England College of Business. We created this data set ourselves. Content There are multiple worksheets within the Excel workbook. These include  Core data set Production staff Sales analysis Salaries Recruiting sources  The Excel workbook revolves around a fictitious company called Dental Magic and the core data set contains names DOBs age gender marital status date of hire reasons for termination department whether they are active or terminated position title pay rate manager name and performance score. Acknowledgements Dr. Carla Patalano provided many suggestions for creating this synthetic data set which has been used now by over 30 Human Resource Management students at the college. Students in the course learn data visualization techniques with Tableau Desktop and use this data set to complete a series of assignments. Inspiration  Is there any relationship between who a person works for and their performance score? What is the overall diversity profile of the organization? What are our best recruiting sources if we want to ensure a diverse organization?  There are so many other interesting questions that could be addressed through this interesting data set. Dr. Patalano and I look forward to seeing what we can come up with.,Employee Name:Employee Number:State:Zip:DOB:Age:Sex:MaritalDesc:CitizenDesc:Hispanic/Latino:RaceDesc:Date of Hire:Date of Termination:Reason For Term:Employment Status:Department:Position:Pay Rate:Manager Name:Employee Source:Performance Score:,string:numeric:string:numeric:dateTime:numeric:string:string:string:string:string:dateTime:dateTime:string:string:string:string:numeric:string:string:string:,trade and business
Good Morning Tweets , Rob Harrand , www.kaggle.com/tentotheminus9/good-morning-tweets , Fri Dec 09 2016 21:54:24 GMT+0530 (IST) , Tweets captured over ~24 hours with the text 'good morning' in them ,312, linguistics- sociology- internet- ,"Context It's possible using R (and no doubt Python) to 'listen' to Twitter and capture tweets that match a certain description. I decided to test this out by grabbing tweets with the text 'good morning' in them over a 24 hours period to see if you could see the world waking up from the location information and time-stamp. The main R package used was streamR Content The tweets have been tidied up quite a bit. First I've removed re-tweets second I've removed duplicates (not sure why Twitter gave me them in the first place) third I've made sure the tweet contained the words 'good morning' (some tweets were returned that didn't have the text in for some reason) and fourth I've removed all the tweets that didn't have a longitude and latitude included. This latter step removed the vast majority. What's left are various aspects of just under 5000 tweets. The columns are  text   retweet_count  favorited  truncated  id_str     in_reply_to_screen_name    source     retweeted  created_at     in_reply_to_status_id_str  in_reply_to_user_id_str    lang   listed_count   verified   location   user_id_str    description    geo_enabled    user_created_at    statuses_count     followers_count favourites_count   protected  user_url   name   time_zone  user_lang  utc_offset     friends_count  screen_name    country_code   country    place_type     full_name  place_name     place_id   place_lat  place_lon  lat    lon    expanded_url   url  Acknowledgements I used a few blog posts to get the code up and running including this one Code The R code I used to get the tweets is as follows (note I haven't includes the code to set up the connection to Twitter. See the streamR PFD and the link above for that. You need a Twitter account) i = 1  while (i <= 280) {  filterStream(""tw_gm.json"" timeout = 300 oauth = my_oauth track = 'good morning' language = 'en') tweets_gm = parseTweets(""tw_gm.json"")  ex = grepl('RT' tweets_gm$text ignore.case = FALSE) #Remove the RTs tweets_gm = tweets_gm[!ex]  ex = grepl('good morning' tweets_gm$text ignore.case = TRUE) #Remove anything without good morning in the main tweet text tweets_gm = tweets_gm[ex]  ex = is.na(tweets_gm$place_lat) #Remove any with missing place_latitude information tweets_gm = tweets_gm[!ex]  tweets.all = rbind(tweets.all tweets_gm) #Add to the collection  i=i+1  Sys.sleep(5)  } ",:text:retweet_count:favorited:truncated:id_str:in_reply_to_screen_name:source:retweeted:created_at:in_reply_to_status_id_str:in_reply_to_user_id_str:lang:listed_count:verified:location:user_id_str:description:geo_enabled:user_created_at:statuses_count:followers_count:favourites_count:protected:user_url:name:time_zone:user_lang:utc_offset:friends_count:screen_name:country_code:country:place_type:full_name:place_name:place_id:place_lat:place_lon:lat:lon:expanded_url:url:,numeric:string:numeric:boolean:boolean:numeric:string:string:boolean:string:numeric:numeric:string:numeric:boolean:string:numeric:string:boolean:string:numeric:numeric:numeric:boolean:string:string:string:string:numeric:numeric:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:string:string:,social media
Average SAT Scores for NYC Public Schools , NYC Open Data , www.kaggle.com/nycopendata/high-schools , Tue Mar 07 2017 23:40:07 GMT+0530 (IST) , Name location enrollment and scores for 2014-2015 school year ,438, education- ,Content This dataset consists of a row for every accredited high school in New York City with its department ID number school name borough building code street address latitude/longitude coordinates phone number start and end times student enrollment with race breakdown and average scores on each SAT test section for the 2014-2015 school year. Acknowledgements The high school data was compiled and published by the New York City Department of Education and the SAT score averages and testing rates were provided by the College Board. Inspiration Which public high school's students received the highest overall SAT score? Highest score for each section? Which borough has the highest performing schools? Do schools with lower student enrollment perform better?,School ID:School Name:Borough:Building Code:Street Address:City:State:Zip Code:Latitude:Longitude:Phone Number:Start Time:End Time:Student Enrollment:Percent White:Percent Black:Percent Hispanic:Percent Asian:Average Score (SAT Math):Average Score (SAT Reading):Average Score (SAT Writing):Percent Tested:,string:string:string:string:string:string:string:numeric:numeric:numeric:string:dateTime:dateTime:numeric:string:string:string:string:numeric:numeric:numeric:string:,student performances
2015 Global Open Data Index , Open Knowledge International , www.kaggle.com/okfn/open-data , Fri Mar 03 2017 22:50:30 GMT+0530 (IST) , What is the state of open data around the world? ,207, research- data analysis- data- ,Context The Global Open Data Index is an annual effort to measure the state of open government data around the world. The crowdsourced survey is designed to assess the openness of specific government datasets according to the Open Definition. The Global Open Data Index is not an official government representation of the open data offering in each country but an independent assessment from a citizen’s perspective. It is a civil society audit of open data and it enables government progress on open data by giving them a measurement tool and a baseline for discussion and analysis of the open data ecosystem in their country and internationally from a key user’s perspective. The Global Open Data Index plays a powerful role in sustaining momentum for open data around the world and in convening civil society networks to use and collaborate around this data. Governments and open data practitioners can review the index results to see how accessible the open data they publish actually appears to their citizens see where improvements are necessary to make open data truly open and useful and track their progress year to year. According to the common open data assessment framework there are four different ways to evaluate data openess — context data use and impact. The Global Open Data Index is intentionally narrowly focused on the data aspect hence limiting its inquiry only to the datasets publication by national governments. It does not look at the broader societal context seek to assess use or impact in a systematic way or evaluate the quality of the data. This narrow focus of data publication enables it to provide a standardized robust comparable assessment of the state of the publication of key data by governments around the world. Acknowledgements The Global Open Data Index is compiled by Open Knowledge International with the assistance of volunteers from the Open Knowledge Network around the world. Inspiration What is the state of open data around the world? Which countries or regions score the highest in all the data categories? Did any countries receive lower open data scores than in previous years?,Country Code:Country Name:2015 Rank:2015 Score:2014 Rank:2014 Score:2013 Rank:2013 Score:,string:string:numeric:numeric:numeric:numeric:numeric:numeric:,politics
Linux Operating System Code Commits , Chase Willden , www.kaggle.com/chasewillden/linuxcommits , Wed Mar 08 2017 22:20:27 GMT+0530 (IST) , The public code committed for the Operating System of Linux ,78, computing and society- programming- ,Context I pulled data from the Github Repo for linux. https//github.com/torvalds/linux. This is looking at the source code committed by the public for the Linux Operating System. Content The content contains 6 columns  - Date The date of the code commit  - Commits The total number of commits on that day by that user  - Additions The total additions made to the code. Essentially added characters  - Deletions The total deletions made to the code.  - UserId The unique user who pushed the commit.  - StartOfWeek I don't completely know. Acknowledgements GitHub and Linux,Date:commits:additions:deletions:userid:startofweek:,dateTime:numeric:numeric:numeric:numeric:numeric:,programming
Elevation Data meets SF Fire Department Calls , BillurEngin , www.kaggle.com/bengin/SanFranciscoFireDepartmentCalls , Mon Jan 09 2017 11:57:49 GMT+0530 (IST) , Do the fires climb? Do fire fighters only fight fire? ,86, firefighting- ,"Context This dataset is generated via merging ""San Francisco Fire Department Calls"" and ""San Francisco Elevation Data"". Fire Calls-For-Service includes all fire units responses to calls. Each record includes the call number neighborhood location unit type call type and all relevant time intervals are also included.  Content  Call Type  Type of call the incident falls into. Call Final Disposition Disposition of the call (Code). For example TH2 Transport to Hospital - Code 2 FIR Resolved by Fire Department Unit Type Unit type Received DtTm Date and time of call is received at the 911 Dispatch Center. Response DtTm Date and time this unit acknowledges the dispatch and records that the unit is en route to the location of the call. On Scene DtTm Date and time the unit records arriving to the location of the incident Call Type Group Call types are divided into four main groups Fire Alarm Potential Life Threatening and Non Life Threatening. Neighborhood  District Neighborhood District associated with this address boundaries available here Location Latitude and longitude of address obfuscated either to the midblock intersection or call box ElevationElevation in meters  Acknowledgements San Francisco Fire Department calls are downloaded from SFOpen webpage. San Francisco DEM (Digital elevation models) file is obtained from National Centers for Environmental Information web page* *Carignan K.S. L.A. Taylor B.W. Eakins R.J. Caldwell D.Z. Friday P.R. Grothe and E. Lim 2011. Digital Elevation Models of Central California and San Francisco Bay Procedures Data Sources and Analysis NOAA Technical Memorandum NESDIS NGDC-52 U.S. Dept. of Commerce Boulder CO 49 pp. Inspiration  Do fire fighters only fight fire?  There is a wide range of calls directed to FD what is the leading cause? How often do firefighters actually fight a fire on a given day/week? How fast do they respond to calls? Does the elevation lag the response?  Are there special times/months where they receive more or less calls?   Is there a relationship between the elevation and the rate or type of calls? ",Call Type:Call Final Disposition:Unit Type:Received DtTm:Response DtTm:On Scene DtTm:Call Type Group:Neighborhood  District:Location:elevation:,string:string:string:dateTime:dateTime:dateTime:string:string:string:numeric:,accidents
Nursing Home Compare , Medicare , www.kaggle.com/medicare/nursing-home-compare , Mon Nov 28 2016 09:15:13 GMT+0530 (IST) , Comparing the quality of care of over 15000 nursing homes in the U.S. ,234, healthcare- geriatrics- ,Context This official dataset from the Medicare.gov Nursing Home Compare website allows for comparison of over 15000 Medicare and Medicaid-certified nursing homes in the country. Content Separate data collections include  Deficiencies including fire safety health and inspection cycle types Ownership details including ownership percentage Penalties including filing date fee and payment date Provider details including non or for profit status staff ratings and survey scores Quality MSR (Minimum Savings Rate) claims including adjusted and observed scores MDS (Minimum Data Set) quality measures scored on a quarterly basis State averages including total number of quarterly deficiencies and nurse staffing hours Survey summaries for each nursing home  Inspiration  How would you determine what the top ten best nursing homes in the country are? The least? Which states have the best level of nursing home care? The least? In general what are the most common types of complaints and deficiencies?   Acknowledgements This dataset was collected by Medicare.gov and the original files can be accessed here.,,,health infrastructure
Linux Kernel Git Revision History , Philipp Schmidt , www.kaggle.com/philschmidt/linux-kernel-git-revision-history , Sun Mar 12 2017 04:54:41 GMT+0530 (IST) , Anonymized git commit log with detailed file information ,74, computing and society- programming- ,This dataset contains commits with detailed information about changed files from about 12 years of the linux kernel master branch. It contains about 600.000 (filtered) commits and this breaks down to about 1.4 million file change records. Each row represents a changed file in a specific commit with annotated deletions and additions to that file as well as the filename and the subject of the commit. I also included anonymized information about the author of each changed file aswell as the time of commit and the timezone of the author. The columns in detail  author_timestamp UNIX timestamp of when the commit happened commit_hash SHA-1 hash of the commit commit_utc_offset_hours Extraced UTC offset in hours from commit time filename The filename that was changed in the commit n_additions Number of added lines n_deletions Number of deleted lines subject Subject of commit author_id Anonymized author ID.  I'm sure with this dataset nice visualizations can be created let's see what we can come up with! For everybody interested how the dataset was created I've setup a github repo that contains all the required steps to reproduce it here. If you have any questions feel free to contact me via PM or discussions here.,author_timestamp:,numeric:,programming
Kaggle Blog: Winners' Posts , Kaggle , www.kaggle.com/kaggle/kaggle-blog-winners-posts , Wed Sep 21 2016 07:51:21 GMT+0530 (IST) , Examine trends in machine learning by analyzing winners' posts on No Free Hunch ,270, data analysis- artificial intelligence- ,In 2010 Kaggle launched its first competition which was won by Jure Zbontar who used a simple linear model. Since then a lot has changed. We've seen the rebirth of neural networks the rise of Python the creation of powerful libraries like XGBoost Keras and Tensorflow.  This is data set is a dump of all winners' posts from the Kaggle blog starting with Jure Zbontar. It allows us to track trends in the techniques tools and libraries that win competitions.  This is a simple dump. If there's demand I can upload more detail (including comments and tags).,,,
School fires in Sweden 1998-2014 , brontosaur , www.kaggle.com/mikaelhuss/swedish-school-fires , Wed Aug 31 2016 20:15:18 GMT+0530 (IST) , Cases reported by municipality and year. Also KPIs for each municipality. ,539, firefighting- ,"Sweden has a surprisingly large number of school fires for a small country (< 10M inhabitants) and many of these fires are due to arson. For instance according to the Division of Fire Safety Engineering at Lund University ""Almost every day between one and two school fires occur in Sweden. In most cases arson is the cause of the fire."" The associated costs can be up to a billion SEK (around 120 million USD) per year. It is hard to say why these fires are so common in Sweden compared to other countries and this dataset doesn't address that question - but could it be possible within a Swedish context to find out which properties and indicators of Swedish towns (municipalities to be exact) might be related to a high frequency of school fires? I have collected data on school fire cases in Sweden between 1998 and 2014 through a web site with official statistics from the Swedish Civil Contingencies Agency (https//ida.msb.se/ida2#page=a0087). At least at the time when I collected the data there was no API to allow easy access to schools fire data so I had to collect them using a quasi-manual process downloading XLSX report generated from the database year by year after which I joined these with an R script into a single table of school fire cases where the suspected reason was arson. (Full details on the data acquisition process are available.)  The number of such cases is reported for each municipality (of which there are currently 290) and year (i e each row is a unique municipality/year combination). The population at the time is also reported. As a complement to these data I provide a list of municipal KPIs (key performance indicators) from 1998 to 2014. There are thousands of these KPIs and it would be a futile task for me to try to translate the descriptions from Swedish to English although I might take a stab at translating a small subset of them at some point. These KPIs were extracted from Kolada (a database of Swedish municipality and county council statistics) by repeatedly querying its API (https//github.com/Hypergene/kolada). I'd be very interested to hear if anyone finds some interesting correlations between schools fire cases and municipality indicators!",,,accidents
StackLite: Stack Overflow questions and tags , Stack Overflow , www.kaggle.com/stackoverflow/stacklite , Tue Feb 07 2017 04:43:03 GMT+0530 (IST) , Stack Overflow questions and tags without text included ,492, linguistics- internet- programming languages- ,A dataset of Stack Overflow programming questions.  For each question it includes  Question ID Creation date Closed date if applicable Score Owner user ID Number of answers Tags  This dataset is ideal for answering questions such as  The increase or decrease in questions in each tag over time Correlations among tags on questions Which tags tend to get higher or lower scores Which tags tend to be asked on weekends vs weekdays  This dataset was extracted from the Stack Overflow database at 2016-10-13 180948 UTC and contains questions up to 2016-10-12. This includes 12583347 non-deleted questions and 3654954 deleted ones. This is all public data within the Stack Exchange Data Dump which is much more comprehensive (including question and answer text) but also requires much more computational overhead to download and process. This dataset is designed to be easy to read in and start analyzing. Similarly this data can be examined within the Stack Exchange Data Explorer but this offers analysts the chance to work with it locally using their tool of choice. Note that for space reasons only non-deleted questions are included in the sqllite dataset but the csv.gz files include deleted questions as well (with an additional DeletionDate file). See the GitHub repo for more.,Id:Tag:,numeric:string:,programming
Illegal Immigrants Arrested by US Border Patrol , US Customs and Border Protection , www.kaggle.com/cbp/illegal-immigrants , Fri Jan 27 2017 22:55:31 GMT+0530 (IST) , Has the number of Mexican citizens crossing the border increased or decreased? ,844, crime- international relations- ,Content This report provides statistics for the number of illegal immigrants arrested or apprehended by the border patrol in each division (or sector) of the United States borders with Canada Mexico and Caribbean islands; this data is a partial measure of the flow of people illegally entering the United States. Acknowledgements Data was compiled and published by the US Border Patrol on the Customs and Border Protection webpage.,Border:Sector:State/Territory:2000 (All Illegal Immigrants):2000 (Mexicans Only):2001 (All Illegal Immigrants):2001 (Mexicans Only):2002 (All Illegal Immigrants):2002 (Mexicans Only):2003 (All Illegal Immigrants):2003 (Mexicans Only):2004 (All Illegal Immigrants):2004 (Mexicans Only):2005 (All Illegal Immigrants):2005 (Mexicans Only):2006 (All Illegal Immigrants):2006 (Mexicans Only):2007 (All Illegal Immigrants):2007 (Mexicans Only):2008 (All Illegal Immigrants):2008 (Mexicans Only):2009 (All Illegal Immigrants):2009 (Mexicans Only):2010 (All Illegal Immigrants):2010 (Mexicans Only):2011 (All Illegal Immigrants):2011 (Mexicans Only):2012 (All Illegal Immigrants):2012 (Mexicans Only):2013 (All Illegal Immigrants):2013 (Mexicans Only):2014 (All Illegal Immigrants):2014 (Mexicans Only):2015 (All Illegal Immigrants):2015 (Mexicans Only):2016 (All Illegal Immigrants):2016 (Mexicans Only):,string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Obama Visitor Logs , Jay Ravaliya , www.kaggle.com/jayrav13/obama-visitor-logs , Sat Apr 15 2017 20:47:41 GMT+0530 (IST) , About 5.9 million visitor logs released by the Obama White House ,131, politics- ,Context This dataset was released by the Obama White House consisting of about 5.9 million Visitor Logs. The more recent administration does not plan on releasing this dataset so I thought it would be nice to move the Obama dataset to Kaggle to have this platform serve as an alternate home for this data. Challenges Note that the total dataset (5.9 million rows) is a total of 1.1 GB so I split it into 6 files of 1 million rows each. More Info Source https//obamawhitehouse.archives.gov/briefing-room/disclosures/visitor-records,NAMELAST:NAMEFIRST:NAMEMID:UIN:BDGNBR:Type of Access:TOA:POA:TOD:POD:APPT_MADE_DATE:APPT_START_DATE:APPT_END_DATE:APPT_CANCEL_DATE:Total_People:LAST_UPDATEDBY:POST:LastEntryDate:TERMINAL_SUFFIX:visitee_namelast:visitee_namefirst:MEETING_LOC:MEETING_ROOM:CALLER_NAME_LAST:CALLER_NAME_FIRST:CALLER_ROOM:Description:RELEASE_DATE:,string:string:string:string:string:string:string:string:string:string:string:dateTime:dateTime:string:string:string:string:string:string:string:string:string:string:string:string:string:string:dateTime:,politics
Freedom of the Press 2001-2015 , Freedom House , www.kaggle.com/freedomhouse/press-freedom , Sat Feb 04 2017 05:00:16 GMT+0530 (IST) , Scores on legal political and economic freedom in all countries ,177, news agencies- law- ,Content The 2016 edition of Freedom of the Press which provides analytical reports and numerical scores for 199 countries and territories continues a process conducted by Freedom House since 1980. Each country and territory is given a total press freedom score from 0 (best) to 100 (worst) on the basis of 23 methodology questions divided into three subcategories. The total score determines the status designation of Free Partly Free or Not Free. The scores and reports included in Freedom of the Press 2016 cover events that took place between January 1 2015 and December 31 2015. The level of press freedom in each country and territory is evaluated through 23 methodology questions divided into three broad categories the legal environment the political environment and the economic environment. For each methodology question a lower number of points is allotted for a more free situation while a higher number of points is allotted for a less free environment. A country or territory’s final score (from 0 to 100) represents the total of the points allotted for each question. A total score of 0 to 30 results in a press freedom status of Free; 31 to 60 results in a status of Partly Free; and 61 to 100 indicates a status of Not Free. The legal environment category encompasses an examination of both the laws and regulations that could influence media content and the extent to which they are used in practice to enable or restrict the media’s ability to operate. We assess the positive impact of legal and constitutional guarantees for freedom of expression; the potentially negative aspects of security legislation the penal code and other statutes; penalties for libel and defamation; the existence of and ability to use freedom of information legislation; the independence of the judiciary and official regulatory bodies; registration requirements for both media outlets and journalists; and the ability of journalists’ organizations to operate freely. Under the political environment category we evaluate the degree of political influence in the content of news media. Issues examined include the editorial independence of both state-owned and privately owned outlets; access to information and sources; official censorship and self-censorship; the vibrancy of the media and the diversity of news available within each country or territory; the ability of both foreign and local reporters to cover the news in person without obstacles or harassment; and reprisals against journalists or bloggers by the state or other actors including arbitrary detention violent assaults and other forms of intimidation. Our third category examines the economic environment for the media. This includes the structure of media ownership; transparency and concentration of ownership; the costs of establishing media as well as any impediments to news production and distribution; the selective withholding of advertising or subsidies by the state or other actors; the impact of corruption and bribery on content; and the extent to which the economic situation in a country or territory affects the development and sustainability of the media.,Country:2001 Legal Score:2001 Political Score:2001 Economic Score:2001 Score:2001 Status:2002 Legal Score:2002 Political Score:2002 Economic Score:2002 Score:2002 Status:2003 Legal Score:2003 Political Score:2003 Economic Score:2003 Score:2003 Status:2004 Legal Score:2004 Political Score:2004 Economic Score:2004 Score:2004 Status:2005 Legal Score:2005 Political Score:2005 Economic Score:2005 Score:2005 Status:2006 Legal Score:2006 Political Score:2006 Economic Score:2006 Score:2006 Status:2007 Legal Score:2007 Political Score:2007 Economic Score:2007 Score:2007 Status:2008 Legal Score:2008 Political Score:2008 Economic Score:2008 Score:2008 Status:2009 Legal Score:2009 Political Score:2009 Economic Score:2009 Score:2009 Status:2010 Legal Score:2010 Political Score:2010 Economic Score:2010 Score:2010 Status:2011 Legal Score:2011 Political Score:2011 Economic Score:2011 Score:2011 Status:2012 Legal Score:2012 Political Score:2012 Economic Score:2012 Score:2012 Status:2013 Legal Score:2013 Political Score:2013 Economic Score:2013 Score:2013 Status:2014 Legal Score:2014 Political Score:2014 Economic Score:2014 Score:2014 Status:2015 Legal Score:2015 Political Score:2015 Economic Score:2015 Score:2015 Status:,string:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:,news
U.S. Homicide Reports 1980-2014 , jyzaguirre , www.kaggle.com/jyzaguirre/us-homicide-reports , Sun Mar 12 2017 05:33:51 GMT+0530 (IST) , Homicides between 1980 and 2014 ,374, history- crime- ,"Context This datasheet is an extension of the job of ""Murder Accountability Project"". In this datasheet is included a vectorial file of states to make easier the labour of geographical plotting. Content The Murder Accountability Project is the most complete database of homicides in the United States currently available. This dataset includes murders from the FBI's Supplementary Homicide Report from 1976 to the present and Freedom of Information Act data on more than 22000 homicides that were not reported to the Justice Department. This dataset includes the age race sex ethnicity of victims and perpetrators in addition to the relationship between the victim and perpetrator and weapon used. Acknowledgements The data was compiled and made available by the Murder Accountability Project founded by Thomas Hargrove. Inspiration Can you develop an algorithm to detect serial killer activity?",Record ID:Agency Code:Agency Name:Agency Type:City:State:Year:Month:Incident:Crime Type:Crime Solved:Victim Sex:Victim Age:Victim Race:Victim Ethnicity:Perpetrator Sex:Perpetrator Age:Perpetrator Race:Perpetrator Ethnicity:Relationship:Weapon:Victim Count:Perpetrator Count:Record Source:,numeric:string:string:string:string:string:numeric:string:numeric:string:string:string:numeric:string:string:string:numeric:string:string:string:string:numeric:numeric:string:,
Obama White House , Jay Ravaliya , www.kaggle.com/jayrav13/obama-white-house , Tue Apr 11 2017 05:32:22 GMT+0530 (IST) , A set of 20000+ documents released on the Obama White House website ,134, politics- ,Why? Inspired by an interest in scraping and organizing data released by the federal government this is an easy-to-navigate CSV of all of the documents released by the Obama White House now found on obamawhitehouse.archives.gov. This includes the full content of each of the documents released (wherever possible) along with link references to each document. Further each of them is broken down by document type as well.,number:,numeric:,politics
HanziDB , Rudd Fawcett , www.kaggle.com/ruddfawcett/hanzidb , Tue Oct 03 2017 21:33:59 GMT+0530 (IST) , List of simplified Chinese characters ordered by frequency rank. ,34, languages- china - linguistics- ,Content A ranked list (by frequency) of over 9k simplified Chinese characters.  Acknowledgements All data scraped from HanziDB.org which is based on Jun Da's Modern Chinese Character Frequency List. Inspiration Some possible questions  What is the distribution of radicals through the 100 most popular characters? 500? 1000? Does stroke count affect usage? Is there an association between the number of strokes and the HSK level of characters? ,frequency_rank:charcter:pinyin:definition:radical:radical_code:stroke_count:hsk_levl:general_standard_num:,numeric:string:string:string:string:numeric:numeric:numeric:numeric:,Written script
Earthquakes <-?-> Solar System objects? , tusha kutusha , www.kaggle.com/aradzhabov/earthquakes-solar-system-objects , Sun Apr 23 2017 03:12:59 GMT+0530 (IST) , Is there any relationship between Earthquakes and Solar System objects? ,267, geology- space- ,"Context We all know that there is relationship between tides and Moon. What if we try to find the match between the position of objects in our Solar System and Earthquakes? So I prepared the dataset to answer the question. Content The dataset has information about Earthquakes (magnitude 6.1+) occur between  yyyy.mm.dd 1986.05.04 to 2016.05.04 and position (and other params) of Solar System planets + Sun and Moon  at the time when the specific Earthquake occured Each row has 1) info about the specific Earthquake date and time where it occur latitude and longitude magnitude place (it is useless field since we have latitude and longitude but I left the filed just to have humanreading meaning e.g. 7km SW of Ueki Japan) 2) Planets Moon and Sun information (position and etc)  relatively  latitude and longitude  of place and time of the Earthquake. Acknowledgements Tha dataset has two sources of information. Both ones are free and available for public. 1) Earthquakes info The USGS Earthquake Hazards Program https//earthquake.usgs.gov/ 2) Solar System objects info  NGINOV Astropositions http//api.nginov note NGINOV uses a bit specific calculation of azimuth (as far as i know more often the one calculates from geographicall north). The note from NGINOV ""An astronomical azimuth is expressed in degree or schedules arcs. Taking as a reference point geographically south of the place of observation and a dextrorotatory angular progression."" note I am not quite strong in Astronomic stuff. I expressed the idea about  possible relationship and wrote a simple app to match and merge the info from two data sources into the dataset which possibly help to answer the question. Inspiration May be there is a relationship between the position and other params of objects in our Solar System and Earthquakes? Hope someone will find the match! ) Good luck!!",earthquake.time:earthquake.latitude:earthquake.longitude:earthquake.mag:earthquake.place:MoonPhase.dynamic:MoonPhase.value:MoonPhase.total:MoonPhase.percent:MoonPhase.illumination:day.sunrise:day.zenith:day.sunset:day.duration:night.duration:twilight.civil:twilight.nautical:twilight.astronomical:Sun.longitude:Sun.latitude:Sun.rectascension:Sun.declination:Sun.azimuth:Sun.height:Sun.speed:Sun.house:Sun.housenumber:Moon.longitude:Moon.latitude:Moon.rectascension:Moon.declination:Moon.azimuth:Moon.height:Moon.speed:Moon.house:Moon.housenumber:Mercury.longitude:Mercury.latitude:Mercury.rectascension:Mercury.declination:Mercury.azimuth:Mercury.height:Mercury.speed:Mercury.house:Mercury.housenumber:Venus.longitude:Venus.latitude:Venus.rectascension:Venus.declination:Venus.azimuth:Venus.height:Venus.speed:Venus.house:Venus.housenumber:Mars.longitude:Mars.latitude:Mars.rectascension:Mars.declination:Mars.azimuth:Mars.height:Mars.speed:Mars.house:Mars.housenumber:Jupiter.longitude:Jupiter.latitude:Jupiter.rectascension:Jupiter.declination:Jupiter.azimuth:Jupiter.height:Jupiter.speed:Jupiter.house:Jupiter.housenumber:Saturn.longitude:Saturn.latitude:Saturn.rectascension:Saturn.declination:Saturn.azimuth:Saturn.height:Saturn.speed:Saturn.house:Saturn.housenumber:Uranus.longitude:Uranus.latitude:Uranus.rectascension:Uranus.declination:Uranus.azimuth:Uranus.height:Uranus.speed:Uranus.house:Uranus.housenumber:Neptune.longitude:Neptune.latitude:Neptune.rectascension:Neptune.declination:Neptune.azimuth:Neptune.height:Neptune.speed:Neptune.house:Neptune.housenumber:Pluto.longitude:Pluto.latitude:Pluto.rectascension:Pluto.declination:Pluto.azimuth:Pluto.height:Pluto.speed:Pluto.house:Pluto.housenumber:,dateTime:numeric:numeric:numeric:string:string:numeric:numeric:numeric:numeric:dateTime:dateTime:dateTime:dateTime:dateTime:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,disasters
Hillary Clinton's Emails , Kaggle , www.kaggle.com/kaggle/hillary-clinton-emails , Thu Oct 06 2016 08:34:14 GMT+0530 (IST) , Uncover the political landscape in Hillary Clinton's emails ,10590, politics- telecommunications- ,Throughout 2015 Hillary Clinton has been embroiled in controversy over the use of personal email accounts on non-government servers during her time as the United States Secretary of State. Some political experts and opponents maintain that Clinton's use of personal email accounts to conduct Secretary of State affairs is in violation of protocols and federal laws that ensure appropriate recordkeeping of government activity. Hillary's campaign has provided their own four sentence summary of her email use here.  There have been a number of Freedom of Information lawsuits filed over the State Department's failure to fully release the emails sent and received on Clinton's private accounts. On Monday August 31 the State Department released nearly 7000 pages of Clinton's heavily redacted emails (its biggest release of emails to date).  The documents were released by the State Department as PDFs. We've cleaned and normalized the released documents and are hosting them for public analysis. Kaggle's choice to host this dataset is not meant to express any particular political affiliation or intent.  Here's the code that creates this data release.,Id:Alias:PersonId:,numeric:string:numeric:,politics
US Population By Zip Code , US Census Bureau , www.kaggle.com/census/us-population-by-zip-code , Tue Jun 27 2017 23:26:05 GMT+0530 (IST) , For both 2000 and 2010 ,300, demographics- ,Content The United States census count (also known as the Decennial Census of Population and Housing) is a count of every resident of the US. The census occurs every 10 years and is conducted by the United States Census Bureau. Census data is publicly available through the census website but much of the data is available in summarized data and graphs. The raw data is often difficult to obtain is typically divided by region and it must be processed and combined to provide information about the nation as a whole. The United States census dataset includes nationwide population counts from the 2000 and 2010 censuses. Data is broken out by gender age and location using zip code tabular areas (ZCTAs) and GEOIDs. ZCTAs are generalized representations of zip codes and often though not always are the same as the zip code for an area. GEOIDs are numeric codes that uniquely identify all administrative legal and statistical geographic areas for which the Census Bureau tabulates data. GEOIDs are useful for correlating census data with other censuses and surveys. Dataset Description | geo_id      | STRING  | Geo code                                                                                                                                                                       | |-------------|---------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------| | minimum_age | INTEGER | The minimum age in the age range. If null this indicates the row as a total for male female or overall population.                                                          | | maximum_age | INTEGER | The maximum age in the age range. If null this indicates the row as having no maximum (such as 85 and over) or the row is a total of the male female or overall population. | | gender      | STRING  | male or female. If empty the row is a total population summary.                                                                                                               | | population  | INTEGER | The total count of the population for this segment.                                                                                                                            | Acknowledgements This dataset was created by the United States Census Bureau. Use this dataset with BigQuery You can use Kernels to analyze share and discuss this data on Kaggle but if you’re looking for real-time updates and bigger data check out the data on BigQuery too https//cloud.google.com/bigquery/public-data/international-census.,minimum_age:maximum_age:gender:population:zipcode:geo_id:,numeric:numeric:string:numeric:numeric:string:,demography
International Datasets , US Census Bureau , www.kaggle.com/census/international-data , Tue Jun 27 2017 23:21:46 GMT+0530 (IST) , International health and population metrics ,706, demographics- international relations- ,Content The United States Census Bureau’s International Dataset provides estimates of country populations since 1950 and projections through 2050. Specifically the data set includes midyear population figures broken down by age and gender assignment at birth. Additionally they provide time-series data for attributes including fertility rates birth rates death rates and migration rates. The full documentation is available here. For basic field details please see the data dictionary.  Note The U.S. Census Bureau provides estimates and projections for countries and areas that are recognized by the U.S. Department of State that have a population of at least 5000. Acknowledgements This dataset was created by the United States Census Bureau. Inspiration Which countries have made the largest improvements in life expectancy? Based on current trends how long will it take each country to catch up to today’s best performers? Use this dataset with BigQuery You can use Kernels to analyze share and discuss this data on Kaggle but if you’re looking for real-time updates and bigger data check out the data on BigQuery too https//cloud.google.com/bigquery/public-data/international-census.,country_code:country_name:year:fertility_rate_15_19:fertility_rate_20_24:fertility_rate_25_29:fertility_rate_30_34:fertility_rate_35_39:fertility_rate_40_44:fertility_rate_45_49:total_fertility_rate:gross_reproduction_rate:sex_ratio_at_birth:,string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Rare diseases - Sentiment analysis , Natalia , www.kaggle.com/natt77/rare-diseases-sentimient-analysis , Thu Jul 06 2017 13:23:25 GMT+0530 (IST) , Sentiment analysis on rare disease Facebook groups ,80, linguistics- medicine- internet- ,Sentiment analysis on rare disesases Facebook groups.  The origin of this file is 'Rare Diseases on Facebook Groups' also available in Kaggle. This file contained Facebook posts from rare diseases groups in Spanish.  Based on that file the post_message was extracted and translated into english using Google Translate. Sentimient analysis was performed to obtain the polarity and subjectivity using Python (Textblob). The result is this output file containing the post_message both in spanish and english and the polarity and subjectivity of the message.,;post_message_en;post_message;polarity;subjectivity:,string:,social media
UK Car Accidents 2005-2015 , silicon99 , www.kaggle.com/silicon99/dft-accident-data , Tue Feb 21 2017 18:34:02 GMT+0530 (IST) , Data from the UK Department for Transport ,2352, road transport- ,Context UK police forces collect data on every vehicle collision in the uk on a form called Stats19. Data from this form ends up at the DfT and is published at https//data.gov.uk/dataset/road-accidents-safety-data Content There are 3 CSVs in this set. Accidents is the primary one and has references by Accident_Index to the casualties and vehicles tables. This might be better done as a database. Inspiration Questions to ask of this data -  combined with population data how do different areas compare? what trends are there for accidents involving different road users eg motorcycles peds cyclists are road safety campaigns effective? likelihood of accidents for different groups / vehicles many more..  Manifest dft05-15.tgz - tar of Accidents0515.csv Casualties0515.csv and Vehicles0515.csv tidydata.sh - script to get and tidy data.,Accident_Index:Location_Easting_OSGR:Location_Northing_OSGR:Longitude:Latitude:Police_Force:Accident_Severity:Number_of_Vehicles:Number_of_Casualties:Date:Day_of_Week:Time:Local_Authority_(District):Local_Authority_(Highway):1st_Road_Class:1st_Road_Number:Road_Type:Speed_limit:Junction_Detail:Junction_Control:2nd_Road_Class:2nd_Road_Number:Pedestrian_Crossing-Human_Control:Pedestrian_Crossing-Physical_Facilities:Light_Conditions:Weather_Conditions:Road_Surface_Conditions:Special_Conditions_at_Site:Carriageway_Hazards:Urban_or_Rural_Area:Did_Police_Officer_Attend_Scene_of_Accident:LSOA_of_Accident_Location:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:dateTime:numeric:dateTime:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:,accidents
Predict NHL Player Salaries , Cam Nugent , www.kaggle.com/camnugent/predict-nhl-player-salaries , Fri Aug 18 2017 23:39:56 GMT+0530 (IST) , Build a model to predict the salaries of NHL players based on player data ,136, sports- money- ,Context & Content This dataset features the salaries of 874 nhl players for the 2016/2017 season. I have randomly split the players into a training (612 players) and test (262 players) populations. There are 151 predictor columns (described in column legend section if you're not familiar with hockey the meaning of some of these may be a bit cryptic!) as well as a leading column with the players 2016/2017 annual salary.  For the test population the actual salaries have been broken off into a separate .csv file. Acknowledgements Raw excel sheet was acquired http//www.hockeyabstract.com/ Inspiration Can you build a model to predict NHL player's salaries? What are the best predictors of how much a player will make? Column Legend Acronym - Meaning %FOT - Percentage of all on-ice faceoffs taken by this player. +/- - Plus/minus 1G - First goals of a game A/60 - Events Against per 60 minutes defaults to Corsi but can be set to another stat A1 - First assists primary assists A2 - Second assists secondary assists BLK% - Percentage of all opposing shot attempts blocked by this player Born - Birth date C.Close - A player shot attempt (Corsi) differential when the game was close C.Down - A player shot attempt (Corsi) differential when the team was trailing C.Tied - A player shot attempt (Corsi) differential when the team was tied C.Up - A player shot attempt (Corsi) differential when the team was in the lead CA - Shot attempts allowed (Corsi SAT) while this player was on the ice Cap Hit - The player's cap hit CBar  - Crossbars hit CF - The team's shot attempts (Corsi SAT) while this player was on the ice CF.QoC - A weighted average of the Corsi percentage of a player's opponents CF.QoT - A weighted average of the Corsi percentage of a player's linemates CHIP - Cap Hit of Injured Player is games lost to injury multiplied by cap hit per game City - City of birth Cntry - Country of birth DAP - Disciplined aggression proxy which is hits and takeaways divided by minor penalties DFA - Dangerous Fenwick against which is on-ice unblocked shot attempts weighted by shot quality DFF - Dangerous Fenwick for which is on-ice unblocked shot attempts weighted by shot quality DFF.QoC - Quality of Competition metric based on Dangerous Fenwick which is unblocked shot attempts weighted for shot quality DftRd - Round in which the player was drafted DftYr - Year drafted Diff - Events for minus event against defaults to Corsi but can be set to another stat Diff/60 - Events for minus event against per 60 minutes defaults to Corsi but can be set to another stat DPS - Defensive point shares a catch-all stats that measures a player's defensive contributions in points in the standings DSA - Dangerous shots allowed while this player was on the ice which is rebounds plus rush shots DSF - The team's dangerous shots while this player was on the ice which is rebounds plus rush shots DZF - Shifts this player has ended with an defensive zone faceoff dzFOL - Faceoffs lost in the defensive zone dzFOW - Faceoffs win in the defensive zone dzGAPF - Team goals allowed after faceoffs taken in the defensive zone dzGFPF - Team goals scored after faceoffs taken in the defensive zone DZS - Shifts this player has started with an defensive zone faceoff dzSAPF - Team shot attempts allowed after faceoffs taken in the defensive zone dzSFPF - Team shot attempts taken after faceoffs taken in the defensive zone E+/- - A player's expected +/- based on his team and minutes played ENG - Empty-net goals Exp dzNGPF - Expected goal differential after faceoffs taken in the defensive zone based on the number of them Exp dzNSPF - Expected shot differential after faceoffs taken in the defensive zone based on the number of them Exp ozNGPF - Expected goal differential after faceoffs taken in the offensive zone based on the number of them Exp ozNSPF - Expected shot differential after faceoffs taken in the offensive zone based on the number of them F.Close - A player unblocked shot attempt (Fenwick) differential when the game was close F.Down - A player unblocked shot attempt (Fenwick) differential when the team was trailing F.Tied - A player unblocked shot attempt (Fenwick) differential when the team was tied F.Up - A player unblocked shot attempt (Fenwick) differential when the team was in the lead. Not the best acronym. F/60 - Events For per 60 minutes defaults to Corsi but can be set to another stat FA - Unblocked shot attempts allowed (Fenwick USAT) while this player was on the ice FF - The team's unblocked shot attempts (Fenwick USAT) while this player was on the ice First Name -  FO% - Faceoff winning percentage FO%vsL - Faceoff winning percentage against lefthanded opponents FO%vsR - Faceoff winning percentage against righthanded opponents FOL - The team's faceoff losses while this player was on the ice FOL.Close - Faceoffs lost when the score was close FOL.Down - Faceoffs lost when the team was trailing FOL.Up - Faceoffs lost when the team was in the lead FovsL - Faceoffs taken against lefthanded opponents FovsR - Faceoffs taken against righthanded opponents FOW - The team's faceoff wins while this player was on the ice FOW.Close - Faceoffs won when the score was close FOW.Down - Faceoffs won when the team was trailing FOW.Up - Faceoffs won when the team was in the lead G - Goals G.Bkhd - Goals scored on the backhand G.Dflct - Goals scored with deflections G.Slap - Goals scored with slap shots G.Snap - Goals scored with snap shots G.Tip - Goals scored with tip shots G.Wrap - Goals scored with a wraparound G.Wrst - Goals scored with a wrist shot GA - Goals allowed while this player was on the ice Game - Game Misconduct penalties GF - The team's goals while this player was on the ice GP - Games Played Grit - Defined as hits blocked shots penalty minutes and majors GS - The player's combined game score GS/G - The player's average game score GVA - The team's giveaways while this player was on the ice GWG - Game-winning goals GWG - Game-winning goals HA - The team's hits taken while this player was on the ice Hand - Handedness HF - The team's hits thrown while this player was on the ice HopFO - Opening faceoffs taken at home HopFOW - Opening faceoffs won at home Ht - Height iBLK - Shots blocked by this individual iCF - Shot attempts (Corsi SAT) taken by this individual iDS - Dangerous shots taken by this player the sum of rebounds and shots off the rush iFF - Unblocked shot attempts (Fenwick USAT) taken by this individual iFOL - Faceoff losses by this individual iFOW - Faceoff wins by this individual iGVA - Giveaways by this individual iHA - Hits taken by this individual iHDf - The difference in hits thrown by this individual minus those taken iHF - Hits thrown by this individual iMiss - Individual shots taken that missed the net. Injuries - List of types of injuries incurred if any iPEND - Penalties drawn by this individual iPenDf - The difference in penalties drawn minus those taken iPENT - Penalties taken by this individual IPP% - Individual points percentage which is on-ice goals for which this player had the goal or an assist iRB - Rebound shots taken by this individual iRS - Shots off the rush taken by this individual iSCF - All scoring chances taken by this individual iSF - Shots on goal taken by this individual iTKA - Takeaways by this individual ixG - Expected goals (weighted shots) for this individual which is shot attempts weighted by shot location Last Name -  Maj - Major penalties taken Match - Match penalties MGL - Games lost due to injury Min - Minor penalties taken Misc - Misconduct penalties Nat - Nationality NGPF - Net Goals Post Faceoff. A differential of all goals within 10 seconds of a faceoff relative to expectations set by the zone in which they took place NHLid - NHL player id useful when looking at the raw data in game files NMC - What kind of no-movement clause this player's contract has if any NPD - Net Penalty Differential is the player's penalty differential relative to a player of the same position with the same ice time per manpower situation NSPF - Net Shots Post Faceoff. A differential of all shot attempts within 10 seconds of a faceoff relative to expectations set by the zone in which they took place NZF - Shifts this player has ended with a neutral zone faceoff nzFOL - Faceoffs lost in the neutral zone nzFOW - Faceoffs won in the neutral zone nzGAPF - Team goals allowed after faceoffs taken in the neutral zone nzGFPF - Team goals scored after faceoffs taken in the neutral zone NZS - Shifts this player has started with a neutral zone faceoff nzSAPF - Team shot attempts allowed after faceoffs taken in the neutral zone nzSFPF - Team shot attempts taken after faceoffs taken in the neutral zone OCA - Shot attempts allowed (Corsi SAT) while this player was not on the ice OCF - The team's shot attempts (Corsi SAT) while this player was not on the ice ODZS - Defensive zone faceoffs that occurred without this player on the ice OFA - Unblocked shot attempts allowed (Fenwick USAT) while this player was not on the ice OFF - The team's unblocked shot attempts (Fenwick USAT) while this player was not on the ice OGA - Goals allowed while this player was not on the ice OGF - The team's goals while this player was not on the ice ONZS - Neutral zone faceoffs that occurred without this player on the ice OOZS - Offensive zone faceoffs that occurred without this player on the ice OpFO - Opening faceoffs taken OpFOW - Opening faceoffs won OppCA60 - A weighted average of the shot attempts (Corsi SAT) the team allowed per 60 minutes of a player's opponents OppCF60 - A weighted average of the shot attempts (Corsi SAT) the team generated per 60 minutes of a player's opponents OppFA60 - A weighted average of the unblocked shot attempts (Fenwick USAT) the team allowed per 60 minutes of a player's opponents OppFF60 - A weighted average of the unblocked shot attempts (Fenwick USAT) the team generated per 60 minutes of a player's opponents OppGA60 - A weighted average of the goals the team allowed per 60 minutes of a player's opponents OppGF60 - A weighted average of the goals the team scored per 60 minutes of a player's opponents OppSA60 - A weighted average of the shots on goal the team allowed per 60 minutes of a player's opponents OppSF60 - A weighted average of the shots on goal the team generated per 60 minutes of a player's opponents OPS - Offensive point shares a catch-all stats that measures a player's offensive contributions in points in the standings OSA - Shots on goal allowed while this player was not on the ice OSCA - Scoring chances allowed while this player was not on the ice OSCF - The team's scoring chances while this player was not on the ice OSF - The team's shots on goal while this player was not on the ice OTF - Shifts this player started with an on-the-fly change OTG - Overtime goals OTOI - The amount of time this player was not on the ice. Over - Shots that went over the net Ovrl - Where the player was drafted overall OxGA - Expected goals allowed (weighted shots) while this player was not on the ice which is shot attempts weighted by location OxGF - The team's expected goals (weighted shots) while this player was not on the ice which is shot attempts weighted by location OZF - Shifts this player has ended with an offensive zone faceoff ozFO - Faceoffs taken in the offensive zone ozFOL - Faceoffs lost in the offensive zone ozFOW - Faceoffs won in the offensive zone ozGAPF - Team goals allowed after faceoffs taken in the offensive zone ozGFPF - Team goals scored after faceoffs taken in the offensive zone OZS - Shifts this player has started with an offensive zone faceoff ozSAPF - Team shot attempts allowed after faceoffs taken in the offensive zone ozSFPF - Team shot attempts taken after faceoffs taken in the offensive zone Pace - The average game pace as estimated by all shot attempts per 60 minutes Pass - An estimate of the player's setup passes (passes that result in a shot attempt) Pct% - Percentage of all events produced by this team defaults to Corsi but can be set to another stat PDO - The team's shooting and save percentages added together times a thousand PEND - The team's penalties drawn while this player was on the ice PENT - The team's penalties taken while this player was on the ice PIM - Penalties in minutes Position - Positions played. NHL source listed first followed by those listed by any other source. Post - Times hit the post Pr/St - Province or state of birth PS - Point shares a catch-all stats that measures a player's contributions in points in the standings PSA - Penalty shot attempts PSG - Penalty shot goals PTS - Points. Goals plus all assists PTS/60 - Points per 60 minutes QRelCA60  - Shot attempts allowed per 60 minutes relative to how others did against the same competition QRelCF60  - Shot attempts per 60 minutes relative to how others did against the same competition QRelDFA60  - Weighted unblocked shot attempts (Dangeorus Fenwick)  allowed per 60 minutes relative to how others did against the same competition QRelDFF60  - Weighted unblocked shot attempts (Dangeorus Fenwick) per 60 minutes relative to how others did against the same competition RBA - Rebounds allowed while this player was on the ice. Two very different sources. RBF - The team's rebounds while this player was on the ice. Two very different sources. RelA/60 - The player's A/60 relative to the team when he's not on the ice RelC/60 - Corsi differential per 60 minutes relative to his team RelC% - Corsi percentage relative to his team RelDf/60 - The player's Diff/60 relative to the team when he's not on the ice RelF/60 - The player's F/60 relative to the team when he's not on the ice RelF/60 - Fenwick differential per 60 minutes relative to his team RelF% - Fenwick percentage relative to his team RelPct% - The players Pct% relative to the team when he's not on the ice RelZS% - The player's zone start percentage when he's on the ice relative to when he's not. RopFO - Opening faceoffs taken at home RopFOW - Opening faceoffs won at home RSA - Shots off the rush allowed while this player was on the ice RSF - The team's shots off the rush while this player was on the ice S.Bkhd - Backhand shots S.Dflct - Deflections S.Slap - Slap shots S.Snap - Snap shots S.Tip - Tipped shots S.Wrap - Wraparound shots S.Wrst - Wrist shots SA - Shots on goal allowed while this player was on the ice Salary - The player's salary SCA - Scoring chances allowed while this player was on the ice SCF - The team's scoring chances while this player was on the ice sDist - The average shot distance of shots taken by this player SF - The team's shots on goal while this player was on the ice SH% - The team's (not individual's) shooting percentage when the player was on the ice SOG - Shootout Goals SOGDG - Game-deciding shootout goals SOS - Shootout Shots Status - This player's free agency status SV% - The team's save percentage when the player was on the ice Team -  TKA - The team's takeaways while this player was on the ice TMCA60 - A weighted average of the shot attempts (Corsi SAT) the team allowed per 60 minutes of a player's linemates TMCF60 - A weighted average of the shot attempts (Corsi SAT) the team generated per 60 minutes of a player's linemates TMFA60 - A weighted average of the unblocked shot attempts (Fenwick USAT) the team allowed per 60 minutes of a player's linemates TMFF60 - A weighted average of the unblocked shot attempts (Fenwick USAT) the team generated per 60 minutes of a player's linemates TMGA60 - A weighted average of the goals the team allowed per 60 minutes of a player's linemates TMGF60 - A weighted average of the goals the team scored per 60 minutes of a player's linemates TMSA60 - A weighted average of the shots on goal the team allowed per 60 minutes of a player's linemates TMSF60 - A weighted average of the shots on goal the team generated per 60 minutes of a player's linemates TmxGF - A weighted average of a player's linemates of the expected goals the team scored TmxGA - A weighted average of a player's linemates of the expected goals the team allowed TMGA - A weighted average of a player's linemates of the goals the team scored TMGF - A weighted average of a player's linemates of the goals the team allowed TOI - Time on ice in minutes or in seconds (NHL) TOI.QoC - A weighted average of the TOI% of a player's opponents. TOI.QoT - A weighted average of the TOI% of a player's linemates. TOI/GP - Time on ice divided by games played TOI% - Percentage of all available ice time assigned to this player. Wide - Shots that went wide of the net Wt - Weight xGA - Expected goals allowed (weighted shots) while this player was on the ice which is shot attempts weighted by location xGF - The team's expected goals (weighted shots) while this player was on the ice which is shot attempts weighted by location xGF.QoC - A weighted average of the expected goal percentage of a player's opponents xGF.QoT - A weighted average of the expected goal percentage of a player's linemates ZS% - Zone start percentage the percentage of shifts started in the offensive zone not counting neutral zone or on-the-fly changes,Born:,string:,sports scores
Anime Recommendations Database , CooperUnion , www.kaggle.com/CooperUnion/anime-recommendations-database , Wed Dec 21 2016 10:28:34 GMT+0530 (IST) , Recommendation data from 76000 users at myanimelist.net ,2518, popular culture- film- ,"Context This data set contains information on user preference data from 73516 users on 12294 anime. Each user is able to add anime to their completed list and give it a rating and this data set is a compilation of those ratings. Content Anime.csv  anime_id - myanimelist.net's unique id identifying an anime. name - full name of anime. genre - comma separated list of genres for this anime. type - movie TV OVA etc. episodes - how many episodes in this show. (1 if movie). rating - average rating out of 10 for this anime. members - number of community members that are in this anime's ""group"".  Rating.csv  user_id - non identifiable randomly generated user id. anime_id - the anime that this user has rated. rating - rating out of 10 this user has assigned (-1 if the user watched it but didn't assign a rating).  Acknowledgements Thanks to myanimelist.net API for providing anime data and user ratings. Inspiration Building a better anime recommendation system based only on user viewing history.",anime_id:name:genre:type:episodes:rating:members:,numeric:string:string:string:numeric:numeric:numeric:,movies
Govt. of India Census 2001 District-Wise , PreetSinghKhalsa , www.kaggle.com/bazuka/census2001 , Wed Jan 18 2017 01:32:54 GMT+0530 (IST) , One billion hearts a single CSV ,1861, demographics- sociology- ,Context Census of India is a rich database which can tell stories of over a billion Indians. It is important not only for research point of view but commercially as well for the organizations that want to understand India's complex yet strongly knitted heterogeneity.  However nowhere on the web there exists a single database that combines the district- wise information of all the variables (most include no more than 4-5 out of over 50 variables!). Extracting and using data from Census of India 2001 is quite a laborious task since all data is made available in scattered PDFs district wise. Individual PDFs can be extracted from http//www.censusindia.gov.in/(S(ogvuk1y2e5sueoyc5eyc0g55))/Tables_Published/Basic_Data_Sheet.aspx.  Content This database has been extracted from Census of 2001 and includes data of 590 districts having around 80 variables each.  In case of confusion regarding the context of the variable refer to the following PDF and you will be able to make sense out of it http//censusindia.gov.in/Dist_File/datasheet-2923.pdf  All the extraction work can be found @ https//github.com/preetskhalsa97/census2001auto  The final CSV can be found at finalCSV/all.csv The subtle hack that was used to automate extraction to a great extent was the the URLs of all the PDFs were same except the four digits (that were respective state and district codes).  A few abbreviations used for states AN- Andaman and Nicobar CG- Chhattisgarh D_D- Daman and Diu D_N_H- Dadra and Nagar Haveli JK- Jammu and Kashmir MP- Madhya Pradesh TN- Tamil Nadu UP- Uttar Pradesh WB- West Bengal  A few variables for clarification  Growth..1991...2001- population growth from 1991 to 2001 X0..4 years- People in age group 0 to 4 years SC1- Scheduled Class with highest population Acknowledgements Inspiration This is a massive dataset which can be used to explain the interplay between education caste development gender and much more.  It really can explain a lot about India and propel data driven research.  Happy Number Crunching!,:State:District:Persons:Males:Females:Growth..1991...2001.:Rural:Urban:Scheduled.Caste.population:Percentage...SC.to.total:Number.of.households:Household.size..per.household.:Sex.ratio..females.per.1000.males.:Sex.ratio..0.6.years.:Scheduled.Tribe.population:Percentage.to.total.population..ST.:Persons..literate:Males..Literate:Females..Literate:Persons..literacy.rate:Males..Literatacy.Rate:Females..Literacy.Rate:Total.Educated:Data.without.level:Below.Primary:Primary:Middle:Matric.Higher.Secondary.Diploma:Graduate.and.Above:X0...4.years:X5...14.years:X15...59.years:X60.years.and.above..Incl..A.N.S..:Total.workers:Main.workers:Marginal.workers:Non.workers:SC.1.Name:SC.1.Population:SC.2.Name:SC.2.Population:SC.3.Name:SC.3.Population:Religeon.1.Name:Religeon.1.Population:Religeon.2.Name:Religeon.2.Population:Religeon.3.Name:Religeon.3.Population:ST.1.Name:ST.1.Population:ST.2.Name:ST.2.Population:ST.3.Name:ST.3.Population:Imp.Town.1.Name:Imp.Town.1.Population:Imp.Town.2.Name:Imp.Town.2.Population:Imp.Town.3.Name:Imp.Town.3.Population:Total.Inhabited.Villages:Drinking.water.facilities:Safe.Drinking.water:Electricity..Power.Supply.:Electricity..domestic.:Electricity..Agriculture.:Primary.school:Middle.schools:Secondary.Sr.Secondary.schools:College:Medical.facility:Primary.Health.Centre:Primary.Health.Sub.Centre:Post..telegraph.and.telephone.facility:Bus.services:Paved.approach.road:Mud.approach.road:Permanent.House:Semi.permanent.House:Temporary.House:,numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,demography
US Facility-Level Air Pollution (2010-2014) , Jeremy Seibert , www.kaggle.com/jaseibert/us-facilitylevel-air-pollution-20102014 , Sat Oct 07 2017 00:14:51 GMT+0530 (IST) , EPA Toxic & Greenhouse Gas Emissions Data ,52, united states- pollution- demographics- ,"Context This dataset includes the 2010-2014 ""Facility-Level"" emissions data combined with geographical & industry-related data.  It is based on the EPA's Toxic Release Inventory (TRI) & Greenhouse Gas Reporting Inventory (GHG) the national system of nomenclature that is used to describe the industry-related emissions. Although the EPA publishes and maintains the TRI & GHG report in various forms the combination of the two is not readily available. Hence this dataset.  Content The CSV has 28 columnar variables defined as   UniqueID Facility name Rank TRI '14 Rank GHG '14 Latitude Longitude Location address City State ZIP County FIPS code Primary NAICS Second primary NAICS Third primary NAICS Industry type Parent companies 2014 (GHG) Parent companies 2014 (TRI) TRI air emissions 14 (in pounds) TRI air emissions 13 [and previous years] GHG direct emissions 14 (in metric tons) GHG direct emissions 13 [and previous years] GHG Facility Id Second GHG Facility Id [and Third Fourth etc.] TRI Id Second TRI Id [and Third Fourth etc.] FRS Id Second FRS Id [and Third Fourth etc.]  Acknowledgements This dataset was made available by the Center for Public Integrity. ",Unique ID:FacilityName:Rank_TRI_14:Rank_GHG_14:Latitude:Longitude:LocationAddress:City:State:ZIP:County:FIPScode:PrimaryNAICS:SecondPrimaryNAICS:ThirdPrimaryNAICS:IndustryType:Parent_Companies_2014_GHG:Parent_Companies_2014_TRI:TRI_Air_Emissions_14_in_lbs:TRI_Air_Emissions_13_in_lbs:TRI_Air_Emissions_12_in_lbs:TRI_Air_Emissions_11_in_lbs:TRI_Air_Emissions_10_in_lbs:GHG_Direct_Emissions_14_in_metric_tons:GHG_Direct_Emissions_13_in_metric_tons:GHG_Direct_Emissions_12_in_metric_tons:GHG_Direct_Emissions_11_in_metric_tons:GHG_Direct_Emissions_10_in_metric_tons:GHG_ID:Second_GHG_ID:Third_GHG_ID:Fourth_GHG_ID:Fifth_GHG_ID:Sixth_GHG_ID:TRI_ID:Second_TRI_ID:Third_TRI_ID:Fourth_TRI_ID:Fifth_TRI_ID:FRS_ID:Second_FRS_ID:Third_FRS_ID:Fourth_FRS_ID:,numeric:string:numeric:numeric:numeric:numeric:string:string:string:numeric:string:numeric:numeric:numeric:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:numeric:string:string:string:,geographical information
Color terms dataset , Rachael Tatman , www.kaggle.com/rtatman/color-terms-dataset , Wed Jul 26 2017 02:42:51 GMT+0530 (IST) , Literal & figurative use of color terms and the colors of objects ,86, visual arts- linguistics- artificial intelligence- ,Context Color terms are interesting in natural language processing because it’s an area where it’s possible to link distributional semantics (models of word meanings based on which words are used together in texts) to things in the world. This dataset was created to help link semantic models to images. Content This dataset is made up of two smaller files but were both presented and discussed in the same paper (see Acknowledgements). All data in this dataset is in English. Concrete color terms This dataset contains a list of common items manually labeled with one of the 11 colors from the set black blue brown green grey orange pink purple red white yellow. Literal vs. nonliteral colors This dataset is made up of color adjective-noun phrases randomly drawn from the most frequent 8K nouns and 4K adjectives in the concatenated ukWaC Wackypedia and BNC corpora. These were tagged by consensus by two human judges as literal (white towel black feather) or nonliteral (white wine white musician green future). Some phrases had both literal and nonliteral uses such as blue book in “book that is blue” vs. “automobile price guide”. In these cases only the most common sense (according to the judges) was taken into account for the present experiment. The dataset consists of 370 phrases. Acknowledgements If you use these datasets please cite Bruni E. G. Boleda M. Baroni N. K. Tran. 2012. Distributional semantics in technicolor. Proceedings of ACL 2012 pages 136-145 Jeju Island Korea. Inspiration  Are some colors used more often in a literal sense? Is there a relationship between how many objects are a given color and how often that color is used in a literal sense? Can you use the color of concrete and an image database of those objects to create an automatic color labeller? ,object:color:,string:string:,text analysis
NASA Astronauts 1959-Present , NASA , www.kaggle.com/nasa/astronaut-yearbook , Wed Mar 08 2017 20:35:22 GMT+0530 (IST) , Which American astronaut has spent the most time in space? ,431, space- astronauts- employment- ,"Context The term ""astronaut"" derives from the Greek words meaning ""space sailor"" and refers to all who have been launched as crew members aboard NASA spacecraft bound for orbit and beyond. Content The National Aeronautics and Space Administration (NASA) selected the first group of astronauts in 1959. From 500 candidates with the required jet aircraft flight experience and engineering training in addition to a height below 5 feet 11 inches seven military men became the nation's first astronauts. The second and third groups chosen included civilians with extensive flying experience. By 1964 requirements had changed and emphasis was placed on academic qualifications; in 1965 six scientist astronauts were selected from a group of 400 applicants who had a doctorate or equivalent experience in the natural sciences medicine or engineering. The group named in 1978 was the first of space shuttle flight crews and fourteen groups have been selected since then with a mix of pilots and mission specialists. There are currently 50 active astronauts and 35 management astronauts in the program; 196 astronauts have retired or resigned and 49 are deceased (as of April 2013). Acknowledgements This dataset was published by the National Aeronautics and Space Administration as the ""Astronaut Fact Book"" (April 2013 edition). Active astronauts' mission names and flight statistics were updated from the NASA website. Inspiration Which American astronaut has spent the most time in space? What university has produced the most astronauts? What subject did the most astronauts major in at college? Have most astronauts served in the military? Which branch? What rank did they achieve?",Name:Year:Group:Status:Birth Date:Birth Place:Gender:Alma Mater:Undergraduate Major:Graduate Major:Military Rank:Military Branch:Space Flights:Space Flight (hr):Space Walks:Space Walks (hr):Missions:Death Date:Death Mission:,string:numeric:numeric:string:dateTime:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:string:string:string:,
Extinct Languages , The Guardian , www.kaggle.com/the-guardian/extinct-languages , Wed Dec 07 2016 21:16:29 GMT+0530 (IST) , Number of endangered languages in the world and their likelihood of extinction ,1211, languages- linguistics- ,"Context A recent Guardian blog post asks ""How many endangered languages are there in the World and what are the chances they will die out completely?"" The United Nations Education Scientific and Cultural Organisation (UNESCO) regularly publishes a list of endangered languages using a classification system that describes its danger (or completion) of extinction.  Content The full detailed dataset includes names of languages number of speakers the names of countries where the language is still spoken and the degree of endangerment. The UNESCO endangerment classification is as follows  Vulnerable most children speak the language but it may be restricted to certain domains (e.g. home) Definitely endangered children no longer learn the language as a 'mother tongue' in the home Severely endangered language is spoken by grandparents and older generations; while the parent generation may understand it they do not speak it to children or among themselves Critically endangered the youngest speakers are grandparents and older and they speak the language partially and infrequently Extinct there are no speakers left  Acknowledgements Data was originally organized and published by The Guardian and can be accessed via this Datablog post.  Inspiration  How can you best visualize this data? Which rare languages are more isolated (Sicilian for example) versus more spread out? Can you come up with a hypothesis for why that is the case? Can you compare the number of rare speakers with more relatable figures? For example are there more Romani speakers in the world than there are residents in a small city in the United States? ",ID:Name in English:Name in French:Name in Spanish:Countries:Country codes alpha 3:ISO639-3 codes:Degree of endangerment:Alternate names:Name in the language:Number of speakers:Sources:Latitude:Longitude:Description of the location:,numeric:string:string:string:string:string:string:string:string:string:numeric:string:numeric:numeric:string:,history
Vehicle Collisions in NYC 2015-Present , NYPD , www.kaggle.com/nypd/vehicle-collisions , Thu Mar 09 2017 10:44:51 GMT+0530 (IST) , Where are the most pedestrians struck by vehicles in New York City? ,1141, walking- road transport- ,Content The motor vehicle collision database includes the date and time location (as borough street names zip code and latitude and longitude coordinates) injuries and fatalities vehicle number and types and related factors for all 65500 collisions in New York City during 2015 and 2016. Acknowledgements The vehicle collision data was collected by the NYPD and published by NYC OpenData.,UNIQUE KEY:,numeric:,accidents
Vegetarian & Vegan Restaurants , Datafiniti , www.kaggle.com/datafiniti/vegetarian-vegan-restaurants , Thu Nov 17 2016 08:40:02 GMT+0530 (IST) , A list of over 18000 restaurants that serve vegetarian or vegan food in the US. ,658, food and drink- ,About This Data This is a list of over 18000 restaurants in the US that serve vegetarian or vegan food.  The data is provided by Datafiniti's Business Database. Data includes address city state business name business categories menu data phone numbers and more. The data in this data set was used to determine the most vegetarian and vegan-friendly cities in the US. About Datafiniti Datafiniti provides instant access to web data.  We compile data from thousands of websites to create standardized databases of business product and property information.  Learn more. Want More? If you're interested in more data like this please contact us.,,,real estate
Hacker News Posts , Hacker News , www.kaggle.com/hacker-news/hacker-news-posts , Tue Sep 27 2016 08:44:41 GMT+0530 (IST) , Hacker News posts from the past 12 months (including # of votes and comments) ,554, news agencies- internet- ,This data set is Hacker News posts from the last 12 months (up to September 26 2016).  It includes the following columns  title title of the post (self explanatory) url the url of the item being linked to num_points the number of upvotes the post received num_comments the number of comments the post received author the name of the account that made the post created_at the date and time the post was made (the time zone is Eastern Time in the US)  One fun project suggestion is a model to predict the number of votes a post will attract. The scraper is written so I can keep this up-to-date and add more historical data. I can also scrape the comments. Just make the request in this dataset's forum. The is a fork of minimaxir's HN scraper (thanks minimaxir) https//github.com/minimaxir/get-all-hacker-news-submissions-comments,id:url:num_points:num_comments:author:created_at:title:,numeric:string:numeric:numeric:string:dateTime:string:,social media
Election Day Tweets , Ed King , www.kaggle.com/kinguistics/election-day-tweets , Sun Nov 27 2016 04:31:06 GMT+0530 (IST) , Tweets scraped from Twitter on November 8 2016 ,559, politics- internet- ,"Tweets scraped by Chris Albon on the day of the 2016 United States elections. Chris Albon's site only posted tweet IDs rather than full tweets. We're in the process of scraping the full information but due to API limiting this is taking a very long time. Version 1 of this dataset contains just under 400k tweets about 6% of the 6.5 million originally posted. This dataset will be updated as more tweets become available. Acknowledgements The original data was scraped by Chris Albon and tweet IDs were posted to his Github page. The Data Since I (Ed King) used my own Twitter API key to scrape these tweets this dataset contains a couple of fields with information on whether I have personally interacted with particular users or tweets. Since Kaggle encouraged me to not remove any data from a dataset I'm leaving it in; feel free to build a classifier of the types of users I follow. The dataset consists of the following fields  text text of the tweet created_at date and time of the tweet geo a JSON object containing coordinates [latitude longitude] and a `type' lang Twitter's guess as to the language of the tweet place a Place object from the Twitter API coordinates a JSON object containing coordinates [longitude latitude] and a `type'; note that coordinates are reversed from the geo field user.favourites_count number of tweets the user has favorited user.statuses_count number of statuses the user has posted user.description the text of the user's profile description user.location text of the user's profile location user.id unique id for the user user.created_at when the user created their account user.verified bool; is user verified? user.following bool; am I (Ed King) following this user? user.url the URL that the user listed in their profile (not necessarily a link to their Twitter profile) user.listed_count number of lists this user is on (?) user.followers_count number of accounts that follow this user user.default_profile_image bool; does the user use the default profile pic? user.utc_offset positive or negative distance from UTC in seconds user.friends_count number of accounts this user follows user.default_profile bool; does the user use the default profile? user.name user's profile name user.lang user's default language user.screen_name user's account name user.geo_enabled bool; does user have geo enabled? user.profile_background_color user's profile background color as hex in format ""RRGGBB"" (no '#') user.profile_image_url a link to the user's profile pic user.time_zone full name of the user's time zone id unique tweet ID favorite_count number of times the tweet has been favorited retweeted is this a retweet? source if a link where is it from (e.g. ""Instagram"") favorited have I (Ed King) favorited this tweet? retweet_count number of times this tweet has been retweeted  I've also included a file called bad_tweets.csv  which includes all of the tweet IDs that could not be scraped along with the error message I received while trying to scrape them. This typically happens because the tweet has been deleted the user has deleted their account (or been banned) or the user has made their tweets private. The fields in this file are id and exception.response.",,,social media
Subreddit Interactions for 25000 Users , colemaclean , www.kaggle.com/colemaclean/subreddit-interactions , Sun Feb 19 2017 19:46:06 GMT+0530 (IST) , Modeling Reddit users from their metadata ,122, sociology- internet- ,Context The dataset is a csv file compiled using a python scrapper developed using Reddit's PRAW API. The raw data is a list of 3-tuples of [usernamesubredditutc timestamp]. Each row represents a single comment made by the user representing about 5 days worth of Reddit data. Note that the actual comment text is not included only the user subreddit and comment timestamp of the users comment. The goal of the dataset is to provide a lens in discovering user patterns from reddit meta-data alone. The original use case was to compile a dataset suitable for training a neural network in developing a subreddit recommender system. That final system can be found here A very unpolished EDA for the dataset can be found here. Note the published dataset is only half of the one used in the EDA and recommender system to meet kaggle's 500MB size limitation. Content user - The username of the person submitting the comment  subreddit - The title of the subreddit the user made the comment in  utc_stamp - the utc timestamp of when the user made the comment   Acknowledgements The dataset was compiled as part of a school project. The final project report with my collaborators can be found here Inspiration We were able to build a pretty cool subreddit recommender with the dataset. A blog post for it can be found here and the stand alone jupyter notebook for it here. Our final model is very undertuned so there's definitely improvements to be made there but I think there are many other cool data projects and visualizations that could be built from this dataset. One example would be to analyze the spread of users through the Reddit ecosystem whether the average user clusters in close communities or traverses wide and far to different corners. If you do end up building something on this please share! And have fun! Released under Reddit's API licence,username:subreddit:utc:,string:string:numeric:,social media
Starcraft: Scouting The Enemy , Ed King , www.kaggle.com/kinguistics/starcraft-scouting-the-enemy , Mon Nov 07 2016 06:47:09 GMT+0530 (IST) , Limited reconnaissance in a real-time strategy game ,194, video games- ,This dataset contains information on player reconnaissance in over 500 professional-level Starcraft games. From the perspective of one player (the Terran) it contains information on how many enemy (Protoss) units the player has observed can observe has seen destroyed etc. along with an overall measure of how much enemy territory the player can see.  Acknowledgements This dataset was downloaded from this webpage. It was the basis for the following paper Hostetler J. Dereszynski E. Dietterich T. and Fern A. (2012). Inferring strategies from limited reconnaissance in real-time strategy games. Proc. 28th Conference on Uncertainty in Artificial Intelligence (UAI 2012) (to appear). The Data Games are divided into 30 second chunks with the first 7 minutes of each game being represented in this dataset. Values of variables at any given time cycle represent their values over the entire chunk that ends at that time. This dataset contains the following fields  game a unique identifier for the game being played cycle the cycle (in game frames which are typically 24 fps) unit the enemy unit that this row gives info for losses how many of this enemy unit were lost during this time chunk? observable-units how many of this enemy unit could the player see during this time chunk? observed-losses how many of this enemy did the player observe being lost during this time chunk? production how many of this enemy unit became observable (i.e. was produced or -- in the case of buildings -- was under construction) during this time chunk? scouting how many of this enemy unit did the player scout during this time chunk? vision what proportion of the total enemy territory could the player observe during this time chunk? -- NOTE that vision appears once per unit; however the vision variable is not linked to any one unit. Its value spans the time chunk and is identical in every row that represents a given time chunk ,,,sports teams and players
Bible Verses from King James Version , Brian Liao , www.kaggle.com/phyred23/bibleverses , Thu Mar 16 2017 06:31:43 GMT+0530 (IST) , Text of Bible by book chapter and verse ,141, religious faiths traditions and movements- ,"Context On qxczv.pw a 4chan styled board an anon posted the whole Bible in King James Version. I chose to scrape it and format it into a Bible data set. Content Data is in CSV in the format citation book chapter verse text. For example citation Genesis 11 book Genesis chapter 1 verse 1 text ""In the beginning God created the heaven and the earth. "" Acknowledgements I'd like to thank qxczv.pw Andrew Palmer Jessica Butterfield Gary Handwerk Brian Wurtz and the whole Lake Washington High School. Papa Bless. Inspiration I am unsure what data can be analysis from this data set but am thinking graphing distributions of words or running natural language processing on this could be interesting. Send me a pm if you have any ideas.",citation:book:chapter:verse:text:,string:string:numeric:numeric:string:,books and comics
Who starts and who debunks rumors , Armineh Nourbakhsh , www.kaggle.com/arminehn/rumor-citation , Mon Mar 27 2017 20:32:32 GMT+0530 (IST) , Webpages cited by rumor trackers ,262, linguistics- sociology- ,"Context Emergent.info was a major rumor tracker created by veteran journalist Craig Silverman. It has been defunct for a while but its well-structured format and well-documented content provides an opportunity for analyzing rumors on the web.  Snopes.com is one of the oldest rumors trackers on the web. Originally launched by Barbara and David Mikkelson it is now run by a team of editors who investigate urban legends myths viral rumors and fake news. The investigators try to provide a detailed explanation for why they have chosen to confirm or debunk a rumor often citing several web pages and other external sources.  Politifact.com is a fact-checker that is focused on statements made by politicians and claims circulated by political campaigns blogs and similar websites. Politifact's labels range from ""true"" to ""pants on fire!""    Content This dataset consists of three files. One file is a collection of all webpages cited in Emergent.info and the second is a collection of webpages cited in Snopes.com and the third is a similar collection from Politifact.com. The webpages were often cited because they had started a rumor shared a rumor or debunked a rumor.  Emergent.info Emergent.info often provides a clean timeline of the rumor's propagation on the web and identifies which page was for the rumor which page was against it and which page was simply observing it. Please refer to the image below to learn more about the fields in this dataset.  Snopes.com The structure of posts on Snopes.com is not as well-defined. Please refer to the image below to learn more about the fields in the Snopes dataset.  Politifact.com Similar to Emergent.info Politifact.com follows a well-structured format in reporting and documenting rumors. There is a sidebar on the right side of each page that lists all of the sources cited within the page. The top link is the likeliest to be the original source of the rumor. For this link page_is_first_citation is set to true.    Inspiration I created this dataset in order to study domains that frequently start propagate or debunk rumors. By studying these domains and people who follow them I hope to gain some insight into the dynamics of rumor propagation on the web as well as social media.   Notes/Disclaimer When using the Snopes dataset please keep the following in mind   In addition to debunking rumors Snopes.com occasionally reports news and other types of content. This collection only includes data from ""Fact Check"" posts on Snopes. Snopes.com was launched years ago. Some of the older posts on the website do not follow the current format of the site therefore some of the fields might be missing. Snopes.com used to use a service named ""DoNotLink.com"" for citation purposes. That service is no longer active and as a result some of the links are missing from older posts on Snopes.  In addition some of the shortened links would time-out prior to resolution in which case they would not be added to the dataset.  Occasionally a website that has been cited has not maliciously started a rumor. For instance Andy Borowitz is a humorist who writes for The New Yorker. His satirical column is sometimes mistaken for real news; as a result The New Yorker may be cited as a source of fake news on Snopes.com. This does not mean that The New Yorker is a fake news website.  When using the Politifact dataset please keep the following in mind  The data included in this dataset are collected from the ""truth-o-meter"" page of Politifact.com. Politifact often fact-checks statements made by politicians. Since this dataset is focused on websites I have ignored all the posts in which the rumor was attributed to a person a political party a campaign or an organization. Instead I have only included rumors attributed explicitly to websites or blogs.    Useful Tips for Using the Snopes collection As opposed to the Emergent collection where each page is flagged with whether it was for or against a rumor no such information is available for the Snopes dataset. To avoid manually labeling the data you may use the following heuristics to identify which page started a rumor  Webpages that are cited in the ""Examples"" section of a post are often ""observing"" the rumor i.e. they have not started it but they are repeating it. In the snopes.csv file these webpages have been flagged as ""page_is_example."" Webpages that are cited in the ""Featured Image"" section of a post are often not related to the rumor. The editors on Snopes have simply extracted an image from those pages to embed in their posts. In the snopes.csv file these webpages have been flagged as ""page_is_image_credit."" Webpages that are cited through a secondary service (such as archive.is) are likelier to be rumor-propagators. Editors do not link to them directly so that a record of their page is available even if it is later deleted. If neither of these hints help very often (but not always) the first link cited on the page (for which ""page_is_example"" and ""page_is_image_credit"" are false) is the link to a page that started the rumor. This link is identified by the ""page_is_first_citation"" field. Pages for which both ""page_is_first_citation"" and ""page_is_archived"" are true are very likely to be rumor propagators.  To identify satirical websites that are mistaken for real news it's useful to inspect the way they are cited on Snopes. To demonstrate that a website contains satire or humor Snopes writers often cite the ""about us"" page of the site. Therefore it's useful to  see which domains often contain a URI to their ""about"" page (e.g. ""http//politicops.com/about-us/""). ",emergent_page:claim:claim_description:claim_label:tags:claim_source_domain:claim_course_url:date:body:page_domain:page_url:page_headline:page_position:page_shares:page_order:,string:string:string:string:string:string:string:dateTime:string:string:string:string:string:numeric:numeric:,online information
Ae. aegypti and Ae. albopictus occurrences , Dryad Digital Repository , www.kaggle.com/dryad/ae-aegypti-and-ae-albopictus-occurrences , Sat Oct 15 2016 04:07:24 GMT+0530 (IST) , Ocurrences of the mosquitos that transmit Zika ,367, diseases- epidemiology- animals- ,Aedes aegypti and Ae. albopictus are the main vectors transmitting dengue and chikungunya viruses. Despite being pathogens of global public health importance knowledge of their vectors’ global distribution remains patchy and sparse.  A global geographic database of known occurrences of Ae. aegypti and Ae. albopictus between 1960 and 2014 was compiled. The database which comprises occurrence data linked to point or polygon locations was derived from peer-reviewed literature and unpublished studies including national entomological surveys and expert networks. The authors describe all data collection processes as well as geo-positioning methods database management and quality-control procedures in their 2015 paper cited below.  This is the first comprehensive global database of Ae. aegypti and Ae. albopictus occurrence consisting of 19930 and 22137 geo-positioned occurrence records respectively. The dataset can be used for a variety of mapping and spatial analyses of the vectors and by inference the diseases they transmit. Citations Kraemer MUG Sinka ME Duda KA Mylne A Shearer FM Brady OJ Messina JP Barker CM Moore CG Carvalho RG Coelho GE Van Bortel W Hendrickx G Schaffner F Wint GRW Elyazar IRF Teng H Hay SI (2015) The global compendium of Aedes aegypti and Ae. albopictus occurrence. Scientific Data 2(7) 150035. http//dx.doi.org/10.1038/sdata.2015.35 Kraemer MUG Sinka ME Duda KA Mylne A Shearer FM Brady OJ Messina JP Barker CM Moore CG Carvalho RG Coelho GE Van Bortel W Hendrickx G Schaffner F Wint GRW Elyazar IRF Teng H Hay SI (2015) Data from The global compendium of Aedes aegypti and Ae. albopictus occurrence. Dryad Digital Repository. http//dx.doi.org/10.5061/dryad.47v3c,,,diseases and epidemics
Electoral Integrity in 2016 US Election , Harvard University , www.kaggle.com/harvard-university/electoral-integrity , Thu Feb 09 2017 09:25:39 GMT+0530 (IST) , How did 700+ experts perceive the integrity of the presidential election? ,163, politics- ,Context Electoral integrity refers to international standards and global norms governing the appropriate conduct of elections. These standards have been endorsed in a series of authoritative conventions treaties protocols and guidelines by agencies of the international community and apply universally to all countries throughout the electoral cycle including during the pre-electoral period the campaign on polling day and in its aftermath. Content The Perceptions of Electoral Integrity (PEI) survey asks experts to evaluate elections according to 49 indicators grouped into eleven categories reflecting the whole electoral cycle. The PEI dataset is designed to provide a comprehensive systematic and reliable way to monitor the quality of elections worldwide. It includes disaggregated scores for each of the individual indicators summary indices for the eleven dimensions of electoral integrity and a PEI index score out of 100 to summarize the overall integrity of the election. Acknowledgements This study was conducted by Pippa Norris Alessandro Nai and Max Grömping for Harvard University's Electoral Integrity Project.,Election Year:Expert ID:State:Sex:Age Range:Politician:Candidate:Activist:Monitor:Election Official:Voter:Citizen:Political Scale:Candidate Supported:Perceptions of Electoral Integrity Index:State Electoral Integrity:National Electoral Integrity:Laws Discriminated:Laws Favored Incumbent:Laws Restricted Citizen Rights:Electoral Laws Index:Election Managed Well:Voting Information Available:Election Officials Fair:Election Followed Law:Election Procedures Index:Boundaries Discriminated:Boundaries Favored Incumbent:Boundaries Impartial:Voting District Boundaries Index:Citizens Not Found in Register:Register Inaccurate:Ineligible Voters Registered:Voter Registration Index:Opposition Prevented:Women Provided Opportunity:Leaders Selected Candidates:Campaign Rallies Restricted:Party/Candidate Registration Index:Newspapers Balanced:Television Favored Incumbent:Media Access Fair:Media Coverage Fair:Social Media Exposed Fraud:Media Coverage Index:Subsidy Access Fair:Donation Access Fair:Campaign Accounts Transparent:Elections Bought by Rich:Resources Improperly Used:Campaign Finance Index:Voters Threatened with Violence:Fradulent Votes Cast:Voting Process Easy:Choice of Candidates:Postal Ballots Available:Disabled Provided Access:Expatriates Able to Vote:Internet Ballots Available:Voting Process Index:Ballot Boxes Secure:Results Announced Without Delay:Vote Count Fair:International Monitors Restricted:Domestic Monitors Restricted:Vote Count Index:Results Challenged:Protests Peaceful:Protests Violent:Dispute Resolved in Courts:Election Results Index:Authorities Impartial:Information Distributed:Authorities Scrutinized:Authorities Performed Well:Electoral Authorities Index:Election Rigged:Deadlines Restrictive:Voters Waited:Voters Intimidated:Multiple Ballots Cast:Machines Accurate:Records Secure:Votes Counted Quickly:Outcome Reflected Popular Will:,numeric:numeric:string:string:string:string:string:string:string:string:numeric:numeric:numeric:string:numeric:numeric:numeric:string:string:string:numeric:string:string:string:string:numeric:string:string:string:numeric:string:string:string:numeric:string:string:string:string:numeric:string:string:string:string:string:numeric:string:string:string:string:string:numeric:string:string:string:string:string:string:string:string:numeric:string:string:string:string:string:numeric:string:string:string:string:numeric:string:string:string:string:numeric:string:string:string:string:string:string:string:string:string:,elections
Independent Political Ad Spending (2004-2016) , Federal Election Commission , www.kaggle.com/fec/independent-political-ad-spending , Tue Nov 01 2016 07:45:02 GMT+0530 (IST) , Spending on political ads by independent (non-candidate) groups ,187, finance- politics- ,"What is an Independent Expenditure? Independent expenditures are what some refer to as ""hard money"" in politics -- spending on ads that specifically mention a candidate (either supporting or opposing). The money for these ads must come from PACs that are independent of the candidate and campaign and the PACs cannot coordinate with the candidate. The Federal Election Commission (FEC) collects information on independent expenditures to ensure payers' independence from candidates. What can we look at? I'm super interested to see how much spending has increased over the years. The FEC data only goes back to 2004 and it may be the case that the older data is spotty but I don't doubt that political spending has gone up in the past few years (the 2016 Presidential campaign reportedly involved the most political money since the 1970s). What does the data look like? This dataset includes a ton of information from the independent expenditure reports  committee_id  unique id of the PAC that made the payment committee_name  name of the PAC that made the payment report_year  the year the report was file report_type  one of 24 or 48; whether this is a 24-hour report or a 48-hour report image_number  unique id of the scanned image of the report line_number  line number in the report file_number  unique id of the report payee_name  who got paid payee_first_name  if an individual payee their first name payee_middle_name  if an individual payee their middle name payee_last_name  if an individual payee their last name payee_street_1  payee street address (1 of 2) payee_street_2  payee street address (2 of 2) payee_city  payee city payee_state  payee state payee_zip  payee ZIP code expenditure_description  a string describing the expenditure expenditure_date  when was this expenditure made? dissemination_date  when was the advertisement disseminated? expenditure_amount  how much was spent? office_total_ytd  how much has this PAC spent on this office year-to-date? category_code  category of the expenditure (need to find categories!) category_code_full  category of the expenditure (need to find categories!) support_oppose_indicator  one of S or O; whether the ad is in support of or opposition to the candidate memo_code  memo_code_full  candidate_id  unique id of the candidate candidate_name  name of the candidate candidate_prefix  title or prefix of the candidate candidate_first_name  first name of the candidate candidate_middle_name  middle name of the candidate candidate_last_name  last name of the candidate candidate_suffix  suffix of the candidate's name candidate_office  office that the candidate is running for -- one of P (President) S (Senate) or H (House) cand_office_state  if House or Senate race in what state? cand_office_district  if House or Senate race in what district? conduit_committee_id  conduit_committee_name  conduit_committee_street1  conduit_committee_street2  conduit_committee_city  conduit_committee_state  conduit_committee_zip  election_type  one of P (primary) or G (general) election_type_full  an id comprising the election type and the year with no delimiter independent_sign_name  independent_sign_date  notary_sign_name  notary_sign_date  notary_commission_expiration_date  back_reference_transaction_id  back_reference_schedule_name  filer_first_name   filer_middle_name  filer_last_name  transaction_id  unique id identifying the transaction original_sub_id  action_code  action_code_full  schedule_type_full  filing_form  link_id  sub_id  payee_prefix  payee_suffix  is_notice  memo_text  filer_prefix  filer_suffix  schedule_type  pdf_url  link to the scanned form ",,,politics
Ebola Cases 2014 to 2016 , LiamLarsen , www.kaggle.com/kingburrito666/ebola-cases , Mon Apr 24 2017 01:14:22 GMT+0530 (IST) , Ebola data in record format with indicator country date and value ,260, diseases- epidemiology- human medicine- ,from Aug 29 2014 - Mar 23 2016 Content  indicator  36 DISTINCT Country 12 DISTINCT Date 259 DISTINCT Value > 1000  Acknowledgements Original source https//data.humdata.org/dataset/ebola-cases-2014,Indicator:Country:Date:value:,string:string:dateTime:numeric:,diseases and epidemics
Minneapolis Incidents & Crime , Megan Risdal , www.kaggle.com/mrisdal/minneapolis-incidents-crime , Sat Aug 20 2016 21:49:01 GMT+0530 (IST) , What's been goin' on in Minneapolis MN (2010 to 2016) ,743, crime- ,"Thinking of making a move to the lovely Twin Cities? First check out this dataset (curtesy of Open Data Minneapolis) before you pack your bags for the ""Little Apple."" The datasets included contain information about 311 calls and crimes committed between 2010 to 2016 which will help you convince your friends family and loved ones that Minneapolis is the place to be (or not). Snow plow noise complaints be darned!",,,
Refugees in the United States 2006-2015 , Department of Homeland Security , www.kaggle.com/dhs/refugee-report , Fri Jan 20 2017 00:00:25 GMT+0530 (IST) , Where do most people granted refugee or asylum status come from? ,853, demographics- international relations- ,Context A refugee is a person outside his or her country of nationality who is unable or unwilling to return to his or her country of nationality because of persecution or a well-founded fear of persecution on account of race religion nationality membership in a particular social group or political opinion. An asylee is a person who meets the definition of refugee and is already present in the United States or is seeking admission at a port of entry. Refugees are required to apply for lawful permanent resident (“green card”) status one year after being admitted and asylees may apply for green card status one year after being granted asylum. Content The Office of Immigration Statistics (OIS) Annual Flow Reports on refugees and asylees contain information obtained from the Worldwide Refugee Admissions Processing System (WRAPS) of the Bureau of Population Refugees and Migration of the US Department of State on the numbers and demographic profiles of persons admitted to the United States as refugees and those granted asylum status during a given fiscal year.,Continent/Country of Nationality:2006:2007:2008:2009:2010:2011:2012:2013:2014:2015:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Museum of Modern Art Collection , The Museum of Modern Art , www.kaggle.com/momanyc/museum-collection , Wed Feb 15 2017 20:10:59 GMT+0530 (IST) , Title artist date and medium of every artwork in the MoMA collection ,408, museums- visual arts- ,Context The Museum of Modern Art (MoMA) acquired its first artworks in 1929 the year it was established. Today the Museum’s evolving collection contains almost 200000 works from around the world spanning the last 150 years. The collection includes an ever-expanding range of visual expression including painting sculpture printmaking drawing photography architecture design film and media and performance art. Content MoMA is committed to helping everyone understand enjoy and use our collection. The Museum’s website features 72706 artworks from 20956 artists. The artworks dataset contains 130262 records representing all of the works that have been accessioned into MoMA’s collection and cataloged in our database. It includes basic metadata for each work including title artist date medium dimensions and date acquired by the Museum. Some of these records have incomplete information and are noted as “not curator approved.” The artists dataset contains 15091 records representing all the artists who have work in MoMA's collection and have been cataloged in our database. It includes basic metadata for each artist including name nationality gender birth year and death year. Inspiration Which artist has the most works in the museum collection or on display? What is the largest work of art in the collection? How many pieces in the collection were made during your birth year? What gift or donation is responsible for the most artwork in the collection?,Artist ID:Name:Nationality:Gender:Birth Year:Death Year:,numeric:string:string:string:numeric:numeric:,visual arts
Cheltenham's Facebook Groups , Mike Chirico , www.kaggle.com/mchirico/cheltenham-s-facebook-group , Sat Aug 19 2017 19:15:31 GMT+0530 (IST) , Discover How a Community Leverages Facebook ,816, internet- ,Facebook is becoming an essential tool for more than just family and friends.  Discover how Cheltenham Township (USA) a diverse community just outside of Philadelphia deals with major issues such as the Bill Cosby trial everyday traffic issues sewer I/I problems and lost cats and dogs.  And yes theft.   Communities work when they're connected and exchanging information.  What and who are the essential forces making a positive impact and when and how do conversational threads get directed or misdirected?      Use Any Facebook Public Group You can leverage the examples here for any public Facebook group.  For an example of the source code used to collect this data and a quick start docker image take a look at the following project facebook-group-scrape.   Data Sources There are 4 csv files in the dataset with data from the following 5 public Facebook groups  Unofficial Cheltenham Township Elkins Park Happenings! Free Speech Zone Cheltenham Lateral Solutions Cheltenham Township Residents  post.csv These are the main posts you will see on the page.  It might help to take a quick look at the page.  Commas in the msg field have been replaced with {COMMA} and apostrophes have been replaced with {APOST}.   gid Group id (5 different Facebook groups)  pid  Main Post id id    Id of the user posting name  User's name timeStamp shares url msg  Text of the message posted.  likes Number of likes  comment.csv These are comments to the main post. Note Facebook postings have comments and comments on comments.    gid  Group id pid  Matches Main Post identifier in post.csv cid  Comment Id. timeStamp  id  Id of user commenting name  Name of user commenting rid   Id of user responding to first comment  msg  Message  like.csv These are likes and responses.  The two keys in this file (pidcid) will join to post and comment respectively.  gid Group id pid  Matches Main Post identifier in post.csv cid  Matches Comments id. response  Response such as LIKE ANGRY etc. id  The id of user responding name Name of the user responding  member.csv These are all the members in the group.  Some members never or rarely post or comment.  You may find multiple entries in this table for the same person.  The name of the individual never changes but they change their profile picture. Each profile picture change is captured in this table.  Facebook gives users a new id in this table when they change their profile picture.  gid Group id  id Id of the member name Name of the member url  URL of the member ,gid:pid:cid:timeStamp:id:name:rid:msg:,numeric:string:numeric:dateTime:numeric:string:string:string:,
News Articles , AsadMahmood , www.kaggle.com/asad1m9a9h6mood/news-articles , Sun Apr 30 2017 16:32:29 GMT+0530 (IST) , This dataset include articles from 2015 till date ,461, news agencies- journalism- linguistics- ,Content This Dataset is scraped from https//www.thenews.com.pk website. It has news articles from 2015 till date related to business and sports. It Contains the Heading of the particular Article Its content and its date. The content also contains the place from where the statement or Article was published. Importance This dataset can be used to detect main patterns between writing pattern of different types of articles. One more thing that can be extracted from it is that we could also detect the main locations from where the different types of articles originate. Improvements Some Data Cleaning could still be done specially in the content area of the dataset. One more thing that could be done is that we could extract the locations from the content and make a separated table for it. Acknowledgements I'd like to thanks developer of Selenium Library. That helped a lot in retrieving the data.,Article:Date:Heading:NewsType:,string:dateTime:string:string:,news
Executions in the United States 1976-2016 , Death Penalty Information Center , www.kaggle.com/usdpic/execution-database , Wed Jan 25 2017 03:10:14 GMT+0530 (IST) ," Use of capital punishment or ""death penalty"" in criminal justice system ",335, crime- law- ,Content The execution database includes records of every execution performed in the United States since the Supreme Court reinstated the death penalty in 1976. Federal executions are indicated by FE in the state field and included in the region in which the crime occurred. The information in this database was obtained from news reports the Department of Corrections in each state and the NAACP Legal Defense Fund. Acknowledgements The execution database was compiled and published by the Death Penalty Information Center. Victim details including quantity sex and race were acquired from the Criminal Justice Project's Death Row USA report.,,,court cases
US Unemployment Rate by County 1990-2016 , Jay Ravaliya , www.kaggle.com/jayrav13/unemployment-by-county-us , Tue May 23 2017 01:39:19 GMT+0530 (IST) , Thanks to the US Department of Labor's Bureau of Labor Statistics ,409, employment- ,Context This is a dataset that I built by scraping the United States Department of Labor's Bureau of Labor Statistics. I was looking for county-level unemployment data and realized that there was a data source for this but the data set itself hadn't existed yet so I decided to write a scraper and build it out myself. Content This data represents the Local Area Unemployment Statistics from 1990-2016 broken down by state and month. The data itself is pulled from this mapping site https//data.bls.gov/map/MapToolServlet?survey=la&map=county&seasonal=u Further the ever-evolving and ever-improving codebase that pulled this data is available here https//github.com/jayrav13/bls_local_area_unemployment Acknowledgements Of course a huge shoutout to bls.gov and their open and transparent data. I've certainly been inspired to dive into US-related data recently and having this data open further enables my curiosities. Inspiration I was excited about building this data set out because I was pretty sure something similar didn't exist - curious to see what folks can do with it once they run with it! A curious question I had was surrounding Unemployment vs 2016 Presidential Election outcome down to the county level. A comparison can probably lead to interesting questions and discoveries such as trends in local elections that led to their most recent election outcome etc. Next Steps Version 1 of this is as a massive JSON blob normalized by year / month / state. I intend to transform this into a CSV in the future as well.,Year:Month:State:County:Rate:,numeric:string:string:string:numeric:,jobs and employment
Wordgame , LouweAL , www.kaggle.com/anneloes/wordgame , Fri Jul 21 2017 19:55:08 GMT+0530 (IST) , 0.3M word-word associations scraped from 10 internet forums ,89, linguistics- internet- ,This dataset was created to as part of an ongoing research on what information about the human mind could be possibly hidden in word-word associations.  Inspiration Here are a few questions you might try to answer with this dataset  How well can we classify word pairs as originating from a specific online community? What are the properties of the graph/network of word associations? What are frequently used words? Are there differences among communities?  Content The data was scraped from 10 public internet forums. The data is anonymous (all usernames are converted to unique user IDs) and cleaned[script].  Most topics were still active at the time of scraping (june 2017) thus rescraping will result in a (slightly) bigger dataset. The dataset contains 4 columns {author word1 word2 source} where author is the person who wrote the second word as reaction to the first word. A word can also be a phrase or (in some cases) a sentence.,AC:,string:,text analysis
RxNorm Drug Name Conventions , National Library of Medicine , www.kaggle.com/nlm-nih/rxnorm-drug-name-conventions , Thu Jul 06 2017 03:58:25 GMT+0530 (IST) , A normalized naming system for clinical drugs ,74, linguistics- medicine- ,Context RxNorm was created by the U.S. National Library of Medicine (NLM) to provide a normalized naming system for clinical drugs defined as the combination of {ingredient + strength + dose form}. In addition to the naming system the RxNorm dataset also provides structured information such as brand names ingredients drug classes and so on for each clinical drug. Typical uses of RxNorm include navigating between names and codes among different drug vocabularies and using information in RxNorm to assist with health information exchange/medication reconciliation e-prescribing drug analytics formulary development and other functions. Content The full technical documentation is available here. Please note that the NLM updates RxNorm on a regular basis; you should assume that this version is out of date. Acknowledgements This dataset uses publicly available data from the U.S. National Library of Medicine (NLM) National Institutes of Health Department of Health and Human Services. Please cite this dataset as RxNorm META2016AB Full Update 2017_03_06 Bethesda MD National Library of Medicine Use this dataset with BigQuery You can use Kernels to analyze share and discuss this data on Kaggle but if you’re looking for real-time updates and bigger data check out the data on BigQuery too https//cloud.google.com/bigquery/public-data/rxnorm.,file:column name:data type:description:,string:string:string:string:,drugs and addiction
Facial Expression of Emotion , Javier Villanueva-Valle , www.kaggle.com/sivlemx/facial-expression-of-emotion , Thu Mar 09 2017 00:18:27 GMT+0530 (IST) , Frame-by-frame analysis of facial expressions in a video interview ,621, film- sociology- ,Context An interview was videotaped to analyze the facial expressions of emotion. This interview lasts for 2130 minutes. Content An interview with a duration of 2130 minutes was videotaped. Emotional facial expressions were analyzed every 0.12 seconds with FaceReader software. Emotions were neutral joy fear anger surprise fear and contemp positive-negative valences arousal degrees of head direction facial action units among others. Acknowledgements Acknowledgements to The Clinic of Borderline Personality Disorder for contributing the material also to the Laboratory of Chronoecology and Human Ethology. Inspiration How does the direction of the gaze relate to the expressions of emotions? From what score of any emotion is considered open closed and / or neutral in the right eye left eye right eyebrow and left eyebrow? In addition to descriptive statistical analyzes what other analyzes can be performed?,Video Time:Neutral:Happy:Sad:Angry:Surprised:Scared:Disgusted:Contempt:Valence:Arousal:Gender:Age:Beard:Moustache:Glasses:Ethnicity:Y - Head Orientation:X - Head Orientation:Z - Head Orientation:Quality:Mouth:Left Eye:Right Eye:Left Eyebrow:Right Eyebrow:Gaze Direction:Identity:Action Unit 01 - Inner Brow Raiser:Action Unit 02 - Outer Brow Raiser:Action Unit 04 - Brow Lowerer:Action Unit 05 - Upper Lid Raiser:Action Unit 06 - Cheek Raiser:Action Unit 07 - Lid Tightener:Action Unit 09 - Nose Wrinkler:Action Unit 10 - Upper Lip Raiser:Action Unit 12 - Lip Corner Puller:Action Unit 14 - Dimpler:Action Unit 15 - Lip Corner Depressor:Action Unit 17 - Chin Raiser:Action Unit 18 - Lip Puckerer:Action Unit 20 - Lip Stretcher:Action Unit 23 - Lip Tightener:Action Unit 24 - Lip Pressor:Action Unit 25 - Lips Part:Action Unit 26 - Jaw Drop:Action Unit 27 - Mouth Stretch:Action Unit 43 - Eyes Closed:Heart Rate:Stimulus:Event Marker:,dateTime:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:,videos
Rdatasets , Rachael Tatman , www.kaggle.com/rtatman/rdatasets , Wed Jul 12 2017 03:37:52 GMT+0530 (IST) , An archive of datasets distributed with different R packages ,81, statistics- programming languages- programming- ,Context Packages for the R programming language often include datasets. This dataset collects information on those datasets to make them easier to find. Content Rdatasets is a collection of 1072 datasets that were originally distributed alongside the statistical software environment R and some of its add-on packages. The goal is to make these data more broadly accessible for teaching and statistical software development. Acknowledgements This data was collected by Vincent Arel-Bundock @vincentarelbundock on Github. The version here was taken from Github on July 11 2017 and is not actively maintained. Inspiration In addition to helping find a specific dataset this dataset can help answer questions about what data is included in R packages. Are specific topics very popular or unpopular? How big are datasets included in R packages? What the naming conventions/trends for packages that include data? What are the naming conventions/trends for datasets included in packages? License This dataset is licensed under the  GNU General Public License .,Package:Item:Title:Rows:Cols:csv:doc:,string:string:string:numeric:numeric:string:string:,programming
White House Salaries , Adam Schroeder , www.kaggle.com/adamschroeder/white-house-salaries , Mon Jul 10 2017 09:40:05 GMT+0530 (IST) , Trump vs. Obama Administration ,249, income- politics- ,Context For democracy to function we need transparency. Part of the transparency is given to us through government salaries and names of employees. Since 1996 the White House has been required by Congress to disclose a list of staff and their salaries. Content The Obama_staff_salaries covers salaries under the Obama administration from 2009-2016 (by Julianna Langston).  The White_house_2017_salaries was released by the White House as a 16-page PDF detailing the salaries of Trump Administration's employees. This is a CSV scraped from the PDF using Tabula (by Carl V. Lewis). Acknowledgements I would like to thank @julilangston and @carblewis at data.world for providing these datasets. Inspiration How do WH staff salaries compare to Trump staff salaries?  How much did each administration spend on Immigration advisor/assistant staff?    Who has more executive assistants?    How did salaries under the Obama's administration change from 2009-2016?,name:status:salary:pay_basis:title:year:,string:string:string:string:string:numeric:,politics
SF Bay Area Pokemon Go Spawns , kveykva , www.kaggle.com/kveykva/sf-bay-area-pokemon-go-spawns , Thu Sep 15 2016 09:42:39 GMT+0530 (IST) , Find patterns in spawn location type and time ,699, video games- ,Pokemon Go type latitude longitude and despawn times - July 26 to July 28. This was an early mined dataset from Pokemon Go.  Representing a fairly large spatial area within a thin time frame. Mostly useful in identifying potential spatial patterns in pokemon spawns.,,,
The freeCodeCamp 2017 New Coder Survey , FreeCodeCamp , www.kaggle.com/free-code-camp/the-freecodecamp-2017-new-coder-survey , Fri May 26 2017 03:26:57 GMT+0530 (IST) , An open data survey of 20000+ people who are new to software development ,142, employment- computing and society- programming- ,Free Code Camp is an open source community where you learn to code and build projects for nonprofits. We surveyed more than 20000 people who started coding within the past 5 years. We reached them through the twitter accounts and email lists of various organizations that help people learn to code. Our goal was to understand these people's motivations in learning to code how they're learning to code their demographics and their socioeconomic background. We've written in depth about this dataset here https//medium.freecodecamp.com/we-asked-20-000-people-who-they-are-and-how-theyre-learning-to-code-fff5d668969,Age:,numeric:,programming
Airline Fleets , traceyvanp , www.kaggle.com/traceyvanp/airlinefleet , Thu Feb 09 2017 22:39:17 GMT+0530 (IST) , The top 100+ airlines and their fleet specifics. ,694, aviation- ,"Planespotters.net has a full database on airlines around the world and the airplanes that each owns and operates. This dataset collects the top 100+ airlines in the world (by the size of their fleet). It is combined with information found on Wikipedia on the respective airline's fleet and the average value/cost of the manufactured airplane. Updated January 2017. Dataset includes  Parent Airline i.e. International Airlines Group (IAG) Airline i.e. Iberia Aer Lingus British Airways...etc. which are owned by IAG Aircraft Type Manufacturer & Model Current Quantity of airplanes in Operation Future Quantity of airplanes on order from planespotter.net Order Quantity airplanes on order from Wikipedia Unit Cost Average unit cost ($M) of Aircraft Type as found by Wikipedia and various google searches Total Cost Current quantity * Unit Cost ($M) Average Age Average age of ""Current"" airplanes by ""Aircraft Type""  Sources Planespotters.net Wikipedia.org",Parent Airline:Airline:Aircraft Type:Current:Future:Historic:Total:Orders:Unit Cost:Total Cost (Current):Average Age:,string:string:string:numeric:string:numeric:numeric:string:string:string:numeric:,airways
Deceptive Opinion Spam Corpus , Rachael Tatman , www.kaggle.com/rtatman/deceptive-opinion-spam-corpus , Tue Jul 18 2017 22:01:06 GMT+0530 (IST) , A corpus of truthful and deceptive hotel reviews ,92, languages- linguistics- ,Context This corpus consists of truthful and deceptive hotel reviews of 20 Chicago hotels. The data is described in two papers according to the sentiment of the review. In particular we discuss positive sentiment reviews in [1] and negative sentiment reviews in [2]. While we have tried to maintain consistent data preprocessing procedures across the data there are differences which are explained in more detail in the associated papers. Please see those papers for specific details. Content This corpus contains  400 truthful positive reviews from TripAdvisor (described in [1]) 400 deceptive positive reviews from Mechanical Turk (described in [1]) 400 truthful negative reviews from Expedia Hotels.com Orbitz Priceline TripAdvisor and Yelp (described in [2]) 400 deceptive negative reviews from Mechanical Turk (described in [2])  Each of the above datasets consist of 20 reviews for each of the 20 most popular Chicago hotels (see [1] for more details). The files are named according to the following conventions Directories prefixed with fold correspond to a single fold from the cross-validation experiments reported in [1] and [2]. Hotels included in this dataset  affinia Affinia Chicago (now MileNorth A Chicago Hotel) allegro Hotel Allegro Chicago - a Kimpton Hotel amalfi Amalfi Hotel Chicago ambassador Ambassador East Hotel (now PUBLIC Chicago) conrad Conrad Chicago fairmont Fairmont Chicago Millennium Park hardrock Hard Rock Hotel Chicago hilton Hilton Chicago homewood Homewood Suites by Hilton Chicago Downtown hyatt Hyatt Regency Chicago intercontinental InterContinental Chicago james James Chicago knickerbocker Millennium Knickerbocker Hotel Chicago monaco Hotel Monaco Chicago - a Kimpton Hotel omni Omni Chicago Hotel palmer The Palmer House Hilton sheraton Sheraton Chicago Hotel and Towers sofitel Sofitel Chicago Water Tower swissotel Swissotel Chicago talbott The Talbott Hotel  References [1] M. Ott Y. Choi C. Cardie and J.T. Hancock. 2011. Finding Deceptive Opinion Spam by Any Stretch of the Imagination. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics Human Language Technologies. [2] M. Ott C. Cardie and J.T. Hancock. 2013. Negative Deceptive Opinion Spam. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics Human Language Technologies. Acknowledgements If you use any of this data in your work please cite the appropriate associated paper (described above). Please direct questions to Myle Ott (myleott@cs.cornell.edu).,deceptive:,boolean:,online reviews and ratings
Health Insurance Coverage , US Department of Health and Human Services , www.kaggle.com/hhs/health-insurance , Fri Mar 03 2017 00:10:23 GMT+0530 (IST) , Coverage rates before and after the Affordable Care Act ,859, health- ,Context The Affordable Care Act (ACA) is the name for the comprehensive health care reform law and its amendments which addresses health insurance coverage health care costs and preventive care. The law was enacted in two parts The Patient Protection and Affordable Care Act was signed into law on March 23 2010 by President Barack Obama and was amended by the Health Care and Education Reconciliation Act on March 30 2010. Content This dataset provides health insurance coverage data for each state and the nation as a whole including variables such as the uninsured rates before and after Obamacare estimates of individuals covered by employer and marketplace healthcare plans and enrollment in Medicare and Medicaid programs. Acknowledgements The health insurance coverage data was compiled from the US Department of Health and Human Services and US Census Bureau. Inspiration How has the Affordable Care Act changed the rate of citizens with health insurance coverage? Which states observed the greatest decline in their uninsured rate? Did those states expand Medicaid program coverage and/or implement a health insurance marketplace? What do you predict will happen to the nationwide uninsured rate in the next five years?,State:Uninsured Rate (2010):Uninsured Rate (2015):Uninsured Rate Change (2010-2015):Health Insurance Coverage Change (2010-2015):Employer Health Insurance Coverage (2015):Marketplace Health Insurance Coverage (2016):Marketplace Tax Credits (2016):Average Monthly Tax Credit (2016):State Medicaid Expansion (2016):Medicaid Enrollment (2013):Medicaid Enrollment (2016):Medicaid Enrollment Change (2013-2016):Medicare Enrollment (2016):,string:string:string:string:numeric:numeric:numeric:numeric:string:boolean:numeric:numeric:numeric:numeric:,Insurance
Eurovision YouTube Comments , Rachael Tatman , www.kaggle.com/rtatman/eurovision-youtube-comments , Thu Jul 20 2017 03:04:38 GMT+0530 (IST) , YouTube comments on entries from the 2003-2008 Eurovision Song Contests ,58, languages- music- linguistics- internet- ,Context The Eurovision Song Contest which originated in 1956 is present on YouTube through uploads of songs performed in the Contest. Any user can freely comment on these songs. This dataset is made of up a collection of comments made on four YouTube videos of Eurovision entries by Belgium. The comments are in a number of languages. Content The YouTube online forums associated with the Eurovision Song Contest have a large number of users from varied linguistic backgrounds who because of their interests in song performance are particularly attentive to language-related issues such as the accent of the performers and the choice of language of the songs. Commentaries are made by forum participants from disparate locations on a variety of topics one of the most prominent being language including language features and perceptions of language use. Acknowledgements This dataset was collected by Dejan Ivković for the purpose of linguistic research. If you made use of this data please cite the following article Ivković D. (2013). The Eurovision Song Contest on YouTube A corpus-based analysis of language attitudes. Language@Internet 10 article 1. (urnnbnde0009-7-35977) Inspiration  This dataset contains multiple languages. Can you identify and the language of each comment? Can you automatically find positive and negative comments about different country’s songs? Are some commenters more positive or more negative than others? ,name:comment:,string:string:,Online forums 
Speed Camera Violations in Chicago 2014-2016 , Chicago Police Department , www.kaggle.com/chicagopolice/speed-violations , Tue Sep 12 2017 23:47:36 GMT+0530 (IST) , Daily volume of speed limit violations recorded by cameras on Chicago streets ,276, crime- vehicles- ,Content This dataset reflects the daily volume of speed violations that have been recorded by each camera installed in the City of Chicago as part of the Automated Speed Enforcement Program. The data reflects violations that occurred from July 1 2014 until December 31 2016. The reported violations were collected by the camera and radar system and reviewed by two separate city contractors. This dataset contains all violations regardless of whether a citation was issued. Acknowledgements The speed camera data was collected and published by the Chicago Police Department on the City of Chicago data portal website. Inspiration What neighborhood has the highest density of speed cameras? Do speed cameras capture more violations on weekdays or weekends? Which camera has captured the most violations? Has the number of speed violations recorded decreased over time?,DATE:CAMERA ID:ADDRESS:VIOLATIONS:LATITUDE:LONGITUDE:LOCATION:,dateTime:string:string:numeric:numeric:numeric:string:,traffic violations
Hacker News Corpus , Hacker News , www.kaggle.com/hacker-news/hacker-news-corpus , Fri Jun 30 2017 01:46:20 GMT+0530 (IST) , A subset of all Hacker News articles ,168, news agencies- internet- ,"Context This dataset contains a randomized sample of roughly one quarter of all stories and comments from Hacker News from its launch in 2006. Hacker News is a social news website focusing on computer science and entrepreneurship. It is run by Paul Graham's investment fund and startup incubator Y Combinator. In general content that can be submitted is defined as ""anything that gratifies one's intellectual curiosity"". Content Each story contains a story ID the author that made the post when it was written and the number of points the story received. Please note that the text field includes profanity. All texts are the author’s own do not necessarily reflect the positions of Kaggle or Hacker News and are presented without endorsement. Acknowledgements This dataset was kindly made publicly available by Hacker News under the MIT license. Inspiration  Recent studies have found that many forums tend to be dominated by a very small fraction of users. Is this true of Hacker News? Hacker News has received complaints that the site is biased towards Y Combinator startups. Do the data support this?  Is the amount of coverage by Hacker News predictive of a startup’s success?  Use this dataset with BigQuery You can use Kernels to analyze share and discuss this data on Kaggle but if you’re looking for real-time updates and bigger data check out the data in BigQuery too https//cloud.google.com/bigquery/public-data/hacker-news The BigQuery version of this dataset has roughly four times as many articles.",title:,string:,news
Nutrition facts for Starbucks Menu , Starbucks , www.kaggle.com/starbucks/starbucks-menu , Fri Jul 21 2017 03:19:50 GMT+0530 (IST) , Nutrition information for Starbucks menu items including food and drinks ,519, food and drink- nutrition- ,Context Starbucks is an American coffee chain founded in Seattle. It serves both beverages and food.  Content This dataset includes the nutritional information for Starbucks’ food and drink menu items. All nutritional information for drinks are for a 12oz serving size. Acknowledgements Food composition data is in the public domain but product names marked with ® or ™ remain the registered trademarks of Starbucks. Inspiration  Can you train a Markov Chain to generate new Starbucks drink or food items? Can you design an easy-to-interpret visualization for the nutrition of each item? How to Starbucks menu items compare to McDonald’s menu items (see link to dataset below) in terms of nutrition?  You may also like  Nutrition Facts for McDonald's Menu  Starbucks Locations Worldwide  ,Beverage_category:Beverage:Beverage_prep:Calories: Total Fat (g):Trans Fat (g) :Saturated Fat (g): Sodium (mg): Total Carbohydrates (g) :Cholesterol (mg): Dietary Fibre (g): Sugars (g): Protein (g) :Vitamin A (% DV) :Vitamin C (% DV): Calcium (% DV) :Iron (% DV) :Caffeine (mg):,string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:numeric:,food and nutrition
Foodborne Disease Outbreaks 1998-2015 , Centers for Disease Control and Prevention , www.kaggle.com/cdc/foodborne-diseases , Wed Feb 15 2017 22:35:13 GMT+0530 (IST) , What contaminant has caused the most hospitalizations and fatalities? ,726, food and drink- public health- ,"Context Next time you take a bite consider this roughly one in six (or 48 million) people in the United States get sick from eating contaminated food per year. More than 250 pathogens and toxins have been known to cause foodborne illness and almost all of them can cause an outbreak. A foodborne disease outbreak occurs when two or more people get the same illness from the same contaminated food or drink. While most foodborne illnesses are not part of a recognized outbreak outbreaks provide important information on how germs spread which foods cause illness and how to prevent infection. Public health agencies in all 50 states the District of Columbia U.S. territories and Freely Associated States have primary responsibility for identifying and investigating outbreaks and use a standard form to report outbreaks voluntarily to CDC. During 1998–2008 reporting was made through the electronic Foodborne Outbreak Reporting System (eFORS). Content This dataset provides data on foodborne disease outbreaks reported to CDC from 1998 through 2015. Data fields include year state (outbreaks occurring in more than one state are listed as ""multistate"") location where the food was prepared reported food vehicle and contaminated ingredient etiology (the pathogen toxin or chemical that caused the illnesses) status (whether the etiology was confirmed or suspected) total illnesses hospitalizations and fatalities. In many outbreak investigations a specific food vehicle is not identified; for these outbreaks the food vehicle variable is blank. Inspiration Are foodborne disease outbreaks increasing or decreasing? What contaminant has been responsible for the most illnesses hospitalizations and deaths? What location for food preparation poses the greatest risk of foodborne illness?",Year:Month:State:Location:Food:Ingredient:Species:Serotype/Genotype:Status:Illnesses:Hospitalizations:Fatalities:,numeric:string:string:string:string:string:string:string:string:numeric:numeric:numeric:,diseases and epidemics
Ironic Corpus , Rachael Tatman , www.kaggle.com/rtatman/ironic-corpus , Tue Jul 25 2017 05:05:26 GMT+0530 (IST) , 1950 sentences labeled for ironic content ,52, languages- linguistics- ,"Context Irony in language is when a statement is produced with one meaning but the intended meaning is exactly the opposite. For instance someone who has burned toast might serve it and say ironically “it’s a little underdone”.  Automatically detecting when language is ironic is an especially difficult task in Natural Language Processing. Content This dataset contains 1950 comments which have been labeled as ironic (1) or not ironic (-1) by human annotators. The text was taken from Reddit comments. Acknowledgements This dataset and analysis of it is presented in the following paper. Wallace B. C. Do Kook Choe L. K. Kertz L. & Charniak E. (2014 April). Humans Require Context to Infer Ironic Intent (so Computers Probably do too). In ACL (2) (pp. 512-516). Url http//www.byronwallace.com/static/articles/wallace-irony-acl-2014.pdf Made possible by support from the Army Research Office (ARO) grant 64481-MA / W9111F-13-1-0406 ""Sociolinguistically Informed Natural Language Processing Automating Irony Detection"" Inspiration  Is irony more likely when discussing certain topics? Does ironic text tend to have more positive or more negative sentiment? What novel features can you develop to help detect irony? ",comment_text:label:,string:numeric:,text analysis
New Orlean's Slave Sales , Chris Crawford , www.kaggle.com/crawford/new-orleans-slave-sales , Thu Jul 13 2017 23:24:39 GMT+0530 (IST) , A dataset of 15377 slave sales from 1856 - 1861 ,149, slaves- history- ,"Context Abraham Lincoln's election produced Southern secession war and abolition. This dataset was used to study connections between news and slave prices for the period 1856-1861. By August 1861 slave prices had declined by roughly one-third from their 1860 peak. That decline was similar for all age and sex cohorts and thus did not reflect expected emancipation without compensation. The decision to secede reflected beliefs that the North would not invade and that emancipation without compensation was unlikely. Both were encouraged by Lincoln's conciliatory tone before the attack on Fort Sumter and subsequently dashed by Lincoln's willingness to wage all-out war.  Calomiris Charles W. and Jonathan Pritchett. 2016. ""Betting on Secession Quantifying Political Events Surrounding Slavery and the Civil War."" American Economic Review 106(1) 1-23.  Content Data description by Jonathan Pritchett These data were collected from the office of the Orleans parish Civil Clerk of Court. The sample includes all slave sales recorded by the register of conveyance from October 1856 to August 1861. The construction of the dataset is similar to that employed previously by Fogel and Engerman (1976). The unit of observation is the individual with the exception of children who were bundled with their mothers. Fields are defined as follows  ID number Unique observation number. Conveyance Number of Conveyance volume. Page Page number of transaction. Researcher Initials of research assistant who transcribed transaction. Notary First Name First name of public notary who recorded transaction. Notary Last Name Last name of public notary. Sales Date Sales date of transaction (MM/DD/YYYY format). This is NOT the date the sale was recorded in conveyance office. Sellers First Name Seller’s First Name. Sellers Last Name Seller’s Last Name. Sellers County of Origin Seller’s county (or city) of origin. Sellers State of Origin Seller’s state of origin. Representing Seller  Name of agent representing seller if seller is not present at time of sale (normally blank). Relationship to Seller Agent’s relationship to seller. Buyers First Name Buyer’s First Name. Buyers Last Name Buyer’s Last Name. Buyers County of Origin Buyer’s County (or city) of Origin. Buyers State of Origin Buyer’s State of Origin. Representing Buyer Name of agent representing buyer if buyer is not present at time of sale (normally blank). Relationship to Buyer Agent’s relationship to buyer. Slave Name Slave’s first name; rarely last name also listed. Sex Male (M) or female (F). Gender often inferred from sale record  such as Negro vs. Negress mulatto vs. mulattress etc. Age Age in years. Color Description of slave’s skin color but may also indicate ancestry (such as mulatto). Occupation Slave’s occupation – often blank. Family Relationship Describes family relationship of slaves (if any) sold in groups Name Child 1  Name of child 1 (sold with mother). Blank when slaves are listed separately and/or with separate prices. Sex Child 1  Gender of child 1 (sold with mother). Age Child 1 Age in years of child 1 (sold with mother). Decimal equivalents for age in months. Name Child 2 Name of child 2 (sold with mother). Blank when slaves are listed separately and/or with separate prices. Sex Child 2 Gender of child 2 (sold with mother). Age Child 2 Age in years of child 2 (sold with mother). Decimal equivalents for age in months. Name Child 3 Name of child 3 (sold with mother). Blank when slaves are listed separately and/or with separate prices. Sex Child 3 Gender of child 3 (sold with mother). Age Child 3 Age in years of child 3 (sold with mother). Decimal equivalents for age in months. Name Child 4 Name of child 4 (sold with mother). Blank when slaves are listed separately and/or with separate prices. Sex Child 4 Gender of child 4 (sold with mother). Age Child 4 Age in years of child 4 (sold with mother). Decimal equivalents for age in months. Name Child 5 Name of child 5 (sold with mother). Blank when slaves are listed separately and/or with separate prices Sex Child 5 Gender of child 5 (sold with mother). Age Child 5 Age in years of child 5 (sold with mother). Decimal equivalents for age in months. Name Child 6 Name of child 6 (sold with mother). Blank when slaves are listed separately and/or with separate prices Sex Child 6 Gender of child 6 (sold with mother). Age Child 6 Age in years of child 6 (sold with mother). Decimal equivalents for age in months. Name Child 7 Name of child 7 (sold with mother). Blank when slaves are listed separately and/or with separate prices. Sex Child 7 Gender of child 7 (sold with mother). Age Child 7 Age in years of child 7 (sold with mother). Decimal equivalents for age in months. Name Child 8  Name of child 8 (sold with mother). Blank when slaves are listed separately and/or with separate prices. Sex Child 8 Gender of child 8 (sold with mother). Age Child 8 Age in years of child 8 (sold with mother). Decimal equivalents for age in months. Guaranteed Yes or No. Most conveyance records omit this information (missing value). Notes on Guarantee Description of guarantee/flaw; reason why slave doesn’t have full guarantee. Number of Total Slaves Total number of slaves listed in transaction.  Number of Adult Slaves Total number of “principal” slaves – corresponds to the number of separate entries for each transaction. Recall that children (especially those under 10 years) were bundled with mothers. Number of Child Slaves Total number of children listed in transaction. Number of Prices Total number of prices listed in transaction. Price Price associated with slaves. For group sales with a single price only one price is listed for first slave and for other slaves entry is blank. Payment Method Cash or Credit. Sometimes “Cash and Credit” for credit sales with down payment. Also slave exchange typical result of redhibition    claim. Payment flag Description of payment schedule for credit sales. DUMMY credit 0 or 1 indicator for credit sales. Down Payment Number value of cash down payment for credit sales. mthcred Maximum length of credit (in months). Interest Rate Annual interest rate charged on credit sales. Discount Rate Calculated monthly discount rate. predicted rate Predicted monthly interest rate for credit sales without explicit interest rates. Calculations Intermediate calculation – please ignore. Ratio Intermediate calculation – please ignore. PresentValue Present value calculation for credit sales; blank for cash sales. DUMMY omission 0 or 1 indicator for omitting observation. Reason for Omission Reason for excluding observation from working sample. Comments Description of unusual characteristics for observation. DUMMY Estate Sale 0 or 1 indicator for estate sale.  Acknowledgements Calomiris Charles W. and Jonathan Pritchett. 2016. ""Betting on Secession Quantifying Political Events Surrounding Slavery and the Civil War."" American Economic Review 106(1) 1-23. DOI 10.1257/aer.20131483 This dataset was converted from XLSX to CSV Inspiration As a principal port New Orleans played a major role during the antebellum era in the Atlantic slave trade.  The authors of ""Betting on Secession Quantifying Political Events Surrounding Slavery and the Civil War."" did a fantastic job of putting this dataset together to learn more about the country's connections between slave trade and the American Civil War.",ID number:Conveyance:Page:Researcher:Notary First Name:Notary Last Name:Sales Date:Sellers First Name:Sellers Last Name:Sellers County of Origin:Sellers State of Origin:Representing Seller:Relationship to Seller:Buyers First Name:Buyers Last Name:Buyers County of Origin:Buyers State of Origin:Representing Buyer:Relationship to Buyer:Slave Name:Sex:Age:Color:Occupation:Family Relationship:Name Child 1:Sex Child 1:Age Child 1:Name Child 2:Sex Child 2:Age Child 2:Name Child 3:Sex Child 3:Age Child 3:Name Child 4:Sex Child 4:Age Child 4:Name Child 5:Sex Child 5:Age Child 5:Name Child 6:Sex Child 6:Age Child 6:Name Child 7:Sex Child 7:Age Child 7:Name Child 8:Sex Child 8:Age Child 8:Guaranteed:Notes on Guarantee:Number of Total Slaves:Number of Adult Slaves:Number of Child Slaves:Number of Prices:Price:Payment Method:Payment flag:DUMMY credit:Down Payment:mthcred:Interest Rate:Discount Rate:predicted rate:Calculations:Ratio:PresentValue:DUMMY omission:Reason for Omission:Comments:DUMMY Estate Sale:,numeric:numeric:numeric:string:string:string:dateTime:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:string:string:string:string:string:numeric:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:string:string:numeric:numeric:string:string:string:,history
Top 980 Starred Open Source Projects on GitHub , Chase Willden , www.kaggle.com/chasewillden/topstarredopensourceprojects , Sun Jun 25 2017 03:53:42 GMT+0530 (IST) , Which types of projects are the most popular on GitHub? ,158, internet- programming languages- programming- ,Context GitHub is the leader in hosting open source projects. For those who are not familiar with open source projects a group of developers share and contribute to common code to develop software. Example open source projects include Chromium (which makes Google Chrome) WordPress and Hadoop. Open source projects are said to have disrupted the software industry (2008 Kansas Keynote). Content For this study I crawled the leader in hosting open source projects GitHub.com and extracted a list of the top starred open source projects. On GitHub a user may choose the star a repository representing that they “like” the project. For each project I gathered the repository username or Organization the project resided in the repository name a description the last updated date the language of the project the number of stars any tags and finally the url of the project. Acknowledgements This data wouldn't be available if it weren't for GitHub. An example micro-study can be found at The Concept Center,Username:Repository Name:Description:Last Update Date:Language:Number of Stars:Tags:Url:,string:string:string:dateTime:string:string:string:string:,programming
StarCraft II Replay Analysis , Simon Fraser University - Summit , www.kaggle.com/sfu-summit/starcraft-ii-replay-analysis , Fri Nov 04 2016 23:57:22 GMT+0530 (IST) , In-Depth Look at StarCraft II Replays ,388, video games- ,Context This dataset is an aggregate of the screen-fixations from screen movements of StarCraft 2 replay files. Content This dataset contains 21 variables  GameID Unique ID for each game LeagueIndex 1-8 for Bronze Silver Gold Diamond Master GrandMaster Professional leagues Age Age of each player HoursPerWeek Hours spent playing per week TotalHours Total hours spent playing APM Action per minute SelectByHotkeys Number of unit selections made using hotkeys per timestamp AssignToHotkeys Number of units assigned to hotkeys per timestamp UniqueHotkeys Number of unique hotkeys used per timestamp MinimapAttacks Number of attack actions on minimal per timestamp MinimapRightClicks Number of right-clicks on minimal per timestamp NumberOfPACs Number of PACs per timestamp GapBetweenPACs Mean duration between PACs (milliseconds) ActionLatency Mean latency from the onset of PACs to their first action (milliseconds) ActionsInPAC Mean number of actions within each PAC TotalMapExplored Number of 24x24 game coordinate grids viewed by player per timestamp WorkersMade Number of SCVs drones probes trained per timestamp UniqueUnitsMade Unique units made per timestamp ComplexUnitsMade Number of ghosts investors and high templars trained per timestamp ComplexAbilityUsed Abilities requiring specific targeting instructions used per timestamp MaxTimeStamp Time stamp of game's last recorded event  Inspiration Questions worth exploring  How do the replay attributes differ by level of player expertise?  What are significant predictors of a player's league?  Acknowledgements This dataset is from Simon Fraser University - Summit and can be found here. You must give attribution to the work; You may not use this work for commercial purposes; You may not alter transform or build upon this work. Any further uses require the permission of the rights holder.,GameID:LeagueIndex:Age:HoursPerWeek:TotalHours:APM:SelectByHotkeys:AssignToHotkeys:UniqueHotkeys:MinimapAttacks:MinimapRightClicks:NumberOfPACs:GapBetweenPACs:ActionLatency:ActionsInPAC:TotalMapExplored:WorkersMade:UniqueUnitsMade:ComplexUnitsMade:ComplexAbilityUsed:MaxTimeStamp:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,video games
Colonia Corpus of Historical Portuguese , Rachael Tatman , www.kaggle.com/rtatman/colonia-corpus-of-historical-portuguese , Sat Jul 29 2017 04:54:49 GMT+0530 (IST) , A 5.1 million word corpus of historical Portuguese ,23, languages- literature- brazil- history- linguistics- ,Context Portuguese is a romance language that is the native language of over 215 million speakers worldwide. Like Spanish English and French it was the language of both its country of origin and also that country’s colonial possessions. This corpus contains examples of historical Portuguese  written between 1500 and 1936 both in Portugal and Brazil. Content The corpus contains complete Portuguese manuscripts published from 1500 to 1936 divided into 5 sub-corpora per century (summarized in the table below). The part of speech (POS) of words in this corpus was tagged using TreeTagger. You can find more information on this corpus on the Colonia homepage. Century Texts   Tokens 16th    13  399245 17th    18  709646 18th    14  425624 19th    38  2490771 20th    17  1132696 Total   100 5157982 Texts are balanced in terms of the variety consisting of 48 European Portuguese texts and 52 Brazilian Portuguese texts. You can find more information in the paper that describes the corpus. The complete inventory of texts is here and more detail regarding annotation can be found here. Part of Speech (POS) Tags The works in this corpus have been automatically tagged for their part of speech (POS). The tagset used to annotate the corpus is presented in the table below. It contains not only the classic POS tags (e.g. V DET N) but also a couple of compound tags such as the combination of preposition plus determiner as (PREP+DET) or verb plus pronoun (V+P). The tool used to annotate the corpus was TreeTagger. Category    POS Example Adjective   ADJ bonita Adverb  ADV muita Determiner  DET os Cardinal    CARD    primeiro Noun    NOM mesa Pronoun P   eles Preposition PRP de Verb    V   fazer Interjection    I   Oh! Commas  VIRG     Punctuation SENT    . Studies report that TreeTagger achieves performance higher than 95% accuracy in attributing the correct POS tag and lemma of a token. Acknowledgements If you use this corpus in your work please cite this paper Zampieri M. and Becker M. (2013) Colonia Corpus of Historical Portuguese. In ZSM Studien Special Volume on Non-Standard Data Sources in Corpus-Based Research. Volume 5. Shaker.  Inspiration  What changes have occurred in Portuguese over time? Have words changed? Syntactic structures? How grammatical agreement is expressed? Can you create a classifier which can classify the era and unseen work is from? Using the part of speech tags in this tagger can you train a new tagger and run it over the Brazilian Portuguese Literature Corpus linked below?  You may also like A 3.7 million word literary corpus of Brazilian Portugese,Author:Title:Year:Filename:Subcorpus:Tokens:,string:string:numeric:string:string:numeric:,history
Connecticut inmates awaiting trial , Connecticut Open Data , www.kaggle.com/Connecticut-open-data/connecticut-inmates-awaiting-trial , Thu Jul 27 2017 03:11:31 GMT+0530 (IST) , Inmates being held in correcitonal facilities until trial ,25, ,Context Since July 1 2016 Connecticut has updated this nightly dataset of every inmate held in jail while awaiting trial.  At the time of download this dataset contains just over one year of data with 1132352 rows of data where one row is one inmate. Content Field Descriptions * DOWNLOAD DATE Date in which the data were extracted and reflecting the population for that day.  IDENITIFIER Individual Inmate Identifier LATEST ADMISSION DATE Most recent date in which the inmate has been admitted. In some instances this may reflect an original date of admission to a correctional facility. Generally if a date is more than one year old an inmate should not be considered to have been held for the entire duration of that time. RACE Race of inmate AGE Age of inmate BOND AMOUNT Amount of bond for which the inmate is being held. In some instances for particularly low (less than $100) this bond amount may be considered a place holder value OFFENSE Controlling offense for which the bond amount has been set. FACILITY Department of Correction facility where the inmate is currently held. DETAINER Denotes whether inmate is being held at the request of another criminal justice agency or if another agency is to be notified upon release.  Acknowledgements Thanks to [http//dataispluralc.om] for the tip on this dataset!  This dataset was downloaded on July 26 2017 - Chekc the original source for more up-to-date data (updated nightly) [https//data.ct.gov/Public-Safety/Accused-Pre-Trial-Inmates-in-Correctional-Faciliti/b674-jy6w] Inspiration This dataset contains information about inmate's race and the nature of the crimes. The Minority Report is a sci-fi story pretty well known for predicting crimes and arresting people before they happen. Can you do the same? Would you dare do the same?,DOWNLOAD DATE:IDENTIFIER:LATEST ADMISSION DATE:RACE:GENDER:AGE:BOND AMOUNT:OFFENSE:FACILITY:DETAINER                                        :,dateTime:string:dateTime:string:string:numeric:numeric:string:string:string:,
Patent Litigations , US Patent and Trademark Office , www.kaggle.com/uspto/patent-litigations , Thu Jul 13 2017 21:10:47 GMT+0530 (IST) , Detailed Patent Litigation Data on 74k Cases 1963-2015 ,107, law- ,Context Achieving the appropriate balance of intellectual property (IP) protection through patent litigation is critical to economic growth. Examining the interplay between US patent law and economic effect is of great interest to many stakeholders. Published in March 2017 this dataset is the most comprehensive public body of information on USPTO patent litigation. Content The dataset covers over 74k cases across 52 years. Five different files (attorneys.csv cases.csv documents.csv names.csv pacer_cases.csv) detail the litigating parties their attorneys results locations and dates. The large documents.csv file covers more than 5 million relevant documents (a tool like split might be your friend here). Acknowledgements This data was collected by the Office of the Chief Economist at the USPTO. Data was collected from both the Public Access to Court Electronics Records (PACER) as well as RECAP an independent PACER repository. Further documentation available via this paper. Inspiration Patent litigation is a tug of war between patent holders competing parties using similar IP and government policy. Which industries see the most litigation? Any notable changes over time? Is there a positive (or negative) correlation between litigation and a company’s economic fortunes? License Public Domain Mark 1.0 Also see source.,case_row_id:case_number:party_row_count:party_type:attorney_row_count:name:contactinfo:position:,numeric:string:numeric:string:numeric:string:string:string:,court cases
Bus Breakdown and Delays NYC , saagie_anthony , www.kaggle.com/anthobau/busbreakdownanddelays , Fri Jul 21 2017 13:13:09 GMT+0530 (IST) , When and why a bus was delayed ? Bus delays 2015 to 2017 ,136, ,Context Bus Breakdown and Delays You can find the road where the traffic was heavy for the New York City Taxi Trip Duration playground.  Content The Bus Breakdown and Delay system collects information from school bus vendors operating out in the field in real time. Bus staff that encounter delays during the route are instructed to radio the dispatcher at the bus vendor’s central office. The bus vendor staff are then instructed to log into the Bus Breakdown and Delay system to record the event and notify OPT. OPT customer service agents use this system to inform parents who call with questions regarding bus service. The Bus Breakdown and Delay system is publicly accessible and contains real time updates. All information in the system is entered by school bus vendor staff. You can find data for years 2015 to 2017.,School_Year:Busbreakdown_ID:Run_Type:Bus_No:Route_Number:Reason:Schools_Serviced:Occurred_On:Created_On:Boro:Bus_Company_Name:How_Long_Delayed:Number_Of_Students_On_The_Bus:Has_Contractor_Notified_Schools:Has_Contractor_Notified_Parents:Have_You_Alerted_OPT:Informed_On:Incident_Number:Last_Updated_On:Breakdown_or_Running_Late:School_Age_or_PreK:,string:numeric:string:numeric:numeric:string:numeric:dateTime:dateTime:string:string:string:numeric:string:string:string:dateTime:string:dateTime:string:string:,traffic 
USA Income Tax Data by ZIP Code 2014 , williamnowak , www.kaggle.com/wpncrh/zip-code-income-tax-data-2014 , Tue Nov 15 2016 01:05:40 GMT+0530 (IST) , Distribution of income for 6 earning brackets ,997, geography- income- demographics- ,The Statistics of Income (SOI) division bases its ZIP code data on administrative records of individual income tax returns (Forms 1040) from the Internal Revenue Service (IRS) Individual Master File (IMF) system. Included in these data are returns filed during the 12-month period January 1 2015 to December 31 2015. While the bulk of returns filed during the 12-month period are primarily for Tax Year 2014 the IRS received a limited number of returns for tax years before 2014 and these have been included within the ZIP code data. There is data for more years here https//www.irs.gov/uac/soi-tax-stats-individual-income-tax-statistics-zip-code-data-soi See documentation file attached. Crucially ZIPCODE - 5-digit Zip code   AGI_STUB - Size of adjusted gross income 1 = $1 under $25000 2 = $25000 under $50000 3 = $50000 under $75000 4 = $75000 under $100000 5 = $100000 under $200000 6 = $200000 or more,STATEFIPS:STATE:zipcode:agi_stub:N1:mars1:MARS2:MARS4:PREP:N2:NUMDEP:TOTAL_VITA:VITA:TCE:A00100:N02650:N00200:A00200:N00300:A00300:N00600:A00600:N00650:A00650:N00700:A00700:N00900:A00900:N01000:A01000:N01400:A01400:N01700:A01700:SCHF:N02300:A02300:N02500:A02500:N26270:A26270:N02900:A02900:N03220:A03220:N03300:A03300:N03270:A03270:N03150:A03150:N03210:A03210:N03230:A03230:N03240:A03240:N04470:A04470:A00101:N18425:A18425:N18450:A18450:N18500:A18500:N18300:A18300:N19300:A19300:N19700:A19700:N04800:A04800:N05800:A05800:N09600:A09600:N05780:A05780:N07100:A07100:N07300:A07300:N07180:A07180:N07230:A07230:N07240:A07240:N07220:A07220:N07260:A07260:N09400:A09400:N85770:A85770:N85775:A85775:N09750:A09750:N10600:A10600:N59660:A59660:N59720:A59720:N11070:A11070:N10960:A10960:N11560:A11560:N06500:A06500:N10300:A10300:N85530:A85530:N85300:A85300:N11901:A11901:N11902:A11902:A02650:,numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
2016 US Presidential Debates , Megan Risdal , www.kaggle.com/mrisdal/2016-us-presidential-debates , Mon Oct 24 2016 08:43:26 GMT+0530 (IST) , Full transcripts of the face-off between Clinton & Trump ,2935, politics- political science- ,"Context In November the United States will elect a new president. Before then three presidential debates will take place between Hillary Clinton and Donald Trump as well as one vice presidential debate between Tim Kaine and Mike Pence. While you can watch the debates live why not also read deeply into the candidates' responses with text analytics? You can now answer any questions you have about the platforms of our presidential hopefuls or their speaking skills.  Which candidate is the most given to loquaciousness?  How many times does Clinton get interrupted? Who gets the most audience applause? When is positive sentiment at its highest during the candidates' word play?  Content & Acknowledgements For consistency full transcripts of the debates were all taken from The Washington Post who made annotated transcripts available following each debate  First debate taking place September 26th 2016 was obtained from The Washington Post.  The vice presidential debate from October 4th 2016 was similarly obtained here. The ""town hall"" presidential debate on October 9th is found here. The final presidential debate taking place on October 19th is found here.   Please make any dataset suggestions or requests on the forum. Word cloud from Debate Visualization by Jane Yu.",Line:Speaker:Text:Date:,numeric:string:string:dateTime:,politics
Atlas of Pidgin and Creole Language Structures , Rachael Tatman , www.kaggle.com/rtatman/atlas-of-pidgin-and-creole-language-structures , Fri Jul 28 2017 05:58:58 GMT+0530 (IST) , Information on 76 Creole and Pidgin Languages ,35, languages- linguistics- ,Context When groups of people who don’t share a spoken language come together they will often create a new language which combines elements of their first languages. These languages are known as “pidgins”. If they are then learned by children as their first language they become fully-fledged languages known as “creoles”. This dataset contains information on both creoles and pidgins spoken around the world. Content This dataset includes information on the grammatical and lexical structures of 76 pidgin and creole languages. The language set contains not only the most widely studied Atlantic and Indian Ocean creoles but also less well known pidgins and creoles from Africa South Asia Southeast Asia Melanesia and Australia including some extinct varieties and several mixed languages. This dataset is made up of several tables each of which contains different pieces of information  language A table of language names & the unique id’s associated with them. language_data A table of data on the different languages including the name speakers’ call their language (Autoglossonym) other names the language is called how many speakers it has the language which contributed the most words to the language (Major lexifier) other languages which contribute to that language where it is spoken and where it is an official language fro. The column language_id has the id linked to the language table. language_source The sources referenced on each language (referencing the language and source tables). langauge_table Information on the geographic location of each language. source Information on the scholarly sources referenced for information on language.  Acknowledgements This dataset contains information from the online portion of the Atlas of Pidgin and Creole Language Structures (APiCS). It is distributed under a Creative Commons Attribution 3.0 Unported License . If you use this dataset in your work please use this citation Salikoko S. Mufwene. 2013. Kikongo-Kituba structure dataset.  In Michaelis Susanne Maria & Maurer Philippe & Haspelmath Martin & Huber Magnus (eds.)  Atlas of Pidgin and Creole Language Structures Online.  Leipzig Max Planck Institute for Evolutionary Anthropology.  (Available online at http//apics-online.info/contributions/58 Accessed on 2017-07-28.) Inspiration  Which areas of the world have the most creoles/pidgins? Which language has contributed to the most creoles/pidgins? Why might this be? Can you map the areas of influence of the various lexicalized Major Lexifier languages?   You may also be interested in  World Language Family Map The Sign Language Analyses (SLAY) Database World Atlas of Language Structures Information on the linguistic structures in 2679 languages ,id:name:,numeric:string:,grammar
OpenAddresses - U.S. Northeast , OpenAddresses , www.kaggle.com/openaddresses/openaddresses-us-northeast , Fri Jul 28 2017 02:35:11 GMT+0530 (IST) , Addresses and geo locations for the U.S. Northeast ,81, ,Context OpenAddresses's goal is to connect the digital and physical worlds by sharing geographic coordinates street names house numbers and postal codes.  Content This dataset contains one datafile for each state in the U.S. Northeast region. States included in this dataset  Connecticut - ct.csv Massachusetts - ma.csv Maine - me.csv New Hampshite - nh.csv New Jersey - nj.csv New York - ny.csv Pennsylvania - pa.csv Rhode Island - ri.csv Vermont - vt.csv  Field descriptions  LON - Longitude LAT - Latitude NUMBER - Street number STREET - Street name UNIT - Unit or apartment number CITY - City name DISTRICT - ? REGION - ? POSTCODE - Postcode or zipcode ID - ? HASH - ?  Acknowledgements Data collected around 2017-07-25 by OpenAddresses (http//openaddresses.io). Address data is essential infrastructure. Street names house numbers and postal codes when combined with geographic coordinates are the hub that connects digital to physical places. Data licenses can be found in LICENSE.txt. Data source information can be found at https//github.com/openaddresses/openaddresses/tree/9ea72b079aaff7d322349e4b812eb43eb94d6d93/sources Inspiration Use this dataset to create maps in conjunction with other datasets for crime or weather,LON:LAT:NUMBER:STREET:UNIT:CITY:DISTRICT:REGION:POSTCODE:ID:HASH:,numeric:numeric:numeric:string:string:string:string:string:numeric:string:string:,geographical information
Congress Trump Score , FiveThirtyEight , www.kaggle.com/fivethirtyeight/trump-score , Mon Jun 26 2017 20:08:55 GMT+0530 (IST) , How often do congresspeople vote with or against Trump? ,278, politics- ,"Context This is FiveThirtyEight's Congress Trump Score. As the website itself puts it it's ""an updating tally of how often every member of the House and the Senate votes with or against the president"". Content There are two tables cts and votes. The first one has summary information for every congressperson their name their state their Trump Score Trump's share of the votes in the election etc. The second one has information about every vote each congressperson has cast their vote Trump's position on the issue etc. The data was extracted using R. The code is available as a package on github. Acknowledgements The data is 100% collected and maintained by FiveThirtyEight. They are awesome.",name:chamber:party:state:district:trump_score:trump_margin:predicted_score:trump_plus_minus:,string:string:string:string:string:numeric:dateTime:numeric:numeric:,politics
Birds' Bones and Living Habits , zjf , www.kaggle.com/zhangjuefei/birds-bones-and-living-habits , Wed Jan 18 2017 09:23:49 GMT+0530 (IST) , Measurements of bones and ecological groups of birds ,344, biology- ecology- ,Context There are many kinds of birds pigeons ducks ostriches penguins... Some are good at flying others can't fly but run fast. Some swim under water others wading in shallow pool.  According to their living environments and living habits birds are classified into different ecological groups. There are 8 ecological groups of birds  Swimming Birds Wading Birds Terrestrial Birds Raptors Scansorial Birds Singing Birds Cursorial Birds (not included in dataset) Marine Birds (not included in dataset)  First 6 groups are main and are covered by this dataset. Apparently birds belong to different ecological groups have different appearances flying birds have strong wings and wading birds have long legs. Their living habits are somewhat reflected in their bones' shapes. As data scientists we may think of examining the underlying relationship between sizes of bones and ecological groups  and recognising birds' ecological groups by their bones' shapes. Content There are 420 birds contained in this dataset. Each bird is represented by 10 measurements (features)  Length and Diameter of Humerus Length and Diameter of Ulna Length and Diameter of Femur Length and Diameter of Tibiotarsus Length and Diameter of Tarsometatarsus   All measurements are continuous float numbers (mm) with missing values represented by empty strings. The skeletons of this dataset are collections of Natural History Museum of Los Angeles County. They belong to 21 orders 153 genera 245 species. Each bird has a label for its ecological group  SW Swimming Birds W Wading Birds T Terrestrial Birds R Raptors P Scansorial Birds SO Singing Birds  Acknowledgements This dataset is provided by Dr. D. Liu of Beijing Museum of Natural History. Inspiration This dataset is a 420x10 size continuous values unbalanced multi-class dataset. What can be done include  Data Visualisation Statical Analysis Supervised Classification Unsupervised Clustering  License Please do not publish or cite this dataset in research papers or other public publications.,id:huml:humw:ulnal:ulnaw:feml:femw:tibl:tibw:tarl:tarw:type:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:,zoological
Craft Beers Dataset , Jean-NicholasHould , www.kaggle.com/nickhould/craft-cans , Wed Jan 18 2017 08:04:16 GMT+0530 (IST) , 2K+ craft canned beers from the US and 500+ breweries in the United States. ,3269, food and drink- ,"This dataset contains a list of 2410 US craft beers and 510 US breweries. The beers and breweries are linked together with an ""id"". This data was collected in January 2017 on CraftCans.com. The dataset is an a tidy format and values have been cleaned up for your enjoyment. If you are interested in learning more about how this dataset was acquired I wrote an extensive blogpost about it (http//www.jeannicholashould.com/python-web-scraping-tutorial-for-craft-beers.html). Enjoy!",:abv:ibu:id:name:style:brewery_id:ounces:,numeric:numeric:string:numeric:string:string:numeric:numeric:,food and nutrition
Mr Donald Trump Speeches , Binks , www.kaggle.com/binksbiz/mrtrump , Sun Aug 13 2017 13:47:59 GMT+0530 (IST) , Psychological profile of Donald Trump based on his spoken language ,92, languages- presidents- politics- linguistics- psychology- ,"Context Youtube has introduced automatic generation of subtitles based on speech recognition of uploaded video. This dataset provides collection of subtitles Donald Trump's uploaded speeches. It serves as database for an introduction to algorithmic analysis of spoken language. Content Mr Donald Trump speeches dataset consists of 836 subtitles (sets of words) retrieved from Youtube playlists ""Donald Trump Speeches & Events"" ""DONALD TRUMP SPEECHES & PRESS CONFERENCE"" ""President Donald Trump Weekly Address 2017"" ""President Donald Trump's First 100 Days | NBC News"" ""Donald Trump Rally Speech Events Press Conference Rallies Playlist"". This dataset consists of a single CSV file MrTrumpSpeeches.csv. The columns are 'id' 'playlist' 'upload_date' 'title' 'view_count' 'average_rating' 'like_count' 'dislike_count' 'subtitles' which are delimited with tilde character '~'. Text data in columns 'subtitles' is not sentence based there are not commas or dots. It is only stream of words being translated from speech into text by GoogleVoice (more here https//googleblog.blogspot.com.au/2009/11/automatic-captions-in-youtube.html). Acknowledgements The data was downloaded using youtube-dl package.  Inspiration I'm interested in psychological profiles of people speaking based on language used. (For example see https//medium.com/@TSchnoebelen/trump-does-not-talk-like-a-woman-breaking-news-gender-continues-to-be-complicated-and-confusing-4c0d28b41d7)",id~playlist~upload_date~title~view_count~average_rating~like_count~dislike_count~subtitles:,string:,speech
Trial and Terror , Jacob Boysen , www.kaggle.com/jboysen/trial-and-terror , Wed Aug 16 2017 21:23:36 GMT+0530 (IST) , Database of US Terrorism Prosecutions and Sentencing Information ,42, ,Context This database of terrorism prosecutions and sentencing information was created using public records including three lists of prosecutions from the U.S. Department of Justice (from 2010 2014 and 2015) court files available through the federal judiciary’s case management system DOJ press releases and inmate data from the Bureau of Prisons.  Content Trevor Aaronson created the first iteration of this database as part of a project funded by the Investigative Reporting Program at the University of California Berkeley. Mother Jones magazine published that data in 2011 along with accompanying articles in a package that is still available online. Beginning in 2016 Aaronson and Margot Williams collaborated to update and expand the database with a new emphasis to include Bureau of Prisons data because so many post-9/11 terrorism defendants had been released. The cases include any prosecutions after September 11 2001 that the U.S. government labeled as related to international terrorism. The Intercept first published this database on April 20 2017. For each defendant in the database U.S. criminal code data related to charges has been categorized according to this legend Acknowledgements This database is licensed under Creative Commons for noncommercial uses with appropriate attribution. If you publish this database in part or whole you must credit Trevor Aaronson and Margot Williams. Inspiration  What are the most common charges? Are the sentence lengths similar? ,id:firstName:lastName:description:released:disposition:cooperator:race:gender:releaseDate:institution_nameDisplay:institution_city:institution_state:institution_securityLevel:case_informant:case_chargeDate:case_convictionDate:case_sentenceDate:case_district:case_imprisonment:case_restitution:case_supervised_release:case_state:case_sting:case_charge_1:case_charge_2:case_charge_3:case_charge_4:case_charge_5:case_charge_6:case_charge_7:case_charge_8:case_charge_9:case_additional_sentence_details_1:case_additional_sentence_details_2:case_additional_sentence_details_3:case_terrorOrg_1:case_terrorOrg_2:case_terrorOrg_3:,string:string:string:string:boolean:string:string:string:string:string:string:string:string:string:boolean:dateTime:dateTime:dateTime:string:string:numeric:string:string:boolean:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:,crime
Rio de Janeiro Crime Records , Daniel Esteves , www.kaggle.com/danielesteves/rio-police-records , Tue Aug 15 2017 23:38:53 GMT+0530 (IST) , Crime records from Rio de Janeiro State ,94, ,Context Rio de Janeiro is one of the most beautiful and famous city in the world. Unfortunately it's also one of the most dangerous. For the last years in a scenario of economical and political crisis in Brazil the State of Rio de Janeiro was one of the most affected. Since 2006 the Instituto de Segurança Pública do Rio de Janeiro (Institue of Public Security of Rio de Janeiro State) publishes reports of each police station.  Content Three datasets are available BaseDPEvolucaoMensalCisp - Monthly evolution of statistics by police station PopulacaoEvolucaoMensalCisp - Monthly evolution of population covered by police station delegacias - Info about each police station Most of the data are in Brazilian Portuguese because it was extracted directly from government sites. Acknowledgements This dataset is provided by the Instituto de Segurança Pública. delegacias.csv was compiled by myself. Inspiration  What is the most unsafe city in Rio de Janeiro State? And the safest?   Which events can be correlated with the numbers in dataset? (Elections crisis...)   How crime correlates with population? ,CISP;mes;vano;mes_ano;area_cisp;AISP;RISP;munic;mcirc;Regiao;hom_doloso;lesao_corp_morte;latrocinio;tentat_hom;lesao_corp_dolosa;estupro;hom_culposo;lesao_corp_culposa;encontro_cadaver;encontro_ossada;roubo_comercio;roubo_residencia;roubo_veiculo;roubo_ca:,string:,
ENEM 2015 , Gustavo Bonesso , www.kaggle.com/gbonesso/enem2015 , Thu Jul 06 2017 00:10:09 GMT+0530 (IST) , Data from ENEM 2015 the Brazilian High School National Exam. ,60, education- ,Context This dataset was downloaded from INEP a department from the Brazilian Education Ministry. It contains data from the applicants for the 2015 National High School Exam. Content Inside this dataset there are not only the exam results but the social and economic context of the applicants. Acknowledgements The original dataset is provided by INEP (http//portal.inep.gov.br/microdados). I removed some information from original files to fit the file size into the Kaggle constraints. Inspiration The objective is to explore the dataset to achieve a better understanding of the social and economic context of the applicants in the exams results.,,,student performances
StackSample: 10% of Stack Overflow Q&A , Stack Overflow , www.kaggle.com/stackoverflow/stacksample , Fri Oct 21 2016 07:02:23 GMT+0530 (IST) , Text from 10% of Stack Overflow questions and answers on programming topics ,728, internet- programming languages- ,Dataset with the text of 10% of questions and answers from the Stack Overflow programming Q&A website. This is organized as three tables  Questions contains the title body creation date closed date (if applicable) score and owner ID for all non-deleted Stack Overflow questions whose Id is a multiple of 10. Answers contains the body creation date score and owner ID for each of the answers to these questions. The ParentId column links back to the Questions table. Tags contains the tags on each of these questions  Datasets of all R questions and all Python questions are also available on Kaggle but this dataset is especially useful for analyses that span many languages. Example projects include  Identifying tags from question text Predicting whether questions will be upvoted downvoted or closed based on their text Predicting how long questions will take to answer  License All Stack Overflow user contributions are licensed under CC-BY-SA 3.0 with attribution required.,,,programming
Test Driven Data , SuperDave , www.kaggle.com/superdave/test-driven-data , Tue Jun 20 2017 16:52:37 GMT+0530 (IST) , Test patterns for gaining intuition of hyperparmeters in machine learning ,153, artificial intelligence- programming- ,Context In machine learning there is a long path from understanding to intuition. I have created many data files of traditional electronics test pattern to see the response of different activation  loss optimizers and metrics in Keras. These files should give some ability to test drive your chosen type of machine learning with a very deliberate data set. I wanted something that was infinitely predicable to see how all the different settings effected the algorithms to set a base line for me to gain intuition as to how they should behave once I make more complex models.  Content These files most contain single line 10000 example patterns in sine cosine triangle and others.  Frequency and amplitude in some change through out the set. One has 2500 example with 4 features of a sine wave 90 degrees out of phase from each other. The values are all between zero and one so no scaling should be necessary. CosineDecAmpFreqInc CosineDecreasingAmp CosineIncAmpFreqInc CosineIncAmpFreqSlowing ExponentialDecayTenWaves ExponentialRiseTenWaves FourSineWaves LinearFall LinearRise Lorentz Multitone Pulse10Waves Pulse10WavesInverted RandomSamples SinFiveWaves SinFourtyWaves SinTenWaves SinTwentyWaves 30000 SquareFiveWaves SquareTenWaves SweepOneToFive SweepOneToTwo SweepOneToTwoPointFive SyncPattern TriangleFiveWaves TriangleTenWaves.csv Acknowledgements Some were generated using Tektronics ArbExpress and modified in Excel for scale. Some I generated in c#.  Inspiration How about a good Toy example of a LSTM in Keras with multivariate data and a single prediction of one of the columns. I did the 4 sine wave .csv to try this. So far the examples I have found just average all of them.,0.567667642:,numeric:,artificial intelligence
The State of JavaScript 2016 , 姜上（Integ） , www.kaggle.com/integjs/state-of-javascript-2016 , Mon Dec 05 2016 07:39:40 GMT+0530 (IST) , Responses to the State of JavaScript survey ,124, programming languages- programming- ,Context Over nine thousand developers took part in the first edition of the State Of JavaScript survey. They answered questions on topics ranging from front-end frameworks and state management to build tools and testing libraries. You'll find out which libraries developers most want to learn next and which have the highest satisfaction ratings. And hopefully this data will help you make sense of the ever-changing JavaScript ecosystem. Content http//stateofjs.com/2016/introduction/ Acknowledgements Thanks to http//stateofjs.com/ open the data for download.,"#:Good Old Plain JavaScript:ES6:CoffeeScript:TypeScript:Elm:ClojureScript:On a scale of one to five dogs, how happy are you with your current flavor of JavaScript?:No Front-End Framework:React:Angular:Angular 2:Ember:Vue:Backbone:Other Front-End Frameworks:On a scale of one to five cats, how happy are you with your current solution for the front-end?:Redux:MobX:Relay:Other State Management Libraries:On a scale of one to five thunderbolts, how happy are you with your current solution for state management?:Custom REST API:Firebase:GraphQL:Apollo:Falcor:Horizon:Other API layer solutions:On a scale of one to five crowns, how happy are you with your current solution for the API layer?:Meteor:FeathersJS:DoneJS:MERN:MEAN:Other stacks:On a scale of one to five trophies, how happy are you with your current full-stack solution?:Mocha:Jasmine:Enzyme:Jest:Cucumber:Ava:Other testing frameworks:On a scale of one to five severed hands, how happy are you with the current state of JavaScript testing?:Plain CSS:SASS/SCSS:LESS:CSS Modules:Aphrodite:Other CSS solutions:On a scale of one to five lightbulbs, how happy are you with the current state of CSS?:Webpack:Grunt:Gulp:Browserify:Bower:Other build tools:On a scale of one to five droplets, how happy are you with the current state of build tools?:Native Apps:React Native:Cordova:PhoneGap:NativeScript:Other mobile apps solutions:On a scale of one to five pencils, how happy are you with the current state of mobile apps?:Server-Side Rendering:Code Splitting:Optimistic Updates:Hot Module Reloading:Time-Travel Debugging:Real-Time Operations:Dead Code Elimination:Progressive Enhancement:Other Features:JavaScript is moving in the right direction:Building JavaScript apps is overly complex right now:JavaScript is over-used online:I enjoy building JavaScript apps:I would like JavaScript to be my main programming language:The JavaScript ecosystem is changing too fast:This survey is too damn long!:Years of Experience:Company Size:Yearly Salary:Favorite Text Editor:Other:Tabs or Spaces?:Other Comments:Start Date (UTC):Submit Date (UTC):",string:string:string:string:string:string:string:numeric:string:string:string:string:string:string:string:string:numeric:string:string:string:string:numeric:string:string:string:string:string:string:string:numeric:string:string:string:string:string:string:numeric:string:string:string:string:string:string:string:numeric:string:string:string:string:string:string:numeric:string:string:string:string:string:string:numeric:string:string:string:string:string:string:numeric:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:dateTime:dateTime:,programming
Fine-grained Context-sensitive Lexical Inference , Vered Shwartz , www.kaggle.com/vered1986/context-lexinf , Sat Aug 12 2017 15:42:46 GMT+0530 (IST) , Annotations for semantic relations between words within context sentences ,28, ,"Context Recognizing lexical inference is an essential component in natural language understanding. In question answering for instance identifying that broadcast and air are synonymous enables answering the question ""When was 'Friends' first aired?"" given the text ""'Friends' was first broadcast in 1994"". Semantic relations such as synonymy (tall high) and hypernymy (cat pet) are used to infer the meaning of one term from another in order to overcome lexical variability. This inference should typically be performed within a given context considering both the term meanings in context and the specific semantic relation that holds between the terms.  Content This dataset provides annotations for fine-grained lexical inferences in-context.  The dataset consists of 3750 term pairs each given within a context sentence built upon a subset of terms from PPDB.  Each term pair is annotated to the semantic relation that holds between the terms in the given contexts. Files  full_dataset.csv - the full dataset is provided as well as the train-test-validation split.  train.csv test.csv validation.csv - A split of the dataset to 70% train 25% test and 5% validation sets. Each of the sets contains different term-pairs to avoid overfitting for the most common relation of a term-pair in the training set.  File Structure comma-separated file Fields  x the first term y the second term context_x the sentence in which x appears (highlighted by x) context_y the sentence in which y appears (highlighted by y) semantic_relation the (directional) semantic relation that holds between x and y equivalence forward_entailment reverse_entailment alternation other-related and independence. confidence the relation annotation confidence (percentage of annotators that selected this relation) in a scale of 0-1  Acknowledgements If you use this dataset please cite the following paper Adding Context to Semantic Data-Driven Paraphrasing. Vered Shwartz and Ido Dagan. *SEM 2016. Inspiration I hope that this dataset will motivate the development of context-sensitive lexical inference methods which have been relatively overlooked although they are crucial for applications.","bicycle:riding:Bolotta recounted finding 22 sharpened <x>bicycle</x> spokes jabbed into the lawn while she was out with the lawn mower.:A lesser known work of Hopper's, 'Bridal Path' shows a horseback <y>riding</y> path in Central Park.:other-related:0.6:",string:string:string:string:string:numeric:,grammar
The National Summary of Meats , US Department of Agriculture , www.kaggle.com/usda/the-national-summary-of-meats , Wed Aug 23 2017 03:59:54 GMT+0530 (IST) , USDA's data on beef and mutton production since the 1930s ,47, government- agriculture- ,Beef. Lamb. Veal. We might not all eat them but they are the meats whose grades the US Department of Agriculture has seen fit to publish. This dataset contains records on meat production and quality as far back as 1930.  After meat and poultry are inspected for wholesomeness producers and processors may request that they have products graded for quality by a licensed Federal grader. The USDA's Agricultural Marketing Service (http//www.ams.usda.gov) is the agency responsible for grading meat and poultry. Those who request grading must pay for the service. Grading for quality means the evaluation of traits related to tenderness juiciness and flavor of meat; and for poultry a normal shape that is fully fleshed and meaty and free of defects. USDA grades are based on nationally uniform Federal standards of quality. No matter where or when a consumer purchases graded meat or poultry it must have met the same grade criteria. The grade is stamped on the carcass or side of beef and is usually not visible on retail cuts. However retail packages of beef as well as poultry will show the U.S. grade mark if they have been officially graded. To better understand the available fields  - All fields labeled 'pounds' are really in units of indicate millions    of pounds.  - You can find a helpful explanation of what the different grades mean    here. Acknowledgements This data was kindly released by the US Department of Agriculture. You can find their most recent meat updates here. Inspiration  This is a good dataset for anyone looking to do basic data cleanup. I've converted it into a properly formed CSV but there are still numerous missing values footnoted fields and exceptions. This is a good candidate for regression analysis especially in conjunction with other datasets. Can you identify correlates for the amount of beef produced? Validate how well cattle futures predict annual yields? 2015 was a banner year for beef production. What happened? ,YEAR:POUNDS GRADED:PRIME:%:CHOICE:SELECT:STNDRD:COMRCL:UTILITY:CUTTER:CANNER:S/H:%  of FEDERAL  SLAUGHTER, BEEF:Y1:Y2:Y3:Y4:Y5:,food and nutrition
General Practice Prescribing Data , National Health Service , www.kaggle.com/nhs/general-practice-prescribing-data , Thu Aug 10 2017 21:48:00 GMT+0530 (IST) , One year of British National Health Service Prescription data ,73, pharmaceutical industry- pharmaceuticals policy- pharmacy- human medicine- government- ,Context The British National Health Service releases data covering every public sector prescription made in the country. This covers a single year of that data. Content Covering all general practices in England the data includes figures on the number of prescription items that are dispensed each month and information relating to costs. For each GP practice the total number of items that were prescribed and then dispensed is shown. The total Net Ingredient Cost and the total Actual Cost of these items is shown. Chemical level All prescribed and dispensed medicines (by chemical name) dressings and appliances (at section level) are listed for each GP practice. Presentation level All prescribed and dispensed medicines dressings and appliances are listed at presentation level for each GP practice. (Presentation level gives the individual drug name the form and strength or size accordingly). The total quantity of drugs dispensed (in terms of number of tablets or millilitres for example) is shown. This data does not list each individual prescription and does not contain any patient identifiable data. The data have been edited from their original version. During the data preparation process I - Dropped obsolete and redundant columns. - Normalized the BNF (British National Formulary) codes BNF names and practice codes. These steps reduced the total file size by roughly 75% at the cost of requiring one table join to access some of the data. For further details please see - FAQ - Glossary of Terms Acknowledgements This dataset was kindly released by the United Kingdom's National Health Service under their government open data license v3. You can find this and other datasets at their open data site. Inspiration  What trends can you see in the data? For example can you identify the onset of winter based on the types of drugs being prescribed? The BNF Name entries contain dosage data that I haven't yet cleaned and extracted. Can you unpack that field into item dispensed units and dosage? If so let me know in the forums and I'll add it to the dataset! Per this blog from Oxford the raw BNF codes contain quite a bit of information about a drug's function. Can you find a source of open data for translating these codes? It's probable that one exists somewhere at https//www.nhsbsa.nhs.uk/nhs-prescription-services. ,CHEM SUB:NAME:,numeric:string:,pharmaceuticals
Salt Lake City Crime Reports , foenix , www.kaggle.com/foenix/slc-crime , Sat Aug 19 2017 04:14:08 GMT+0530 (IST) , Includes latitude and longitudes offence descriptions and city council numbers ,209, crime- ,Context A collection of SLC End-of-Year Crime Reports geocoded to standard GPS coordinates. Content 2016 Crime Statistics for Salt Lake City UT. Includes  Case Numbers Offence Codes for categorization Descriptions for context IBR (National Incident-Based Reporting System Number) Occurrence Date Report Date Day of the Week (1 = Monday 7 = Sunday) Location (Addresses in SLC) City Council District SLCPD Police Zones SLCPD Grid x_coordinate note that this is based on epsg32043 projections y_coordinate note that this is based on epsg32043 projections x_gps_coords (added by yours truly converted to epsg4326) y_gps_coords (added by yours truly converted to epsg4326)  Data Accuracy Notes  Some data wrangling will still likely be required to clean up null columns.  I went ahead and lowercased column names (and corrected a spelling mistake in the y-coordinate column). epsg32043 projections were converted to epsg4326 projections using pyplot with distances preserved. Multiple year munging performed here https//github.com/octaflop/slcpd/blob/master/develop/2017-08-16-crunch.ipynb Still awaiting dataset owner clarification of Calls vs Cases  Acknowledgements Taken from the SLC Open Data Web Site.  Thank you Dean Larson the original dataset owner. Thank you to the City of Salt Lake government and the Utah.gov catalog for providing this data for public use. Thanks to the DAT Science EdEx course for inspiring me to take a look at my own city's crime stats. Thank you to the SLCPD for keeping Salt Lake City citizens safe and enforcing an internal discipline of open data-collection. Inspiration  Crime report locations by season?  Cross Reference of city council districts Time of day Offence descriptions Moving centroids based on time of day / season? Holiday rowdiness?  Coming Soon  Full 2016 reports (eta Spring 2017) ✔ 3-year combined reports (eta Summer 2017) ✔ 3-year combined cases vs calls (eta Summer 2017) year-by-year files (eta Fall 2017) ,case:date cleared:call description:location:police zone:police grid:city council:x-coordinate:y-coordinate:x_gps_coords:y_gps_coords:,string:dateTime:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:,geographical information
California Crime and Law Enforcement , Federal Bureau of Investigation , www.kaggle.com/fbi-us/california-crime , Thu Dec 08 2016 12:00:40 GMT+0530 (IST) , Crime and law enforcement employment data from 2015 ,501, crime- law- ,Context The Uniform Crime Reporting (UCR) Program has been the starting place for law enforcement executives students of criminal justice researchers members of the media and the public at large seeking information on crime in the nation. The program was conceived in 1929 by the International Association of Chiefs of Police to meet the need for reliable uniform crime statistics for the nation. In 1930 the FBI was tasked with collecting publishing and archiving those statistics. Today four annual publications Crime in the United States National Incident-Based Reporting System Law Enforcement Officers Killed and Assaulted and Hate Crime Statistics are produced from data received from over 18000 city university/college county state tribal and federal law enforcement agencies voluntarily participating in the program. The crime data are submitted either through a state UCR Program or directly to the FBI’s UCR Program. This dataset focuses on the crime rates and law enforcement employment data in the state of California. Content Crime and law enforcement employment rates are separated into individual files focusing on offenses by enforcement agency college/university campus county and city. Categories of crimes reported include violent crime murder and nonnegligent manslaughter rape robbery aggravated assault property crime burglary larceny-theft motor vehicle damage and arson. In the case of rape data is collected for both revised and legacy definitions. In some cases a small number of enforcement agencies switched definition collection sometime within the same year.  Acknowledgements This dataset originates from the FBI UCR project and the complete dataset for all 2015 crime reports can be found here.  Inspiration  What are the most common types of crimes in California? Are there certain crimes that are more common in a particular place category such as a college/university campus compared to the rest of the state? How does the number of law enforcement officers compare to the crime rates of a particular area? Is the ratio similar throughout the state or do certain campuses counties or cities have a differing rate?  How does the legacy vs. refined definition of rape differ and how do the rape counts compare? If you pulled the same data from FBI datasets for previous years can you see a difference in rape rates over time? ,State/Tribal/Other :Agency:Unit/Office:Total law enforcement employees:Total officers:Total civilians:,string:string:string:numeric:numeric:numeric:,
Ubuntu Dialogue Corpus , Rachael Tatman , www.kaggle.com/rtatman/ubuntu-dialogue-corpus , Thu Aug 17 2017 00:40:26 GMT+0530 (IST) , 26 million turns from natural two-person dialogues ,121, languages- linguistics- computing and society- ,"Context Building dialogue systems where a human can have a natural-feeling conversation with a virtual agent is a difficult task in Natural Language Processing and the focus of much ongoing research. Some of the challenges include linking references to the same entity over time tracking what’s happened in the conversation previously and generating appropriate responses. This corpus of naturally-occurring dialogues can be helpful for building and evaluating dialogue systems. Content The new Ubuntu Dialogue Corpus consists of almost one million two-person conversations extracted from the Ubuntu chat logs used to receive technical support for various Ubuntu-related problems. The conversations have an average of 8 turns each with a minimum of 3 turns. All conversations are carried out in text form (not audio).  The full dataset contains 930000 dialogues and over 100000000 words and is available here. This dataset contains a sample of this dataset spread across .csv files. This dataset contains more than 269 million words of text spread out over 26 million turns.   folder The folder that a dialogue comes from. Each file contains dialogues from one folder . dialogueID An ID number for a specific dialogue. Dialogue ID’s are reused across folders. date A timestamp of the time this line of dialogue was sent. from The user who sent that line of dialogue. to The user to whom they were replying. On the first turn of a dialogue this field is blank. text The text of that turn of dialogue separated by double quotes (“). Line breaks (\n) have been removed.  Acknowledgements This dataset was collected by Ryan Lowe Nissan Pow  Iulian V. Serban† and Joelle Pineau. It is made available here under the Apache License  2.0. If you use this data in your work please include the following citation  Ryan Lowe Nissan Pow Iulian V. Serban and Joelle Pineau ""The Ubuntu Dialogue Corpus A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems"" SIGDial 2015. URL http//www.sigdial.org/workshops/conference16/proceedings/pdf/SIGDIAL40.pdf Inspiration Can you use these chat logs to build a chatbot that offers help with Ubuntu?",lines:words:characters:filename:,numeric:numeric:numeric:string:,Online forums 
UK fleet and foreign fleet landings by port , The Flying Munkey , www.kaggle.com/theflyingmunkey/uk-fleet-landings , Thu Aug 24 2017 20:44:24 GMT+0530 (IST) , Data from 2008-2015 on fishing vessels either from the UK or landing in the UK ,34, government agencies- fishing- business- ,Context Data taken from the Marine Management Organisation on all UK vessels landing in ports or foreign vessels landing in UK ports. This dataset contains data on the catch also the weight and value (£) of the catch. Content  Year year of landing 2008-2015 Month calendar months 1-12 Port of Landing name of port Port Nationality nationality of the port of landing Vessel Nationality nationality of the vessel Length Group length of the vessel 10m or under/Over 10m Gear Category gear carried by the vessel Species Code three letter code of the catch Species Name name of the catch Species as shown in publication name of the catch with fewer subcategories Species Group catch species Live Weight (tonnes) weight of live catch Landed Weight (tonnes) landed weight of catch Value (£) the value of the catch in GBP most likely without any inflation adjustment  Points to note  Data on Port Nationality and Vessel Nationality for 2008 were supplied as 3 letter codes not all of which matched standard country codes. I've tried to clean these up as best I can to match with standard country codes but ones that couldn't be matched have been left as-is. Species Code and Species Name were not supplied for 2008. You may be able to infer some from the 2009-2015 data.  Inspiration  Which UK ports see the greatest activity? Which foreign ports see the greatest number of UK vessels? Has the price-paid per tonne of goods varied during the data collection period? Has there been any major changes in activity for particular species?  Acknowledgements Data taken from the Office of National Statistics and is part of the UK Sea Fisheries Annual Statistics. Data are available under a Open Government Licence v3.0.,year:,numeric:,trade and business
TSA Claims database , Terminal Security Agency , www.kaggle.com/terminal-security-agency/tsa-claims-database , Tue Aug 22 2017 04:40:34 GMT+0530 (IST) , Property and injury claims filed from 2002 - 2015 ,83, government agencies- ,Context Did you know that claims can be filed against TSA? Sometimes US Terminal Security Agency (TSA) makes mistakes. People can get hurt and property can be damaged lost or stolen. Claims are generally filed against TSA for personal injuries and lost or damaged property during screenings and they keep records of every claim!  Content The dataset includes claims filed between 2002 through 2015.  Claim Number Date Received Incident Date Airport Code Airport Name Airline Name Claim Type Claim Site Item Claim Amount Status Close Amount Disposition  Acknowledgements File modifications - Excel format to TSV - commas to semicolons - TSV to CSV Original data can be found here https//www.dhs.gov/tsa-claims-data Inspiration I took a quick look at these data and discovered that the most claims are filed against TSA at John F. Kennedy International. I also discovered four claims against Wrongful Death!,Claim Number:Date Received:Incident Date:Airport Code:Airport Name:Airline Name:Claim Type:Claim Site:Item:Claim Amount:Status:Close Amount:Disposition:,numeric:dateTime:dateTime:string:string:string:string:string:string:string:string:string:string:,airways
Narrativity in Scientific Publishing , Crowdflower , www.kaggle.com/crowdflower/narrativity-in-scientific-publishing , Fri Apr 07 2017 21:08:51 GMT+0530 (IST) , Is scientific research written in a narrative style more influential? ,73, research tools and topics- research- science and culture- ,"CrowdFlower was used in a recent study published in PLOS One on how narrative style affects the way scientific findings are cited and shared. Refer to the article’s supplementary materials for more information. The dataset contains abstracts from peer-reviewed studies on climate change that were labeled using the CrowdFlower platform. Abstracts were each assessed by multiple raters (n = 7) for their narrativity. Narrativity includes whether the abstract appeals to the reader has a narrative perspective using sensory language and other factors. The dataset also contains additional information about the studies including citation rate journal identity and number of authors. Past research From the study abstract  Peer-reviewed publications focusing on climate change are growing exponentially with the consequence that the uptake and influence of individual papers varies greatly. Here we derive metrics of narrativity from psychology and literary theory and use these metrics to test the hypothesis that more narrative climate change writing is more likely to be influential using citation frequency as a proxy for influence. From a sample of 732 scientific abstracts drawn from the climate change literature we find that articles with more narrative abstracts are cited more often. This effect is closely associated with journal identity higher-impact journals tend to feature more narrative articles and these articles tend to be cited more often. These results suggest that writing in a more narrative style increases the uptake and influence of articles in climate literature and perhaps in scientific literature more broadly.  Inspiration Can you replicate the authors' findings? Are abstracts with narrative qualities cited more often? What other variables are associated with narrativity in scientific abstracts about climate change? Examine relationships between citation rate abstract length abstract authors and more. Acknowledgements This dataset is made available via CrowdFlower's ""Data for Everyone"" collection which hosts open data jobs that have come through the crowdsourced labeling platform.",:X_unit_id:X_created_at:X_id:X_started_at:X_tainted:X_channel:X_trust:X_worker_id:X_country:X_region:X_city:X_ip:appeal_to_reader:conjunctions:connectivity:narrative_perspective:sensory_language:setting:ab:appeal_to_reader_gold:conjunctions_gold:connectivity_gold:narrative_perspective_gold:pmid:py:sensory_language_gold:setting_gold:so:tc:af:au:bp:di:ep:is:pd:pt:sn:ti:ut:vl:z9:cin_mas:firstauthor:numberauthors:pid_mas:title:,numeric:numeric:dateTime:numeric:dateTime:boolean:string:numeric:numeric:string:numeric:string:string:string:numeric:numeric:string:numeric:string:string:string:string:string:string:numeric:numeric:string:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:string:numeric:numeric:string:,
Human Mobility During Natural Disasters , Dryad Digital Repository , www.kaggle.com/dryad/human-mobility-during-natural-disasters , Thu Aug 31 2017 03:09:34 GMT+0530 (IST) , Twitter geolocation for users during 15 natural disasters ,431, geography- demographics- internet- ,This dataset contains geolocation information for thousands of Twitter users during natural disasters in their area.  Abstract (from original paper) Natural disasters pose serious threats to large urban areas therefore understanding and predicting human movements is critical for evaluating a population’s vulnerability and resilience and developing plans for disaster evacuation response and relief. However only limited research has been conducted into the effect of natural disasters on human mobility. This study examines how natural disasters influence human mobility patterns in urban populations using individuals’ movement data collected from Twitter. We selected fifteen destructive cases across five types of natural disaster and analyzed the human movement data before during and after each event comparing the perturbed and steady state movement data. The results suggest that the power-law can describe human mobility in most cases and that human mobility patterns observed in steady states are often correlated with those in perturbed states highlighting their inherent resilience. However the quantitative analysis shows that this resilience has its limits and can fail in more powerful natural disasters. The findings from this study will deepen our understanding of the interaction between urban dwellers and civil infrastructure improve our ability to predict human movement patterns during natural disasters and facilitate contingency planning by policymakers. Acknowledgments The original journal article for which this dataset was collected  Wang Q Taylor JE (2016) Patterns and limitations of urban human mobility resilience under the influence of multiple types of natural disaster. PLoS ONE 11(1) e0147299. http//dx.doi.org/10.1371/journal.pone.0147299 The Dryad page that this dataset was downloaded from  Wang Q Taylor JE (2016) Data from Patterns and limitations of urban human mobility resilience under the influence of multiple types of natural disaster. Dryad Digital Repository. http//dx.doi.org/10.5061/dryad.88354 The Data This dataset contains the following fields  disaster.event the natural disaster during which the observation was collected. One of  -- one of  --- *01_Wipha* *02_Halong* *03_Kalmaegi* *04_Rammasun_Manila* (typhoons)  --- *11_Bohol* *12_Iquique* *13_Napa* (earthquakes)  --- *21_Norfolk* *22_Hamburg* *23_Atlanta* (winter storms)  --- *31_Phoenix* *32_Detroit* *33_Baltimore* (thunderstorms)  --- *41_AuFire1* *42_AuFire2* (wildfires)   user.anon an anonymous user id; unique within each disaster event   latitude latitude of user's tweet   longitude.anon longitude of user's tweet; shifted to preserve anonymity time the date and time of the tweet ,disaster.event:user.anon:latitude:longitude.anon:time:,string:numeric:numeric:numeric:dateTime:,
Homelessness , Adam Schroeder , www.kaggle.com/adamschroeder/homelessness , Mon Aug 07 2017 09:13:12 GMT+0530 (IST) , Homelessness in the United States 2007 to 2016 ,392, communities- united states- sociology- ,"Context The previous New York City policies eliminated all housing resources for homeless families and single adults. I wanted to see the consequences. Content ""These raw data sets contain Point-in-Time (PIT) estimates and national PIT estimates of homelessness as well as national estimates of homelessness by state and estimates of chronic homelessness from 2007 - 2016. Estimates of homeless veterans are also included beginning in 2011. The accompanying Housing Inventory Count (HIC) data is available as well from 2007 - 2016."" (Department of Housing and Urban Development Acknowledgements I would like to thank Matthew Schnars for providing this dataset from  https//www.hudexchange.info/resource/3031/pit-and-hic-data-since-2007/ Inspiration Many of our fellow human beings go through hardships that we would never know about. But it's our obligation as a society to take care of one another. That's why I was hoping this dataset shine light on some of the challenges our cities and states are still facing in this topic.",Year:,dateTime:,
Corruption Perceptions Index , Transparency International , www.kaggle.com/transparencyint/corruption-index , Thu Jan 26 2017 23:14:15 GMT+0530 (IST) , Perceived level of political corruption for every country in the world ,390, crime- politics- ,Content The Corruption Perceptions Index scores and ranks countries/territories based on how corrupt a country’s public sector is perceived to be. It is a composite index a combination of surveys and assessments of corruption collected by a variety of reputable institutions. The CPI is the most widely used indicator of corruption worldwide. Corruption generally comprises illegal activities which are deliberately hidden and only come to light through scandals investigations or prosecutions. There is no meaningful way to assess absolute levels of corruption in countries or territories on the basis of hard empirical data. Possible attempts to do so such as by comparing bribes reported the number of prosecutions brought or studying court cases directly linked to corruption cannot be taken as definitive indicators of corruption levels. Instead they show how effective prosecutors the courts or the media are in investigating and exposing corruption. Capturing perceptions of corruption of those in a position to offer assessments of public sector corruption is the most reliable method of comparing relative corruption levels across countries. Acknowledgements The data sources used to calculate the Corruption Perceptions Index scores and ranks were provided by the African Development Bank Bertelsmann Stiftung Foundation The Economist Freedom House IHS Markit IMD Business School Political and Economic Risk Consultancy Political Risk Services World Bank World Economic Forum World Justice Project and Varieties of Democracy Project.,CPI 2016 Rank:Country:Country Code:Region:CPI 2016 Score:CPI 2015 Score:CPI 2014 Score:CPI 2013 Score:CPI 2012 Score:,numeric:string:string:string:numeric:numeric:numeric:numeric:numeric:,
Movebank: Animal Tracking , PULKIT KHANDELWAL , www.kaggle.com/pulkit8595/movebank-animal-tracking , Mon Jan 09 2017 09:55:58 GMT+0530 (IST) , Analyzing migratory patterns of animals ,169, animals- ,Context Movebank is a free online database of animal tracking data hosted by the Max Planck Institute for Ornithology. It is designed to help animal tracking researchers to manage share protect analyze and archive their data. Movebank is an international project with over 11000 users including people from research and conservation groups around the world. The animal tracking data accessible through Movebank belongs to researchers all over the world. These researchers can choose to make part or all of their study information and animal tracks visible to other registered users or to the public. Animal tracking Animal tracking data helps us understand how individuals and populations move within local areas migrate across oceans and continents and evolve through millennia. This information is being used to address environmental challenges such as climate and land use change biodiversity loss invasive species and the spread of infectious diseases. Read more.,event-id:visible:timestamp:location-long:location-lat:manually-marked-outlier:sensor-type:individual-taxon-canonical-name:tag-local-identifier:individual-local-identifier:study-name:ECMWF Interim Full Daily Invariant Low Vegetation Cover:NCEP NARR SFC Vegetation at Surface:ECMWF Interim Full Daily Invariant High Vegetation Cover:,numeric:boolean:dateTime:numeric:numeric:string:string:string:numeric:string:string:numeric:numeric:numeric:,
Circadian Rhythm in the Brain , Kevin Mader , www.kaggle.com/kmader/circadian-rhythm-in-the-brain , Tue Mar 21 2017 16:22:20 GMT+0530 (IST) , Fluorescence signal from the circadian regulation region of the brain ,235, neuroscience- ,Overview The data are a time-series of fluorescence images measured of  at OHSU Lab of Charles Allen (https//www.ohsu.edu/xd/research/centers-institutes/oregon-institute-occupational-health-sciences/research/allen/). Introduction We use a fluorescent protein as a reporter for the circadian clock gene Period1. We are able to follow the expression of this gene in many neurons for several days to understand how the neural network in the suprachiasmatic nucleus synchronizes the circadian clock of individual neurons to produce a precise circadian rhythm. We analyze each image to determine the fluorescence intensity of each neuron over multiple circadian cycles.  FAQ How where the images obtained which animal and what staining? The images were taken from a transgenic mouse in which expression of the fluorescent protein Venus is driven by the promoter for the circadian clock gene Period 1. What is the anatomy of the images and how are they oriented? The bright line is the third ventricle which resides on the midline of the brain. The two bright regions on either side of the ventricle are the two portions of the Suprachiasmatic nucleus (SCN). Below the ventricle and the SCN is a dark horizontal band that represents the optic chasm.  What is the bright vertical line in the top middle? The bright line is the third ventricle. Pericytes that line the ventricle express the Venus at very high levels. We don't know the function of the circadian clock in these cells.   Challenge Currently we have to analyze each experiment by hand to follow an individual through a couple hundred images. This takes several days. This problem is going to get worse because we have just purchased a new automated microscope stage that will allow us to simultaneously image from four suprachiasmatic nuclei.  Preview  Ideas for Analysis  Wavelets (pywavelets) following https//www.ncbi.nlm.nih.gov/pubmed/18931366   Questions  Do the cells move during the experiment?  How regular is their signal? Is the period 24 hours? Do nearby cells oscillate together? Do they form chunks or groups over what range do they work? Are there networks formed from time-precedence? ,Image.No.:,numeric:,
Hospital ratings , Center for Medicare and Medicaid , www.kaggle.com/center-for-medicare-and-medicaid/hospital-ratings , Thu Jul 27 2017 03:39:56 GMT+0530 (IST) , The official dataset used on Medicare.gov for hospital quality comparison ,305, hospitals- public health- health- ,Context This are the official datasets used on the Medicare.gov Hospital Compare Website provided by the Centers for Medicare & Medicaid Services. These data allow you to compare the quality of care at over 4000 Medicare-certified hospitals across the country. Content Dataset fields  Provider ID Hospital Name Address City State ZIP Code County Name Phone Number Hospital Type Hospital Ownership Emergency Services Meets criteria for meaningful use of EHRs Hospital overall rating Hospital overall rating footnote Mortality national comparison Mortality national comparison footnote Safety of care national comparison Safety of care national comparison footnote Readmission national comparison Readmission national comparison footnote Patient experience national comparison Patient experience national comparison footnote Effectiveness of care national comparison Effectiveness of care national comparison footnote Timeliness of care national comparison Timeliness of care national comparison footnote Efficient use of medical imaging national comparison Efficient use of medical imaging national comparison  Acknowledgements Dataset was downloaded from [https//data.medicare.gov/data/hospital-compare] Inspiration If you just broke your leg you might need to use this dataset to find the best Hospital to get that fixed!,Provider ID:Hospital Name:Address:City:State:ZIP Code:County Name:Phone Number:Hospital Type:Hospital Ownership:Emergency Services:Meets criteria for meaningful use of EHRs:Hospital overall rating:Hospital overall rating footnote:Mortality national comparison:Mortality national comparison footnote:Safety of care national comparison:Safety of care national comparison footnote:Readmission national comparison:Readmission national comparison footnote:Patient experience national comparison:Patient experience national comparison footnote:Effectiveness of care national comparison:Effectiveness of care national comparison footnote:Timeliness of care national comparison:Timeliness of care national comparison footnote:Efficient use of medical imaging national comparison:Efficient use of medical imaging national comparison footnote:,numeric:string:string:string:string:numeric:string:numeric:string:string:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:,
Firefighter Fatalities in the United States , Federal Emergency Management Agency , www.kaggle.com/fema/firefighter-fatalities , Thu Jan 26 2017 01:25:05 GMT+0530 (IST) , Name rank and cause of death for all firefighters killed since 2000 ,187, firefighting- ,Content The U. S. Fire Administration tracks and collects information on the causes of on-duty firefighter fatalities that occur in the United States. We conduct an annual analysis to identify specific problems so that we may direct efforts toward finding solutions that will reduce firefighter fatalities in the future. Acknowledgements This study of firefighter fatalities would not have been possible without members of individual fire departments chief fire officers fire service organizations the National Fire Protection Association and the National Fallen Firefighters Foundation.,First Name:Last Name:Age:Rank:Classification:Date of Incident:Date of Death:Cause Of Death:Nature Of Death:Duty:Activity:Emergency:Property Type::,string:string:numeric:string:string:dateTime:dateTime:string:string:string:string:string:string:string:,
Hate Crime Classification , Team AI , www.kaggle.com/team-ai/classification-of-hate-crime-in-the-us , Sun Aug 20 2017 11:17:36 GMT+0530 (IST) , Let's stop hate crimes with the power of data science! ,128, ,Context We should definitely stop hate crimes. Let's use data science to stop them. This is mainly classification but any other approach is welcome. Example; prediction for next possible hate crime. Content 3700 rows of CSV from Google Trend. Headline date location URL. Acknowledgements Special thanks to ; http//googletrends.github.io/data/ Inspiration Media data is mainly NLP CSV. We have to come up with other ways to add the value from it.,Article Date:Article Title:Organization:City:State:URL:Keywords:Summary::,dateTime:dateTime:string:string:string:string:string:string:string:,
Text Similarity , Rishi Sankineni , www.kaggle.com/rishisankineni/text-similarity , Sun Mar 19 2017 13:32:56 GMT+0530 (IST) , Natural Language Processing on Stock data ,574, languages- finance- linguistics- ,Context Natural Language Processing(NLP) Text Similarity(lexical and semantic) Content  In each row of the included datasets(train.csv and test.csv) products X(description_x) and Y(description_y) are considered to refer to the same security(same_security) if they have the same ticker(ticker_xticker_y) even if the descriptions don't exactly match. You can make use of these descriptions to predict whether each pair in the test set also refers to the same security. Dataset info Train - description_x description_y ticker_x ticker_y same_security. Test - description_x description_y same_security(to be predicted) Past Research  This dataset is pretty similar to the Quora Question Pairs . You can also check out my kernel for dataset exploration and n-gram analysis N-gram analysis on stock data. How to Approach  There are several good ways to approach this check out this algorithm and see how far you can go with it https//en.wikipedia.org/wiki/Tf–idf http//scikit learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html. You can also try doing n-gram analysis(check out my kernel). I would suggest using log-loss as your evaluation metric since it gives you a number between 0 and 1 instead of binary classification which is not so effective in this case. Acknowledgements Quovo stock data.,test_id:description_x:description_y:same_security:,numeric:string:string:string:,
U.S. Charities and Non-profits , Chris Crawford , www.kaggle.com/crawford/us-charities-and-nonprofits , Sat Aug 19 2017 03:51:53 GMT+0530 (IST) , All of the charities and non-profits registered with the IRS ,82, ,"Context This dataset comes from ""The Exempt Organization Business Master File Extract"" (EO BMF) which includes cumulative information on tax-exempt organizations.  Content Data is current up to 8/14/2017  EIN Employer Identification Number (EIN) NAME Primary Name of Organization ICO In Care of Name STREET Street Address CITY City STATE State ZIP Zip Code GROUP Group Exemption Number SUBSECTION Subsection Code AFFILIATION Affiliation Code CLASSIFICATION Classification Code(s) RULING Ruling Date DEDUCTIBILITY Deductibility Code FOUNDATION Foundation Code ACTIVITY Activity Codes ORGANIZATION Organization Code STATUS Exempt Organization Status Code TAX_PERIOD Tax Period ASSET_CD Asset Code INCOME_CD Income Code FILING_REQ_CD Filing Requirement Code PF_FILING_REQ_CD PF Filing Requirement Code ACCT_PD Accounting Period ASSET_AMT Asset Amount INCOME_AMT Income Amount (includes negative sign if amount is negative) REVENUE_AMT Form 990 Revenue Amount (includes negative sign if amount is negative) NTEE_CD National Taxonomy of Exempt Entities (NTEE) Code SORT_NAME Sort Name (Secondary Name Line)  There are six data files separated by regions eo1  CT MA ME NH NJ NY RI VT  eo2  DC DE IA IL IN KY MD MI MN NC ND NE OH PA SC SD VA WI WV  eo3  AK AL AR AZ CA CO FL GA HI ID KS LA MO MS MT NM NV OK OR TN TX UT WA WY  eo4  AA AE AP AS FM GU MH MP PR PW VI  eo_pr  Puerto Rico  eo_xx Various international non-profits (too many countries to list). See columns 5 and 6. Acknowledgements More information and updated data an be found here",EIN:NAME:ICO:STREET:CITY:STATE:ZIP:GROUP:SUBSECTION:AFFILIATION:CLASSIFICATION:RULING:DEDUCTIBILITY:FOUNDATION:ACTIVITY:ORGANIZATION:STATUS:TAX_PERIOD:ASSET_CD:INCOME_CD:FILING_REQ_CD:PF_FILING_REQ_CD:ACCT_PD:ASSET_AMT:INCOME_AMT:REVENUE_AMT:NTEE_CD:SORT_NAME:,numeric:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:,
Daily Happiness & Employee Turnover , Jose Berengueres , www.kaggle.com/harriken/employeeturnover , Mon Aug 07 2017 14:42:12 GMT+0530 (IST) , Is There a Relationship Between Employee Happiness and Job Turnover? ,493, economics- ,  Can Happiness Predict Employee Turnover or is it the Other Way Around? It is the summer of 2016. I am in Barcelona and it is hot and humid. By chance I go to a talk where  Alex Rios - the ceo of myhappyforce.com explains his product. He has built an app where employees report daily happiness levels at work. This app is used by companies to track happiness of the workforce. After the talk I ask him if he would opensource the (anonymized data) so we can better understad the phenomenon of employee turnover. Here is what we did we developed a model that predicts which employees will churn. Then we looked at the features (used by the model) that are common to employees that churn. The top feautures of employees that churn are  low ratio of likes received (likeability) low posting frequency (engagement)  low relative happiness (employee happiness normalized by company mean).   Surprisingly a priori expected explanatory features such as mean happiness level and the ratio of likes (positivity) were not significant. Precision@50 = 80% out of a test set with 116 churns sample size N=2k. Another surprise was that raw happiness is a bad predictor of churn. But the question is What did we miss? Can you find more insights? Starter script R starter script https//www.kaggle.com/harriken/how-many-unlikes-it-takes-to-get-fired Content The data consists of four tables votes comments interactions and churn. A vote was obtained when an employee opened the app and answered the question How happy are you at work today? To vote the employee indicates their feeling by touching one of four icons that appeared on the screen. After the employee indicates their happiness level a second screen appears where they can input a text explanation (usually a complaint suggestion or comment) this is the comments table. Out of 4356 employees 2638 employees commented at least once. Finally in a third screen the employee can see their peers’ comments and like or dislike them this data is stored in the interactions table. 3516 employees liked or disliked at least one of their peers’ comments. The churn table contains when an employee churned (quit or was fired). Acknowledgements  Python script version with social graph features http//bit.ly/2v2sEZg More detailed R scripts https//github.com/orioli/e3 The paper which was presented at ASONAM 2017 Sydney Slides https//www.slideshare.net/harriken/ieee-happiness-an-inside-job-asoman-2017  Inspiration The cost of employee turnover has been pointed out extensively in the literature. A high turnover rate not only increases human resource costs which can reach up to 150% of the annual salary per replaced employee but it also has social costs as it is correlated with lower wages lower productivity per employee and not surprisingly a less loyal workforce 1. For reference in 2006 turnover at Walmart’s Sam’s Club was 44% with an average hourly pay of $10.11 while at Costco it was a much lower 17% with a higher $17.0 hourly wage 2. In addition a more recent study correlated companies with low turnover with a series of socially positive characteristics dubbed high-involvement work practices 3. On the other hand research on employee turnover (churn) is not a prolific topic in the engineering community. In IEEE publications one can find just over 278 publications with titles containing the keyword churn and the bulk of those focus on customer churn and specifically churn in the telecommunications industry while on the topic of employee churn there is just one title indexed 4. The goal is to clarify the characteristics of employees that will churn (or that are at risk of churning) to help companies understand the causes so they can reduce the turnover rate. ,employee:companyAlias:numVotes:lastParticipationDate:stillExists:,numeric:string:numeric:string:boolean:,
Crime in Context 1975-2015 , The Marshall Project , www.kaggle.com/marshallproject/crime-rates , Fri Feb 10 2017 10:10:15 GMT+0530 (IST) , Are violent crime rates rising or falling in American cities? ,921, history- crime- ,"Context Is crime in America rising or falling? The answer is not as simple as politicians make it out to be because of how the FBI collects crime data from the country’s more than 18000 police agencies. National estimates can be inconsistent and out of date as the FBI takes months or years to piece together reports from those agencies that choose to participate in the voluntary program. To try to fill this gap The Marshall Project collected and analyzed more than 40 years of data on the four major crimes the FBI classifies as violent — homicide rape robbery and assault — in 68 police jurisdictions with populations of 250000 or greater. We obtained 2015 reports which have yet to be released by the FBI directly from 61 of them. We calculated the rate of crime in each category and for all violent crime per 100000 residents in the jurisdiction based on the FBI’s estimated population for that year. We used the 2014 estimated population to calculate 2015 crime rates per capita. Acknowledgements The crime data was acquired from the FBI Uniform Crime Reporting program's ""Offenses Known and Clearances by Arrest"" database for the year in question held at the National Archives of Criminal Justice Data. The data was compiled and analyzed by Gabriel Dance Tom Meagher and Emily Hopkins of The Marshall Project; the analysis was published as Crime in Context on 18 August 2016.",report_year:agency_code:agency_jurisdiction:population:violent_crimes:homicides:rapes:assaults:robberies:months_reported:crimes_percapita:homicides_percapita:rapes_percapita:assaults_percapita:robberies_percapita:,numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Gun Deaths in the US: 2012-2014 , Zurda , www.kaggle.com/hakabuk/gun-deaths-in-the-us , Wed Jan 25 2017 16:02:17 GMT+0530 (IST) , Information about gun-deaths from the CDC: Ages gender intent and more ,1307, death- crime- violence- demographics- ,Context This dataset includes information about gun-death in the US in the years 2012-2014.  Content The data includes data regarding the victim's age sex race education intent time (month and year) and place of death and whether or not police was at the place of death.  Acknowledgements I came across this thanks to FiveThirtyEight's Gun Deaths in America project. The data originated from the CDC and can be found here.,:year:month:intent:police:sex:age:race:hispanic:place:education:,numeric:numeric:numeric:string:numeric:string:numeric:string:numeric:string:numeric:,
Chat messages , Oleksii Nidzelskyi , www.kaggle.com/onidzelskyi/chat-messages , Mon Mar 06 2017 22:49:48 GMT+0530 (IST) , Urban night city chat messages ,406, cities- linguistics- telecommunications- ,Context Collection of chat messages in night urban city between boys and girls. Content Data set of messages (more than 1 million of rows) in Russian language from teenager population taken in period from 2012 to 2016 inclusive Acknowledgements All personal info in the message' body were taken from public web source and though are free of use.  Inspiration This dataset can be used to classify chat messages as male / female. Key objectives  Extract phone numbers from messages. All phone numbers are located in Ukraine and belongs to one from next operators +380 50 +380 95 +380 66 +380 99 +380 63 +380 73 +380 93 +380 68 +380 67 +380 96 +380 97 +380 98 Classify chat messages by gender (male/female) ,date:msg:,dateTime:string:,
EMPRES Global Animal Disease Surveillance , Rob Harrand , www.kaggle.com/tentotheminus9/empres-global-animal-disease-surveillance , Thu Aug 24 2017 20:45:01 GMT+0530 (IST) , Global animal disease outbreaks from the last 2 years ,43, ,Context Data downloaded from the EMPRES Global Animal Disease Information System. Content Data shows the when where and what of animal disease outbreaks from the last 2 years including African swine fever Foot and mouth disease and bird-flu. Numbers of cases deaths etc are also included. Acknowledgements This data is from the Food and Agriculture Organization of the United Nations. The EMPRES-i system can be access here Read more about the details of the system here,Id:source:latitude:longitude:region:country:admin1:localityName:localityQuality:observationDate:reportingDate:status:disease:serotypes:speciesDescription:sumAtRisk:sumCases:sumDeaths:sumDestroyed:sumSlaughtered:humansGenderDesc:humansAge:humansAffected:humansDeaths:,numeric:string:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:string:numeric:string:string:,
NYC Restaurant Inspections , City of New York , www.kaggle.com/new-york-city/nyc-inspections , Tue Aug 29 2017 23:52:05 GMT+0530 (IST) , ~400k Rows of Restaurant Inspections Data ,178, government agencies- food and drink- business- ,Context Restaurant inspections for permitted food establishments in NYC. Restaurants are graded on A-F scale with regular visits by city health department.  Content Dataset includes address cuisine description inspection date type action violation code and description(s). Data covers all of NYC and starts Jan 1 2010-Aug 29 2017.  Acknowledgements Data was collected by the NYC Department of Health and is available here.  Inspiration  Can you predict restaurant closings? Are certain violations more prominent in certain neighborhoods? By cuisine? Who gets worse grades--chain restaurants or independent establishments? ,CAMIS:DBA:BORO:BUILDING:STREET:ZIPCODE:PHONE:CUISINE DESCRIPTION:INSPECTION DATE:ACTION:VIOLATION CODE:VIOLATION DESCRIPTION:CRITICAL FLAG:SCORE:GRADE:GRADE DATE:RECORD DATE:INSPECTION TYPE:,numeric:string:string:numeric:string:numeric:numeric:string:dateTime:string:string:string:string:numeric:string:dateTime:dateTime:string:,
Individual Income Tax Statistics , Internal Revenue Service , www.kaggle.com/irs/individual-income-tax-statistics , Wed Sep 06 2017 21:46:57 GMT+0530 (IST) , Summaries of individual income tax returns by zip code ,287, finance- government- ,ZIP Code data show selected income and tax items classified by State ZIP Code and size of adjusted gross income. Data are based on individual income tax returns filed with the IRS. The data include items such as  Number of returns which approximates the number of households Number of personal exemptions which approximates the population Adjusted gross income  Wages and salaries Dividends before exclusion Interest received    Content For details of the exact fields available please see the field_definitions.csv. Please note that the exact fields available can change from year to year this definitions file was generated by retaining only the most recent year's entry from the years which had pdf manuals. The associated IRS form numbers are the most likely to change over time.  Acknowledgements This data was generated by the Internal Revenue Service.,STATEFIPS:STATE:zipcode:agi_stub:N1:mars1:MARS2:MARS4:PREP:N2:NUMDEP:TOTAL_VITA:VITA:TCE:VITA_EIC:RAL:RAC:ELDERLY:A00100:N02650:A02650:N00200:A00200:N00300:A00300:N00600:A00600:N00650:A00650:N00700:A00700:N00900:A00900:N01000:A01000:N01400:A01400:N01700:A01700:SCHF:N02300:A02300:N02500:A02500:N26270:A26270:N02900:A02900:N03220:A03220:N03300:A03300:N03270:A03270:N03150:A03150:N03210:A03210:N03230:A03230:N03240:A03240:N04470:A04470:A00101:N18425:A18425:N18450:A18450:N18500:A18500:N18300:A18300:N19300:A19300:N19700:A19700:N04800:A04800:N05800:A05800:N09600:A09600:N05780:A05780:N07100:A07100:N07300:A07300:N07180:A07180:N07230:A07230:N07240:A07240:N07220:A07220:N07260:A07260:N09400:A09400:N85770:A85770:N85775:A85775:N09750:A09750:N10600:A10600:N59660:A59660:N59720:A59720:N11070:A11070:N10960:A10960:N11560:A11560:N06500:A06500:N10300:A10300:N85530:A85530:N85300:A85300:N11901:A11901:N11902:A11902:,numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
(Better) - Donald Trump Tweets! , LiamLarsen , www.kaggle.com/kingburrito666/better-donald-trump-tweets , Sun Apr 16 2017 09:54:29 GMT+0530 (IST) , A collection of all of Donald Trump tweets--better than its predecessors ,535, politics- internet- ,Context Unlike This dataset (which proved to be unusable). And This one which was filled with unnecessary columns; This Donald trump dataset has the cleanest usability and consists of over 7000 tweets no nonsense You may need to use a decoder other than UTF-8 if you want to see the emojis Content Data consists of  -Date -Time -Tweet_Text -Type -Media_Type -Hashtags -Tweet_Id -Tweet_Url -twt_favourites_IS_THIS_LIKE_QUESTION_MARK -Retweets  I scrapped this from someone on reddit,Date:,dateTime:,
Corporate Prosecution Registry , University of Virginia , www.kaggle.com/university-of-virginia/corporate-prosecution-registry , Tue Jun 27 2017 22:13:02 GMT+0530 (IST) , Details of federal cases in the United States against corporations since 2001 ,60, business- crime- ,Context The goal of this Corporate Prosecutions Registry is to provide comprehensive and up-to-date information on federal organizational prosecutions in the United States so that we can better understand how corporate prosecutions are brought and resolved. It includes detailed information about every federal organizational prosecution since 2001 as well as deferred and non-prosecution agreements with organizations since 1990. Dataset Description These data on deferred prosecution and non-prosecution agreements were collected by identifying agreements through news searches press releases by the Department of Justice and U.S. Attorney’s Office and also when practitioners brought agreements to our attention. The Government Accountability Office conducted a study of federal deferred prosecution and non-prosecution agreements with organizations and in August 2010 the GAO provided a list of those agreements in response to an information request. Finally searches of the Bloomberg dockets database located additional prosecution agreements with companies that had not previously been located. Jon Ashley has contacted U.S. Attorney’s Offices to request agreements. An effort by the First Amendment Clinic at the University of Virginia School of Law to litigate Freedom of Information Act requests resulted in locating a group of missing agreements which are now available on the Registry. This Registry only includes information about federal organizational prosecutions and not cases brought solely in state courts. Nor does this Registry include leniency agreements entered through the Antitrust Division’s leniency program which are kept confidential. The Registry also does not include convictions overturned on appeal or cases in which the indictment was dismissed or the company was acquitted at a trial. The U.S. Sentencing Commission reports sentencing data concerning organizational prosecutions each year. That data does not include cases resolved without a formal sentencing such as deferred and non-prosecution agreements. Acknowledgements The Corporate Prosecutions Registry is a project of the University of Virginia School of Law. It was created by Professor Brandon Garrett (bgarrett@virginia.edu) and Jon Ashley (jaa6c@virginia.edu). Please cite this dataset as  “Brandon L. Garrett and Jon Ashley Corporate Prosecutions Registry University of Virginia School of Law at http//lib.law.virginia.edu/Garrett/corporate-prosecution-registry/index.html” Inspiration  Which industries face the most prosecutions? Which government organizations have been the most successful at pursuing cases against corporations? Not a single case in the dataset led to a trial conviction. Can you link these corporate cases to criminal cases against the individuals involved? How many of them were convicted instead? ,REC_ID:COMPANY:DISPOSITION_TYPE:PRIMARY_CRIME_CODE:SWISS_BANK_PROGRAM:USAO:COUNTRY:FINANCIAL_INSTITUTION:CASE_NAME:CASE_ID:DOCKET_NO:DATE:JUDGMENT_DATE:PLEA_DATE:TICKER:US_PUBLIC_CO:ADDITIONAL_REGULATORY_FINE_OR_PAYMENT:COMMUNITY_SERVICE_OR_OTHER:FINE:FORFEITURE_DISGORGEMENT:PROBATION_LENGTH:RESTITUTION:TOTAL_PAYMENT:ACCEPTS_RESPONSIBILITY:AGREEMENT_REQUIRED_NEW_POSITIONS:AGREEMENT_REQUIRED_OUTSIDE_AUDITORS_OR_EXPERTS:CITATION_AND_DESCRIPTION:CIVIL_JUDGMENT_OR_SETTLEMENT:COMPLIANCE_PROGRAM_DESCRIPTION:COMPLIANCE_PROGRAM_REQUIRED_BY_AGREEMENT:COMPLIANCE_REQUIRED_BY_REGULATORS:CRIME_DESC:DESCRIPTION_OF_PAYMENTS:DOES_AGREEMENT_DISCUSS_REASONS_OR_RELEVENT_CONSIDERATIONS_FOR_LENIENCY:DOJ_CAN_UNILATERALLY_TERMINATE:FINE_CALCULATION_INCLUDED:FINE_DESCRIPTION:INDEP_MONITOR_REQUIRED:MUST_COMPORT_WITH_USSG_OR_AUDIT_COMPLIANCE:OTHER_AGREEMENT:OTHER_AGREEMENT_REQUIRED_GOVERNANCE_CHANGES:OTHER_COMPLIANCE_OFFICER_OR_CONSULTANT_REQUIRED:PARALLEL_CIVIL_SUIT:PARALLEL_REGULATORY_ACTION_OR_LOCAL_PROSECUTOR:PRE_AGREEMENT_COMPLIANCE:PRE_AGREEMENT_COMPLIANCE_DESCRIPTION:PRIVACY_WAIVER:REGULATORY_DISGORGEMENT_RESTITUTION_FORFEITURE:REGULATORY_FINE:REG_AGENCY:STATEMENT_OF_FACTS:TOTAL_REGULATORY:UNRELATED_TERMS:AGMT_YEAR:SOURCE:NOTES:,numeric:string:string:string:string:string:string:string:string:string:numeric:dateTime:dateTime:dateTime:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:string:string:,
Indian Prison Statistics  (2001 - 2013) , Rajanand Ilangovan / இராஜ்ஆனந்த் இளங்கோவன் , www.kaggle.com/rajanand/prison-in-india , Tue Sep 05 2017 17:10:37 GMT+0530 (IST) , Details of Inmates are classified according to 35+ factors. (35+ csv files) ,403, india- crime- ,Context This dataset contains the complete detail about the Prison and various characteristics of inmates. This will help to understand better about prison system in India. Content  Details of Jail wise population of prison inmates Details about the list of jails in India at the end of year 2015. Jail category wise population of inmates.  Capacity of jails by inmate population.  Age group nationality and gender wise population of inmates.   Religion and gender wise population of inmates. Caste and gender wise population of inmates.  Education standards of inmates.   Domicile of inmates.   Incidence of recidivism. Rehabilitation of prisoners. Distribution of sentence periods of convicts in various jails by sex and age-groups.  Details of under trial prisoners by the type of IPC (Indian Penal Code) offences. Details of convicts by the type of IPC (Indian Penal Code) offences. Details of SLL (special & local law) Crime headwise distribution of inmates who convicted Details of SLL (special & local law) Crime head wise distribution of inmates under trial Details of educational facilities provided to prisoners.  Details of Jail breaks group clashes and firing in jail (Tranquility). Details of wages per day to convicts.  Details of Prison inmates trained under different vocational training. Details of capital punishment (death sentence) and life imprisonment.  Details of prison inmates escaped.  Details of prison inmates released.  Details of Strength of officials Details of Total Budget and Actual Expenditure during the year 2015-16. Details of Budget Details of Expenditure Details of Expenditure on inmates Details of Inmates suffering from mental ilness Details of Period of detention of undertrials Details of Number of women prisoners with children Details of Details of inmates parole during the year Details of Value of goods produced by inmates Details of Number of vehicles available Details of Training of Jail Officers Details of Movements outside jail premises Details of Details of electronic equipment used in prison  Inspiration There are many questions about Indian prison with this dataset. Some of the interesting questions are  Percentage of jails over crowded. Is there any change in percentage over time? How many percentage of inmates re-arrested? Which state/u.t pay more wages to the inmates? Which state/u.t has more capital punishment/life imprisonment inmates? Inmates gender ratio per state   Acknowledgements National Crime Records Bureau (NCRB) Govt of India has shared this dataset under Govt. Open Data License - India. NCRB has also shared prison data on their website.,state_name:is_state:year:category:type:gender:age_16_18:age_18_30:age_30_50:age_50_above:,string:numeric:numeric:string:string:string:numeric:numeric:numeric:numeric:,
Flaredown Autoimmune Symptom Tracker , Flaredown , www.kaggle.com/flaredown/flaredown-autoimmune-symptom-tracker , Sat Jun 24 2017 01:32:41 GMT+0530 (IST) , Help patients of chronic autoimmune and invisible illnesses improve symptoms ,132, diseases- epidemiology- human medicine- health- ,This dataset was downloaded here and its description is reproduced below Please drop Logan a line at logan@flaredown.com and let me know who you are and what you’re investigating Introduction Flaredown is an app that helps patients of chronic autoimmune and invisible illnesses improve their symptoms by avoiding triggers and evaluating treatments. These diseases are tough to reliably treat and the internet (where many patients go for help) is full of dubious theories and anecdotal evidence making it extremely hard to find the worthwhile data in a mountain of empty information. In return for providing a useful tool we receive data that we can use to investigate these theories. Because our data is self-reported and uncontrolled our goal is not to comprehensively test hypotheses but rather to be the “canary in the coalmine” that indicates potentially worthwhile areas of study. And if any of those indications turns into recognition of a new treatment or debunking of a harmful myth or any other insight for patients Flaredown will have accomplished its goal. About the data Instead of coupling symptoms to a particular illness Flaredown asks users to create their unique set of conditions symptoms and treatments (“trackables”). They can then “check-in” each day and record the severity of symptoms and conditions the doses of treatments and “tag” the day with any unexpected environmental factors. User includes an ID age sex and country. Condition an illness or diagnosis for example Rheumatoid Arthritis rated on a scale of 0 (not active) to 4 (extremely active). Symptom self-explanatory also rated on a 0–4 scale. Treatment anything a patient uses to improve their symptoms along with an optional dose which is a string that describes how much they took during the day. For instance “3 x 5mg”. Tag a string representing an environmental factor that does not occur every day for example “ate dairy” or “rainy day”. Food food items were seeded from the publicly-available USDA food database. Users have also added many food items manually. Weather weather is pulled automatically for the user's postal code from the Dark Sky API. Weather parameters include a description precipitation intensity humidity pressure and min/max temperatures for the day. If users do not see a symptom treatment tag or food in our database (for instance “Abdominal Pain” as a symptom) they may add it by simply naming it. This means that the data requires some cleaning but it is patient-centered and indicates what they really care about. Suggested Questions  Does X treatment affect Y symptom positively/negatively/not at all? What are the most strongly-correlated symptoms and treatments? Are there subsets within our current diagnoses that could more accurately represent symptoms and predict effective treatments? Can we reliably predict what triggers a flare for a given user or all users with a certain condition? Could we recommend treatments more effectively based on similarity of users rather than specific symptoms and conditions? (Netflix recommendations for treatments) Can we quantify a patient’s level of disease activity based on their symptoms? How different is it from our existing measures? Can we predict which symptom should be treated to have the greatest effect on a given illness? How accurately can we guess a condition based on a user’s symptoms? Can we detect new interactions between treatments?  Email logan@flaredown.com if you have questions about the project,user_id:age:sex:country:checkin_date:trackable_id:trackable_type:trackable_name:trackable_value:,string:string:string:string:dateTime:numeric:string:string:numeric:,
.nyc Domain Registrations , City of New York , www.kaggle.com/new-york-city/dot-nyc-domain-registrations , Sat Sep 02 2017 01:18:28 GMT+0530 (IST) , All .nyc domain names registered with the City of New York ,16, cities- internet- ,Context Every website registered as a .nyc domain between the period of March 20 2014 when the domain was acquired by the City of New York and August 31 2017. Content The data includes the domain name registered the date the name was registered and the domain classification type. The .nyc domain has been a focus of New York City’s smart city branding ever since its acquisition in 2014. Customers and businesses local to the city have been encouraged to register new websites with a “.nyc” ending under the aegis of the Own It NYC marketing campaign. As a recent and very popular greenfield domain name the .nyc registrations dataset provide a lens into what constitutes a “high value domain” on today's web. Acknowledgements This dataset is published as-is by the New York City Department of Information Technology and Telecommunications. Inspiration  What is the split between individuals and organizations registering a .nyc domain? What common words or text strings were registered first? Is there evidence that these are “high-value” domains? ,Domain Name :Domain Registration Date :Nexus Category:,string:dateTime:string:,
Flight Route Database , OpenFlights , www.kaggle.com/open-flights/flight-route-database , Tue Aug 29 2017 22:49:35 GMT+0530 (IST) , A database of 59036 flight routes ,159, ,"Routes database As of January 2012 the OpenFlights/Airline Route Mapper Route Database contains 59036 routes between 3209 airports on 531 airlines spanning the globe. Content The data is ISO 8859-1 (Latin-1) encoded. Each entry contains the following information  Airline   2-letter (IATA) or 3-letter (ICAO) code of the airline. Airline ID    Unique OpenFlights identifier for airline (see Airline). Source airport    3-letter (IATA) or 4-letter (ICAO) code of the source airport. Source airport ID Unique OpenFlights identifier for source airport (see Airport) Destination airport   3-letter (IATA) or 4-letter (ICAO) code of the destination airport. Destination airport ID    Unique OpenFlights identifier for destination airport (see Airport) Codeshare ""Y"" if this flight is a codeshare (that is not operated by Airline but another carrier) empty otherwise. Stops Number of stops on this flight (""0"" for direct) Equipment 3-letter codes for plane type(s) generally used on this flight separated by spaces  The special value \N is used for ""NULL"" to indicate that no value is available.  Notes  Routes are directional if an airline operates services from A to B and from B to A both A-B and B-A are listed separately. Routes where one carrier operates both its own and codeshare flights are listed only once.  Acknowledgements This dataset was downloaded from Openflights.org under the Open Database license. This is an excellent resource and there is a lot more on their website so check them out!",airline:airline ID: source airport: source airport id: destination apirport: destination airport id: codeshare: stops: equipment:,string:numeric:string:numeric:string:numeric:string:numeric:string:,
Restaurants That Sell Tacos and Burritos , Datafiniti , www.kaggle.com/datafiniti/restaurants-burritos-and-tacos , Wed Jul 12 2017 06:32:01 GMT+0530 (IST) ," A list of 19000+ businesses offering ""burrito"" or ""taco"" menu items in the U.S. ",110, ,"About this Data This is a sample data set of menu items containing ""burrito"" or ""taco"" in their names. The data set covers 19439 restaurants and similar businesses located in the USA. Each row corresponds to a single menu item from the restaurant. Note that the entirety of each restaurant's menu is not listed. Only burrito or taco items are listed. What You Can Do with this Data You can use this data to discover all sorts of interesting trends related to tacos and burritos. E.g.  Uncover differences in pricing trends between burritos and tacos. Identify which cities or states are more likely to serve burritos and tacos. What words are most often used to describe burritos and tacos dishes? Identify the most popular type of burritos and tacos.  About Datafiniti Datafiniti provides instant access to web data.  We compile data from thousands of websites to create standardized databases of business product and property information.  Learn more. Want More? If you're interested in more data like this please contact us.",id:address:categories:city:country:cuisines:dateAdded:dateUpdated:keys:latitude:longitude:menuPageURL:menus.amountMax:menus.amountMin:menus.category:menus.currency:menus.dateSeen:menus.description:menus.name:name:postalCode:priceRangeCurrency:priceRangeMin:priceRangeMax:province:websites::,string:string:string:string:string:string:dateTime:dateTime:string:numeric:numeric:string:string:string:string:string:dateTime:string:string:string:numeric:string:numeric:numeric:string:string:string:,
South Park Dialogue , Ksenia Sukhova , www.kaggle.com/tovarischsukhov/southparklines , Wed Mar 15 2017 00:21:34 GMT+0530 (IST) , More than 70000 lines of dialogue by season episode and character ,820, popular culture- linguistics- ,South Park cartoon lines +70k lines annotated with season episode and speaker It is interesting to practice NLP with ML techniques in order to guess who is speaking. Later there will be file with pre-proccesed data to train,Season:Episode:Character:Line:,numeric:numeric:string:string:,
NIPS 2017: Adversarial Learning Development Set , Google Brain , www.kaggle.com/google-brain/nips-2017-adversarial-learning-development-set , Sun Jul 02 2017 09:22:41 GMT+0530 (IST) , Development images used in the NIPS 2017 Adversarial Learning challenges ,675, artificial intelligence- ,Most existing machine learning classifiers are highly vulnerable to adversarial examples. An adversarial example is a sample of input data which has been modified very slightly in a way that is intended to cause a machine learning classifier to misclassify it. In many cases these modifications can be so subtle that a human observer does not even notice the modification at all yet the classifier still makes a mistake. Adversarial examples pose security concerns because they could be used to perform an attack on machine learning systems even if the adversary has no access to the underlying model. To accelerate research on adversarial examples Google Brain is organizing Competition on Adversarial Examples and Defenses within the NIPS 2017 competition track. This dataset contains the development images for this competition. The competition on Adversarial Examples and Defenses consist of three sub-competitions  Non-targeted Adversarial Attack. The goal of the non-targeted attack is to slightly modify source image in a way that image will be classified incorrectly by generally unknown machine learning classifier. Targeted Adversarial Attack. The goal of the targeted attack is to slightly modify source image in a way that image will be classified as specified target class by generally unknown machine learning classifier. Defense Against Adversarial Attack. The goal of the defense is to build machine learning classifier which is robust to adversarial example i.e. can classify adversarial images correctly.  In each of the sub-competitions you're invited to make and submit a program which solves the corresponding task. In the end of the competition we will run all attacks against all defenses to evaluate how each of the attacks performs against each of the defenses.,CategoryId:CategoryName:,numeric:string:,
NYC Dog Names , City of New York , www.kaggle.com/new-york-city/nyc-dog-names , Thu Aug 31 2017 21:34:44 GMT+0530 (IST) , Popularity of 16k dog names ,93, cities- animals- ,Context The NYC Department of Health requires all dog owners to license their dogs. The resulting names data was released on GitHub with a nice interactive D3 word cloud. Additional data (including type and color) is available from WNYC here. Content This data covers dog names and the counts of each name.,Row_Labels:Count_AnimalName:,numeric:numeric:,
The Demographic /r/ForeverAlone Dataset , LiamLarsen , www.kaggle.com/kingburrito666/the-demographic-rforeveralone-dataset , Sat Apr 29 2017 04:38:58 GMT+0530 (IST) , A survey taken by redditers in /r/ForeverAlone. You would be surprised. ,303, linguistics- sociology- internet- ,Why? Last year a redditor created a survey to collect demographic data on the subreddit /r/ForeverAlone. Since then they have deleted their account but they left behind their data set. Columns are below Content  Timestamp  DateTime  What is your Gender?  String  What is your sexual orientation?  String  How old are you?  DateTime  What is your level of income?  DateTime  What is your race?  String  How would you describe your body/weight?  String  Are you a virgin?  String  Is prostitution legal where you live?  String  Would you pay for sex?  String  How many friends do you have IRL?  DateTime  Do you have social anxiety/phobia?  String  Are you depressed?  String  What kind of help do you want from others? (Choose all that apply)  String  Have you attempted suicide?  String  Employment Status Are you currently…?  String  What is your job title?  String  What is your level of education?  String  What have you done to try and improve yourself? (Check all that apply) ,time:gender:sexuallity:age:income:race:bodyweight:virgin:prostitution_legal:pay_for_sex:friends:social_fear:depressed:what_help_from_others:attempt_suicide:employment:job_title:edu_level:improve_yourself_how:,dateTime:string:string:numeric:string:string:string:string:string:string:numeric:string:string:string:string:string:string:string:string:,
Zillow Rent Index 2010-Present , Zillow , www.kaggle.com/zillow/rent-index , Sat Mar 04 2017 02:30:13 GMT+0530 (IST) , Which city has the highest median price or price per square foot? ,1254, cities- home- ,Context Zillow operates an industry-leading economics and analytics bureau led by Zillow’s Chief Economist Dr. Stan Humphries. At Zillow Dr. Humphries and his team of economists and data analysts produce extensive housing data and analysis covering more than 500 markets nationwide. Zillow Research produces various real estate rental and mortgage-related metrics and publishes unique analyses on current topics and trends affecting the housing market. At Zillow’s core is our living database of more than 100 million U.S. homes featuring both public and user-generated information including number of bedrooms and bathrooms tax assessments home sales and listing data of homes for sale and for rent. This data allows us to calculate among other indicators the Zestimate a highly accurate automated estimated value of almost every home in the country as well as the Zillow Home Value Index and Zillow Rent Index leading measures of median home values and rents.  Content The Zillow Rent Index is the median estimated monthly rental price for a given area and covers multifamily single family condominium and cooperative homes in Zillow’s database regardless of whether they are currently listed for rent. It is expressed in dollars and is seasonally adjusted. The Zillow Rent Index is published at the national state metro county city neighborhood and zip code levels. Zillow produces rent estimates (Rent Zestimates) based on proprietary statistical and machine learning models. Within each county or state the models observe recent rental listings and learn the relative contribution of various home attributes in predicting prevailing rents. These home attributes include physical facts about the home prior sale transactions tax assessment information and geographic location as well as the estimated market value of the home (Zestimate). Based on the patterns learned these models estimate rental prices on all homes including those not presently for rent. Because of the availability of Zillow rental listing data used to train the models Rent Zestimates are only available back to November 2010; therefore each ZRI time series starts on the same date. Acknowledgements The rent index data was calculated from Zillow's proprietary Rent Zestimates and published on its website. Inspiration What city has the highest and lowest rental prices in the country? Which metropolitan area is the most expensive to live in? Where have rental prices increased in the past five years and where have they remained the same? What city or state has the lowest cost per square foot?,City Code:City:Metro:County:State:Population Rank:November 2010:December 2010:January 2011:February 2011:March 2011:April 2011:May 2011:June 2011:July 2011:August 2011:September 2011:October 2011:November 2011:December 2011:January 2012:February 2012:March 2012:April 2012:May 2012:June 2012:July 2012:August 2012:September 2012:October 2012:November 2012:December 2012:January 2013:February 2013:March 2013:April 2013:May 2013:June 2013:July 2013:August 2013:September 2013:October 2013:November 2013:December 2013:January 2014:February 2014:March 2014:April 2014:May 2014:June 2014:July 2014:August 2014:September 2014:October 2014:November 2014:December 2014:January 2015:February 2015:March 2015:April 2015:May 2015:June 2015:July 2015:August 2015:September 2015:October 2015:November 2015:December 2015:January 2016:February 2016:March 2016:April 2016:May 2016:June 2016:July 2016:August 2016:September 2016:October 2016:November 2016:December 2016:January 2017:,numeric:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Toxic Release Inventory , US Environmental Protection Agency , www.kaggle.com/epa/toxic-release-inventory , Wed Aug 23 2017 23:55:45 GMT+0530 (IST) , US EPA data on release of toxic chemicals for 1987-2016 ,89, government agencies- pollution- ,Context This database is managed by the  US Environmental Protection Agency and contains information reported annually by some industry groups as well as federal facilities. Each year companies across a wide range of industries (including chemical mining paper oil and gas industries) that produce more than 25000 pounds or handle more than 10000 pounds of a listed toxic chemical must report it to the TRI. The TRI threshold was initially set at 75000 pounds annually. If the company treats recycles disposes or releases more than 500 pounds of that chemical into the environment (as opposed to just handling it) then they must provide a detailed inventory of that chemical's inventory. Content  There are roughly 100 columns in this dataset; please see the tri_basic_data_file_format_v15.pdf for details. You may also wish to consult factors_to_consider_6.15.15_final.pdf for general background about interpreting the data. I've merged all of the TRI basic data files into a single large csv. You will probably need to process it in batches or use a tool like Dask to stay within kernel memory limits. Please note that the 2016 data remains preliminary at the time of this release.  Acknowledgements This dataset was released by the US EPA. You can find the original dataset more detailed versions of the data  and a great deal of background information here https//www.epa.gov/toxics-release-inventory-tri-program/tri-data-and-tools Inspiration The EPA runs an annual university contest. Their list of previous winners contains a lot of great ideas that people have had for this dataset in the past. The 2017 competition is already over but you can find the rules here.,YEAR:TRI_FACILITY_ID:FRS_ID:FACILITY_NAME:STREET_ADDRESS:CITY:COUNTY:ST:ZIP:BIA_CODE:TRIBE:LATITUDE:LONGITUDE:FEDERAL_FACILITY:INDUSTRY_SECTOR_CODE:INDUSTRY_SECTOR:PRIMARY_SIC:SIC_2:SIC_3:SIC_4:SIC_5:SIC_6:PRIMARY_NAICS:NAICS_2:NAICS_3:NAICS_4:NAICS_5:NAICS_6:DOC_CTRL_NUM:CHEMICAL:CAS_#/COMPOUND_ID:SRS_ID:CLEAR_AIR_ACT_CHEMICAL:CLASSIFICATION:METAL:METAL_CATEGORY:CARCINOGEN:FORM_TYPE:UNIT_OF_MEASURE:5.1_FUGITIVE_AIR:5.2_STACK_AIR:5.3_WATER:5.4_UNDERGROUND:5.4.1_UNDERGROUND_CLASS_I:5.4.2_UNDERGROUND_CLASS_II-V:5.5.1_LANDFILLS:5.5.1A_RCRA_C_LANDFILLS:5.5.1B_OTHER_LANDFILLS:5.5.2_LAND_TREATMENT:5.5.3_SURFACE_IMPOUNDMENT:5.5.3A_RCRA_C_SURFACE_IMP.:5.5.3B_Other_SURFACE_IMP.:5.5.4_OTHER_DISPOSAL:ON-SITE_RELEASE_TOTAL:6.1_POTW-TRANSFERS_FOR_RELEASE:6.1_POTW-TRANSFERS_FOR_TREATM.:6.1_POTW-TOTAL_TRANSFERS:6.2_M10:6.2_M41:6.2_M62:6.2_M71:6.2_M81:6.2_M82:6.2_M72:6.2_M63:6.2_M66:6.2_M67:6.2_M64:6.2_M65:6.2_M73:6.2_M79:6.2_M90:6.2_M94:6.2_M99:OFF-SITE_RELEASE_TOTAL:6.2_M20:6.2_M24:6.2_M26:6.2_M28:6.2_M93:OFF-SITE_RECYCLED_TOTAL:6.2_M56:6.2_M92:OFF-SITE_RECOVERY_TOTAL:6.2_M40:6.2_M50:6.2_M54:6.2_M61:6.2_M69:6.2_M95:OFF-SITE_TREATED_TOTAL:TOTAL_RELEASES:8.1_RELEASES:8.1A_ON-SITE_CONTAINED_REL.:8.1B_ON-SITE_OTHER_RELEASES:8.1C_OFF-SITE_CONTAINED_REL.:8.1D_OFF-SITE_OTHER_RELEASES:8.2_ENERGY_RECOVERY_ON-SITE:8.3_ENERGY_RECOVERY_OFF-SITE:8.4_RECYCLING_ON-SITE: 8.5_RECYCLING_OFF-SITE:8.6_TREATMENT_ON-SITE:8.7_TREATMENT_OFF-SITE:PROD._WASTE_(8.1_THRU_8.7):8.8_ONE-TIME_RELEASE:PROD_RATIO_OR_ACTIVITY:8.9_PRODUCTION_RATIO:PARENT_COMPANY_NAME:PARENT_COMPANY_DB_NUMBER:Unnamed: 109:,numeric:string:numeric:string:string:string:string:string:numeric:string:string:numeric:numeric:string:numeric:string:string:string:string:string:string:string:numeric:numeric:string:string:string:string:numeric:string:numeric:numeric:string:string:string:numeric:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:string:numeric:string:,
Airbnb Property Data from Texas , PromptCloud , www.kaggle.com/PromptCloudHQ/airbnb-property-data-from-texas , Tue Jul 25 2017 01:51:04 GMT+0530 (IST) , Dataset of 18000+ properties ,308, united states- hotels- ,Context Sharing economy and vacation rentals are among the hottest topics that has touched millions of lives across the globe. Airbnb has been instrumental in this space and currently operating in more than 191 countries. Hence it'd be good idea to analyze this data and uncover insights. Content Dataset contains more than 18000 property listings from Texas United Staes. Given below are the data fields Rate per night Number of bedrooms City Joining month and year Longitude Latitude Property description Property title Property URL The Airbnb data was extracted by PromptCloud’s Data-as-a-Service solution. Initial Analysis The following article covers spatial data visualization and topic modelling of the description text http//www.kdnuggets.com/2017/08/insights-data-mining-airbnb.html Inspiration Some of the interesting analysis are related to spatial mapping and text mining of the description text apart from the exploratory analysis.,:average_rate_per_night:bedrooms_count:city:date_of_listing:description:latitude:longitude:title:url:,numeric:string:numeric:string:dateTime:string:numeric:numeric:string:string:,
Innerwear Data from Victoria's Secret and Others , PromptCloud , www.kaggle.com/PromptCloudHQ/innerwear-data-from-victorias-secret-and-others , Wed Aug 09 2017 13:51:20 GMT+0530 (IST) , 600000+ innerwear product data extracted from popular retail sites ,418, business- internet- ,Context These datasets provides an opportunity to perform analyses on the fashion trend of innerwear and swimwear products. Content They were created by extracting data from from the popular retail sites via PromptCloud's data extraction solutions.  Sites covered  Amazon Victoria's Secret Btemptd Calvin Klein Hanky Panky American Eagle Macy's Nordstrom Topshop USA  Time period June 2017 to July 2017 Inspiration Some of the most common questions that can be answered are  How does the pricing differ depending on the brand? Topic modelling on the product description What are the most common color used by different brands? Analyses on the product ratings (wherever applicable) Common style attributes (wherever applicable) ,product_name:mrp:price:pdp_url:brand_name:product_category:retailer:description:rating:review_count:style_attributes:total_sizes:available_size:color:,string:string:string:string:string:string:string:string:numeric:numeric:string:string:string:string:,
New York City - 2013 Campaign Contributions , City of New York , www.kaggle.com/new-york-city/nyc-2013-campaign-contributions , Fri Sep 08 2017 23:04:48 GMT+0530 (IST) , Donors recipients and dollar amounts from the 2013 NYC election cycle ,24, money- politics- ,Context A record of every campaign donation made during the 2013 New York City election cycle. This dataset includes the donor recipient and dollar amount of contributions to campaigns both for the mayor of New York City (for the 2013-2017 term which was won by Bill de Blasio) and for the variety of other publicly elected positions in the City of New York. Content This dataset includes identifying information about the name of the person and/or corporation which made the donation the dollar amount of the donation whether or not it was later refunded (if so a date of refund is provided) the archetype the donation falls under the name of the candidate being donated to and identifying information about the donor (including self-identified work area or profession). This dataset includes a field for campaign finance codes read here for more information on what these are. Acknowledgements This data is published as-is by the City of New York. Inspiration  What is the distribution of donations made across candidates? What is the distribution of small-to-large donations? Who is doing the donating? How are they spatially distributed through the city? ,ELECTION:OFFICECD:CANDID:CANCLASS:CANDLAST:CANDFIRST:CANDMI:COMMITTEE:FILING:SCHEDULE:PAGENO:SEQUENCENO:REFNO:DATE:REFUNDDATE:NAME:C_CODE:STRNO:STRNAME:APARTMENT:BOROUGHCD:OCCUPATION:EMPNAME:EMPSTRNO:EMPSTRNAME:AMNT:MATCHAMNT:PREVAMNT:PAY_METHOD:INTERMNO:INTERMNAME:INTSTRNO:INTSTRNM:INTAPTNO:INTST:INTZIP:INTEMPNAME:INTEMPSTNO:INTEMPSTNM:INTEMPCITY:INTEMPST:INTOCCUPA:PURPOSECD:EXEMPTCD:ADJTYPECD:RR_IND:SEG_IND:INT_C_CODE:Location 1:Location 2:Location 3:,numeric:numeric:numeric:string:string:string:string:string:numeric:string:string:string:string:dateTime:dateTime:string:string:numeric:string:string:string:string:string:numeric:string:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:numeric:string:numeric:string:string:string:string:string:string:numeric:string:string:string:string:string:string:,
Software Architectural Styles , QadeemKhan , www.kaggle.com/qadeemkhan/dataset-of-software-architectural-styles , Mon Mar 27 2017 16:54:40 GMT+0530 (IST) , The pattern analysis of software development by statistical/datamining methods ,201, computer architecture- programming- ,Context Software systems are composed of one or more software architectural styles. These styles define the usage patterns of a programmer in order to develop a complex project. These architectural styles are required to analyze for pattern similarity in the structure of multiple groups of projects. The researcher can apply different types of data mining algorithms to analyze the software projects through architectural styles used. The dataset is obtained from an online questionnaire delivered to the world 's best academic and software industry.  Content The content of this dataset are multiple architectural styles utilized by the system. He attributes are  Repository Client Server Abstract MachineObject OrientedFunction OrientedEvent DrivenLayered Pipes & Filters Data centeric Blackboard Rule Based Publish Subscribe Asynchronous Messaging Plug-ins Microkernel Peer-to-Peer Domain Driven Shared Nothing. Acknowledgements Thanks to my honorable teacher Prof.Dr Usman Qamar for guiding me to accomplish this wonderful task. Inspiration The dataset is capable of updating and refinements.Any researcher who want to contribute plz feel free to ask.,Timestamp:Your Good Name?:Organization?:Last Degree?:Job Experience ?:1. How Many Repository Architectural Styles have you used for a particular project?:2. How Many Client Server Styles you have used for a particular project?:3. How Many Abstract Machine Styles you have used for a particular project?:4. How Many Object Oriented Styles you have used for a particular project?:5. How Many Function Oriented Styles you have used for a particular project?:6. How Many Event Driven Styles you have used for a particular project?:7. How Many Layered Styles you have used for a particular project?:8. How Many  Pipes & Filters Architectural Styles  have you used for a particular project?:9. How Many  Data centeric Architectural Styles have you used for a particular project?:10. How Many  Blackboard  Architectural Styles have you used for a particular project?:11. How Many  Rule Based Architectural Styles have you used for a particular project?:12. How Many Publish Subscribe Architectural Styles have you used for a particular project?:13. How Many  Asynchronous Messaging Architectural Styles have you used for a particular project?:14. How Many  Plug-ins Architectural Styles have you used for a particular project?:15. How Many  Micro-kernel Architectural Styles have you used for a particular project?:16. How Many  Peer-to-Peer Architectural Styles have you used for a particular project?:17. How Many  Domain Driven Architectural Styles have you used for a particular project?:18. How Many  Shared Nothing Architectural Styles have you used for a particular project?:,string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Fireballs , NASA , www.kaggle.com/nasa/fireballs , Wed Aug 23 2017 04:22:54 GMT+0530 (IST) , Bolide impacts by the kiloton since 1988. ,65, government agencies- space- ,Fireballs and bolides are astronomical terms for exceptionally bright meteors that are spectacular enough to to be seen over a very wide area. A world map shows a visual representation of the data table that provides a chronological data summary of fireball and bolide events provided by U.S. Government sensors. Ground-based observers sometimes also witness these events at night or much more rarely in daylight as impressive atmospheric light displays. This website is not meant to be a complete list of all fireball events. Only the brightest fireballs are noted. Content The accompanying table provides information on the date and time of each reported fireball event with its approximate total optical radiated energy and its calculated total impact energy. When reported the event’s geographic location altitude and velocity at peak brightness are also provided. Note that data are not provided in real-time and not all fireballs are reported. A blank (empty) field in the table indicates the associated value was not reported. For more information about fireballs and bolides please see https//cneos.jpl.nasa.gov/fireballs/intro.html. Field legend  Peak Brightness Date/Time (UT) The date and time in UT (Universal Time) of this event's peak brightness. Latitude (deg.) Geodetic latitude in degrees north (N) or south (S) of the equator for this event. Longitude (deg.) Geodetic longitude in degrees east (E) or west (W) of the prime meridian for this event. Altitude (km) Altitude in kilometers (km) above the reference geoid for this event. Velocity (km/s) The magnitude of the meteor's pre-impact velocity in kilometers per second (km/s). Velocity Components (km/s) The magnitude of the meteor's pre-impact velocity in a geocentric Earth-fixed reference frame defined as follows the z-axis is directed along the Earth's rotation axis towards the celestial north pole the x-axis lies in the Earth's equatorial plane directed towards the prime meridian and the y-axis completes the right-handed coordinate system. Total Radiated Energy (J) The approximate total radiated energy in the atmosphere in Joules [a unit of energy given in kilograms times velocity squared or kg × (m/s)2] Calculated Total Impact Energy (kt) The impact energy of the event in kilotons of TNT (kt) computed from an empirical expression relating radiated and impact energy  Acknowledgements This dataset was kindly made available by NASA. You can find the original dataset at https//cneos.jpl.nasa.gov/fireballs/ You might also be interested in their Planetary Defense FAQ.,Peak Brightness Date/Time (UT):Latitude (deg.):Longitude (deg.):Altitude (km):Velocity (km/s):vx:vy:vz:Total Radiated Energy (J):Calculated Total Impact Energy (kt):,dateTime:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Online Courses from Harvard and MIT , edX , www.kaggle.com/edx/course-study , Fri Jan 27 2017 20:05:10 GMT+0530 (IST) , What subjects or courses are the most popular on edX? ,1658, education- ,"Context In 2012 the Massachusetts Institute of Technology (MIT) and Harvard University launched open online courses on edX a non-profit learning platform co-founded by the two institutions. Four years later what have we learned about these online “classrooms” and the global community of learners who take them? Content This report provides data on 290 Harvard and MIT online courses 250 thousand certifications 4.5 million participants and 28 million participant hours on the edX platform since 2012. Acknowledgements Isaac Chuang a professor at MIT and Andrew Ho a professor at Harvard University published this data as an appendix to their paper ""HarvardX and MITx Four Years of Open Online Courses"".",Institution:Course Number:Launch Date:Course Title:Instructors:Course Subject:Year:Honor Code Certificates:Participants (Course Content Accessed):Audited (> 50% Course Content Accessed):Certified:% Audited:% Certified:% Certified of > 50% Course Content Accessed:% Played Video:% Posted in Forum:% Grade Higher Than Zero:Total Course Hours (Thousands):Median Hours for Certification:Median Age:% Male:% Female:% Bachelor's Degree or Higher:,string:string:dateTime:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Python Questions from Stack Overflow , Stack Overflow , www.kaggle.com/stackoverflow/pythonquestions , Fri Oct 21 2016 01:45:51 GMT+0530 (IST) , Full text of Stack Overflow Q&A about the Python programming language ,1121, internet- programming languages- ,Full text of questions and answers from Stack Overflow that are tagged with the python tag useful for natural language processing and community analysis. See also the dataset of R questions. This is organized as three tables  Questions contains the title body creation date score and owner ID for each Python question. Answers contains the body creation date score and owner ID for each of the answers to these questions. The ParentId column links back to the Questions table. Tags contains the tags on each question besides the Python tag.  For space reasons only non-deleted and non-closed content are included in the dataset. The dataset contains questions up to 19 October 2016 (UTC). License All Stack Overflow user contributions are licensed under CC-BY-SA 3.0 with attribution required.,,,
OpenAddresses - U.S. West , OpenAddresses , www.kaggle.com/openaddresses/openaddresses-us-west , Thu Aug 03 2017 04:19:23 GMT+0530 (IST) , Addresses and geo-locations for the U.S. West ,91, ,Context OpenAddresses's goal is to connect the digital and physical worlds by sharing geographic coordinates street names house numbers and postal codes.  Content This dataset contains one datafile for each state in the U.S. West region. States included in this dataset  Alaska - ak.csv Arizona - az.csv California - ca.csv Colorado - co.csv Hawaii - hi.csv Idaho - id.csv Montana - mt.csv New Mexico - nm.csv Nevada - nv.csv Oregon - or.csv Utah - ut.csv Washington - wa.csv Wyoming - wy.csv  Field descriptions  LON - Longitude LAT - Latitude NUMBER - Street number STREET - Street name UNIT - Unit or apartment number CITY - City name DISTRICT - ? REGION - ? POSTCODE - Postcode or zipcode ID - ? HASH - ?  Acknowledgements Data collected around 2017-07-25 by OpenAddresses (http//openaddresses.io). Address data is essential infrastructure. Street names house numbers and postal codes when combined with geographic coordinates are the hub that connects digital to physical places. Data licenses can be found in LICENSE.txt. Data source information can be found at https//github.com/openaddresses/openaddresses/tree/9ea72b079aaff7d322349e4b812eb43eb94d6d93/sources Inspiration Use this dataset to create maps in conjunction with other datasets for crime or weather,LON:LAT:NUMBER:STREET:UNIT:CITY:DISTRICT:REGION:POSTCODE:ID:HASH:,numeric:numeric:numeric:string:string:string:string:string:numeric:string:string:,
NYC Baby Names , City of New York , www.kaggle.com/new-york-city/nyc-baby-names , Sat Sep 09 2017 01:34:20 GMT+0530 (IST) , Baby names popular in New York City. ,130, children- ,Context Baby names for children recently born in New York City. This dataset is notable because it includes a breakdown by the ethnicity of the mother of the baby a source of ethnic information that is missing from many other similar datasets published on state and national levels. Content This dataset includes columns for the name year of birth sex and mother's ethnicity of the baby. It also includes a rank column (that name's popularity relative to the rest of the names on the list). Acknowledgements This data is published as-is by the City of New York. Inspiration  How do baby names in New York City differ from national trends? What names are most more or less popular amongst different ethnicities? ,Year of Birth:Gender:Ethnicity:Child's First Name:Count:Rank:,numeric:string:string:string:numeric:numeric:,
Biomechanical features of orthopedic patients , UCI Machine Learning , www.kaggle.com/uciml/biomechanical-features-of-orthopedic-patients , Thu Sep 07 2017 04:24:11 GMT+0530 (IST) , Classifying patients based on six features ,174, ,Context The data have been organized in two different but related classification tasks.   column_3C_weka.csv (file with three class labels) The first task consists in classifying patients as belonging to one out of three categories Normal (100 patients) Disk Hernia (60 patients) or Spondylolisthesis (150 patients).  column_2C_weka.csv (file with two class labels) For the second task the categories Disk Hernia and Spondylolisthesis were merged into a single category labelled as 'abnormal'. Thus the second task consists in classifying patients as belonging to one out of two categories Normal (100 patients) or Abnormal (210 patients).  Content Field Descriptions Each patient is represented in the data set by six biomechanical attributes derived from the shape and orientation of the pelvis and lumbar spine (each one is a column)   pelvic incidence pelvic tilt lumbar lordosis angle sacral slope pelvic radius grade of spondylolisthesis  Acknowledgements The original dataset was downloaded from UCI ML repository Lichman M. (2013). UCI Machine Learning Repository [http//archive.ics.uci.edu/ml]. Irvine CA University of California School of Information and Computer Science Files were converted to CSV Inspiration Use these biomechanical features to classify patients according to their labels ,pelvic_incidence:pelvic_tilt numeric:lumbar_lordosis_angle:sacral_slope:pelvic_radius:degree_spondylolisthesis:class:,numeric:numeric:numeric:numeric:numeric:numeric:string:,
Airports Train Stations and Ferry Terminals , OpenFlights , www.kaggle.com/open-flights/airports-train-stations-and-ferry-terminals , Tue Aug 29 2017 04:09:31 GMT+0530 (IST) , Openflight.org's database of the worlds transportation hubs ,188, transport- aviation- public transport- rail transport- vehicles- ,"Context This is a database of airports train stations and ferry terminals around the world. Some of the data come from public sources and some of it comes from OpenFlights.org user contributions. Content  Airport ID    Unique OpenFlights identifier for this airport. Name  Name of airport. May or may not contain the City name. City  Main city served by airport. May be spelled differently from Name. Country   Country or territory where airport is located. See countries.dat to cross-reference to ISO 3166-1 codes. IATA  3-letter IATA code. Null if not assigned/unknown. ICAO  4-letter ICAO code. Null if not assigned. Latitude  Decimal degrees usually to six significant digits. Negative is South positive is North. Longitude Decimal degrees usually to six significant digits. Negative is West positive is East. Altitude  In feet. Timezone  Hours offset from UTC. Fractional hours are expressed as decimals eg. India is 5.5. DST   Daylight savings time. One of E (Europe) A (US/Canada) S (South America) O (Australia) Z (New Zealand) N (None) or U (Unknown). See also Help Time Tz database time zone Timezone in ""tz"" (Olson) format eg. ""America/Los_Angeles"". Type  Type of the airport. Value ""airport"" for air terminals ""station"" for train stations ""port"" for ferry terminals and ""unknown"" if not known. Source    Source of this data. ""OurAirports"" for data sourced from OurAirports ""Legacy"" for old data not matched to OurAirports (mostly DAFIF) ""User"" for unverified user contributions. In airports.csv only source=OurAirports is included.  Acknowledgements This dataset was downloaded from Openflights.org under the Open Database license. This is an excellent resource and there is a lot more on their website so check them out! ",1:Goroka Airport:Goroka:Papua New Guinea:GKA:AYGA:-6.081689834590001:145.391998291:5282:10:U:Pacific/Port_Moresby:airport:OurAirports:,numeric:string:string:string:string:string:numeric:numeric:numeric:numeric:string:string:string:string:,
Emotion Aging and Sentiment Over Time , Chris Roth , www.kaggle.com/cjroth/chronist , Mon Feb 13 2017 04:14:03 GMT+0530 (IST) , Data from the Chronist project ,617, gerontology- linguistics- ,Chronist is a project to quantitatively monitor the emotional and physical changes of an individual over periods of time. My thesis is that if you can accurately show emotional or physical change over time you can objectively pinpoint how an environmental change such as a career change moving to a new city starting or ending a relationship or starting a new habit like going to the gym affected your physical and emotional health. This can lead to important insights on an individual level and for a population as a whole. If you are interested in hearing more about this project contributing your data or collaborating contact me at chris@cjroth.com. See the GitHub repository to read more about the tools that were used to generate the dataset.,date:sentiment.comparative:sentiment.negative_count:sentiment.positive_count:sentiment.score:time:,dateTime:numeric:numeric:numeric:numeric:dateTime:,
Health Care Access/Coverage for 1995-2010 , Centers for Disease Control and Prevention , www.kaggle.com/cdc/health-care-access-coverage , Thu Nov 17 2016 10:30:17 GMT+0530 (IST) , Prevalence and Trends of Health Care Acess ,580, healthcare- ,Context This dataset contains the prevalence and trends of health care access/coverage for 1995-2010. Percentages are weighted to population characteristics. Data are not available if it did not meet Behavioral Risk Factor Surveillance System (BRFSS) stability requirements. For more information on these requirements as well as risk factors and calculated variables see the Technical Documents and Survey Data for a specific year - http//www.cdc.gov/brfss/annual_data/annual_data.htm.  Content This dataset has 7 variables  Year State Yes No Category Condition Location 1  Acknowledgements The original dataset can be found here. Recommended citation Centers for Disease Control and Prevention (CDC). Behavioral Risk Factor Surveillance System. Atlanta Georgia U.S. Department of Health and Human Services Centers for Disease Control and Prevention [appropriate year]. Inspiration  How does health care coverage change over time? Does health care access differ by state? ,Year:State:Yes:No:Category:Condition:Location 1:,numeric:string:string:string:string:string:string:,
"The ""Trump Effect"" in Europe ", Dalia Research , www.kaggle.com/daliaresearch/trump-effect , Tue Jan 24 2017 19:03:13 GMT+0530 (IST) , A post-election survey about populism in the US and the EU-28 ,939, politics- international relations- ,"Context  The election of Donald Trump has taken the world by surprise and is fuelling populist movements in Europe e.g. in Italy Austria and France. Understanding populism and assessing the impact of the “Trump effect” on Europe is a tremendous challenge and Dalia wants to help pool brainpower to find answers.  The goal is to find out where the next wave of populism could hit in Europe by comparing and contrasting US and EU voter profiles opinions of Trump vs Clinton voters Brexit vs. Bremain voters and future expectations. Content Expanding Dalia’s quarterly ""EuroPulse"" omnibus survey to the USA Dalia has conducted a representative survey with n=11.283 respondents across all 28 EU member countries and n=1.052 respondents from the United States of America. To find out where the next wave of populism could hit Europe Dalia’s survey traces commonalities in social and political mindsets (like authoritarianism prejudice open-mindedness xenophobia etc.) voting behaviour and socio-demographic profiles on both sides of the Atlantic. Inspiration The sources of our inspirations are many but to name a few who influenced the way we asked questions we were very inspired by the 'angry voter' profile laid out by Douglas Rivers the influence of political and moral attitudes pointed out by Jonathan Haidt and the profile of ""America's forgotten working class"" by J. D. Vance.  Researchers should apply the necessary logic caution and diligence when analysing and interpreting the results. ",question_id_mapped:question_wording:question_kind:code:value:,string:string:string:numeric:string:,
Crimes Committed in France , Government of France , www.kaggle.com/government-of-france/crimes-in-france , Fri Sep 29 2017 22:38:37 GMT+0530 (IST) , Monthly counts of crimes committed since 2000 ,137, europe- crime- ,Context This dataset is an aggregated count of all crimes committed in France broken down by month and category. Content This data was aggregated by the French national government and published online on the French Open Data Portal. It is a combination of records kept by both local and national police forces. It's important to note that the name of the categories of crime are in French! Acknowledgements This data is a part of a larger group of Excel files published by the French Goverment on the French Open Data Portal. It has been converted to a single CSV file before uploading here. Inspiration This is a simple time series dataset that can be probed for trends in the underlying types of crimes committed. Is petty theft more or less popular today than it was ten years ago? How much variation is there in the amount of robberies year-to-year? Can you normalize the growth in the number of crimes against the growth in the number of people? How do crimes committed here differ from those committed in say Los Angeles?,Index:Libellé index:2017_08:2017_07:2017_06:2017_05:2017_04:2017_03:2017_02:2017_01:2016_12:2016_11:2016_10:2016_09:2016_08:2016_07:2016_06:2016_05:2016_04:2016_03:2016_02:2016_01:2015_12:2015_11:2015_10:2015_09:2015_08:2015_07:2015_06:2015_05:2015_04:2015_03:2015_02:2015_01:2014_12:2014_11:2014_10:2014_09:2014_08:2014_07:2014_06:2014_05:2014_04:2014_03:2014_02:2014_01:2013_12:2013_11:2013_10:2013_09:2013_08:2013_07:2013_06:2013_05:2013_04:2013_03:2013_02:2013_01:2012_12:2012_11:2012_10:2012_09:2012_08:2012_07:2012_06:2012_05:2012_04:2012_03:2012_02:2012_01:2011_12:2011_11:2011_10:2011_09:2011_08:2011_07:2011_06:2011_05:2011_04:2011_03:2011_02:2011_01:2010_12:2010_11:2010_10:2010_09:2010_08:2010_07:2010_06:2010_05:2010_04:2010_03:2010_02:2010_01:2009_12:2009_11:2009_10:2009_09:2009_08:2009_07:2009_06:2009_05:2009_04:2009_03:2009_02:2009_01:2008_12:2008_11:2008_10:2008_09:2008_08:2008_07:2008_06:2008_05:2008_04:2008_03:2008_02:2008_01:2007_12:2007_11:2007_10:2007_09:2007_08:2007_07:2007_06:2007_05:2007_04:2007_03:2007_02:2007_01:2006_12:2006_11:2006_10:2006_09:2006_08:2006_07:2006_06:2006_05:2006_04:2006_03:2006_02:2006_01:2005_12:2005_11:2005_10:2005_09:2005_08:2005_07:2005_06:2005_05:2005_04:2005_03:2005_02:2005_01:2004_12:2004_11:2004_10:2004_09:2004_08:2004_07:2004_06:2004_05:2004_04:2004_03:2004_02:2004_01:2003_12:2003_11:2003_10:2003_09:2003_08:2003_07:2003_06:2003_05:2003_04:2003_03:2003_02:2003_01:2002_12:2002_11:2002_10:2002_09:2002_08:2002_07:2002_06:2002_05:2002_04:2002_03:2002_02:2002_01:2001_12:2001_11:2001_10:2001_09:2001_08:2001_07:2001_06:2001_05:2001_04:2001_03:2001_02:2001_01:2000_12:2000_11:2000_10:2000_09:2000_08:2000_07:2000_06:2000_05:2000_04:2000_03:2000_02:2000_01:,numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Airline Database , OpenFlights , www.kaggle.com/open-flights/airline-database , Tue Aug 29 2017 22:22:34 GMT+0530 (IST) , A database of over 5000 airlines ,235, aviation- ,"Airline database As of January 2012 the OpenFlights Airlines Database contains 5888 airlines. Some of the information is public data and some is contributed by users. Content The data is ISO 8859-1 (Latin-1) encoded. Each entry contains the following information - Airline ID    Unique OpenFlights identifier for this airline. - Name  Name of the airline. - Alias Alias of the airline. For example All Nippon Airways is commonly known as ""ANA"". - IATA  2-letter IATA code if available. - ICAO  3-letter ICAO code if available. - Callsign  Airline callsign. - Country   Country or territory where airline is incorporated. - Active    ""Y"" if the airline is or has until recently been operational ""N"" if it is defunct. This field is not reliable in particular major airlines that stopped flying long ago but have not had their IATA code reassigned (eg. Ansett/AN) will incorrectly show as ""Y"". The special value \N is used for ""NULL"" to indicate that no value is available. This is from a MySQL database where \N is used for NULL.  Notes Airlines with null codes/callsigns/countries generally represent user-added airlines. Since the data is intended primarily for current flights defunct IATA codes are generally not included. For example ""Sabena"" is not listed with a SN IATA code since ""SN"" is presently used by its successor Brussels Airlines. Acknowledgements This dataset was downloaded from Openflights.org under the Open Database license. This is an excellent resource and there is a lot more on their website so check them out! ",Airline ID:Name:Alias:IATA:ICAO:Callsign:Country:Active:,numeric:string:string:string:string:string:string:string:,
Correlates of War: World Religions , University of Michigan , www.kaggle.com/umichigan/world-religions , Sat Jan 28 2017 00:30:23 GMT+0530 (IST) , World regional and national populations by religious beliefs ,865, religious faiths traditions and movements- politics- war- ,Content The World Religion Project aims to provide detailed information about religious adherence worldwide since 1945. It contains data about the number of adherents by religion in each of the states in the international system for every half-decade period. Some of the religions are divided into religious families and the breakdown of adherents within a given religion into religious families is provided to the extent data are available. The project was developed in three stages. The first stage consisted of the formation of a religions tree. A religion tree is a systematic classification of major religions and of religious families within those major religions. To develop the religion tree we prepared a comprehensive literature review the aim of which was to define a religion to find tangible indicators of a given religion of religious families within a major religion and to identify existing efforts at classifying world religions. The second stage consisted of the identification of major data sources of religious adherence and the collection of data from these sources according to the religion tree classification. This created a dataset that included multiple records for some states for a given point in time yet contained multiple missing data for specific states specific time periods and specific religions. The third stage consisted of cleaning the data reconciling discrepancies of information from different sources and imputing data for the missing cases. Acknowledgements The dataset was created by Zeev Maoz University of California-Davis and Errol Henderson Pennsylvania State University and published by the Correlates of War Project.,year:christianity_protestant:christianity_romancatholic:christianity_easternorthodox:christianity_anglican:christianity_other:christianity_all:judaism_orthodox:judaism_conservative:judaism_reform:judaism_other:judaism_all:islam_sunni:islam_shi’a:islam_ibadhi:islam_nationofislam:islam_alawite:islam_ahmadiyya:islam_other:islam_all:buddhism_mahayana:buddhism_theravada:buddhism_other:buddhism_all:zoroastrianism_all:hinduism_all:sikhism_all:shinto_all:baha’i_all:taoism_all:jainism_all:confucianism_all:syncretism_all:animism_all:noreligion_all:otherreligion_all:religion_all:population:world_population:protestant_percent:romancatholic_percent:easternorthodox_percent:anglican_percent:otherchristianity_percent:christianity_percent:orthodox_percent:conservative_percent:reform_percent:otherjudaism_percent:judaism_percent:sunni_percent:shi’a_percent:ibadhi_percent:nationofislam_percent:alawite_percent:ahmadiyya_percent:otherislam_percent:islam_percent:mahayana_percent:theravada_percent:otherbuddhism_percent:buddhism_percent:zoroastrianism_percent:hinduism_percent:sikhism_percent:shinto_percent:baha’i_percent:taoism_percent:jainism_percent:confucianism_percent:syncretism_percent:animism_percent:noreligion_percent:otherreligion_percent:religion_sumpercent:total_percent:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Eating & Health Module Dataset , US Bureau of Labor Statistics , www.kaggle.com/bls/eating-health-module-dataset , Thu Nov 10 2016 00:11:41 GMT+0530 (IST) , American Time Use Survey (ATUS) Eating & Health Module Files from 2014 ,1269, nutrition- demographics- ,Context The ATUS Eating & Health (EH) Module was fielded from 2006 to 2008 and again in 2014 to 2016. The EH Module data files contain additional information related to eating meal preparation and health.  Data for 2015 currently are being processed and have not yet been released. Data collection is planned to run through December 2016. Content There are 3 datasets from 2014  The EH Respondent file which contains information about EH respondents including general health and body mass index. There are 37 variables. The EH Activity file which contains information such as the activity number whether secondary eating occurred during the activity and the duration of secondary eating. There are 5 variables. The EH Replicate weights file which contains miscellaneous EH weights. There are 161 variables.  The data dictionary can be found here. Acknowledgements The original datasets can be found here. Inspiration Some ideas for exploring the datasets are  What is the relationship between weight or BMI and meal preparation patterns consumption of fresh/fast food or snacking patterns? Do grocery shopping patterns differ by income? ,,,
Airplane Crashes Since 1908 , Sauro Grandi , www.kaggle.com/saurograndi/airplane-crashes-since-1908 , Sat Sep 10 2016 02:13:04 GMT+0530 (IST) , Full history of airplane crashes throughout the world from 1908-present ,14087, aviation- ,"Analysis of the public dataset ""Airplane Crashes and Fatalities Since 1908"" (Full history of airplane crashes throughout the world from 1908-present) hosted by Open Data by Socrata available at https//opendata.socrata.com/Government/Airplane-Crashes-and-Fatalities-Since-1908/q2te-8cvq Questions  Yearly how many planes crashed? how many people were on board? how many survived? how many died? Highest number of crashes by operator and Type of aircrafts. ‘Summary’ field has the details about the crashes. Find the reasons of the crash and categorize them in different clusters i.e Fire shot down weather (for the ‘Blanks’ in the data category can be UNKNOWN) you are open to make clusters of your choice but they should not exceed 7. Find the number of crashed aircrafts and number of deaths against each category from above step. Find any interesting trends/behaviors that you encounter when you analyze the dataset.   My solution The following bar charts display the answers requested by point 1. of the assignment in particular  the planes crashed per year people aboard per year during crashes people dead per year during crashes people survived per year during crashes   The following answers regard point 2 of the assignment  Highest number of crashes by operator Aeroflot with 179 crashes By Type of aircraft Douglas DC-3 with 334 crashes  I have identified 7 clusters using k-means clustering technique on a matrix obtained by a text corpus created by using Text Analysis (plain text remove punctuation to lower etc.) The following table summarize for each cluster the number of crashes and death.  Cluster 1 258 crashes 6368 deaths Cluster 2 500 crashes 9408 deaths Cluster 3 211 crashes 3513 deaths    Cluster 4 1014 crashes 14790 deaths  Cluster 5 2749 crashes 58826 deaths  Cluster 6 195 crashes 4439 deaths    Cluster 7 341 crashes 8135 deaths  The following picture shows clusters using the first 2 principal components  For each clusters I will summarize the most used words and I will try to identify the causes of the crash Cluster 1 (258) aircraft crashed plane shortly taking.  No many information about this cluster can be deducted using Text Analysis Cluster 2 (500) aircraft airport altitude crashed crew due engine failed failure fire flight landing lost pilot plane runway takeoff taking.  Engine failure on the runway after landing or takeoff Cluster 3 (211) aircraft crashed fog  Crash caused by fog Cluster 4 (1014) aircraft airport attempting cargo crashed fire land landing miles pilot plane route runway struck takeoff  Struck a cargo during landing or takeoff Cluster 5 (2749) accident aircraft airport altitude approach attempting cargo conditions control crashed crew due engine failed failure feet fire flight flying fog ground killed land landing lost low miles mountain pilot. plane poor route runway short shortly struck takeoff taking weather  Struck a cargo due to engine failure or bad weather conditions mainly fog Cluster 6 (195) aircraft crashed engine failure fire flight left pilot plane runway  Engine failure on the runway Cluster 7 (341) accident aircraft altitude cargo control crashed crew due engine failure flight landing loss lost pilot plane takeoff  Engine failure during landing or takeoff  Better solutions are welcome. Thanks.",,,
Leading Causes of Death in the USA , LiamLarsen , www.kaggle.com/kingburrito666/leading-causes-of-death-usa , Thu Mar 30 2017 23:28:11 GMT+0530 (IST) , Age-adjusted death rates for the top 10 leading causes of death in the US ,473, death- demographics- ,"Content Age-adjusted Death Rates for Selected Major Causes of Death United States 1900-2013 Age adjusting rates is a way to make fairer comparisons between groups with different age distributions. For example a county having a higher percentage of elderly people may have a higher rate of death or hospitalization than a county with a younger population merely because the elderly are more likely to die or be hospitalized. (The same distortion can happen when comparing races genders or time periods.) Age adjustment can make the different groups more comparable. A ""standard"" population distribution is used to adjust death and hospitalization rates. The age-adjusted rates are rates that would have existed if the population under study had the same age distribution as the ""standard"" population. Therefore they are summary measures adjusted for differences in age distributions. Acknowledgements Scrap data from data.gov",Leading Causes:Year:Age Adjusted Death Rate:,string:numeric:numeric:,
History of Hearthstone , romainvincent , www.kaggle.com/romainvincent/history-of-hearthstone , Thu Jul 06 2017 19:34:24 GMT+0530 (IST) , 346242 decks representing more than 3 years of gameplay! ,329, video games- ,"Context Hearthstone is a very popular collectible card game published by Blizzard Entertainment in 2014. The goal of the game consists in building a 30 cards deck in order to beat your opponent. A few weeks ago I decided to download all the decks posted by players at Hearthpwn. The code to download the data is available here. Content This upload is composed of two files  data.json / data.csv Contains the actual Hearthstone deck records. Each record features   date (str)  the date of publication (or last update) of the deck. user (str)  the user who uploaded the deck. deck_class (str)  one of the nine character class in Hearthstone (Druid Priest ...). deck_archetype (str)  the theme of deck labelled by the user (Aggro Druid Dragon Priest ...). deck_format (str)  the game format of the deck on the day data was recorded (W for ""Wild"" or S for ""Standard""). deck_set (str)  the latest expansion published prior the deck publication (Naxxramas TGT Launch ...). deck_id (int)  the ID of the deck. deck_type (str)  the type of the deck labelled by the user  Ranked Deck  a deck played on ladder. Theorycraft  a deck built with unreleased cards to get a gist of the future metagame. PvE Adventure  a deck built to beat the bosses in adventure mode. Arena  a deck built in arena mode. Tavern Brawl  a deck built for the weekly tavern brawl mode. Tournament  a deck brought at tournament by a pro-player. None  the game type was not mentioned. rating (int)  the number of upvotes received by that deck. title (str)  the name of the deck. craft_cost (int)  the amount of dust (in-game craft material) required to craft the deck. cards (list)  a list of 30 card ids. Each ID can be mapped to the card description using the reference file.  refs.json Contains the reference to the cards played in Hearthstone. This file was originally proposed on HearthstoneJSON. Each record features a lot of informations about the cards I'll list the most important   dbfId (int)  the id of the card (the one used in data.json). rarity (str)  the rarity of the card (EPIC RARE ...). cardClass (str)  the character class (WARLOCK PRIEST ...). artist (str)  the artist behind the card's art. collectible (bool)  whether or not the card can be collected. cost (int)  the card play cost. health (int)  the card health (if it's a minion). attack (int)  the card attack (if it's a minion). name (str)  the card name. flavor (str)  the card's flavor text. set (str)  the set / expansion which featured this card. text (int)  the card's text. type (str)  the card's type (MINION SPELL ...). race (str)  the card's race (if it's a minion). set (str)  the set / expansion which featured this card. ...  If you need help cleaning the data take a look at my start over kernel! What you could do   Try to predict the deck archetype based on the cards features in the deck. Seek relationships between the cost of the deck and it's popularity. Describe the evolution of the meta-game over-time. Find out unbalanced (overplayed) cards ",craft_cost:,numeric:,
World of Warcraft Demographics , Alyssa , www.kaggle.com/avenn98/world-of-warcraft-demographics , Sat Aug 05 2017 00:33:41 GMT+0530 (IST) , A short survey meant to look for any links between player and how they play. ,65, ,"Context This dataset looks at the demographics of World of Warcraft players–gender age sexuality etc.–and how they play the game–role race class–to see if there is an association between any of them. Specifically I was interested in how gender and sexuality affects the gender of the character they play but there are many other things to look at. This data was gathered through a Google Forms survey which was then posted on Reddit Tumblr Twitter and my WoW guild's Discord server. Content There are 14 columns 100 rows (not including the titles). 12 of those columns were gathered from a Google Forms survey and the last two were added by hand. They are  Timestamp Useless. Just when the survey was completed. Gender The gender of the player. Sexuality The sexuality of the player. Age Age of the player. Country Country the player lives in. Main The gender of character the player mains Faction The faction the player mains. Server The server(s) the player mains. Role The role(s) the player mains (DPS Healer Tank or any combination therein). Class The class(es) the player mains. This was a question where the respondent check any number of boxes so there are many different ways it could be answered. Hard to analyze. Race The race(s) the player mains. Same as class. Max The number of 110s (max level) the player has. Only numerical variable in the dataset. Attracted The gender the player is attracted to. Type The ""type"" of person the player is. Combines gender and sexuality (""gay woman"" ""bi male"" etc.)  Acknowledgements This dataset belongs to me. I created the survey and compiled the data. However I would like to thank stormwind-keep on Tumblr and earth2gem on Twitter for helping me get the survey out to a broader audience.  Inspiration I already ran a bunch of my own analyses using R but I could not find a good way to analyze the Class and Race variables. If anyone can figure that one out please do.",Timestamp:Gender:Sexuality:Age:Country:Main:Faction:Server:Role:Class:Race:Max:Attracted:Type:,string:string:string:string:string:string:string:string:string:string:string:numeric:string:string:,
Seattle Airbnb Open Data , Airbnb , www.kaggle.com/airbnb/seattle , Thu Nov 17 2016 10:37:56 GMT+0530 (IST) , A sneak peek into the Airbnb activity in Seattle WA USA ,1175, united states- home- hotels- ,Context Since 2008 guests and hosts have used Airbnb to travel in a more unique personalized way. As part of the Airbnb Inside initiative this dataset describes the listing activity of homestays in Seattle WA.  Content The following Airbnb activity is included in this Seattle dataset * Listings including full descriptions and average review score * Reviews including unique id for each reviewer and detailed comments * Calendar including listing id and the price and availability for that day Inspiration  Can you describe the vibe of each Seattle neighborhood using listing descriptions? What are the busiest times of the year to visit Seattle? By how much do prices spike? Is there a general upward trend of both new Airbnb listings and total Airbnb visitors to Seattle?  For more ideas visualizations of all Seattle datasets can be found here. Acknowledgement This dataset is part of Airbnb Inside and the original source can be found here.,,,
Historical Military Battles , Aleksey Bilogur , www.kaggle.com/residentmario/database-of-battles , Thu Sep 14 2017 02:09:07 GMT+0530 (IST) , Conditions and results from over 600 battles fought in 1600 - 1973 AD ,198, history- military- military science- ,"Context This dataset is a cleaned-up and modernized version of ""CAA Database of Battles Version 1990"" shortnamed ""CDB90"". It contains information on over 600 battles that were fought between 1600 AD and 1973 AD. Descriptive data include battle name date and location; the strengths and losses on each side; identification of the victor; temporal duration of the battle; and selected environmental and tactical environment descriptors (such as type of fortifications type of tactical scheme weather conditions width of front etc.). Content The data contained therein is split across several files. The most important of these is battles.csv which is lists and gives information about the battles themselves. Files marked enum describe the keys used by specific fields. Other files provide additional context. Acknowledgements The original version of this database was distributed by the U.S. Army Concepts Analysis Agency. The version of this dataset you see here is a cleaned-up version created by Jeffrey Arnold. This dataset cleanup code and source data are all available here. Inspiration  How often were battles fought in various weather conditions? How often did an attacker or defender achieve the element of surprise? Did it have a significant effect on the outcome? Did prepared fortifications have a significant effect on outcomes? ",isqno:atp_number:start_time_min:start_time_max:end_time_min:end_time_max:duration_max:duration_min:duration_only:,numeric:numeric:dateTime:dateTime:dateTime:dateTime:numeric:numeric:numeric:,
Localization Data for Posture Reconstruction , UCI Machine Learning , www.kaggle.com/uciml/posture-reconstruction , Wed Sep 06 2017 04:32:14 GMT+0530 (IST) , Recordings of five people while wearing localization tags ,39, human medicine- biotechnology- programming- ,Context These datums  represent a multi-agent system for the care of elderly people living at home on their own with the aim to prolong their independence. The system was designed to provide a reliable robust and flexible monitoring by sensing the user in the environment reconstructing the position and posture to create the physical awareness of the user in the environment reacting to critical situations calling for help in the case of an emergency and issuing warnings if unusual behavior was detected.  Content Columns descriptions  Sequence Name A01 A02 A03 A04 A05 B01 B02 B03 B04 B05 ...E05 A-E represent a person (5 total) 01 02 03 04 05 = Tag Numbers Tag identifiers ANKLE_LEFT = 010-000-024-033 ANKLE_RIGHT = 010-000-030-096 CHEST = 020-000-033-111 BELT = 020-000-032-221 Time stamp Date Format = dd.MM.yyyy HHmmssSSS x coordinate of the tag  y coordinate of the tag  z coordinate of the tag  activity walking falling 'lying down' lying 'sitting down' sitting 'standing up from lying' 'on all fours' 'sitting on the ground' 'standing up from sitting' 'standing up from sitting on the ground  Acknowledgements B. Kaluza V. Mirchevska E. Dovgan M. Lustrek M. Gams An Agent-based Approach to Care in Independent Living International Joint Conference on Ambient Intelligence (AmI-10) Malaga Spain In press Inspiration Given these data can you classify the persons activity from the tags they wore?,A01:010-000-024-033:633790226051280329:27.05.2009 14:03:25:127:4.062931060791016:1.8924342393875122:0.5074254274368286:walking:,string:string:numeric:string:numeric:numeric:numeric:string:,
Question Pairs Dataset , Quora , www.kaggle.com/quora/question-pairs-dataset , Thu Feb 02 2017 06:56:29 GMT+0530 (IST) , Can you identify duplicate questions? ,1166, languages- linguistics- artificial intelligence- ,Context Quora's first public dataset is related to the problem of identifying duplicate questions. At Quora an important product principle is that there should be a single question page for each logically distinct question. For example the queries “What is the most populous state in the USA?” and “Which state in the United States has the most people?” should not exist separately on Quora because the intent behind both is identical. Having a canonical page for each logically distinct query makes knowledge-sharing more efficient in many ways for example knowledge seekers can access all the answers to a question in a single location and writers can reach a larger readership than if that audience was divided amongst several pages. The dataset is based on actual data from Quora and will give anyone the opportunity to train and test models of semantic equivalence. Content There are over 400000 lines of potential question duplicate pairs. Each line contains IDs for each question in the pair the full text for each question and a binary value that indicates whether the line truly contains a duplicate pair. Acknowledgements For more information on this dataset check out Quora's first dataset release page. License This data is subject to Quora's Terms of Service allowing for non-commercial use.,id:qid1:qid2:question2:is_duplicate:question1:,numeric:numeric:numeric:string:numeric:string:,
Comcast Consumer Complaints , Charlie H. , www.kaggle.com/archaeocharlie/comcastcomplaints , Tue Nov 29 2016 04:46:00 GMT+0530 (IST) , Public complaints made about Comcast internet and television service. ,503, business- internet- networks- ,Comcast is notorious for terrible customer service and despite repeated promises to improve they continue to fall short. Only last month (October 2016) the FCC fined them a cool $2.3 million after receiving over 1000 consumer complaints. After dealing with their customer service for hours yesterday I wanted to find out more about others' experiences.  This will serve as a repository of public customer complaints filed against Comcast as I scrape them from the web. The data should not only provide a fun source for analysis but it will help to pin down just what is wrong with Comcast's customer service.,,,
Funding Successful Projects on Kickstarter , Ashok Lathwal , www.kaggle.com/codename007/funding-successful-projects , Tue Jun 20 2017 23:07:38 GMT+0530 (IST) , Predict if a project will get successfully funded or not using labeled data ,586, business- finance- ,Problem Statement Kickstarter is a community of more than 10 million people comprising of creative tech enthusiasts who help in bringing creative project to life. Till now more than $3 billion dollars have been contributed by the members in fueling creative projects. The projects can be literally anything – a device a game an app a film etc. Kickstarter works on all or nothing basis i.e if a project doesn’t meet it goal the project owner gets nothing. For example if a projects’s goal is $500. Even if it gets funded till $499 the project won’t be a success. Recently Kickstarter released its public data repository to allow researchers and enthusiasts like us to help them solve a problem. Will a project get fully funded ? In this challenge you have to predict if a project will get successfully funded or not. Data Description There are three files given to download train.csv test.csv and sample_submission.csv The train data consists of sample projects from the May 2009 to May 2015. The test data consists of projects from June 2015 to March 2017.,project_id:final_status:,string:numeric:,
US Permanent Visa Applications , Jacob Boysen , www.kaggle.com/jboysen/us-perm-visas , Fri Aug 25 2017 00:32:56 GMT+0530 (IST) , Detailed Information on 374k Decisions ,457, government agencies- immigration- ,Context A permanent labor certification issued by the Department of Labor (DOL) allows an employer to hire a foreign worker to work permanently in the United States. In most instances before the U.S. employer can submit an immigration petition to the Department of Homeland Security's U.S. Citizenship and Immigration Services (USCIS) the employer must obtain a certified labor certification application from the DOL's Employment and Training Administration (ETA). The DOL must certify to the USCIS that there are not sufficient U.S. workers able willing qualified and available to accept the job opportunity in the area of intended employment and that employment of the foreign worker will not adversely affect the wages and working conditions of similarly employed U.S. workers. Content Data covers 2012-2017 and includes information on employer position wage offered job posting history employee education and past visa history associated lawyers and final decision. Acknowledgements This data was collected and distributed by the US Department of Labor. Inspiration  Can you predict visa decisions based on employee/employer/wage? How does this data compare to H1B decisions in this dataset? ,add_these_pw_job_title_9089:agent_city:agent_firm_name:agent_state:application_type:case_no:case_number:case_received_date:case_status:class_of_admission:country_of_citizenship:country_of_citzenship:decision_date:employer_address_1:employer_address_2:employer_city:employer_country:employer_decl_info_title:employer_name:employer_num_employees:employer_phone:employer_phone_ext:employer_postal_code:employer_state:employer_yr_estab:foreign_worker_info_alt_edu_experience:foreign_worker_info_birth_country:foreign_worker_info_city:foreign_worker_info_education:foreign_worker_info_education_other:foreign_worker_info_inst:foreign_worker_info_major:foreign_worker_info_postal_code:foreign_worker_info_rel_occup_exp:foreign_worker_info_req_experience:foreign_worker_info_state:foreign_worker_info_training_comp:foreign_worker_ownership_interest:foreign_worker_yr_rel_edu_completed:fw_info_alt_edu_experience:fw_info_birth_country:fw_info_education_other:fw_info_postal_code:fw_info_rel_occup_exp:fw_info_req_experience:fw_info_training_comp:fw_info_yr_rel_edu_completed:fw_ownership_interest:ji_foreign_worker_live_on_premises:ji_fw_live_on_premises:ji_live_in_dom_svc_contract:ji_live_in_domestic_service:ji_offered_to_sec_j_foreign_worker:ji_offered_to_sec_j_fw:job_info_alt_cmb_ed_oth_yrs:job_info_alt_combo_ed:job_info_alt_combo_ed_exp:job_info_alt_combo_ed_other:job_info_alt_field:job_info_alt_field_name:job_info_alt_occ:job_info_alt_occ_job_title:job_info_alt_occ_num_months:job_info_combo_occupation:job_info_education:job_info_education_other:job_info_experience:job_info_experience_num_months:job_info_foreign_ed:job_info_foreign_lang_req:job_info_job_req_normal:job_info_job_title:job_info_major:job_info_training:job_info_training_field:job_info_training_num_months:job_info_work_city:job_info_work_postal_code:job_info_work_state:naics_2007_us_code:naics_2007_us_title:naics_code:naics_title:naics_us_code:naics_us_code_2007:naics_us_title:naics_us_title_2007:orig_case_no:orig_file_date:preparer_info_emp_completed:preparer_info_title:pw_amount_9089:pw_determ_date:pw_expire_date:pw_job_title_908:pw_job_title_9089:pw_level_9089:pw_soc_code:pw_soc_title:pw_source_name_9089:pw_source_name_other_9089:pw_track_num:pw_unit_of_pay_9089:rec_info_barg_rep_notified:recr_info_barg_rep_notified:recr_info_coll_teach_comp_proc:recr_info_coll_univ_teacher:recr_info_employer_rec_payment:recr_info_first_ad_start:recr_info_job_fair_from:recr_info_job_fair_to:recr_info_on_campus_recr_from:recr_info_on_campus_recr_to:recr_info_pro_org_advert_from:recr_info_pro_org_advert_to:recr_info_prof_org_advert_from:recr_info_prof_org_advert_to:recr_info_professional_occ:recr_info_radio_tv_ad_from:recr_info_radio_tv_ad_to:recr_info_second_ad_start:recr_info_sunday_newspaper:recr_info_swa_job_order_end:recr_info_swa_job_order_start:refile:ri_1st_ad_newspaper_name:ri_2nd_ad_newspaper_name:ri_2nd_ad_newspaper_or_journal:ri_campus_placement_from:ri_campus_placement_to:ri_coll_tch_basic_process:ri_coll_teach_pro_jnl:ri_coll_teach_select_date:ri_employee_referral_prog_from:ri_employee_referral_prog_to:ri_employer_web_post_from:ri_employer_web_post_to:ri_job_search_website_from:ri_job_search_website_to:ri_layoff_in_past_six_months:ri_local_ethnic_paper_from:ri_local_ethnic_paper_to:ri_posted_notice_at_worksite:ri_pvt_employment_firm_from:ri_pvt_employment_firm_to:ri_us_workers_considered:schd_a_sheepherder:us_economic_sector:wage_offer_from_9089:wage_offer_to_9089:wage_offer_unit_of_pay_9089:wage_offered_from_9089:wage_offered_to_9089:wage_offered_unit_of_pay_9089:,string:string:string:string:string:string:string:string:string:string:string:string:dateTime:string:string:string:string:string:string:string:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:string:string:string:string:,
UN General Debates , United Nations , www.kaggle.com/unitednations/un-general-debates , Wed Sep 06 2017 04:42:36 GMT+0530 (IST) , Transcriptions of general debates at the UN from 1970 to 2016 ,134, international relations- linguistics- ,"Context Every year since 1947 representatives of UN member states gather at the annual sessions of the United Nations General Assembly. The centrepiece of each session is the General Debate. This is a forum at which leaders and other senior officials deliver statements that present their government’s perspective on the major issues in world politics. These statements are akin to the annual legislative state-of-the-union addresses in domestic politics. This dataset the UN General Debate Corpus (UNGDC) includes the corpus of texts of General Debate statements from 1970 (Session 25) to 2016 (Session 71). Content This dataset includes the text of each country’s statement from the general debate separated by country session and year and tagged for each. The text was scanned from PDFs of transcripts of the UN general sessions. As a result the original scans included  page numbers in the text from OCR (Optical character recognition) scans which have been removed. This dataset only includes English. Acknowledgements This dataset was prepared by  Alexander Baturo Niheer Dasandi and Slava Mikhaylov and is presented in the paper ""Understanding State Preferences With Text As Data Introducing the UN General Debate Corpus"" Research & Politics 2017. Inspiration This dataset includes over forty years of data from different countries which allows for the exploration of differences between countries and over time. This allows you to ask both country-specific and longitudinal questions. Some questions that might be interesting  How has the sentiment of each country’s general debate changed over time?  What topics have been more or less popular over time and by region?  Can you build a classifier which identifies which country a given text is from?  Are there lexical or syntactic changes over time or differences between region?  How does the latitude of a country affect lexical complexity? ",session:,numeric:,
Brazilian congress , FelipeLeiteAntunes , www.kaggle.com/felipeleiteantunes/braziliancongress , Mon Nov 14 2016 00:03:34 GMT+0530 (IST) , Patterns in the Brazilian congress voting behavior ,193, crime- politics- ,Patterns in the Brazilian congress voting behavior The Brazilian Government House of Representatives maintains a public database that contains legislative information since 1970. One type of information that is available are the records of bills. For each bill the database gives a list of votes choices state and party of each deputy and a list of details about the bill itself like type year text of proposal benches orientations and situation (a bill can be voted more than one time in this work we will treat each votation as a single one). We retrieved more than 100000 bills (propList) where less than 1% was voted (propVotList) until November 2016.   Our objective is detect regularity patterns of legislative behavior institutional arrangements and legislative outcome. Raw data from http//www2.camara.leg.br/transparencia/dados-abertos/dados-abertos-legislativo/webservices/proposicoes-1/proposicoes,,,
Tourists Visiting Brazil , Luiza Fontana , www.kaggle.com/zafontana/touristsinbrazil , Sun Nov 27 2016 05:35:15 GMT+0530 (IST) , Who visited Brazil between 1989 and 2015? ,590, brazil- leisure- ,Context  This dataset contains the number of international tourists arriving in Brazil each month from 1989 to 2015. Content  Continent Country State of arrival Way in (by land sea river or air) Year  Month Count  Acknowledgements  I've downloaded this dataset from dados.gov.br the Brazilian open data portal and tried to tidy it up a bit.,Country:State:WayIn:Year:Month:Count:Continent:,string:string:string:numeric:string:numeric:string:,
2016 U.S. Presidential Election Memes , SIZZLE , www.kaggle.com/SIZZLE/2016electionmemes , Wed Nov 02 2016 00:36:26 GMT+0530 (IST) , Analyze 45000+ U.S. Presidential Election Memes ,1240, popular culture- politics- internet- ,We’re releasing 30000+ OCR’d political memes and their captions . With the election just days away we hope to contribute to the pre and post-election analysis of the most meme-orable election in modern history.  v2 of the dataset includes 8 csv’s Bern.csv 146 rows Bernie.csv 2100 rows Clinton.csv 4362 rows Donald.csv 6499 rows Gary_Johnston.csv 140 rows Hillary.csv 7398 rows Jill Stein.csv 96 rows Trump.csv 12139 rows with the following columns timestamp (date published) id (our unique identifier) link (post url) caption (meme caption via ocr) author network likes/upvotes Let us know any revisions you'd like to see. And of course if you find errors in the data do let us know. ,timestamp:id:link:caption:author:network:likes:,numeric:numeric:string:string:string:string:numeric:,
Deep-NLP , samdeeplearning , www.kaggle.com/samdeeplearning/deepnlp , Wed Mar 01 2017 11:13:51 GMT+0530 (IST) , natural language processing ,1083, languages- linguistics- ,What's In The Deep-NLP Dataset? Sheet_1.csv contains 80 user responses in the response_text column to a therapy chatbot. Bot said 'Describe a time when you have acted as a resource for someone else'.  User responded. If a response is 'not flagged' the user can continue talking to the bot. If it is 'flagged' the user is referred to help.   Sheet_2.csv contains 125 resumes in the resume_text column. Resumes were queried from Indeed.com with keyword 'data scientist' location 'Vermont'. If a resume is 'not flagged' the applicant can submit a modified resume version at a later date. If it is 'flagged' the applicant is invited to interview. What Do I Do With This? Classify new resumes/responses as flagged or not flagged.  There are two sets of data here - resumes and responses. Split the data into a train set and a test set to test the accuracy of your classifier. Bonus points for using the same classifier for both problems.  Good luck. Acknowledgements Thank you to Parsa Ghaffari (Aylien) without whom these visuals (cover photo is in Parsa Ghaffari's excellent LinkedIn article on English Spanish and German postive v. negative sentiment analysis) would not exist. There Is A 'deep natural language processing' Kernel. I will update it. I Hope You Find It Useful. You can use any of the code in that kernel anywhere on or off Kaggle. Ping me at @_samputnam for questions.,response_id:class:response_text::,string:string:string:string:,
Deep Sea Corals , NOAA , www.kaggle.com/noaa/deep-sea-corals , Mon Aug 28 2017 22:41:03 GMT+0530 (IST) , Coral Records from NOAA’s Deep-Sea Coral Research and Technology Program ,62, science and culture- fishing- oceans- biology- oceanography- ,"Context This dataset contains information about deep sea corals and sponges collected by NOAA and NOAA’s partners. Amongst the data are geo locations of deep sea corals and sponges and the whole thing is tailored to the occurrences of azooxanthellates - a subset of all corals and all sponge species (i.e. they don't have symbiotic relationships with certain microbes).  Additionally these records only consists of observations deeper than 50 meters to truly focus on the deep sea corals and sponges. Content Column descriptions  CatalogNumber Unique record identifier assigned by the Deep-Sea Coral Research and Technology Program. DataProvider The institution publication or individual who ultimately deserves credit for acquiring or aggregating the data and making it available. ScientificName Taxonomic identification of the sample as a Latin binomial. VernacularNameCategory Common (vernacular) name category of the organism. TaxonRank Identifies the level in the taxonomic hierarchy of the ScientificName term. ObservationDate Time as hhmmss when the sample/observation occurred (UTC). Latitude (degrees North) Latitude in decimal degrees where the sample or observation was collected. Longitude (degrees East) Longitude in decimal degrees where the sample or observation was collected. DepthInMeters Best single depth value for sample as a positive value in meters. DepthMethod Method by which best singular depth in meters (DepthInMeters) was determined. ""Averaged"" when start and stop depths were averaged. ""Assigned"" when depth was derived from bathymetry at the location. ""Reported"" when depth was reported based on instrumentation or described in literature. Locality A specific named place or named feature of origin for the specimen or observation (e.g. Dixon Entrance Diaphus Bank or Sur Ridge). Multiple locality names can be separated by a semicolon arranged in a list from largest to smallest area (e.g. Gulf of Mexico; West Florida Shelf Pulley Ridge). IdentificationQualifier Taxonomic identification method and level of expertise. Examples “genetic ID”; “morphological ID from sample by taxonomic expert”; “ID by expert from image”; “ID by non-expert from video”; etc.  SamplingEquipment Method of data collection. Examples ROV submersible towed camera SCUBA etc. RecordType Denotes the origin and type of record. published literature (""literature""); a collected specimen (""specimen""); observation from a still image (""still image""); observation from video (""video observation""); notation without a specimen or image (""notation""); or observation from trawl surveys longline surveys and/or observer records (""catch record"").  Acknowledgements Big shout out to NOAA and it's partners. Thank you for being scientists!  The original and probably more up-to-date dataset can be found here https//deepseacoraldata.noaa.gov/website/AGSViewers/DeepSeaCorals/mapSites.htm This dataset hasn't been changed in anyway. NOAA (2015) National Database for Deep-Sea Corals and Sponges (version 20170324-0). https//deepseacoraldata.noaa.gov/; NOAA Deep Sea Coral Research & Technology Program. Inspiration Who doesn't love coral and sponges?!  I challenge you to find the best algorithm that successfully SAVES the world's corals 100% of the time! ",CatalogNumber:DataProvider:ScientificName:VernacularNameCategory:TaxonRank:Station:ObservationDate:latitude:longitude:DepthInMeters:DepthMethod:Locality:LocationAccuracy:SurveyID:Repository:IdentificationQualifier:EventID:SamplingEquipment:RecordType:SampleID:,numeric:string:string:string:string:string:dateTime:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:,
Amending America , U.S. National Archives and Records Administration , www.kaggle.com/national-archives/amending-america , Fri Jun 23 2017 04:26:52 GMT+0530 (IST) , 11000+ Proposed Amendments to the United States Constitution from 1787 to 2014 ,43, history- politics- ,"Context Article Five of the United States Constitution describes a process that allows for alteration of the federal Constitution. So far 27 amendments have been fully added to the federal Constitution but there have been a lot of proposals that didn’t make it through. This dataset contains information about a whopping 11797 Constitutional amendments that have been proposed to Congress from 1787 to 2014!  Content This dataset consists of 11797 rows with 17 fields and was compiled by NARA volunteers that transcribed information from written records that were issued by Congress. Because a lot of the information comes from written records the dataset may not be a complete record of all amendment proposals. Proposals before 1973 were taken from various government publications and proposals after 1973 are publicly available on https//www.congress.gov.  Identifier Unique code generated by NARA that serves as a unique identifier. Source_code Code generated by NARA that represents the government publication or website where the information was transcribed. Source_citation Bibliographic citation of the government publication or website from which the information was transcribed. Source_index_number An index number listed within the source publication. Title_or_description_from_source Title or description of the proposed amendment transcribed from the source publication or website. Date_approximation When the date is estimated the term includes “circa” otherwise it is left blank. Year Year that the amendment was proposed in Congress (YYYY format). Month Month that the amendment was proposed in Congress (blank if unknown). Day Day that the amendment was proposed in Congress (blank if unknown). Congress The number for the congress in which the amendment was proposed. Congressional_session The number or designation of the session of Congress in which the amendment was proposed. Joint_resolution_chamber The chamber of Congress in which the amendment was proposed. Joint_resolution_number The number assigned to the proposed amendment by Congress. (Amendments are submitted as joint resolutions) Sponsor_name The name of the member of Congress or group who proposed the amendment. (Blank if unknown). Sponsor_state_or_territory The U.S. state or territory represented by the amendment’s sponsoring member of Congress. Committee_of_referral The committee to which the amendment was referred for further consideration following formal introduction to Congress. Last_modified the timestamp of the most recent modification made on the data contained within the particular row.  Acknowledgements The National Archives and Records Administration created this dataset as part of the Amending America initiative. To prepare for the 2016 ""Amending America"" exhibition at the National Archives Museum in Washington D.C. NARA volunteers and staff transcribed and edited over 11000 entries representing proposed amendments to the U.S. Constitution as recorded by Congress. http//www.archives.gov/amending-america Inspiration This is an interesting dataset because it contains a lot of history that isn’t necessarily reflected in the Constitution. You could use it to glean insight into the political climates at different times in the history of the United States. For instance what kind of amendments were being proposed during the Civil War? Who proposed the most amendments? Historically have there been more proposals during any particular time of year?",identifier:source_code:source_citation:source_index_number:title_or_description_from_source:date_approximation:year:month:day:congress:congressional_session:joint_resolution_chamber:joint_resolution_number:sponsor_name:sponsor_state_or_territory:committee_of_referral:last_modified:,string:string:string:numeric:string:string:numeric:numeric:numeric:string:string:string:string:string:string:string:dateTime:,
Boston Airbnb Open Data , Airbnb , www.kaggle.com/airbnb/boston , Thu Nov 17 2016 10:48:33 GMT+0530 (IST) , A sneak peek into the Airbnb activity in Boston MA USA ,2798, united states- home- hotels- ,Context Since 2008 guests and hosts have used Airbnb to travel in a more unique personalized way. As part of the Airbnb Inside initiative this dataset describes the listing activity of homestays in Boston MA.  Content The following Airbnb activity is included in this Boston dataset * Listings including full descriptions and average review score * Reviews including unique id for each reviewer and detailed comments * Calendar including listing id and the price and availability for that day Inspiration  Can you describe the vibe of each Boston neighborhood using listing descriptions? What are the busiest times of the year to visit Boston? By how much do prices spike? Is there a general upward trend of both new Airbnb listings and total Airbnb visitors to Boston?  For more ideas visualizations of all Boston datasets can be found here. Acknowledgement This dataset is part of Airbnb Inside and the original source can be found here.,,,
Portland Oregon Crime Data , katzwigmore , www.kaggle.com/katzwigmore/portland-oregon-crime-data , Mon Sep 25 2017 01:02:31 GMT+0530 (IST) , By Year Event and Location ,105, crime- ,Content The contents of this data set comes from public data available on the city of Portland website. Each individual crime reported is lists the location time and date of the incident as well as a the neighborhood in which the event occurred.   All data prior to 2015 has the same general format but the newer 2015-17 data needs to be reformatted for easier comparison since it does not match the older organizational scheme.  To this end I will be adding new .csv with 2015  2016 and 2017 YTD data broken out.  Coordinate data will also be added to make the data sets more easily comparable and mappable. Update  I created new .csv for each year 2015-2017 changing the formatting from the Portland Police Department's tab separated values to the standard comma separated values.  The pre-2015 data still isn't comparable because of the differences in the crime categorization but I will work creating some sort of key so that the full data set can be analyzed as a single batch of information.  Acknowledgements Banner image by Zack Spear on Unsplash. All data gathered from portlandoregon.gov and civicapps.org,Record ID:Report Date:Report Time:Major Offense Type:Address:Neighborhood:Police Precinct:Police District:X Coordinate:Y Coordinate:,numeric:dateTime:dateTime:string:string:string:string:numeric:numeric:numeric:,
US Dept of Education: College Scorecard , Kaggle , www.kaggle.com/kaggle/college-scorecard , Mon May 01 2017 23:33:23 GMT+0530 (IST) , Raise the curtain on the true cost of higher education ,8550, education- finance- ,"It's no secret that US university students often graduate with debt repayment obligations that far outstrip their employment and income prospects. While it's understood that students from elite colleges tend to earn more than graduates from less prestigious universities the finer relationships between future income and university attendance are quite murky. In an effort to make educational investments less speculative the US Department of Education has matched information from the student financial aid system with federal tax returns to create the College Scorecard dataset. Kaggle is hosting the College Scorecard dataset in order to facilitate shared learning and collaboration. Insights from this dataset can help make the returns on higher education more transparent and in turn more fair. Data Description Here's a script showing an exploratory overview of some of the data. college-scorecard-release-*.zip contains a compressed version of the same data available through Kaggle Scripts. It consists of three components  All the raw data files released in version 1.40 of the college scorecard data Scorecard.csv a single CSV file with all the years data combined. In it we've converted categorical variables represented by integer keys in the original data to their labels and added a Year column database.sqlite a SQLite database containing a single Scorecard table that contains the same information as Scorecard.csv  New to data exploration in R? Take the free interactive DataCamp course ""Data Exploration With Kaggle Scripts"" to learn the basics of visualizing data with ggplot. You'll also create your first Kaggle Scripts along the way.",NAME OF DATA ELEMENT:Year:dev-category:developer-friendly name:VARIABLE NAME:API data type:label:VALUE:LABEL:SCORECARD? Y/N:SOURCE:NOTES:,string:string:string:string:string:string:string:string:string:string:string:string:,
Questions from Cross Validated Stack Exchange , Stack Overflow , www.kaggle.com/stackoverflow/statsquestions , Fri Oct 21 2016 02:33:35 GMT+0530 (IST) , Full text of Q&A from Cross Validated the Stack Exchange statistics site ,217, statistics- internet- ,Full text of questions and answers from Cross Validated the statistics and machine learning Q&A site from the Stack Exchange network. This is organized as three tables  Questions contains the title body creation date score and owner ID for each question. Answers contains the body creation date score and owner ID for each of the answers to these questions. The ParentId column links back to the Questions table. Tags contains the tags on each question  For space reasons only non-deleted and non-closed content are included in the dataset. The dataset contains questions up to 19 October 2016 (UTC). License All Stack Exchange user contributions are licensed under CC-BY-SA 3.0 with attribution required.,,,
United States Commutes , figshare , www.kaggle.com/figshare/united-states-commutes , Sun Dec 04 2016 06:40:59 GMT+0530 (IST) , Visualizing over 4 million home-to-work commutes in the United States ,228, transport- ,"Context The emergence in the United States of large-scale “megaregions” centered on major metropolitan areas is a phenomenon often taken for granted in both scholarly studies and popular accounts of contemporary economic geography. This dataset comes from a paper (Nelson & Rae 2016. An Economic Geography of the United States From Commutes to Megaregions) that uses a data set of more than 4000000 commuter flows as the basis for an empirical approach to the identification of such megaregions.  Content This dataset consists of two files one contains the commuting data and one is a gazetteer describing the population and locations of the census tracts referred to by the commuting data. The fields Ofips and Dfips (FIPS codes for the originating and destination census tracts respectively) in commute_data.csv refer to the GEOID field in census_tracts_2010.csv. commute_data This file contains information on over 4 million commute flows. It has the following fields  Ofips the full FIPS code for the origin census tract of an individual flow line *Dfips * the full FIPS code for the destination census tract of an individual flow line Ostfips the FIPS code for the origin state of an individual flow line Octfips the FIPS code for the origin county of an individual flow line Otrfips the FIPS code for the destination census tract of an individual flow line Dstfips the FIPS code for the destination state of an individual flow line Dctfips the FIPS code for the destination county of an individual flow line Dtrfips the FIPS code for the destination census tract of an individual flow line Flow the total number of commuters associated with this individual point to point flow line (i.e. the total number of journeys to work) Moe margin of error of the Flow value above LenKM length of each flow line in Kilometers ESTDIVMOE the Flow value divided by the Margin of Error of the estimate  census_tracts_2010 This file contains the following fields which represent information about different U.S. Census Tracts  USPS United States Postal Service State Abbreviation GEOID Geographic Identifier - fully concatenated geographic code (State FIPS and County FIPS) ANSICODE American National Standards Institute code NAME Name POP10 2010 Census population count. HU10 2010 Census housing unit count. ALAND Land Area (square meters) - Created for statistical purposes only. AWATER Water Area (square meters) - Created for statistical purposes only. ALAND_SQMI Land Area (square miles) - Created for statistical purposes only. AWATER_SQMI Water Area (square miles) - Created for statistical purposes only. INTPTLAT Latitude (decimal degrees) First character is blank or ""-"" denoting North or South latitude respectively. INTPTLONG Longitude (decimal degrees) First character is blank or ""-"" denoting East or West longitude respectively.  Acknowledgements This dataset comes from the following article Nelson & Rae 2016. An Economic Geography of the United States From Commutes to Megaregions The full dataset (in GIS shapefile format) can be found on figshare here",USPS:GEOID:POP10:HU10:ALAND:AWATER:ALAND_SQMI:AWATER_SQMI:INTPTLAT:INTPTLONG                                                                                                                  :,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Pokemon Go Gen II (251) , AaronMcKisic , www.kaggle.com/aaronmckisic/pokemon-go-gen-ii-251 , Tue Apr 18 2017 19:04:13 GMT+0530 (IST) , Factors that impact a Pokemon's CP combat defense and other variables ,128, video games- ,Context Pokemon has been around for the majority of my life. I obsessed over it as a child and enjoy seeing the success it carries still today. I figure that I can give the Pokemon Company a nod by applying my passion for data science to their datasets. Content This is compiled data from two websites that I will acknowledge soon. As for the data the primary variables are id name attack defense health and cp. Other variables include tankiness potentialdamage basicdps attackbasicdps (damage per second with strongest basic attack*attack) chargedps oneshotpotential (damage per second with strongest charge attack*attack) and various rankings in each category as well as growth rates for each ranking (this variable only makes sense when sorted by each variable's ranking).  Acknowledgements I have to pay tribute to two websites serebii.net and pokemongodb.net // these two pages allowed me to find the data that helped best explore the Pokemon Go universe. Thank you very much. Inspiration The data makes it pretty clear what plays into a Pokemon's CP. But I am curious to know what hidden gems you might find when going through this data. For example is Dragonite really the powerhouse we think it is?,id:name:attack:defense:health:cp:tankiness:basicdps:chargedps:damagepotential:attackbasicdps:oneshotpotential:attackgrowthrate:defensegrowthrate:cpgrowthrate:healthgrowthrate:healthrank:attackrank:defenserank:cprank:tankgrowthrate:tankinessrank:,numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Crowdedness at the Campus Gym , Nick Rose , www.kaggle.com/nsrose7224/crowdedness-at-the-campus-gym , Sun Mar 19 2017 09:36:26 GMT+0530 (IST) , Number of attendees every 10 minutes from the last year in the gym ,1381, health- demographics- sociology- ,Background When is my university campus gym least crowded so I know when to work out? We measured how many people were in this gym once every 10 minutes over the last year. We want to be able to predict how crowded the gym will be in the future. Goals  Given a time of day (and maybe some other features including weather) predict how crowded the gym will be.  Figure out which features are actually important which are redundant and what features could be added to make the predictions more accurate.  Data The dataset consists of 26000 people counts (about every 10 minutes) over the last year. In addition I gathered extra info including weather and semester-specific information that might affect how crowded it is. The label is the number of people which I'd like to predict given some subset of the features.  Label  Number of people   Features  date (string; datetime of data) timestamp (int; number of seconds since beginning of day) day_of_week (int; 0 [monday] - 6 [sunday]) is_weekend (int; 0 or 1) [boolean if 1 it's either saturday or sunday otherwise 0] is_holiday (int; 0 or 1) [boolean if 1 it's a federal holiday 0 otherwise] temperature (float; degrees fahrenheit) is_start_of_semester (int; 0 or 1) [boolean if 1 it's the beginning of a school semester 0 otherwise] month (int; 1 [jan] - 12 [dec]) hour (int; 0 - 23)  Acknowledgements This data was collected with the consent of the university and the gym in question.,number_people:,numeric:,
Health Analytics , Rajanand Ilangovan / இராஜ்ஆனந்த் இளங்கோவன் , www.kaggle.com/rajanand/key-indicators-of-annual-health-survey , Thu Aug 10 2017 00:51:42 GMT+0530 (IST) , 26 health indicators (642 variables) from 9 states and 284 districts of India ,851, india- public health- health- ,Context India - Annual Health Survey(AHS) 2012-13 The survey was conducted in Empowered Action Group (EAG) states Uttarakhand Rajasthan Uttar Pradesh Bihar Jharkhand  Odisha Chhattisgarh & Madhya Pradesh and Assam. These nine states which account for about 48 percent of the total population 59 percent of Births 70 percent of Infant Deaths 75 percent of Under 5 Deaths and 62 percent of Maternal Deaths in the country are the high focus States in view of their relatively higher fertility and mortality.  A representative sample of about 21 million population and 4.32 million households were covered 20k+ sample units which is spread across rural and urban area of these 9 states.  The objective of the AHS is to yield a comprehensive representative and reliable dataset on core vital indicators including composite ones like Infant Mortality Rate Maternal Mortality Ratio and Total Fertility Rate along with their co-variates (process and outcome indicators) at the district level and map the changes therein on an annual basis. These benchmarks would help in better and holistic understanding and timely monitoring of various determinants on well-being and health of population particularly Reproductive and Child Health. Source  Content This dataset contains the data about the below 26 key indicators.  AA. Sample Particulars Sample Units Households Population Ever Married Women (aged 15-49 years) Currently Married Women (aged 15-49 years) Children 12-23 months BB. Household Characteristics Average Household Size SC ST All Population below age 15 years (%) Dependency Ratio Currently Married Illiterate Women aged 15-49 years (%) CC. Sex Ratio Sex Ratio at Birth Sex Ratio (0- 4 years) Sex Ratio (All ages) DD. Effective Literacy Rate  EE. Marriage Marriages among Females below legal age (18 years) (%) Marriages among Males below legal age (21 years) (%) Currently Married Women aged 20-24 years married before legal age (18 years) (%) Currently Married Men aged 25-29 years married before legal age (21 years) (%) Mean age at Marriage# - Male Mean age at Marriage# - Female FF. Schooling Status Children currently attending school (Age 6-17 years) (%) Children attended before / Drop out (Age 6-17 years) (%)  GG. Work Status Children aged 5-14 years engaged in work (%)  Work Participation Rate (15 years and above)   HH. Disability Prevalence of any type of Disability (Per 100000 Population)  II. Injury Number of Injured Persons by type of Treatment received (Per 100000 Population) Severe   Major Minor JJ. Acute Illness  Persons suffering from Acute Illness (Per 100000 Population)  Diarrhoea/Dysentery  Acute Respiratory Infection (ARI) Fever (All Types)  Any type of Acute Illness  Persons suffering from Acute Illness and taking treatment from Any Source (%) Persons suffering from Acute Illness and taking treatment from Government Source (%) KK. Chronic Illness Having any kind of Symptoms of Chronic Illness (Per 100000 Population) Having any kind of Symptoms of Chronic Illness and sought Medical Care (%) Having diagnosed for Chronic Illness (Per 100000 Population)  Diabetes Hypertension Tuberculosis (TB) Asthma / Chronic Respiratory Disease Arthritis Any kind of Chronic Illness Having diagnosed for any kind of Chronic Illness and getting Regular Treatment (%) Having diagnosed for any kind of Chronic Illness and getting Regular Treatment from Government Source (%) LL. Fertility Crude Birth Rate (CBR) Natural Growth Rate Total Fertility Rate Women aged 20-24 reporting birth of order 2 & above (%) Women reporting birth of order 3 & above (%) Women with two children wanting no more children (%) Women aged 15-19 years who were already mothers or pregnant at the time of survey (%) Median age at first live birth of Women aged 15-49 years Median age at first live birth of Women aged 25-49 years Live Births taking place after an interval of 36 months (%) Mean number of children ever born to Women aged 15-49 years Mean number of children surviving to Women aged 15-49 years Mean number of children ever born to Women aged 45-49 years MM. Abortion Pregnancy to Women aged 15-49 years resulting in abortion (%) Women who received any ANC before abortion (%) Women who went for Ultrasound before abortion (%) Average Month of pregnancy at the time of abortion Abortion performed by skilled health personnel (%) Abortion taking place in Institution (%) NN. Family Planning Practices (Cmw Aged 15-49 Years) Current Usage Any Method (%) Any Modern Method (%) Female Sterilization (%) Male Sterilization (%) Copper-T/IUD (%) Pills (%) Condom/Nirodh (%) Emergency Contraceptive Pills (%) Any Traditional Method (%) Periodic Abstinence (%) Withdrawal (%) LAM (%) OO. Unmet Need For Family Planning Unmet need for Spacing (%) Unmet need for Limiting (%) Total Unmet need (%) PP. Ante Natal Care Currently Married Pregnant Women aged 15-49 years registered for ANC (%) Mothers who received any Antenatal Check-up (%) Mothers who had Antenatal Check-up in First Trimester (%) Mothers who received 3 or more Antenatal Care (%) Mothers who received at least one Tetanus Toxoid (TT) injection (%) Mothers who consumed IFA for 100 days or more (%) Mothers who had Full Antenatal Check-up (%) Mothers who received ANC from Govt. Source (%) Mothers whose Blood Pressure (BP) taken (%) Mothers whose Blood taken for Hb (%) Mothers who underwent Ultrasound (%) QQ. Delivery Care Institutional Delivery (%) Delivery at Government Institution (%) Delivery at Private Institution (%) Delivery at Home (%) Delivery at home conducted by skilled health personnel (%) Safe Delivery (%) Caesarean out of total delivery taken place in Government Institutions (%) Caesarean out of total delivery taken place in Private Institutions (%) RR. Post Natal Care Less than 24 hrs. stay in institution after delivery (%) Mothers who received Post-natal Check-up within 48 hrs. of delivery (%) Mothers who received Post-natal Check-up within 1 week of delivery (%) Mothers who did not receive any Post-natal Check-up (%) New borns who were checked up within 24 hrs. of birth (%) SS. Janani Suraksha Yojana (JSY) Mothers who availed financial assistance for delivery under JSY (%) Mothers who availed financial assistance for institutional delivery under JSY (%) Mothers who availed financial assistance for Government Institutional delivery under JSY (%) TT. Immunization Vitamin A & Iron Supplement And Birth Weight Children aged 12-23 months having Immunization Card (%) Children aged 12-23 months who have received BCG (%) Children aged 12-23 months who have received 3 doses of Polio vaccine (%) Children aged 12-23 months who have received 3 doses of DPT vaccine (%) Children aged 12-23 months who have received Measles vaccine (%) Children aged 12-23 months Fully Immunized (%) Children who have received Polio dose at birth (%) Children who did not receive any vaccination (%) Children (aged 6-35 months) who received at least one Vitamin A dose during last six months (%) Children (aged 6-35 months) who received IFA tablets/syrup during last 3 months (%) Children whose birth weight was taken (%) Children with birth weight less than 2.5 Kg. (%) UU. Childhood Diseases Children suffering from Diarrhoea (%) Children suffering from Diarrhoea who received HAF/ORS/ORT (%) Children suffering from Acute Respiratory Infection (%) Children suffering from Acute Respiratory Infection who sought treatment (%) Children suffering from Fever (%) Children suffering from Fever who sought treatment (%) VV. Breastfeeding And Supplementation Children breastfed within one hour of birth (%) Children (aged 6-35 months) exclusively breastfed for at least six months (%) Children Who Received Foods Other Than Breast Milk During First 6 Months Water (%) Animal/Formula Milk (%) Semi-Solid Mashed Food (%) Solid (Adult) Food (%) Vegetables/Fruits (%) Average Month By Which Children Received Foods Other Than Breast Milk Water (%) Animal/Formula Milk (%) Semi-Solid Mashed Food (%) Solid (Adult) Food (%) Vegetables/Fruits (%) WW. Birth Registration Birth Registered (%) Children Whose Birth Was Registered And Received Birth Certificate (%) XX. Awareness On Hiv/Aids Rti/Sti Haf/Ors/Ort/Zinc And Ari/Pneumonia Women Who Are Aware of HIV/AIDS RTI/STI HAF/ORS/ORT/ZINC Danger Signs Of ARI/Pneumonia (%)     YY. Mortality (unit level data of mortality is available here) Crude Death Rate (CDR) Infant Mortality Rate (IMR) Neo-Natal Mortality Rate Under Five Mortality Rate (U5MR) ZZ. Confidence Interval (95%) For Some Important Indicators Crude Birth Rate - (Lower and Upper Limit) Crude Death Rate - (Lower and Upper Limit) Infant Mortality Rate - (Lower and Upper Limit) Under Five Mortality Rate (U5MR) - (Lower and Upper Limit) Sex Ratio At Birth  - (Lower and Upper Limit)  Acknowledgements Department of Health and Family Welfare Govt. of India has published this data in Open Govt Data Platform India portal under Govt. Open Data License - India.,State_Name:State_District_Name:AA_Sample_Units_Total:AA_Sample_Units_Rural:AA_Sample_Units_Urban:AA_Households_Total:AA_Households_Rural:AA_Households_Urban:AA_Population_Total:AA_Population_Rural:AA_Population_Urban:AA_Ever_Married_Women_Aged_15_49_Years_Total:AA_Ever_Married_Women_Aged_15_49_Years_Rural:AA_Ever_Married_Women_Aged_15_49_Years_Urban:AA_Currently_Married_Women_Aged_15_49_Years_Total:AA_Currently_Married_Women_Aged_15_49_Years_Rural:AA_Currently_Married_Women_Aged_15_49_Years_Urban:AA_Children_12_23_Months_Total:AA_Children_12_23_Months_Rural:AA_Children_12_23_Months_Urban:BB_Average_Household_Size_Sc_Total:BB_Average_Household_Size_Sc_Rural:BB_Average_Household_Size_Sc_Urban:BB_Average_Household_Size_St_Total:BB_Average_Household_Size_St_Rural:BB_Average_Household_Size_St_Urban:BB_Average_Household_Size_All_Total:BB_Average_Household_Size_All_Rural:BB_Average_Household_Size_All_Urban:BB_Population_Below_Age_15_Years_Total:BB_Population_Below_Age_15_Years_Rural:BB_Population_Below_Age_15_Years_Urban:BB_Dependency_Ratio_Total:BB_Dependency_Ratio_Rural:BB_Dependency_Ratio_Urban:BB_Currently_Married_Illiterate_Women_Aged_15_49_Years_Total:BB_Currently_Married_Illiterate_Women_Aged_15_49_Years_Rural:BB_Currently_Married_Illiterate_Women_Aged_15_49_Years_Urban:CC_Sex_Ratio_At_Birth_Total:CC_Sex_Ratio_At_Birth_Rural:CC_Sex_Ratio_At_Birth_Urban:CC_Sex_Ratio_0_4_Years_Total:CC_Sex_Ratio_0_4_Years_Rural:CC_Sex_Ratio_0_4_Years_Urban:CC_Sex_Ratio_All_Ages_Total:CC_Sex_Ratio_All_Ages_Rural:CC_Sex_Ratio_All_Ages_Urban:DD_Person_Total:DD_Person_Rural:DD_Person_Urban:DD_Male_Total:DD_Male_Rural:DD_Male_Urban:DD_Female_Total:DD_Female_Rural:DD_Female_Urban:EE_Marriages_Among_Females_Below_Legal_Age_18_Years_Total:EE_Marriages_Among_Females_Below_Legal_Age_18_Years_Rural:EE_Marriages_Among_Females_Below_Legal_Age_18_Years_Urban:EE_Marriages_Among_Males_Below_Legal_Age_21_Years_Total:EE_Marriages_Among_Males_Below_Legal_Age_21_Years_Rural:EE_Marriages_Among_Males_Below_Legal_Age_21_Years_Urban:EE_Currently_Married_Women_Aged_20_24_Years_Married_Before_Legal_Age_18_Years_Total:EE_Currently_Married_Women_Aged_20_24_Years_Married_Before_Legal_Age_18_Years_Rural:EE_Currently_Married_Women_Aged_20_24_Years_Married_Before_Legal_Age_18_Years_Urban:EE_Currently_Married_Men_Aged_25_29_Years_Married_Before_Legal_Age_21_Years_Total:EE_Currently_Married_Men_Aged_25_29_Years_Married_Before_Legal_Age_21_Years_Rural:EE_Currently_Married_Men_Aged_25_29_Years_Married_Before_Legal_Age_21_Years_Urban:EE_Mean_Age_At_Marriage_Male_Total:EE_Mean_Age_At_Marriage_Male_Rural:EE_Mean_Age_At_Marriage_Male_Urban:EE_Mean_Age_At_Marriage_Female_Total:EE_Mean_Age_At_Marriage_Female_Rural:EE_Mean_Age_At_Marriage_Female_Urban:FF_Children_Currently_Attending_School_Age_6_17_Years_Person_Total:FF_Children_Currently_Attending_School_Age_6_17_Years_Person_Rural:FF_Children_Currently_Attending_School_Age_6_17_Years_Person_Urban:FF_Children_Currently_Attending_School_Age_6_17_Years_Male_Total:FF_Children_Currently_Attending_School_Age_6_17_Years_Male_Rural:FF_Children_Currently_Attending_School_Age_6_17_Years_Male_Urban:FF_Children_Currently_Attending_School_Age_6_17_Years_Female_Total:FF_Children_Currently_Attending_School_Age_6_17_Years_Female_Rural:FF_Children_Currently_Attending_School_Age_6_17_Years_Female_Urban:FF_Children_Attended_Before_Drop_Out_Age_6_17_Years_Person_Total:FF_Children_Attended_Before_Drop_Out_Age_6_17_Years_Person_Rural:FF_Children_Attended_Before_Drop_Out_Age_6_17_Years_Person_Urban:FF_Children_Attended_Before_Drop_Out_Age_6_17_Years_Male_Total:FF_Children_Attended_Before_Drop_Out_Age_6_17_Years_Male_Rural:FF_Children_Attended_Before_Drop_Out_Age_6_17_Years_Male_Urban:FF_Children_Attended_Before_Drop_Out_Age_6_17_Years_Female_Total:FF_Children_Attended_Before_Drop_Out_Age_6_17_Years_Female_Rural:FF_Children_Attended_Before_Drop_Out_Age_6_17_Years_Female_Urban:GG_Children_Aged_5_14_Years_Engaged_In_Work_Person_Total:GG_Children_Aged_5_14_Years_Engaged_In_Work_Person_Rural:GG_Children_Aged_5_14_Years_Engaged_In_Work_Person_Urban:GG_Children_Aged_5_14_Years_Engaged_In_Work_Male_Total:GG_Children_Aged_5_14_Years_Engaged_In_Work_Male_Rural:GG_Children_Aged_5_14_Years_Engaged_In_Work_Male_Urban:GG_Children_Aged_5_14_Years_Engaged_In_Work_Female_Total:GG_Children_Aged_5_14_Years_Engaged_In_Work_Female_Rural:GG_Children_Aged_5_14_Years_Engaged_In_Work_Female_Urban:GG_Work_Participation_Rate_15_Years_And_Above_Person_Total:GG_Work_Participation_Rate_15_Years_And_Above_Person_Rural:GG_Work_Participation_Rate_15_Years_And_Above_Person_Urban:GG_Work_Participation_Rate_15_Years_And_Above_Male_Total:GG_Work_Participation_Rate_15_Years_And_Above_Male_Rural:GG_Work_Participation_Rate_15_Years_And_Above_Male_Urban:GG_Work_Participation_Rate_15_Years_And_Above_Female_Total:GG_Work_Participation_Rate_15_Years_And_Above_Female_Rural:GG_Work_Participation_Rate_15_Years_And_Above_Female_Urban:HH_Prevalence_Of_Any_Type_Of_Disability_Per_100000_Population_Person_Total:HH_Prevalence_Of_Any_Type_Of_Disability_Per_100000_Population_Person_Rural:HH_Prevalence_Of_Any_Type_Of_Disability_Per_100000_Population_Person_Urban:HH_Prevalence_Of_Any_Type_Of_Disability_Per_100000_Population_Male_Total:HH_Prevalence_Of_Any_Type_Of_Disability_Per_100000_Population_Male_Rural:HH_Prevalence_Of_Any_Type_Of_Disability_Per_100000_Population_Male_Urban:HH_Prevalence_Of_Any_Type_Of_Disability_Per_100000_Population_Female_Total:HH_Prevalence_Of_Any_Type_Of_Disability_Per_100000_Population_Female_Rural:HH_Prevalence_Of_Any_Type_Of_Disability_Per_100000_Population_Female_Urban:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Severe_Person_Total:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Severe_Person_Rural:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Severe_Person_Urban:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Severe_Male_Total:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Severe_Male_Rural:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Severe_Male_Urban:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Severe_Female_Total:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Severe_Female_Rural:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Severe_Female_Urban:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Major_Person_Total:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Major_Person_Rural:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Major_Person_Urban:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Major_Male_Total:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Major_Male_Rural:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Major_Male_Urban:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Major_Female_Total:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Major_Female_Rural:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Major_Female_Urban:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Minor_Person_Total:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Minor_Person_Rural:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Minor_Person_Urban:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Minor_Male_Total:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Minor_Male_Rural:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Minor_Male_Urban:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Minor_Female_Total:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Minor_Female_Rural:II_Number_Of_Injured_Persons_By_Type_Of_Treatment_Received_Per_100000_Population_Minor_Female_Urban:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Diarrhoea_Dysentery_Person_Total:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Diarrhoea_Dysentery_Person_Rural:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Diarrhoea_Dysentery_Person_Urban:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Diarrhoea_Dysentery_Male_Total:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Diarrhoea_Dysentery_Male_Rural:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Diarrhoea_Dysentery_Male_Urban:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Diarrhoea_Dysentery_Female_Total:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Diarrhoea_Dysentery_Female_Rural:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Diarrhoea_Dysentery_Female_Urban:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Acute_Respiratory_Infection_Ari_Person_Total:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Acute_Respiratory_Infection_Ari_Person_Rural:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Acute_Respiratory_Infection_Ari_Person_Urban:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Acute_Respiratory_Infection_Ari_Male_Total:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Acute_Respiratory_Infection_Ari_Male_Rural:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Acute_Respiratory_Infection_Ari_Male_Urban:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Acute_Respiratory_Infection_Ari_Female_Total:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Acute_Respiratory_Infection_Ari_Female_Rural:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Acute_Respiratory_Infection_Ari_Female_Urban:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Fever_All_Types_Person_Total:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Fever_All_Types_Person_Rural:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Fever_All_Types_Person_Urban:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Fever_All_Types_Male_Total:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Fever_All_Types_Male_Rural:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Fever_All_Types_Male_Urban:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Fever_All_Types_Female_Total:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Fever_All_Types_Female_Rural:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Fever_All_Types_Female_Urban:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Any_Type_Of_Acute_Illness_Person_Total:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Any_Type_Of_Acute_Illness_Person_Rural:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Any_Type_Of_Acute_Illness_Person_Urban:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Any_Type_Of_Acute_Illness_Male_Total:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Any_Type_Of_Acute_Illness_Male_Rural:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Any_Type_Of_Acute_Illness_Male_Urban:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Any_Type_Of_Acute_Illness_Female_Total:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Any_Type_Of_Acute_Illness_Female_Rural:JJ_Persons_Suffering_From_Acute_Illness_Per_100000_Population_Any_Type_Of_Acute_Illness_Female_Urban:JJ_Persons_Suffering_From_Acute_Illness_And_Taking_Treatment_From_Any_Source_Person_Total:JJ_Persons_Suffering_From_Acute_Illness_And_Taking_Treatment_From_Any_Source_Person_Rural:JJ_Persons_Suffering_From_Acute_Illness_And_Taking_Treatment_From_Any_Source_Person_Urban:JJ_Persons_Suffering_From_Acute_Illness_And_Taking_Treatment_From_Any_Source_Male_Total:JJ_Persons_Suffering_From_Acute_Illness_And_Taking_Treatment_From_Any_Source_Male_Rural:JJ_Persons_Suffering_From_Acute_Illness_And_Taking_Treatment_From_Any_Source_Male_Urban:JJ_Persons_Suffering_From_Acute_Illness_And_Taking_Treatment_From_Any_Source_Female_Total:JJ_Persons_Suffering_From_Acute_Illness_And_Taking_Treatment_From_Any_Source_Female_Rural:JJ_Persons_Suffering_From_Acute_Illness_And_Taking_Treatment_From_Any_Source_Female_Urban:JJ_Persons_Suffering_From_Acute_Illness_And_Taking_Treatment_From_Government_Source_Person_Total:JJ_Persons_Suffering_From_Acute_Illness_And_Taking_Treatment_From_Government_Source_Person_Rural:JJ_Persons_Suffering_From_Acute_Illness_And_Taking_Treatment_From_Government_Source_Person_Urban:JJ_Persons_Suffering_From_Acute_Illness_And_Taking_Treatment_From_Government_Source_Male_Total:JJ_Persons_Suffering_From_Acute_Illness_And_Taking_Treatment_From_Government_Source_Male_Rural:JJ_Persons_Suffering_From_Acute_Illness_And_Taking_Treatment_From_Government_Source_Male_Urban:JJ_Persons_Suffering_From_Acute_Illness_And_Taking_Treatment_From_Government_Source_Female_Total:JJ_Persons_Suffering_From_Acute_Illness_And_Taking_Treatment_From_Government_Source_Female_Rural:JJ_Persons_Suffering_From_Acute_Illness_And_Taking_Treatment_From_Government_Source_Female_Urban:KK_Having_Any_Kind_Of_Symptoms_Of_Chronic_Illness_Per_100000_Population_Person_Total:KK_Having_Any_Kind_Of_Symptoms_Of_Chronic_Illness_Per_100000_Population_Person_Rural:KK_Having_Any_Kind_Of_Symptoms_Of_Chronic_Illness_Per_100000_Population_Person_Urban:KK_Having_Any_Kind_Of_Symptoms_Of_Chronic_Illness_Per_100000_Population_Male_Total:KK_Having_Any_Kind_Of_Symptoms_Of_Chronic_Illness_Per_100000_Population_Male_Rural:KK_Having_Any_Kind_Of_Symptoms_Of_Chronic_Illness_Per_100000_Population_Male_Urban:KK_Having_Any_Kind_Of_Symptoms_Of_Chronic_Illness_Per_100000_Population_Female_Total:KK_Having_Any_Kind_Of_Symptoms_Of_Chronic_Illness_Per_100000_Population_Female_Rural:KK_Having_Any_Kind_Of_Symptoms_Of_Chronic_Illness_Per_100000_Population_Female_Urban:KK_Having_Any_Kind_Of_Symptoms_Of_Chronic_Illness_And_Sought_Medical_Care_Person_Total:KK_Having_Any_Kind_Of_Symptoms_Of_Chronic_Illness_And_Sought_Medical_Care_Person_Rural:KK_Having_Any_Kind_Of_Symptoms_Of_Chronic_Illness_And_Sought_Medical_Care_Person_Urban:KK_Having_Any_Kind_Of_Symptoms_Of_Chronic_Illness_And_Sought_Medical_Care_Male_Total:KK_Having_Any_Kind_Of_Symptoms_Of_Chronic_Illness_And_Sought_Medical_Care_Male_Rural:KK_Having_Any_Kind_Of_Symptoms_Of_Chronic_Illness_And_Sought_Medical_Care_Male_Urban:KK_Having_Any_Kind_Of_Symptoms_Of_Chronic_Illness_And_Sought_Medical_Care_Female_Total:KK_Having_Any_Kind_Of_Symptoms_Of_Chronic_Illness_And_Sought_Medical_Care_Female_Rural:KK_Having_Any_Kind_Of_Symptoms_Of_Chronic_Illness_And_Sought_Medical_Care_Female_Urban:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Diabetes_Person_Total:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Diabetes_Person_Rural:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Diabetes_Person_Urban:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Diabetes_Male_Total:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Diabetes_Male_Rural:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Diabetes_Male_Urban:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Diabetes_Female_Total:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Diabetes_Female_Rural:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Diabetes_Female_Urban:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Hypertension_Person_Total:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Hypertension_Person_Rural:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Hypertension_Person_Urban:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Hypertension_Male_Total:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Hypertension_Male_Rural:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Hypertension_Male_Urban:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Hypertension_Female_Total:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Hypertension_Female_Rural:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Hypertension_Female_Urban:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Tuberculosis_Tb_Person_Total:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Tuberculosis_Tb_Person_Rural:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Tuberculosis_Tb_Person_Urban:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Tuberculosis_Tb_Male_Total:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Tuberculosis_Tb_Male_Rural:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Tuberculosis_Tb_Male_Urban:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Tuberculosis_Tb_Female_Total:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Tuberculosis_Tb_Female_Rural:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Tuberculosis_Tb_Female_Urban:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Asthma_Chronic_Respiratory_Disease_Person_Total:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Asthma_Chronic_Respiratory_Disease_Person_Rural:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Asthma_Chronic_Respiratory_Disease_Person_Urban:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Asthma_Chronic_Respiratory_Disease_Male_Total:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Asthma_Chronic_Respiratory_Disease_Male_Rural:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Asthma_Chronic_Respiratory_Disease_Male_Urban:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Asthma_Chronic_Respiratory_Disease_Female_Total:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Asthma_Chronic_Respiratory_Disease_Female_Rural:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Asthma_Chronic_Respiratory_Disease_Female_Urban:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Arthritis_Person_Total:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Arthritis_Person_Rural:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Arthritis_Person_Urban:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Arthritis_Male_Total:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Arthritis_Male_Rural:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Arthritis_Male_Urban:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Arthritis_Female_Total:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Arthritis_Female_Rural:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Arthritis_Female_Urban:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Any_Kind_Of_Chronic_Illness_Person_Total:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Any_Kind_Of_Chronic_Illness_Person_Rural:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Any_Kind_Of_Chronic_Illness_Person_Urban:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Any_Kind_Of_Chronic_Illness_Male_Total:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Any_Kind_Of_Chronic_Illness_Male_Rural:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Any_Kind_Of_Chronic_Illness_Male_Urban:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Any_Kind_Of_Chronic_Illness_Female_Total:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Any_Kind_Of_Chronic_Illness_Female_Rural:KK_Having_Diagnosed_For_Chronic_Illness_Per_100000_Population_Any_Kind_Of_Chronic_Illness_Female_Urban:KK_Having_Diagnosed_For_Any_Kind_Of_Chronic_Illness_And_Getting_Regular_Treatment_Person_Total:KK_Having_Diagnosed_For_Any_Kind_Of_Chronic_Illness_And_Getting_Regular_Treatment_Person_Rural:KK_Having_Diagnosed_For_Any_Kind_Of_Chronic_Illness_And_Getting_Regular_Treatment_Person_Urban:KK_Having_Diagnosed_For_Any_Kind_Of_Chronic_Illness_And_Getting_Regular_Treatment_Male_Total:KK_Having_Diagnosed_For_Any_Kind_Of_Chronic_Illness_And_Getting_Regular_Treatment_Male_Rural:KK_Having_Diagnosed_For_Any_Kind_Of_Chronic_Illness_And_Getting_Regular_Treatment_Male_Urban:KK_Having_Diagnosed_For_Any_Kind_Of_Chronic_Illness_And_Getting_Regular_Treatment_Female_Total:KK_Having_Diagnosed_For_Any_Kind_Of_Chronic_Illness_And_Getting_Regular_Treatment_Female_Rural:KK_Having_Diagnosed_For_Any_Kind_Of_Chronic_Illness_And_Getting_Regular_Treatment_Female_Urban:KK_Having_Diagnosed_For_Any_Kind_Of_Chronic_Illness_And_Getting_Regular_Treatment_From_Government_Source_Person_Total:KK_Having_Diagnosed_For_Any_Kind_Of_Chronic_Illness_And_Getting_Regular_Treatment_From_Government_Source_Person_Rural:KK_Having_Diagnosed_For_Any_Kind_Of_Chronic_Illness_And_Getting_Regular_Treatment_From_Government_Source_Person_Urban:KK_Having_Diagnosed_For_Any_Kind_Of_Chronic_Illness_And_Getting_Regular_Treatment_From_Government_Source_Male_Total:KK_Having_Diagnosed_For_Any_Kind_Of_Chronic_Illness_And_Getting_Regular_Treatment_From_Government_Source_Male_Rural:KK_Having_Diagnosed_For_Any_Kind_Of_Chronic_Illness_And_Getting_Regular_Treatment_From_Government_Source_Male_Urban:KK_Having_Diagnosed_For_Any_Kind_Of_Chronic_Illness_And_Getting_Regular_Treatment_From_Government_Source_Female_Total:KK_Having_Diagnosed_For_Any_Kind_Of_Chronic_Illness_And_Getting_Regular_Treatment_From_Government_Source_Female_Rural:KK_Having_Diagnosed_For_Any_Kind_Of_Chronic_Illness_And_Getting_Regular_Treatment_From_Government_Source_Female_Urban:LL_Crude_Birth_Rate_Cbr_Total:LL_Crude_Birth_Rate_Cbr_Rural:LL_Crude_Birth_Rate_Cbr_Urban:LL_Natural_Growth_Rate_Total:LL_Natural_Growth_Rate_Rural:LL_Natural_Growth_Rate_Urban:LL_Total_Fertility_Rate_Total:LL_Total_Fertility_Rate_Rural:LL_Total_Fertility_Rate_Urban:LL_Women_Aged_20_24_Reporting_Birth_Of_Order_2__Above_Total:LL_Women_Aged_20_24_Reporting_Birth_Of_Order_2__Above_Rural:LL_Women_Aged_20_24_Reporting_Birth_Of_Order_2__Above_Urban:LL_Women_Reporting_Birth_Of_Order_3__Above_Total:LL_Women_Reporting_Birth_Of_Order_3__Above_Rural:LL_Women_Reporting_Birth_Of_Order_3__Above_Urban:LL_Women_With_Two_Children_Wanting_No_More_Children_Total:LL_Women_With_Two_Children_Wanting_No_More_Children_Rural:LL_Women_With_Two_Children_Wanting_No_More_Children_Urban:LL_Women_Aged_15_19_Years_Who_Were_Already_Mothers_Or_Pregnant_At_The_Time_Of_Survey_Total:LL_Women_Aged_15_19_Years_Who_Were_Already_Mothers_Or_Pregnant_At_The_Time_Of_Survey_Rural:LL_Women_Aged_15_19_Years_Who_Were_Already_Mothers_Or_Pregnant_At_The_Time_Of_Survey_Urban:LL_Median_Age_At_First_Live_Birth_Of_Women_Aged_15_49_Years_Total:LL_Median_Age_At_First_Live_Birth_Of_Women_Aged_15_49_Years_Rural:LL_Median_Age_At_First_Live_Birth_Of_Women_Aged_15_49_Years_Urban:LL_Median_Age_At_First_Live_Birth_Of_Women_Aged_25_49_Years_Total:LL_Median_Age_At_First_Live_Birth_Of_Women_Aged_25_49_Years_Rural:LL_Median_Age_At_First_Live_Birth_Of_Women_Aged_25_49_Years_Urban:LL_Live_Births_Taking_Place_After_An_Interval_Of_36_Months_Total:LL_Live_Births_Taking_Place_After_An_Interval_Of_36_Months_Rural:LL_Live_Births_Taking_Place_After_An_Interval_Of_36_Months_Urban:LL_Mean_Number_Of_Children_Ever_Born_To_Women_Aged_15_49_Years_Total:LL_Mean_Number_Of_Children_Ever_Born_To_Women_Aged_15_49_Years_Rural:LL_Mean_Number_Of_Children_Ever_Born_To_Women_Aged_15_49_Years_Urban:LL_Mean_Number_Of_Children_Surviving_To_Women_Aged_15_49_Years_Total:LL_Mean_Number_Of_Children_Surviving_To_Women_Aged_15_49_Years_Rural:LL_Mean_Number_Of_Children_Surviving_To_Women_Aged_15_49_Years_Urban:LL_Mean_Number_Of_Children_Ever_Born_To_Women_Aged_45_49_Years_Total:LL_Mean_Number_Of_Children_Ever_Born_To_Women_Aged_45_49_Years_Rural:LL_Mean_Number_Of_Children_Ever_Born_To_Women_Aged_45_49_Years_Urban:MM_Pregnancy_To_Women_Aged_15_49_Years_Resulting_In_Abortion_Total:MM_Pregnancy_To_Women_Aged_15_49_Years_Resulting_In_Abortion_Rural:MM_Pregnancy_To_Women_Aged_15_49_Years_Resulting_In_Abortion_Urban:MM_Women_Who_Received_Any_Anc_Before_Abortion_Total:MM_Women_Who_Received_Any_Anc_Before_Abortion_Rural:MM_Women_Who_Received_Any_Anc_Before_Abortion_Urban:MM_Women_Who_Went_For_Ultrasound_Before_Abortion_Total:MM_Women_Who_Went_For_Ultrasound_Before_Abortion_Rural:MM_Women_Who_Went_For_Ultrasound_Before_Abortion_Urban:MM_Average_Month_Of_Pregnancy_At_The_Time_Of_Abortion_Total:MM_Average_Month_Of_Pregnancy_At_The_Time_Of_Abortion_Rural:MM_Average_Month_Of_Pregnancy_At_The_Time_Of_Abortion_Urban:MM_Abortion_Performed_By_Skilled_Health_Personnel_Total:MM_Abortion_Performed_By_Skilled_Health_Personnel_Rural:MM_Abortion_Performed_By_Skilled_Health_Personnel_Urban:MM_Abortion_Taking_Place_In_Institution_Total:MM_Abortion_Taking_Place_In_Institution_Rural:MM_Abortion_Taking_Place_In_Institution_Urban:NN_Current_Usage_Any_Method_Total:NN_Current_Usage_Any_Method_Rural:NN_Current_Usage_Any_Method_Urban:NN_Current_Usage_Any_Modern_Method_Total:NN_Current_Usage_Any_Modern_Method_Rural:NN_Current_Usage_Any_Modern_Method_Urban:NN_Current_Usage_Female_Sterilization_Total:NN_Current_Usage_Female_Sterilization_Rural:NN_Current_Usage_Female_Sterilization_Urban:NN_Current_Usage_Male_Sterilization_Total:NN_Current_Usage_Male_Sterilization_Rural:NN_Current_Usage_Male_Sterilization_Urban:NN_Current_Usage_Copper_T_Iud_Total:NN_Current_Usage_Copper_T_Iud_Rural:NN_Current_Usage_Copper_T_Iud_Urban:NN_Current_Usage_Pills_Total:NN_Current_Usage_Pills_Rural:NN_Current_Usage_Pills_Urban:NN_Current_Usage_Condom_Nirodh_Total:NN_Current_Usage_Condom_Nirodh_Rural:NN_Current_Usage_Condom_Nirodh_Urban:NN_Current_Usage_Emergency_Contraceptive_Pills_Total:NN_Current_Usage_Emergency_Contraceptive_Pills_Rural:NN_Current_Usage_Emergency_Contraceptive_Pills_Urban:NN_Current_Usage_Any_Traditional_Method_Total:NN_Current_Usage_Any_Traditional_Method_Rural:NN_Current_Usage_Any_Traditional_Method_Urban:NN_Current_Usage_Periodic_Abstinence_Total:NN_Current_Usage_Periodic_Abstinence_Rural:NN_Current_Usage_Periodic_Abstinence_Urban:NN_Current_Usage_Withdrawal_Total:NN_Current_Usage_Withdrawal_Rural:NN_Current_Usage_Withdrawal_Urban:NN_Current_Usage_Lam_Total:NN_Current_Usage_Lam_Rural:NN_Current_Usage_Lam_Urban:OO_Unmet_Need_For_Spacing_Total:OO_Unmet_Need_For_Spacing_Rural:OO_Unmet_Need_For_Spacing_Urban:OO_Unmet_Need_For_Limiting_Total:OO_Unmet_Need_For_Limiting_Rural:OO_Unmet_Need_For_Limiting_Urban:OO_Total_Unmet_Need_Total:OO_Total_Unmet_Need_Rural:OO_Total_Unmet_Need_Urban:PP_Currently_Married_Pregnant_Women_Aged_15_49_Years_Registered_For_Anc_Total:PP_Currently_Married_Pregnant_Women_Aged_15_49_Years_Registered_For_Anc_Rural:PP_Currently_Married_Pregnant_Women_Aged_15_49_Years_Registered_For_Anc_Urban:PP_Mothers_Who_Received_Any_Antenatal_Check_Up_Total:PP_Mothers_Who_Received_Any_Antenatal_Check_Up_Rural:PP_Mothers_Who_Received_Any_Antenatal_Check_Up_Urban:PP_Mothers_Who_Had_Antenatal_Check_Up_In_First_Trimester_Total:PP_Mothers_Who_Had_Antenatal_Check_Up_In_First_Trimester_Rural:PP_Mothers_Who_Had_Antenatal_Check_Up_In_First_Trimester_Urban:PP_Mothers_Who_Received_3_Or_More_Antenatal_Care_Total:PP_Mothers_Who_Received_3_Or_More_Antenatal_Care_Rural:PP_Mothers_Who_Received_3_Or_More_Antenatal_Care_Urban:PP_Mothers_Who_Received_At_Least_One_Tetanus_Toxoid_Tt_Injection_Total:PP_Mothers_Who_Received_At_Least_One_Tetanus_Toxoid_Tt_Injection_Rural:PP_Mothers_Who_Received_At_Least_One_Tetanus_Toxoid_Tt_Injection_Urban:PP_Mothers_Who_Consumed_Ifa_For_100_Days_Or_More_Total:PP_Mothers_Who_Consumed_Ifa_For_100_Days_Or_More_Rural:PP_Mothers_Who_Consumed_Ifa_For_100_Days_Or_More_Urban:PP_Mothers_Who_Had_Full_Antenatal_Check_Up_Total:PP_Mothers_Who_Had_Full_Antenatal_Check_Up_Rural:PP_Mothers_Who_Had_Full_Antenatal_Check_Up_Urban:PP_Mothers_Who_Received_Anc_From_Govt_Source_Total:PP_Mothers_Who_Received_Anc_From_Govt_Source_Rural:PP_Mothers_Who_Received_Anc_From_Govt_Source_Urban:PP_Mothers_Whose_Blood_Pressure_Bp_Taken_Total:PP_Mothers_Whose_Blood_Pressure_Bp_Taken_Rural:PP_Mothers_Whose_Blood_Pressure_Bp_Taken_Urban:PP_Mothers_Whose_Blood_Taken_For_Hb_Total:PP_Mothers_Whose_Blood_Taken_For_Hb_Rural:PP_Mothers_Whose_Blood_Taken_For_Hb_Urban:PP_Mothers_Who_Underwent_Ultrasound_Total:PP_Mothers_Who_Underwent_Ultrasound_Rural:PP_Mothers_Who_Underwent_Ultrasound_Urban:QQ_Institutional_Delivery_Total:QQ_Institutional_Delivery_Rural:QQ_Institutional_Delivery_Urban:QQ_Delivery_At_Government_Institution_Total:QQ_Delivery_At_Government_Institution_Rural:QQ_Delivery_At_Government_Institution_Urban:QQ_Delivery_At_Private_Institution_Total:QQ_Delivery_At_Private_Institution_Rural:QQ_Delivery_At_Private_Institution_Urban:QQ_Delivery_At_Home_Total:QQ_Delivery_At_Home_Rural:QQ_Delivery_At_Home_Urban:QQ_Delivery_At_Home_Conducted_By_Skilled_Health_Personnel_Total:QQ_Delivery_At_Home_Conducted_By_Skilled_Health_Personnel_Rural:QQ_Delivery_At_Home_Conducted_By_Skilled_Health_Personnel_Urban:QQ_Safe_Delivery_Total:QQ_Safe_Delivery_Rural:QQ_Safe_Delivery_Urban:QQ_Caesarean_Out_Of_Total_Delivery_Taken_Place_In_Government_Institutions_Total:QQ_Caesarean_Out_Of_Total_Delivery_Taken_Place_In_Government_Institutions_Rural:QQ_Caesarean_Out_Of_Total_Delivery_Taken_Place_In_Government_Institutions_Urban:QQ_Caesarean_Out_Of_Total_Delivery_Taken_Place_In_Private_Institutions_Total:QQ_Caesarean_Out_Of_Total_Delivery_Taken_Place_In_Private_Institutions_Rural:QQ_Caesarean_Out_Of_Total_Delivery_Taken_Place_In_Private_Institutions_Urban:RR_Less_Than_24_Hrs_Stay_In_Institution_After_Delivery_Total:RR_Less_Than_24_Hrs_Stay_In_Institution_After_Delivery_Rural:RR_Less_Than_24_Hrs_Stay_In_Institution_After_Delivery_Urban:RR_Mothers_Who_Received_Post_Natal_Check_Up_Within_48_Hrs_Of_Delivery_Total:RR_Mothers_Who_Received_Post_Natal_Check_Up_Within_48_Hrs_Of_Delivery_Rural:RR_Mothers_Who_Received_Post_Natal_Check_Up_Within_48_Hrs_Of_Delivery_Urban:RR_Mothers_Who_Received_Post_Natal_Check_Up_Within_1_Week_Of_Delivery_Total:RR_Mothers_Who_Received_Post_Natal_Check_Up_Within_1_Week_Of_Delivery_Rural:RR_Mothers_Who_Received_Post_Natal_Check_Up_Within_1_Week_Of_Delivery_Urban:RR_Mothers_Who_Did_Not_Receive_Any_Post_Natal_Check_Up_Total:RR_Mothers_Who_Did_Not_Receive_Any_Post_Natal_Check_Up_Rural:RR_Mothers_Who_Did_Not_Receive_Any_Post_Natal_Check_Up_Urban:RR_New_Borns_Who_Were_Checked_Up_Within_24_Hrs_Of_Birth_Total:RR_New_Borns_Who_Were_Checked_Up_Within_24_Hrs_Of_Birth_Rural:RR_New_Borns_Who_Were_Checked_Up_Within_24_Hrs_Of_Birth_Urban:SS_Mothers_Who_Availed_Financial_Assistance_For_Delivery_Under_Jsy_Total:SS_Mothers_Who_Availed_Financial_Assistance_For_Delivery_Under_Jsy_Rural:SS_Mothers_Who_Availed_Financial_Assistance_For_Delivery_Under_Jsy_Urban:SS_Mothers_Who_Availed_Financial_Assistance_For_Institutional_Delivery_Under_Jsy_Total:SS_Mothers_Who_Availed_Financial_Assistance_For_Institutional_Delivery_Under_Jsy_Rural:SS_Mothers_Who_Availed_Financial_Assistance_For_Institutional_Delivery_Under_Jsy_Urban:SS_Mothers_Who_Availed_Financial_Assistance_For_Government_Institutional_Delivery_Under_Jsy_Total:SS_Mothers_Who_Availed_Financial_Assistance_For_Government_Institutional_Delivery_Under_Jsy_Rural:SS_Mothers_Who_Availed_Financial_Assistance_For_Government_Institutional_Delivery_Under_Jsy_Urban:TT_Children_Aged_12_23_Months_Having_Immunization_Card_Total:TT_Children_Aged_12_23_Months_Having_Immunization_Card_Rural:TT_Children_Aged_12_23_Months_Having_Immunization_Card_Urban:TT_Children_Aged_12_23_Months_Who_Have_Received_Bcg_Total:TT_Children_Aged_12_23_Months_Who_Have_Received_Bcg_Rural:TT_Children_Aged_12_23_Months_Who_Have_Received_Bcg_Urban:TT_Children_Aged_12_23_Months_Who_Have_Received_3_Doses_Of_Polio_Vaccine_Total:TT_Children_Aged_12_23_Months_Who_Have_Received_3_Doses_Of_Polio_Vaccine_Rural:TT_Children_Aged_12_23_Months_Who_Have_Received_3_Doses_Of_Polio_Vaccine_Urban:TT_Children_Aged_12_23_Months_Who_Have_Received_3_Doses_Of_Dpt_Vaccine_Total:TT_Children_Aged_12_23_Months_Who_Have_Received_3_Doses_Of_Dpt_Vaccine_Rural:TT_Children_Aged_12_23_Months_Who_Have_Received_3_Doses_Of_Dpt_Vaccine_Urban:TT_Children_Aged_12_23_Months_Who_Have_Received_Measles_Vaccine_Total:TT_Children_Aged_12_23_Months_Who_Have_Received_Measles_Vaccine_Rural:TT_Children_Aged_12_23_Months_Who_Have_Received_Measles_Vaccine_Urban:TT_Children_Aged_12_23_Months_Fully_Immunized_Total:TT_Children_Aged_12_23_Months_Fully_Immunized_Rural:TT_Children_Aged_12_23_Months_Fully_Immunized_Urban:TT_Children_Who_Have_Received_Polio_Dose_At_Birth_Total:TT_Children_Who_Have_Received_Polio_Dose_At_Birth_Rural:TT_Children_Who_Have_Received_Polio_Dose_At_Birth_Urban:TT_Children_Who_Did_Not_Receive_Any_Vaccination_Total:TT_Children_Who_Did_Not_Receive_Any_Vaccination_Rural:TT_Children_Who_Did_Not_Receive_Any_Vaccination_Urban:TT_Children_Aged_6_35_Months_Who_Received_At_Least_One_Vitamin_A_Dose_During_Last_Six_Months_Total:TT_Children_Aged_6_35_Months_Who_Received_At_Least_One_Vitamin_A_Dose_During_Last_Six_Months_Rural:TT_Children_Aged_6_35_Months_Who_Received_At_Least_One_Vitamin_A_Dose_During_Last_Six_Months_Urban:TT_Children_Aged_6_35_Months_Who_Received_Ifa_Tablets_Syrup_During_Last_3_Months_Total:TT_Children_Aged_6_35_Months_Who_Received_Ifa_Tablets_Syrup_During_Last_3_Months_Rural:TT_Children_Aged_6_35_Months_Who_Received_Ifa_Tablets_Syrup_During_Last_3_Months_Urban:TT_Children_Whose_Birth_Weight_Was_Taken_Total:TT_Children_Whose_Birth_Weight_Was_Taken_Rural:TT_Children_Whose_Birth_Weight_Was_Taken_Urban:TT_Children_With_Birth_Weight_Less_Than_2_5_Kg_Total:TT_Children_With_Birth_Weight_Less_Than_2_5_Kg_Rural:TT_Children_With_Birth_Weight_Less_Than_2_5_Kg_Urban:UU_Children_Suffering_From_Diarrhoea_Total:UU_Children_Suffering_From_Diarrhoea_Rural:UU_Children_Suffering_From_Diarrhoea_Urban:UU_Children_Suffering_From_Diarrhoea_Who_Received_Haf_Ors_Ort_Total:UU_Children_Suffering_From_Diarrhoea_Who_Received_Haf_Ors_Ort_Rural:UU_Children_Suffering_From_Diarrhoea_Who_Received_Haf_Ors_Ort_Urban:UU_Children_Suffering_From_Acute_Respiratory_Infection_Total:UU_Children_Suffering_From_Acute_Respiratory_Infection_Rural:UU_Children_Suffering_From_Acute_Respiratory_Infection_Urban:UU_Children_Suffering_From_Acute_Respiratory_Infection_Who_Sought_Treatment_Total:UU_Children_Suffering_From_Acute_Respiratory_Infection_Who_Sought_Treatment_Rural:UU_Children_Suffering_From_Acute_Respiratory_Infection_Who_Sought_Treatment_Urban:UU_Children_Suffering_From_Fever_Total:UU_Children_Suffering_From_Fever_Rural:UU_Children_Suffering_From_Fever_Urban:UU_Children_Suffering_From_Fever_Who_Sought_Treatment_Total:UU_Children_Suffering_From_Fever_Who_Sought_Treatment_Rural:UU_Children_Suffering_From_Fever_Who_Sought_Treatment_Urban:VV_Children_Breastfed_Within_One_Hour_Of_Birth_Total:VV_Children_Breastfed_Within_One_Hour_Of_Birth_Rural:VV_Children_Breastfed_Within_One_Hour_Of_Birth_Urban:VV_Children_Aged_6_35_Months_Exclusively_Breastfed_For_At_Least_Six_Months_Total:VV_Children_Aged_6_35_Months_Exclusively_Breastfed_For_At_Least_Six_Months_Rural:VV_Children_Aged_6_35_Months_Exclusively_Breastfed_For_At_Least_Six_Months_Urban:VV_Children_Who_Received_Foods_Other_Than_Breast_Milk_During_First_6_Months_Water_Total:VV_Children_Who_Received_Foods_Other_Than_Breast_Milk_During_First_6_Months_Water_Rural:VV_Children_Who_Received_Foods_Other_Than_Breast_Milk_During_First_6_Months_Water_Urban:VV_Children_Who_Received_Foods_Other_Than_Breast_Milk_During_First_6_Months_Animal_Formula_Milk_Total:VV_Children_Who_Received_Foods_Other_Than_Breast_Milk_During_First_6_Months_Animal_Formula_Milk_Rural:VV_Children_Who_Received_Foods_Other_Than_Breast_Milk_During_First_6_Months_Animal_Formula_Milk_Urban:VV_Children_Who_Received_Foods_Other_Than_Breast_Milk_During_First_6_Months_Semi_Solid_Mashed_Food_Total:VV_Children_Who_Received_Foods_Other_Than_Breast_Milk_During_First_6_Months_Semi_Solid_Mashed_Food_Rural:VV_Children_Who_Received_Foods_Other_Than_Breast_Milk_During_First_6_Months_Semi_Solid_Mashed_Food_Urban:VV_Children_Who_Received_Foods_Other_Than_Breast_Milk_During_First_6_Months_Solid_Adult_Food_Total:VV_Children_Who_Received_Foods_Other_Than_Breast_Milk_During_First_6_Months_Solid_Adult_Food_Rural:VV_Children_Who_Received_Foods_Other_Than_Breast_Milk_During_First_6_Months_Solid_Adult_Food_Urban:VV_Children_Who_Received_Foods_Other_Than_Breast_Milk_During_First_6_Months_Vegetables_Fruits_Total:VV_Children_Who_Received_Foods_Other_Than_Breast_Milk_During_First_6_Months_Vegetables_Fruits_Rural:VV_Children_Who_Received_Foods_Other_Than_Breast_Milk_During_First_6_Months_Vegetables_Fruits_Urban:VV_Average_Month_By_Which_Children_Received_Foods_Other_Than_Breast_Milk_Water_Total:VV_Average_Month_By_Which_Children_Received_Foods_Other_Than_Breast_Milk_Water_Rural:VV_Average_Month_By_Which_Children_Received_Foods_Other_Than_Breast_Milk_Water_Urban:VV_Average_Month_By_Which_Children_Received_Foods_Other_Than_Breast_Milk_Animal_Formula_Milk_Total:VV_Average_Month_By_Which_Children_Received_Foods_Other_Than_Breast_Milk_Animal_Formula_Milk_Rural:VV_Average_Month_By_Which_Children_Received_Foods_Other_Than_Breast_Milk_Animal_Formula_Milk_Urban:VV_Average_Month_By_Which_Children_Received_Foods_Other_Than_Breast_Milk_Semi_Solid_Mashed_Food_Total:VV_Average_Month_By_Which_Children_Received_Foods_Other_Than_Breast_Milk_Semi_Solid_Mashed_Food_Rural:VV_Average_Month_By_Which_Children_Received_Foods_Other_Than_Breast_Milk_Semi_Solid_Mashed_Food_Urban:VV_Average_Month_By_Which_Children_Received_Foods_Other_Than_Breast_Milk_Solid_Adult_Food_Total:VV_Average_Month_By_Which_Children_Received_Foods_Other_Than_Breast_Milk_Solid_Adult_Food_Rural:VV_Average_Month_By_Which_Children_Received_Foods_Other_Than_Breast_Milk_Solid_Adult_Food_Urban:VV_Average_Month_By_Which_Children_Received_Foods_Other_Than_Breast_Milk_Vegetables_Fruits_Total:VV_Average_Month_By_Which_Children_Received_Foods_Other_Than_Breast_Milk_Vegetables_Fruits_Rural:VV_Average_Month_By_Which_Children_Received_Foods_Other_Than_Breast_Milk_Vegetables_Fruits_Urban:WW_Birth_Registered_Total:WW_Birth_Registered_Rural:WW_Birth_Registered_Urban:WW_Children_Whose_Birth_Was_Registered_And_Received_Birth_Certificate_Total:WW_Children_Whose_Birth_Was_Registered_And_Received_Birth_Certificate_Rural:WW_Children_Whose_Birth_Was_Registered_And_Received_Birth_Certificate_Urban:XX_Women_Who_Are_Aware_Of_Hiv_Aids_Total:XX_Women_Who_Are_Aware_Of_Hiv_Aids_Rural:XX_Women_Who_Are_Aware_Of_Hiv_Aids_Urban:XX_Women_Who_Are_Aware_Of_Rti_Sti_Total:XX_Women_Who_Are_Aware_Of_Rti_Sti_Rural:XX_Women_Who_Are_Aware_Of_Rti_Sti_Urban:XX_Women_Who_Are_Aware_Of_Haf_Ors_Ort_Zinc_Total:XX_Women_Who_Are_Aware_Of_Haf_Ors_Ort_Zinc_Rural:XX_Women_Who_Are_Aware_Of_Haf_Ors_Ort_Zinc_Urban:XX_Women_Who_Are_Aware_Of_Danger_Signs_Of_Ari_Pneumonia_Total:XX_Women_Who_Are_Aware_Of_Danger_Signs_Of_Ari_Pneumonia_Rural:XX_Women_Who_Are_Aware_Of_Danger_Signs_Of_Ari_Pneumonia_Urban:YY_Crude_Death_Rate_Cdr_Total_Person:YY_Crude_Death_Rate_Cdr_Total_Male:YY_Crude_Death_Rate_Cdr_Total_Female:YY_Crude_Death_Rate_Cdr_Rural_Person:YY_Crude_Death_Rate_Cdr_Rural_Male:YY_Crude_Death_Rate_Cdr_Rural_Female:YY_Crude_Death_Rate_Cdr_Urban_Person:YY_Crude_Death_Rate_Cdr_Urban_Male:YY_Crude_Death_Rate_Cdr_Urban_Female:YY_Infant_Mortality_Rate_Imr_Total_Person:YY_Infant_Mortality_Rate_Imr_Total_Male:YY_Infant_Mortality_Rate_Imr_Total_Female:YY_Infant_Mortality_Rate_Imr_Rural_Person:YY_Infant_Mortality_Rate_Imr_Rural_Male:YY_Infant_Mortality_Rate_Imr_Rural_Female:YY_Infant_Mortality_Rate_Imr_Urban_Person:YY_Infant_Mortality_Rate_Imr_Urban_Male:YY_Infant_Mortality_Rate_Imr_Urban_Female:YY_Neo_Natal_Mortality_Rate_Total:YY_Neo_Natal_Mortality_Rate_Rural:YY_Neo_Natal_Mortality_Rate_Urban:YY_Post_Neo_Natal_Mortality_Rate_Total:YY_Post_Neo_Natal_Mortality_Rate_Rural:YY_Post_Neo_Natal_Mortality_Rate_Urban:YY_Under_Five_Mortality_Rate_U5MR_Total_Person:YY_Under_Five_Mortality_Rate_U5MR_Total_Male:YY_Under_Five_Mortality_Rate_U5MR_Total_Female:YY_Under_Five_Mortality_Rate_U5MR_Rural_Person:YY_Under_Five_Mortality_Rate_U5MR_Rural_Male:YY_Under_Five_Mortality_Rate_U5MR_Rural_Female:YY_Under_Five_Mortality_Rate_U5MR_Urban_Person:YY_Under_Five_Mortality_Rate_U5MR_Urban_Male:YY_Under_Five_Mortality_Rate_U5MR_Urban_Female:ZZ_Crude_Birth_Rate_Total_Lower_Limit:ZZ_Crude_Birth_Rate_Total_Upper_Limit:ZZ_Crude_Birth_Rate_Rural_Lower_Limit:ZZ_Crude_Birth_Rate_Rural_Upper_Limit:ZZ_Crude_Birth_Rate_Urban_Lower_Limit:ZZ_Crude_Birth_Rate_Urban_Upper_Limit:ZZ_Crude_Death_Rate_Total_Lower_Limit:ZZ_Crude_Death_Rate_Total_Upper_Limit:ZZ_Crude_Death_Rate_Rural_Lower_Limit:ZZ_Crude_Death_Rate_Rural_Upper_Limit:ZZ_Crude_Death_Rate_Urban_Lower_Limit:ZZ_Crude_Death_Rate_Urban_Upper_Limit:ZZ_Infant_Mortality_Rate_Total_Lower_Limit:ZZ_Infant_Mortality_Rate_Total_Upper_Limit:ZZ_Infant_Mortality_Rate_Rural_Lower_Limit:ZZ_Infant_Mortality_Rate_Rural_Upper_Limit:ZZ_Infant_Mortality_Rate_Urban_Lower_Limit:ZZ_Infant_Mortality_Rate_Urban_Upper_Limit:ZZ_Under_Five_Mortality_Rate_U5MR_Total_Lower_Limit:ZZ_Under_Five_Mortality_Rate_U5MR_Total_Upper_Limit:ZZ_Under_Five_Mortality_Rate_U5MR_Rural_Lower_Limit:ZZ_Under_Five_Mortality_Rate_U5MR_Rural_Upper_Limit:ZZ_Under_Five_Mortality_Rate_U5MR_Urban_Lower_Limit:ZZ_Under_Five_Mortality_Rate_U5MR_Urban_Upper_Limit:ZZ_Sex_Ratio_At_Birth_Total_Lower_Limit:ZZ_Sex_Ratio_At_Birth_Total_Upper_Limit:ZZ_Sex_Ratio_At_Birth_Rural_Lower_Limit:ZZ_Sex_Ratio_At_Birth_Rural_Upper_Limit:ZZ_Sex_Ratio_At_Birth_Urban_Lower_Limit:ZZ_Sex_Ratio_At_Birth_Urban_Upper_Limit:,string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
2016 New Coder Survey , Free Code Camp , www.kaggle.com/freecodecamp/2016-new-coder-survey- , Fri Jun 03 2016 05:57:28 GMT+0530 (IST) , A survey of 15000+ people who are new to software development ,3046, employment- computing and society- ,Context Free Code Camp is an open source community where you learn to code and build projects for nonprofits. CodeNewbie.org is the most supportive community of people learning to code. Together we surveyed more than 15000 people who are actively learning to code. We reached them through the twitter accounts and email lists of various organizations that help people learn to code. Our goal was to understand these people's motivations in learning to code how they're learning to code their demographics and their socioeconomic background. We've written in depth about this dataset. In May 2017 we just released an even bigger open dataset with our 2017 survey results.,,,
Food Ingredient Lists , Datafiniti , www.kaggle.com/datafiniti/food-ingredient-lists , Wed Sep 20 2017 02:21:23 GMT+0530 (IST) , 10000 food products and their ingredients ,235, food and drink- nutrition- ,About this Data This is a sample data set of ingredient lists pulled from Datafiniti's Product Data Set.  The data set covers 10000 different food listings and includes the ingredient list for each one. What You Can Do with this Data Use this data to discover insights into ingredients used in various foods.  E.g.  What's the distribution of number of ingredients per listing? What are the most common ingredients used?  About Datafiniti Datafiniti provides instant access to web data.  We compile data from thousands of websites to create standardized databases of business product and property information.  Learn more. Want More? If you're interested in more data like this please contact us.,id:asins:brand:categories:dateAdded:dateUpdated:ean:features.key:features.value:manufacturer:manufacturerNumber:name:sizes:upc:weight::,string:string:string:string:dateTime:dateTime:numeric:string:boolean:string:numeric:string:string:numeric:string:string:,
Education in India , Rajanand Ilangovan / இராஜ்ஆனந்த் இளங்கோவன் , www.kaggle.com/rajanand/education-in-india , Mon Aug 14 2017 22:37:50 GMT+0530 (IST) , District and state-wise primary & secondary school education data 2015-16 ,298, india- education- ,Context When India got independence from British in 1947 the literacy rate was 12.2% and as per the recent census 2011 it is 74.0%. Although it looks an accomplishment still many people are there without access to education.  It would be interesting to know the current status of the Indian education system. Content This dataset contains district and state wise Indian primary and secondary school education data for 2015-16. Granularity Annual List of files   2015_16_Districtwise.csv ( 680 observations and 819 variables ) 2015_16_Statewise_Elementary.csv ( 36 observations and 816 variables ) 2015_16_Statewise_Secondary.csv ( 36 observations and 630 variables  )  Acknowledgements Ministry of Human Resource Development (DISE) has shared the dataset here and also published some reports. Inspiration This dataset provides the complete information about primary and secondary education. There are many inferences can be made from this dataset. There are few things I would like to understand from this dataset.   Drop out ratio in primary and secondary education. (Govt. has made law that every child under age 14 should get free compulsary education.) Various factors affecting examination results of the students. What are all the factors that makes the difference (in literacy rate) between Kerala and Bihar? What could be done to improve the female literacy rate and literacy rate in rural area? ,AC_YEAR:STATCD:DISTCD:STATNAME:DISTNAME:DISTRICTS:BLOCKS:VILLAGES:CLUSTERS:TOTPOPULAT:P_URB_POP:POPULATION_0_6:GROWTHRATE:SEXRATIO:P_SC_POP:P_ST_POP:OVERALL_LI:FEMALE_LIT:MALE_LIT:AREA_SQKM:TOT_6_10_15:TOT_11_13_15:SCH1:SCH2:SCH3:SCH4:SCH5:SCH6:SCH7:SCH9:SCHTOT:SCH1G:SCH2G:SCH3G:SCH4G:SCH5G:SCH6G:SCH7G:SCH9G:SCHTOTG:SCH1P:SCH2P:SCH3P:SCH4P:SCH5P:SCH6P:SCH7P:SCH9P:SCHTOTP:SCH1M:SCH2M:SCH3M:SCH4M:SCH5M:SCH6M:SCH7M:SCH9M:SCHTOTM:SCH1GR:SCH2GR:SCH3GR:SCH4GR:SCH5GR:SCH6GR:SCH7GR:SCH9GR:SCHTOTGR:SCH1GA:SCH2GA:SCH3GA:SCH4GA:SCH5GA:SCH6GA:SCH7GA:SCH9GA:SCHTOTGA:SCH1PR:SCH2PR:SCH3PR:SCH4PR:SCH5PR:SCH6PR:SCH7PR:SCH9PR:SCHTOTPR:SCHBOY1:SCHBOY2:SCHBOY3:SCHBOY4:SCHBOY5:SCHBOY6:SCHBOY7:SCHBOY9:SCHBOYTOT:SCHGIR1:SCHGIR2:SCHGIR3:SCHGIR4:SCHGIR5:SCHGIR6:SCHGIR7:SCHGIR9:SCHGIRTOT:ENR1:ENR2:ENR3:ENR4:ENR5:ENR6:ENR7:ENR9:ENRTOT:ENR1G:ENR2G:ENR3G:ENR4G:ENR5G:ENR6G:ENR7G:ENR9G:ENRTOTG:ENR1P:ENR2P:ENR3P:ENR4P:ENR5P:ENR6P:ENR7P:ENR9P:ENRTOTP:ENR1M:ENR2M:ENR3M:ENR4M:ENR5M:ENR6M:ENR7M:ENR9M:ENRTOTM:ENR1GR:ENR2GR:ENR3GR:ENR4GR:ENR5GR:ENR6GR:ENR7GR:ENR9GR:ENRTOTGR:ENR1PR:ENR2PR:ENR3PR:ENR4PR:ENR5PR:ENR6PR:ENR7PR:ENR9PR:ENRTOTPR:TCH1G:TCH2G:TCH3G:TCH4G:TCH5G:TCH6G:TCH7G:TCH9G:TCHTOTG:TCH1P:TCH2P:TCH3P:TCH4P:TCH5P:TCH6P:TCH7P:TCH9P:TCHTOTP:TCH1M:TCH2M:TCH3M:TCH4M:TCH5M:TCH6M:TCH7M:TCH9M:TCHTOTM:SCLS1:SCLS2:SCLS3:SCLS4:SCLS5:SCLS6:SCLS7:SCLSTOT:STCH1:STCH2:STCH3:STCH4:STCH5:STCH6:STCH7:STCHTOT:ROAD1:ROAD2:ROAD3:ROAD4:ROAD5:ROAD6:ROAD7:ROADTOT:SPLAY1:SPLAY2:SPLAY3:SPLAY4:SPLAY5:SPLAY6:SPLAY7:SPLAYTOT:SBNDR1:SBNDR2:SBNDR3:SBNDR4:SBNDR5:SBNDR6:SBNDR7:SBNDRTOT:SGTOIL1:SGTOIL2:SGTOIL3:SGTOIL4:SGTOIL5:SGTOIL6:SGTOIL7:SGTOILTOT:SBTOIL1:SBTOIL2:SBTOIL3:SBTOIL4:SBTOIL5:SBTOIL6:SBTOIL7:SBTOILTOT:SWAT1:SWAT2:SWAT3:SWAT4:SWAT5:SWAT6:SWAT7:SWATTOT:SELE1:SELE2:SELE3:SELE4:SELE5:SELE6:SELE7:SELETOT:SCOMP1:SCOMP2:SCOMP3:SCOMP4:SCOMP5:SCOMP6:SCOMP7:SCOMPTOT:SRAM1:SRAM2:SRAM3:SRAM4:SRAM5:SRAM6:SRAM7:SRAMTOT:SRAMN1:SRAMN2:SRAMN3:SRAMN4:SRAMN5:SRAMN6:SRAMN7:SRAMNTOT:ESTD1:ESTD2:ESTD3:ESTD4:ESTD5:ESTD6:ESTD7:ESTDTOT:MDM1:MDM2:MDM3:MDM4:MDM5:MDM6:MDM7:MDMTOT:KIT1:KIT2:KIT3:KIT4:KIT5:KIT6:KIT7:KITTOT:KITS1:KITS2:KITS3:KITS4:KITS5:KITS6:KITS7:KITSTOT:ENR501:ENR502:ENR503:ENR504:ENR505:ENR506:ENR507:ENR509:ENR50TOT:SMC1:SMC2:SMC3:SMC4:SMC5:SMC6:SMC7:SMCTOT:CLS1:CLS2:CLS3:CLS4:CLS5:CLS6:CLS7:CLSTOT:TCH1:TCH2:TCH3:TCH4:TCH5:TCH6:TCH7:TCHTOT:TCHF1:TCHF2:TCHF3:TCHF4:TCHF5:TCHF6:TCHF7:TCHFTOT:TCHM1:TCHM2:TCHM3:TCHM4:TCHM5:TCHM6:TCHM7:TCHM9:ENRG1:ENRG2:ENRG3:ENRG4:ENRG5:ENRG6:ENRG7:ENRGTOT:PREP:PRESTD:PPFTCH:PPMTCH:PMTCH:PFTCH:TCHSCM1:TCHSCM2:TCHSCM3:TCHSCM4:TCHSCM5:TCHSCM6:TCHSCM7:TCHSCF1:TCHSCF2:TCHSCF3:TCHSCF4:TCHSCF5:TCHSCF6:TCHSCF7:TCHSTM1:TCHSTM2:TCHSTM3:TCHSTM4:TCHSTM5:TCHSTM6:TCHSTM7:TCHSTF1:TCHSTF2:TCHSTF3:TCHSTF4:TCHSTF5:TCHSTF6:TCHSTF7:TCHOBCM1:TCHOBCM2:TCHOBCM3:TCHOBCM4:TCHOBCM5:TCHOBCM6:TCHOBCM7:TCHOBCF1:TCHOBCF2:TCHOBCF3:TCHOBCF4:TCHOBCF5:TCHOBCF6:TCHOBCF7:TCH_TRNRM1:TCH_TRNRM2:TCH_TRNRM3:TCH_TRNRM4:TCH_TRNRM5:TCH_TRNRM6:TCH_TRNRM7:TCH_TRNRF1:TCH_TRNRF2:TCH_TRNRF3:TCH_TRNRF4:TCH_TRNRF5:TCH_TRNRF6:TCH_TRNRF7:PGRMTCH:PGRFTCH:GRMTCH:GRFTCH:PGCMTCH:PGCFTCH:PCMTCH:PCFTCH:C1_B:C2_B:C3_B:C4_B:C5_B:C6_B:C7_B:C8_B:C9_B:C1_G:C2_G:C3_G:C4_G:C5_G:C6_G:C7_G:C8_G:C9_G:C15A:C68A:C1_BD:C2_BD:C3_BD:C4_BD:C5_BD:C6_BD:C7_BD:C8_BD:C1_GD:C2_GD:C3_GD:C4_GD:C5_GD:C6_GD:C7_GD:C8_GD:C1_BR:C2_BR:C3_BR:C4_BR:C5_BR:C6_BR:C7_BR:C8_BR:C9_BR:C1_GR:C2_GR:C3_GR:C4_GR:C5_GR:C6_GR:C7_GR:C8_GR:C9_GR:SCPTOT:SCPTOT_G:SCUTOT:SCUTOT_G:STPTOT:STPTOT_G:STUTOT:STUTOT_G:OBPTOT:OBUTOT:OBPTOT_G:OBUTOT_G:MUPTOT:MUUTOT:MUPTOT_G:MUUTOT_G:BLC1:LVC1:HEC1:SPC1:LOC1:MEC1:LEC1:CPC1:AUC1:MUC1:BLC2:LVC2:HEC2:SPC2:LOC2:MEC2:LEC2:CPC2:AUC2:MUC2:BLC3:LVC3:HEC3:SPC3:LOC3:MEC3:LEC3:CPC3:AUC3:MUC3:BLC4:LVC4:HEC4:SPC4:LOC4:MEC4:LEC4:CPC4:AUC4:MUC4:BLC5:LVC5:HEC5:SPC5:LOC5:MEC5:LEC5:CPC5:AUC5:MUC5:BLC6:LVC6:HEC6:SPC6:LOC6:MEC6:LEC6:CPC6:AUC6:MUC6:BLC7:LVC7:HEC7:SPC7:LOC7:MEC7:LEC7:CPC7:AUC7:MUC7:BLC8:LVC8:HEC8:SPC8:LOC8:MEC8:LEC8:CPC8:AUC8:MUC8:TOTCLGD1G:TOTCLGD2G:TOTCLGD3G:TOTCLGD4G:TOTCLGD5G:TOTCLGD6G:TOTCLGD7G:TOTCLMI1G:TOTCLMI2G:TOTCLMI3G:TOTCLMI4G:TOTCLMI5G:TOTCLMI6G:TOTCLMI7G:TOTCLMJ1G:TOTCLMJ2G:TOTCLMJ3G:TOTCLMJ4G:TOTCLMJ5G:TOTCLMJ6G:TOTCLMJ7G:TOTCLOT1G:TOTCLOT2G:TOTCLOT3G:TOTCLOT4G:TOTCLOT5G:TOTCLOT6G:TOTCLOT7G:TCHBS1:TCHBS2:TCHBS3:TCHBS4:TCHBS5:TCHBS6:TCHBS7:TCHSEC1:TCHSEC2:TCHSEC3:TCHSEC4:TCHSEC5:TCHSEC6:TCHSEC7:TCHHS1:TCHHS2:TCHHS3:TCHHS4:TCHHS5:TCHHS6:TCHHS7:TCHGD1:TCHGD2:TCHGD3:TCHGD4:TCHGD5:TCHGD6:TCHGD7:TCHPG1:TCHPG2:TCHPG3:TCHPG4:TCHPG5:TCHPG6:TCHPG7:TCHMD1:TCHMD2:TCHMD3:TCHMD4:TCHMD5:TCHMD6:TCHMD7:TCHPD1:TCHPD2:TCHPD3:TCHPD4:TCHPD5:TCHPD6:TCHPD7:TCHNR1:TCHNR2:TCHNR3:TCHNR4:TCHNR5:TCHNR6:TCHNR7:TCHCON1:TCHCON2:TCHCON3:TCHCON4:TCHCON5:TCHCON67:TCHCON8:TCHCON9:TCHRM1:TCHRM2:TCHRM3:TCHRM4:TCHRM5:TCHRM6:TCHRM7:TCHRF1:TCHRF2:TCHRF3:TCHRF4:TCHRF5:TCHRF6:TCHRF7:TCHRN1:TCHRN2:TCHRN3:TCHRN4:TCHRN5:TCHRN6:TCHRN7:TCHCM1:TCHCM2:TCHCM3:TCHCM4:TCHCM5:TCHCM6:TCHCM7:TCHCF1:TCHCF2:TCHCF3:TCHCF4:TCHCF5:TCHCF6:TCHCF7:TCHCN1:TCHCN2:TCHCN3:TCHCN4:TCHCN5:TCHCN6:TCHCN7:TLM_R1:TLM_R2:TLM_R3:TLM_R4:TLM_R5:TLM_R6:TLM_R7:TLME:TLMR:CONTIE:CONTIR:CONTI_R1:CONTI_R2:CONTI_R3:CONTI_R4:CONTI_R5:CONTI_R6:CONTI_R7:PIDAY30:PIDAYSCH:UIDAY35:UIDAYSCH:M1:M2:M3:M4:M5:ENRE11:ENRE12:ENRE13:ENRE14:ENRE15:ENRE16:ENRE17:ENRE21:ENRE22:ENRE23:ENRE24:ENRE25:ENRE26:ENRE27:ENRE31:ENRE32:ENRE33:ENRE34:ENRE35:ENRE36:ENRE37:ENRE41:ENRE42:ENRE43:ENRE44:ENRE45:ENRE46:ENRE47:ENRE51:ENRE52:ENRE53:ENRE54:ENRE55:ENRE56:ENRE57:TCH_5556M:TCH_5556F:TCH_5556T:TCH_5758M:TCH_5758F:TCH_5758T:TCH_5960M:TCH_5960F:TCH_5960T:PPTR30:UPTR35:PSCR30:USCR35:NOTCH_ASS:TCHINV:PTXT_ALL:PTXT_SC:PTXT_ST:PUNI_ALL:PUNI_SC:PUNI_ST:UTXT_ALL:UTXT_SC:UTXT_ST:UUNI_ALL:UUNI_SC:UUNI_ST:TOTCLS1G:TOTCLS2G:TOTCLS3G:TOTCLS4G:TOTCLS5G:TOTCLS6G:TOTCLS7G:,string:numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Hotel Reviews , Datafiniti , www.kaggle.com/datafiniti/hotel-reviews , Mon May 29 2017 21:39:29 GMT+0530 (IST) , A small sample of 1000 hotels and their online reviews. ,822, hotels- linguistics- internet- ,About This Data This is a sample data set of hotel reviews available through Datafiniti's Business Database.  The sample data set covers 1000 hotels from this database.  The full database includes virtually every hotel in the world. Data includes hotel name location review date text title username and rating. A similar data set was used to compare hotel reviews on a state-by-state basis. What You Can Do with This Data Use this data set to experiment with sentiment scoring and other natural language processing techniques.  The review data lets you correlate keywords in the review text with ratings. Data Schema A full schema for the data is available in our support documentation. About Datafiniti Datafiniti provides instant access to web data.  We compile data from thousands of websites to create standardized databases of business product and property information.  Learn more. Want More? If you're interested in more data like this please contact us.,address:categories:city:country:latitude:longitude:name:postalCode:province:reviews.date:reviews.dateAdded:reviews.doRecommend:reviews.id:reviews.rating:reviews.text:reviews.title:reviews.userCity:reviews.username:reviews.userProvince:,string:string:string:string:numeric:numeric:string:numeric:string:dateTime:dateTime:string:string:numeric:string:string:string:string:string:,
Possible Asteroid Impacts with Earth , NASA , www.kaggle.com/nasa/asteroid-impacts , Sat Feb 11 2017 01:44:33 GMT+0530 (IST) , Name orbit and year range for impacts predicted by Sentry system ,648, astronomy- space- ,Context An asteroid's orbit is computed by finding the elliptical path about the sun that best fits the available observations of the object. That is the object's computed path about the sun is adjusted until the predictions of where the asteroid should have appeared in the sky at several observed times match the positions where the object was actually observed to be at those same times. As more and more observations are used to further improve an object's orbit we become more and more confident in our knowledge of where the object will be in the future. When the discovery of a new near Earth asteroid is announced by the Minor Planet Center Sentry automatically prioritizes the object for an impact risk analysis. If the prioritization analysis indicates that the asteroid cannot pass near the Earth or that its orbit is very well determined the computationally intensive nonlinear search for potential impacts is not pursued. If on the other hand a search is deemed necessary then the object is added to a queue of objects awaiting analysis. Its position in the queue is determined by the estimated likelihood that potential impacts may be found. Content Sentry is a highly automated collision monitoring system that continually scans the most current asteroid catalog for possibilities of future impact with Earth over the next 100 years. This dataset includes the Sentry system's list of possible asteroid impacts with Earth and their probability in addition to a list of all known near Earth asteroids and their characteristics. Acknowledgements The asteroid orbit and impact risk data was collected by NASA's Near Earth Object Program at the Jet Propulsion Laboratory (California Institute of Technology). Inspiration During which year is Earth at the highest risk of an asteroid impact? How do asteroid impact predictions change over time? Which possible asteroid impact would be the most devastating given the asteroid's size and speed?,Object Name:Period Start:Period End:Possible Impacts:Cumulative Impact Probability:Asteroid Velocity:Asteroid Magnitude:Asteroid Diameter (km):Cumulative Palermo Scale:Maximum Palermo Scale:Maximum Torino Scale:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Chase Bank Branch Deposits 2010-2016 , Chase Bank , www.kaggle.com/chasebank/bank-deposits , Wed Mar 15 2017 22:06:19 GMT+0530 (IST) , Where did Chase Bank customers deposit the most money last year? ,767, finance- ,Content This dataset includes a record for every branch of Chase Bank in the United States including the branch's name and number date established as a bank office and (if applicable) acquired by JP Morgan Chase physical location as street address city state zip and latitude and longitude coordinates and the amount deposited at the branch (or the institution for the bank's main office) between July 1 and June 30 2016 in US dollars. Acknowledgements The location data was scraped from the Chase Bank website. The deposit data was compiled from the Federal Deposit Insurance Corporation's annual Summary of Deposits reports. Inspiration Where did Chase Bank customers deposit the most money last year? Which bank branch has seen the most growth in deposits? How did the bank network of branch locations grow over the past century? What city has the most bank branches per capita?,Institution Name:Main Office:Branch Name:Branch Number:Established Date:Acquired Date:Street Address:City:County:State:Zipcode:Latitude:Longitude:2010 Deposits:2011 Deposits:2012 Deposits:2013 Deposits:2014 Deposits:2015 Deposits:2016 Deposits:,string:numeric:string:numeric:dateTime:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
California Kindergarten Immunization Rates , Brian Roach , www.kaggle.com/broach/california-kindergarten-immunization-rates , Wed Aug 30 2017 09:58:58 GMT+0530 (IST) , How many new students contributed to “herd immunity” between 2000 and 2015? ,99, diseases- public health- ,"Context Vaccinations provide people the ability to develop immunity to particular diseases.  When the majority of a population is vaccinated “herd immunity” protects those who have not been vaccinated by blocking the spread of these diseases.  A medical research paper published by The Lancet in 1998 suggested an association between the Measles/Mumps/Rubella (MMR) vaccine and Autism spectrum disorders.  The paper was later fully-retracted due controversy surrounding the lead author who had financial conflicts of interest and allegedly manipulated the study data.  However it generated worldwide concern over the safety of MMR and other types of vaccines including Diphtheria/Tetanus/Pertussis (DTP). In California by 2010 the growing trend for parents to opt out of having their children receive vaccines over the following decade coincided with the largest Pertussis outbreak in more than 60 years.  Reduced vaccination frequency was also linked to a high-profile measles outbreak in 2014 that began at Disneyland.  The resulting California state legislation (Senate Bill 277) signed June 2015 made it much more difficult for parents to opt out of vaccinations for their children.  The data set will allow you to explore individual public and private school vaccination rates of incoming Kindergarten students for the 2000 to 2014 school years. Content The data are records for every school with ten or more students reporting the number of incoming Kindergarteners who provided either proof of immunization personal beliefs exemption (PBE) or permanent medical exemption (PME).  Annual records for the 2000-2001 through 2014-2015 school years have been formatted and combined.  Common variables in these annual data sets included in the merged file are the number of students school name school county the number of PBEs PMEs and number of students vaccinated for  Diphtheria/Tetanus/Pertussis (DTP)   Polio  Measles/Mumps/Rubella (MMR)  One additional file contains 5 years of county-level Pertussis case numbers and rates.  Another additional data file contains the number of infant Pertussis cases for infants under three months old for each county in California between 2014-2015. Geographic data are available in a file based on scripted geocode calls using the ggmap R package to find latitude and longitude data using the school names and county names.  Not all calls returned a valid coordinate so additional indicator variables in this file indicate the quality of the match.  The isSchool indicator variable is 1 if the geocode search meta data included ""school"" and the countyMatch indicator is 1 if the latitude and longitude coordinates are contained within the appropriate county in CA.  References  Retracted Lancet Research Article  Report on 2010 Pertussis Outbreak  Acknowledgements Individual data files and detailed annual reports for every school year in this data set are provided by the California Department of Public Health (CDPH).  Individual schools and licensed child care facilities are required to report immunization information to CDPH every year to maintain compliance with the California Health and Safety Code.  Additional details as well as child care and 7th grade data files can be found on the CDPH website https//www.cdph.ca.gov/programs/immunize/Pages/ImmunizationLevels.aspx County level case data were pulled from the following report https//archive.cdph.ca.gov/programs/immunize/Documents/Pertussis_Report_1-7-2015.pdf Infant Pertussis data were reported to CDPH as of 2/10/2016.  Additional Pertussis reports can be found here https//www.cdph.ca.gov/programs/immunize/Pages/PertussisSummaryReports.aspx Inspiration While the Disneyland measles outbreak received much media attention Pertussis outbreaks in California present great health risks to infants and the elderly.  Can you predict which counties and schools are at greatest risk for outbreaks and/or quantify the association between vaccination rates and the number infant Pertussis cases?",longitude:latitude:school_code:countyMatch:isSchool:,numeric:numeric:numeric:boolean:boolean:,
Project Tycho: Contagious Diseases , University of Pittsburgh , www.kaggle.com/pitt/contagious-diseases , Thu Feb 02 2017 23:26:33 GMT+0530 (IST) , Weekly case reports for polio smallpox and other diseases in the United States ,626, diseases- human medicine- ,Context The Project Tycho database was named after the Danish nobleman Tycho Brahe who is known for his detailed astronomical and planetary observations. Tycho was not able to use all of his data for breakthrough discoveries but his assistant Johannes Kepler used Tycho's data to derive the laws of planetary motion. Similarly this project aims to advance the availablity of large scale public health data to the worldwide community to accelerate advancements in scientific discovery and technological progress. Content The Project Tycho database (level one) includes standardized counts at the state level for smallpox polio measles mumps rubella hepatitis A and whooping cough from weekly National Notifiable Disease Surveillance System (NNDSS) reports for the United States. The time period of data varies per disease somewhere between 1916 and 2010. The records include cases and incidence rates per 100000 people based on historical population estimates. These data have been used by investigators at the University of Pittsburgh to estimate the impact of vaccination programs in the United States recently published in the New England Journal of Medicine. Acknowledgements The Project Tycho database was digitized and standardized by a team at the University of Pittsburgh including Professor Wilbert van Panhuis MD PhD Professor John Grefenstette PhD and Dean Donald Burke MD.,week:state:state_name:disease:cases:incidence_per_capita:,numeric:string:string:string:numeric:numeric:,
E-Commerce Data , Carrie , www.kaggle.com/carrie1/ecommerce-data , Thu Aug 17 2017 08:14:30 GMT+0530 (IST) , Actual transactions from UK retailer ,839, ,"Context Typically e-commerce datasets are proprietary and consequently hard to find among publicly available data.  However The UCI Machine Learning Repository has made this dataset containing actual transactions from 2010 and 2011.  The dataset is maintained  on their site where it can be found by the title ""Online Retail"". Content ""This is a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers."" Acknowledgements Per the UCI Machine Learning Repository this data was made available by Dr Daqing Chen Director Public Analytics group. chend '@' lsbu.ac.uk School of Engineering London South Bank University London SE1 0AA UK. Image from stocksnap.io. Inspiration Analyses for this dataset could include time series clustering classification and more. ",InvoiceNo:StockCode:Description:Quantity:InvoiceDate:UnitPrice:CustomerID:Country:,numeric:numeric:string:numeric:dateTime:numeric:numeric:string:,
515K Hotel Reviews Data in Europe , Jason Liu , www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe , Tue Aug 22 2017 02:49:17 GMT+0530 (IST) , Can you make your trip more cozy by using data science? ,517, life- leisure- hotels- business- internet- ,Acknowledgements The data was scraped from Booking.com. All data in the file is publicly available to everyone already. Data is originally owned by Booking.com. Please contact me through my profile if you want to use this dataset somewhere else. Data Context This dataset contains 515000 customer reviews and scoring of 1493 luxury hotels across Europe. Meanwhile the geographical location of hotels are also provided for further analysis. Data Content The csv file contains 17 fields. The description of each field is as below  Hotel_Address Address of hotel.  Review_Date Date when reviewer posted the corresponding review. Average_Score Average Score of the hotel calculated based on the latest comment in the last year. Hotel_Name Name of Hotel Reviewer_Nationality Nationality of Reviewer Negative_Review Negative Review the reviewer gave to the hotel. If the reviewer does not give the negative review then it should be 'No Negative' Review_Total_Negative_Word_Counts Total number of words in the negative review. Positive_Review Positive Review the reviewer gave to the hotel. If the reviewer does not give the negative review then it should be 'No Positive' Review_Total_Positive_Word_Counts Total number of words in the positive review. Reviewer_Score Score the reviewer has given to the hotel based on his/her experience Total_Number_of_Reviews_Reviewer_Has_Given Number of Reviews the reviewers has given in the past. Total_Number_of_Reviews Total number of valid reviews the hotel has. Tags Tags reviewer gave the hotel. days_since_review Duration between the review date and scrape date. Additional_Number_of_Scoring There are also some guests who just made a scoring on the service rather than a review. This number indicates how many valid scores without review in there. lat Latitude of the hotel lng longtitude of the hotel  In order to keep the text data clean I removed unicode and punctuation in the text data and transform text into lower case. No other preprocessing was performed. Inspiration The dataset is large and informative I believe you can have a lot of fun with it! Let me put some ideas below to futher inspire kagglers!  Fit a regression model on reviews and score to see which words are more indicative to a higher/lower score Perform a sentiment analysis on the reviews Find correlation between reviewer's nationality and scores. Beautiful and informative visualization on the dataset. Clustering hotels based on reviews Simple recommendation engine to the guest who is fond of a special characteristic of hotel.  The idea is unlimited! Please have a look into data generate some ideas and leave a master kernel here! I am ready to upvote your ideas and kernels! Cheers!,Hotel_Address:Additional_Number_of_Scoring:Review_Date:Average_Score:Hotel_Name:Reviewer_Nationality:Negative_Review:Review_Total_Negative_Word_Counts:Total_Number_of_Reviews:Positive_Review:Review_Total_Positive_Word_Counts:Total_Number_of_Reviews_Reviewer_Has_Given:Reviewer_Score:Tags:days_since_review:lat:lng:,string:numeric:dateTime:numeric:string:string:string:numeric:numeric:string:numeric:numeric:numeric:string:string:numeric:numeric:,
Hong Kong Horse Racing Results 2014-17 Seasons , Lantana Camara , www.kaggle.com/lantanacamara/hong-kong-horse-racing , Fri Aug 18 2017 20:37:09 GMT+0530 (IST) , Race details include track time  and horse ,761, horse racing- ,Can You Predict The Result? Horse racing is one of the sport which involved many gambling activities. Million of people in the world tried to find their 'winning formula' in order to gain profit from betting. Since there are many factors which could affect the race result data analysis on horse racing became much interesting. Hong Kong horse racing is especially interesting due to the follow reasons  - The handicap system made the race more competitive  - Horse pool is small compared to other countries so that horses will meet their rivalries very often in the races  - Limited number of jockey/trainer  - Data are well managed by the official )   The Dataset The dataset contains the race result of 1561 local races throughout Hong Kong racing seasons 2014-16 and more information will be added into the dataset. The dataset is divided into two tables (which can be joined by race_id). Most of the column description can be found below with one extra piece of information finishing_position -  For special incident please refer to here So can you find any pattern for the winner under some condition? Did you spot out a winning strategy? (FYI betting on all horse equally will bring a loss of ~17.5% on average)  Which jockey/trainer is worth to follow? Don't wait and start the data analysis! You may find some of the kernels I created useful. Enjoy! And please remember to share your finding with the community! Acknowledgement The data are extracted from the website of The Hong Kong Jockey Club How to get started? In case you are not familiar with Hong Kong horse racing please see this notebook as a get started tutorial.,finishing_position:horse_number:horse_name:horse_id:jockey:trainer:actual_weight:declared_horse_weight:draw:length_behind_winner:running_position_1:running_position_2:running_position_3:running_position_4:finish_time:win_odds:running_position_5:running_position_6:race_id:,numeric:numeric:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:dateTime:numeric:string:string:string:,
Italy's Earthquakes , Gabriele Angeletti , www.kaggle.com/blackecho/italy-earthquakes , Tue Dec 06 2016 16:03:06 GMT+0530 (IST) , Data about the earthquakes that hit Italy between August and November 2016. ,501, earth sciences- ,Context This dataset contains data about the earthquakes that hit the center of Italy between August and November 2016. For some simple visualizations of this dataset you can checkout this post. Content The dataset contains events from 2016-08-24 to 2016-11-30. It's a single .csv file with the following header  TimeLatitudeLongitudeDepth/KmMagnitude  The dataset contains 8087 rows (8086 of data + 1 of header) Acknowledgements The dataset was collected from this real-time updated list from the Italian Earthquakes National Center. Inspiration I hope that someone in the kaggle community will find this dataset interesting to analyze and/or visualize.,Time:Latitude:Longitude:Depth/Km:Magnitude:,dateTime:numeric:numeric:numeric:numeric:,
Pizza restaurants and the pizza they sell , Datafiniti , www.kaggle.com/datafiniti/pizza-restaurants-and-the-pizza-they-sell , Sat Sep 30 2017 01:34:34 GMT+0530 (IST) , A random data set of restaurants that serve pizza and the prices of their pizza. ,225, food and drink- business- ,About this Data This is a sample data set of pizza restaurants and the pizzas they sell as pulled from Datafiniti's Business Data Set.  The data set covers over 3500 pizzas from multiple restaurants. The data shown here was used in the analysis The Price of a Slice. What You Can Do with this Data Use this data to discover insights into how pizzas are sold across the US. E.g.  In which cities or states are pizza restaurants most common? How do pizza prices vary across geographies? What words are most often used to describe pizzas?  About Datafiniti Datafiniti provides instant access to web data.  We compile data from thousands of websites to create standardized databases of business product and property information.  Learn more. Want More? If you're interested in more data like this please contact us.,id:address:categories:city:country:keys:latitude:longitude:menuPageURL:menus.amountMax:menus.amountMin:menus.currency:menus.dateSeen:menus.description:menus.name:name:postalCode:priceRangeCurrency:priceRangeMin:priceRangeMax:province:,string:string:string:string:string:string:numeric:numeric:string:numeric:numeric:string:dateTime:string:string:string:numeric:string:numeric:numeric:string:,
Gender Recognition by Voice , Kory Becker , www.kaggle.com/primaryobjects/voicegender , Fri Aug 26 2016 19:59:23 GMT+0530 (IST) , Identify a voice as male or female ,6382, gender- linguistics- ,Voice Gender Gender Recognition by Voice and Speech Analysis This database was created to identify a voice as male or female based upon acoustic properties of the voice and speech. The dataset consists of 3168 recorded voice samples collected from male and female speakers. The voice samples are pre-processed by acoustic analysis in R using the seewave and tuneR packages with an analyzed frequency range of 0hz-280hz (human vocal range). The Dataset The following acoustic properties of each voice are measured and included within the CSV  meanfreq mean frequency (in kHz) sd standard deviation of frequency median median frequency (in kHz) Q25 first quantile (in kHz) Q75 third quantile (in kHz) IQR interquantile range (in kHz) skew skewness (see note in specprop description) kurt kurtosis (see note in specprop description) sp.ent spectral entropy sfm spectral flatness mode mode frequency centroid frequency centroid (see specprop) peakf peak frequency (frequency with highest energy) meanfun average of fundamental frequency measured across acoustic signal minfun minimum fundamental frequency measured across acoustic signal maxfun maximum fundamental frequency measured across acoustic signal meandom average of dominant frequency measured across acoustic signal mindom minimum of dominant frequency measured across acoustic signal maxdom maximum of dominant frequency measured across acoustic signal dfrange range of dominant frequency measured across acoustic signal modindx modulation index. Calculated as the accumulated absolute difference between adjacent measurements of fundamental frequencies divided by the frequency range label male or female  Accuracy Baseline (always predict male) 50% / 50% Logistic Regression 97% / 98% CART 96% / 97% Random Forest 100% / 98% SVM 100% / 99% XGBoost 100% / 99% Research Questions An original analysis of the data-set can be found in the following article  Identifying the Gender of a Voice using Machine Learning The best model achieves 99% accuracy on the test set. According to a CART model it appears that looking at the mean fundamental frequency might be enough to accurately classify a voice. However some male voices use a higher frequency even though their resonance differs from female voices and may be incorrectly classified as female. To the human ear there is apparently more than simple frequency that determines a voice's gender. Questions  What other features differ between male and female voices? Can we find a difference in resonance between male and female voices? Can we identify falsetto from regular voices? (separate data-set likely needed for this) Are there other interesting features in the data?  CART Diagram  Mean fundamental frequency appears to be an indicator of voice gender with a threshold of 140hz separating male from female classifications. References The Harvard-Haskins Database of Regularly-Timed Speech Telecommunications & Signal Processing Laboratory (TSP) Speech Database at McGill University Home VoxForge Speech Corpus Home Festvox CMU_ARCTIC Speech Database at Carnegie Mellon University,,,
Loan  Data , Zhijin , www.kaggle.com/zhijinzhai/loandata , Tue Apr 11 2017 07:52:09 GMT+0530 (IST) , This dataset includes customers who have paid off their loans or not ,2150, finance- ,Context This data set includes customers who have paid off their loans who have been past due and put into collection without paying back their loan and interests and who have paid off only after they were put in collection. The financial product is a bullet loan that customers should pay off all of their loan debt in just one time by the end of the term instead of an installment schedule. Of course they could pay off earlier than their pay schedule. Content Loan_id A unique loan number assigned to each loan customers Loan_status Whether a loan is paid off in collection new customer yet to payoff or paid off after the collection efforts Principal   Basic principal loan amount at the origination terms   Can be weekly (7 days) biweekly and monthly payoff schedule Effective_date  When the loan got originated and took effects Due_date    Since it’s one-time payoff schedule each loan has one single due date Paidoff_time    The actual time a customer pays off the loan Pastdue_days    How many days a loan has been past due Age education gender  A customer’s basic demographic information,,,
Consumer Reviews of Amazon Products , Datafiniti , www.kaggle.com/datafiniti/consumer-reviews-of-amazon-products , Mon Aug 14 2017 21:42:48 GMT+0530 (IST) , Over 1500 reviews of Amazon products like Amazon Kindle Amazon Fire etc. ,389, ,About this Data This is a sample data set of consumer reviews for Amazon products like the Kindle the Fire and others.  The data set contains over 1500 reviews for these products and includes review text rating and basic product information. A similar data set was used to analyze reviews for Amazon products. What You Can Do with this Data Use this data to discover insights into consumer reviews and assist with machine learning models. E.g.  What is the average rating of each product? Over what time interval do reviews get posted for products?  Is there a burst of activity when the product launches or is it more spread out? Map the keywords in the review text against the review ratings to help train sentiment models.  About Datafiniti Datafiniti provides instant access to web data.  We compile data from thousands of websites to create standardized databases of business product and property information.  Learn more. Want More? If you're interested in more data like this please contact us.,id:asins:brand:categories:colors:dateAdded:dateUpdated:dimension:ean:keys:manufacturer:manufacturerNumber:name:prices:reviews.date:reviews.doRecommend:reviews.numHelpful:reviews.rating:reviews.sourceURLs:reviews.text:reviews.title:reviews.userCity:reviews.userProvince:reviews.username:sizes:upc:weight:,string:string:string:string:string:dateTime:dateTime:string:string:string:string:string:string:string:dateTime:string:numeric:numeric:string:string:string:string:string:string:string:string:string:,
NFL Draft Outcomes , Ron Graf , www.kaggle.com/ronaldjgrafjr/nfl-draft-outcomes , Mon Dec 19 2016 08:42:24 GMT+0530 (IST) , All players selected in the NFL Draft from 1985 to 2015 with outcome statistics ,671, american football- ,Context Consolidated draft data from http//www.pro-football-reference.com/ for all drafts from 1985 to 2015. Content Pro-Football-Reference AV Approximate Value is PFR's attempt to attach a single number to every player-season since 1960. Methodology can be found here http//www.pro-football-reference.com/blog/indexd961.html?page_id=8061  Player_Id    Pro Football Reference Player Id Year Draft Year Rnd  Draft Round Pick Draft Pick Tm   Team Player   Player first and last name Pos  Position unfiltered Position Standard    Position standardized to one of the following QB LB WR T DE RB DB DT C C G TE FB P LS K First4AV AV accumulated for this player's first four seasons Age  Age at time of draft To   Year of last season played AP1  # of first team all-pro selections PB   # of pro-bowl selections St   # of years as a primary starter in their primary position CarAV    Weighted Career AV - 100% of best season 95% of second best season 90% of third best season and so on DrAV AV accumulated for team that drafted this  player G    Games played Cmp  Pass completions Pass_Att Pass attempts Pass_Yds Yards gained by passing Pass_TD  Passing touchdowns Pass_Int Interceptions thrown Rush_Att Rushing attempts Rush_Yds Rushing yards gained Rush_TDs Rushing touchdowns Rec  Receptions Rec_Yds  Receiving yards gained Rec_Tds  Receiving touchdowns Tkl  Tackles Def_Int  Defensive interceptions Sk   Sacks College/Univ College/University attended by player  Acknowledgements http//www.pro-football-reference.com/,Player_Id:Year:Rnd:Pick:Tm:Player:Pos:Position Standard:First4AV:Age:To:AP1:PB:St:CarAV:DrAV:G:Cmp:Pass_Att:Pass_Yds:Pass_TD:Pass_Int:Rush_Att:Rush_Yds:Rush_TDs:Rec:Rec_Yds:Rec_Tds:Tkl:Def_Int:Sk:College/Univ::,string:numeric:numeric:numeric:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:,
The fight against malaria , toby jolly , www.kaggle.com/teajay/the-fight-against-malaria , Tue Aug 22 2017 22:25:29 GMT+0530 (IST) , Who is dying and being saved from this destructive disease? ,257, public health- ,Context The data here is from the Global Health Observatory (GHO) who provide data on malaria incidence death and prevention from around the world. I have also included malaria net distribution data the Against Malaria Foundation (AMF). The AMF has consistently been ranked as the most cost effective charity by charity evaluators Give Well - http//www.givewell.org/charities/top-charities Content GHO data is all in narrow format with variables for a country in a given year being found on different rows.  GHO data (there are a number or superfluous columns)  GHO (CODE) GHO (DISPLAY) - this is the variable being measured GHO (URL) PUBLISHSTATE (CODE) PUBLISHSTATE (DISPLAY) PUBLISHSTATE (URL) YEAR (CODE) YEAR (DISPLAY) YEAR (URL) REGION (CODE) REGION (DISPLAY) REGION (URL) COUNTRY (CODE) - can be used to join this data with the AMF data COUNTRY (DISPLAY) COUNTRY (URL) Display Value - this is the measured value Low - lower confidence interval High - higher confidence interval Comments  AMF distribution data  #_llins - total number of malaria nets distributed location - the specific area that received the nets within the target country country - the country in which the nets were distributed when - the period the distribution  by_whom - the organisation(s) which partnered with the AMF to perform the distribution country_code - the country's GHO country code (this will allow joining with the GHO data)  For the current version all data was downloaded 20-08-17 The GHO data covers the years from 2000 to 2015 (not all files have data in all years) The AMF data runs from 2006 - the present. The GHO data is taken as is from the csv (lists) available here http//apps.who.int/gho/data/node.main.A1362?lang=en The source of the AMF's distribution data is here https//www.againstmalaria.com/distributions.aspx - it was assembled into a single csv using Excel (mea culpa) Inspiration Malaria is one of the world's most devastating diseases not least because it largely affects some of the poorest people. Over the past 15 years malaria rates and mortality have dropped (http//www.who.int/malaria/media/world-malaria-report-2016/en/) but there is still a long way to go. Understanding the data is generally one of the most important steps in solving any large problem. I'm excited to see what the Kaggle community can find out about the global trends in malaria over this period and if we can find out anything about the impact of organisations such as the AMF.,#_llins:location:country:when:by_whom:country_code:,numeric:string:string:dateTime:string:string:,
Indian Premier League CSV dataset , HarshaVardhan , www.kaggle.com/harsha547/indian-premier-league-csv-dataset , Fri Dec 30 2016 04:38:28 GMT+0530 (IST) , 577 matches up to season 9 ,2314, cricket- ,Upon request from some users I am uploading  CSV Version. Yes There is already a dataset from manas However I thought this dataset is different than that one.which includes player metadata information about all the 11 players who participated in the match. Thoughts    ■ who are the valuable players for respective teams.   ■ who are more effective bowlers to bowl in the slog overs  is it spinners ?    ■ Dhoni's strike rate against left-arm spinners in last five overs Have fun with this dataset.  Files in the dataset include   1. Ball_by_Ball  Includes ball by ball details of all the 577 matches.   2. Match  Match metadata    3. Player  Player metadata    4. Player_Match  to know  who is the captain and keeper of the match  Includes every player who take part in match even If player haven't get a chance to either bat or bowl.    5. Season  Season wise details  Orange cap  Purple cap  Man_Of_The_Series    6. Team  Team Name   Diagram ,Match_Id:,numeric:,
London Borough Demographics , Jones , www.kaggle.com/marshald/london-boroughs , Sun Jun 04 2017 19:15:03 GMT+0530 (IST) , Analyze profiles of London's boroughs ,144, cities- demographics- ,Content The London boroughs profiles Data about demography diversity labour market economy community safety housing environment transport children health and governance Acknowledgements Thanks for taking your time to look at this data and thanks for any suggestions. Inspiration I am new to data analysis and I would like some suggestions on how to analyse this dataset and possibly create a visualasation or predictive analysis.,"Code:New code:Area name:Inner/ Outer London:GLA Population Estimate 2016:GLA Household Estimate 2016:Inland Area (Hectares):Population density (per hectare) 2016:Average Age, 2016:Proportion of population aged 0-15, 2016:Proportion of population of working-age, 2016:Proportion of population aged 65 and over, 2016:Net internal migration (2014):Net international migration (2014):Net natural change (2014):% of resident population born abroad (2014):Largest migrant population by country of birth (2011):% of largest migrant population (2011):Second largest migrant population by country of birth (2011):% of second largest migrant population (2011):Third largest migrant population by country of birth (2011):% of third largest migrant population (2011):% of population from BAME groups (2016):% people aged 3+ whose main language is not English (2011 Census):Overseas nationals entering the UK (NINo), (2014/15):New migrant (NINo) rates, (2014/15):Largest migrant population arrived during 2014/15:Second largest migrant population arrived during 2014/15:Third largest migrant population arrived during 2014/15:Employment rate (%) (2015):Male employment rate (2015):Female employment rate (2015):Unemployment rate (2015):Youth Unemployment (claimant) rate 18-24 (Dec-14):Proportion of 16-18 year olds who are NEET (%) (2014):Proportion of the working-age population who claim out-of-work benefits (%) (Aug-2015):% working-age with a disability (2015):Proportion of working age people with no qualifications (%) 2015:Proportion of working age with degree or equivalent and above (%) 2015:Gross Annual Pay, (2015):Gross Annual Pay - Male (2015):Gross Annual Pay - Female (2015):Modelled Household median income estimates 2012/13:% adults that volunteered in past 12 months (2010/11 to 2012/13):Number of jobs by workplace (2014):% of employment that is in public sector (2014):Jobs Density, 2014:Number of active businesses, 2014:Two-year business survival rates (started in 2012):Crime rates per thousand population 2014/15:Fires per thousand population (2014):Ambulance incidents per hundred population (2014):Median House Price, 2014:Average Band D Council Tax charge (£), 2015/16:New Homes (net) 2014/15 (provisional):Homes Owned outright, (2014) %:Being bought with mortgage or loan, (2014) %:Rented from Local Authority or Housing Association, (2014) %:Rented from Private landlord, (2014) %:% of area that is Greenspace, 2005:Total carbon emissions (2013):Household Waste Recycling Rate, 2014/15:Number of cars, (2011 Census):Number of cars per household, (2011 Census):% of adults who cycle at least once per month, 2013/14:Average Public Transport Accessibility score, 2014:Achievement of 5 or more A*- C grades at GCSE or equivalent including English and Maths, 2013/14:Rates of Children Looked After (2015):% of pupils whose first language is not English (2015):% children living in out-of-work households (2014):Male life expectancy, (2012-14):Female life expectancy, (2012-14):Teenage conception rate (2014):Life satisfaction score 2011-14 (out of 10):Worthwhileness score 2011-14 (out of 10):Happiness score 2011-14 (out of 10):Anxiety score 2011-14 (out of 10):Childhood Obesity Prevalance (%) 2014/15:People aged 17+ with diabetes (%):Mortality rate from causes considered preventable 2012/14:Political control in council:Proportion of seats won by Conservatives in 2014 election:Proportion of seats won by Labour in 2014 election:Proportion of seats won by Lib Dems in 2014 election:Turnout at 2014 local elections:",string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:string:numeric:string:numeric:numeric:numeric:numeric:numeric:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:,
Public Transport in Zurich , LAdams , www.kaggle.com/laa283/zurich-public-transport , Mon Mar 20 2017 03:45:38 GMT+0530 (IST) , Public transport routes and schedules for the city of Zurich ,133, transport- ,Source The data was collected and organized by https//data.stadt-zuerich.ch/ specifically under the link https//data.stadt-zuerich.ch/dataset/vbz-fahrzeiten-ogd Data The data table is a variance analysis of the times certain trams and busses should have departed and when they actually departed. Interesting Questions / Challenges  What is the fastest way between Klusplatz and Oerlikon at different times of day? What is the most punctual tram stop in Zurich? ,linie:richtung:betriebsdatum:fahrzeug:kurs:seq_von:halt_diva_von:halt_punkt_diva_von:halt_kurz_von1:datum_von:soll_an_von:ist_an_von:soll_ab_von:ist_ab_von:seq_nach:halt_diva_nach:halt_punkt_diva_nach:halt_kurz_nach1:datum_nach:soll_an_nach:ist_an_nach1:soll_ab_nach:ist_ab_nach:fahrt_id:fahrweg_id:fw_no:fw_typ:fw_kurz:fw_lang:umlauf_von:halt_id_von:halt_id_nach:halt_punkt_id_von:halt_punkt_id_nach:,numeric:numeric:dateTime:numeric:numeric:numeric:numeric:numeric:string:dateTime:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:dateTime:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:,
Caravan Insurance Challenge , UCI Machine Learning , www.kaggle.com/uciml/caravan-insurance-challenge , Mon Nov 28 2016 08:32:55 GMT+0530 (IST) , Identify potential purchasers of caravan insurance policies ,750, finance- automobiles- ,This data set used in the CoIL 2000 Challenge contains information on customers of an insurance company. The data consists of 86 variables and includes product usage data and socio-demographic data derived from zip area codes. The data was collected to answer the following question Can you predict who would be interested in buying a caravan insurance policy and give an explanation why? Acknowledgements DISCLAIMER This dataset is owned and supplied by the Dutch datamining company Sentient Machine Research and is based on real world business data. You are allowed to use this dataset and accompanying information for non commercial research and education purposes only. It is explicitly not allowed to use this dataset for commercial education or demonstration purposes. For any other use please contact Peter van der Putten info@smr.nl. This dataset has been used in the CoIL Challenge 2000 datamining competition. For papers describing results on this dataset see the TIC 2000 homepage http//www.wi.leidenuniv.nl/~putten/library/cc2000/ Please cite/acknowledge P. van der Putten and M. van Someren (eds) . CoIL Challenge 2000 The Insurance Company Case. Published by Sentient Machine Research Amsterdam. Also a Leiden Institute of Advanced Computer Science Technical Report 2000-09. June 22 2000. The Data Originally this dataset was broken into two parts the training set and the evaluation set. As this was a competition the responses to the evaluation set were not given as part of the original release; they were however released after the end of the competition in a separate file. This dataset contains all three of these files combined into one. The field ORIGIN in the caravan-insurance-challenge.csv file has the values train and test corresponding to the training and evaluation sets respectively. To simulate the original challenge you can ignore the test rows and test your model's prediction on those observations once you've trained only on the training set. Each observation corresponds to a postal code. Variables beginning with M refer to demographic statistics of the postal code while variables beginning with P and A (as well as CARAVAN the target variable) refer to product ownership and insurance statistics in the postal code. The data file contains the following fields  ORIGIN train or test as described above MOSTYPE Customer Subtype; see L0 MAANTHUI Number of houses 1 - 10 MGEMOMV Avg size household 1 - 6 MGEMLEEF Avg age; see L1 MOSHOOFD Customer main type;  see L2  ** Percentages in each group per postal code (see L3)**  MGODRK Roman catholic MGODPR Protestant ... MGODOV Other religion MGODGE No religion MRELGE Married MRELSA Living together MRELOV Other relation MFALLEEN Singles MFGEKIND Household without children MFWEKIND Household with children MOPLHOOG High level education MOPLMIDD Medium level education MOPLLAAG Lower level education MBERHOOG High status MBERZELF Entrepreneur MBERBOER Farmer MBERMIDD Middle management MBERARBG Skilled labourers MBERARBO Unskilled labourers MSKA Social class A MSKB1 Social class B1 MSKB2 Social class B2 MSKC Social class C MSKD Social class D MHHUUR Rented house MHKOOP Home owners MAUT1 1 car MAUT2 2 cars MAUT0 No car MZFONDS National Health Service MZPART Private health insurance MINKM30 Income < 30.000 MINK3045 Income 30-45.000 MINK4575 Income 45-75.000 MINK7512 Income 75-122.000 MINK123M Income >123.000 MINKGEM Average income MKOOPKLA Purchasing power class  ** Total number of variable in postal code (see L4)**  PWAPART Contribution private third party insurance PWABEDR Contribution third party insurance (firms) ... PWALAND Contribution third party insurane (agriculture) PPERSAUT Contribution car policies PBESAUT Contribution delivery van policies PMOTSCO Contribution motorcycle/scooter policies PVRAAUT Contribution lorry policies PAANHANG Contribution trailer policies PTRACTOR Contribution tractor policies PWERKT Contribution agricultural machines policies PBROM Contribution moped policies PLEVEN Contribution life insurances PPERSONG Contribution private accident insurance policies PGEZONG Contribution family accidents insurance policies PWAOREG Contribution disability insurance policies PBRAND Contribution fire policies PZEILPL Contribution surfboard policies PPLEZIER Contribution boat policies PFIETS Contribution bicycle policies PINBOED Contribution property insurance policies PBYSTAND Contribution social security insurance policies AWAPART Number of private third party insurance 1 - 12 AWABEDR Number of third party insurance (firms) ... AWALAND Number of third party insurance (agriculture) APERSAUT Number of car policies ABESAUT Number of delivery van policies AMOTSCO Number of motorcycle/scooter policies AVRAAUT Number of lorry policies AAANHANG Number of trailer policies ATRACTOR Number of tractor policies AWERKT Number of agricultural machines policies ABROM Number of moped policies ALEVEN Number of life insurances APERSONG Number of private accident insurance policies AGEZONG Number of family accidents insurance policies AWAOREG Number of disability insurance policies ABRAND Number of fire policies AZEILPL Number of surfboard policies APLEZIER Number of boat policies AFIETS Number of bicycle policies AINBOED Number of property insurance policies ABYSTAND Number of social security insurance policies CARAVAN Number of mobile home policies 0 - 1  Keys (L1 - L4) L0 Customer subtype  1 High Income expensive child 2 Very Important Provincials 3 High status seniors 4 Affluent senior apartments 5 Mixed seniors 6 Career and childcare 7 Dinki's (double income no kids) 8 Middle class families 9 Modern complete families 10 Stable family 11 Family starters 12 Affluent young families 13 Young all american family 14 Junior cosmopolitan 15 Senior cosmopolitans 16 Students in apartments 17 Fresh masters in the city 18 Single youth 19 Suburban youth 20 Etnically diverse 21 Young urban have-nots 22 Mixed apartment dwellers 23 Young and rising 24 Young low educated  25 Young seniors in the city 26 Own home elderly 27 Seniors in apartments 28 Residential elderly 29 Porchless seniors no front yard 30 Religious elderly singles 31 Low income catholics 32 Mixed seniors 33 Lower class large families 34 Large family employed child 35 Village families 36 Couples with teens 'Married with children' 37 Mixed small town dwellers 38 Traditional families 39 Large religous families 40 Large family farms 41 Mixed rurals  L1 average age keys 1 20-30 years 2 30-40 years 3 40-50 years 4 50-60 years 5 60-70 years 6 70-80 years L2 customer main type keys  1 Successful hedonists 2 Driven Growers 3 Average Family 4 Career Loners 5 Living well 6 Cruising Seniors 7 Retired and Religeous 8 Family with grown ups 9 Conservative families 10 Farmers  L3 percentage keys  0 0% 1 1 - 10% 2 11 - 23% 3 24 - 36% 4 37 - 49% 5 50 - 62% 6 63 - 75% 7 76 - 88% 8 89 - 99% 9 100%  L4 total number keys  0 0 1 1 - 49 2 50 - 99 3 100 - 199 4 200 - 499 5 500 - 999 6 1000 - 4999 7 5000 - 9999 8 10000 - 19999 9 >= 20000 ,,,
Rare Diseases on Facebook Groups , Natalia , www.kaggle.com/natt77/rare-diseases-on-facebook-groups , Tue Aug 08 2017 13:24:38 GMT+0530 (IST) , Help improve the quality of life of people with rare diseases ,136, diseases- epidemiology- internet- ,"Context This dataset was obtained from Facebook groups as part of my postgraduate thesis. The objective of the thesis was to extract posts from groups related to rare diseases and compare them with the Spanish association of rare diseases (FEDER). If you want to use this open dataset or the code you should cite our paper   Reguera N. Subirats L. Armayones M. Mining Facebook data of people with rare diseases. IEEE Computer-Based Medical Systems (IEEE CBMS 2017) Thessaloniki Greece 22-24th June 2017. Content The file contains information 3917 records from 5 Facebook groups and was extracted using Netvizz. The posts were generated since each group started (as far as 2009) until the 26/11/2016. The content is as follows type Facebook's post classification (e.g. photo status etc.) by either""post_page_pageid"" (post by page) or ""post_user_pageid"" (post by user); post_id id of the post; post_link direct link to the post; post_message text of the post; picture the picture scraped from any link included with the post; full_picture the picture scraped from any link included with the post (full size); link link URL (if the post points to external content); link_domain domain name of link; post_published publishing date post_published_unix publishing date as Unix timestamp (for easy conversion and ranking); post_published_sql publishing date in SQL format (some analysis tools prefer this); likes_count_fb Facebook provided like count for posts; comments_count_fb Facebook provided comment count for posts; reactions_count_fb Facebook provided reactions count for posts (includes likes); shares_count_fb Facebook provided share count for posts; engagement_fb sum of comment reaction and share counts; Acknowledgements I would like to thank my thesis directors who guided me through all the process Laia Subirats Maté and Manuel Armayones Ruiz. Inspiration During my research (code available on https//github.com/natt77/UOC---TFP) several insights were found on the relation between the information posted on the gropus and the information in FEDER. Text analytics was performed together with sentiment analysis. It would be interesting to deepen the analysis create models to predict engagement or any other action that can help improving the life quality of people with rare diseases.",type;by;post_id;post_link;post_message;picture;full_picture;link;link_domain;post_published;post_published_unix;post_published_sql;likes_count_fb;comments_count_fb;reactions_count_fb;shares_count_fb;engagement_fb:,string:,
Massachusetts Public Schools Data , Nigel Dalziel , www.kaggle.com/ndalziel/massachusetts-public-schools-data , Tue Aug 22 2017 07:55:43 GMT+0530 (IST) , Student body funding levels and outcomes (SAT MCAS APs college attendance) ,162, education- ,Data Sources This dataset compiles data from the following  Massachusetts Department of Education reports  Enrollment by Grade Enrollment by Selected Population Enrollment by Race/Gender Class Size by Gender and Selected Populations Teacher Salaries Per Pupil Expenditure Graduation Rates Graduates Attending Higher Ed Advanced Placement Participation Advanced Placement Performance SAT Performance MCAS Achievement Results Accountability Report  In each case the data is the latest available data as of August 2017.  Data Dictionary The data dictionary lists the report from which each field is sourced. It also includes the original field names - minor changes have been made to make the field names easier to understand. Data definitions can be found on the About the Data section of the MA DOE website. Questions  What contributes to differences in schools outcomes? Are there meaningful regional differences within MA? Which schools do well despite limited resources? ,"School Code:School Name:School Type:Function:Contact Name:Address 1:Address 2:Town:State:Zip:Phone:Fax:Grade:District Name:District Code:PK_Enrollment:K_Enrollment:1_Enrollment:2_Enrollment:3_Enrollment:4_Enrollment:5_Enrollment:6_Enrollment:7_Enrollment:8_Enrollment:9_Enrollment:10_Enrollment:11_Enrollment:12_Enrollment:SP_Enrollment:TOTAL_Enrollment:First Language Not English:% First Language Not English:English Language Learner:% English Language Learner:Students With Disabilities:% Students With Disabilities:High Needs:% High Needs:Economically Disadvantaged:% Economically Disadvantaged:% African American:% Asian:% Hispanic:% White:% Native American:% Native Hawaiian, Pacific Islander:% Multi-Race, Non-Hispanic:% Males:% Females:Total # of Classes:Average Class Size:Number of Students:Salary Totals:Average Salary:FTE Count:In-District Expenditures:Total In-district FTEs:Average In-District Expenditures per Pupil:Total Expenditures:Total Pupil FTEs:Average Expenditures per Pupil:# in Cohort:% Graduated:% Still in School:% Non-Grad Completers:% GED:% Dropped Out:% Permanently Excluded:High School Graduates (#):Attending Coll./Univ. (#):% Attending College:% Private Two-Year:% Private Four-Year:% Public Two-Year:% Public Four-Year:% MA Community College:% MA State University:% UMass:AP_Test Takers:AP_Tests Taken:AP_One Test:AP_Two Tests:AP_Three Tests:AP_Four Tests:AP_Five or More Tests:AP_Score=1:AP_Score=2:AP_Score=3:AP_Score=4:AP_Score=5:% AP_Score 1-2:% AP_Score 3-5:SAT_Tests Taken:Average SAT_Reading:Average SAT_Writing:Average SAT_Math:MCAS_3rdGrade_Math_P+A #:% MCAS_3rdGrade_Math_P+A:MCAS_3rdGrade_Math_A #:% MCAS_3rdGrade_Math_A:MCAS_3rdGrade_Math_P #:% MCAS_3rdGrade_Math_P:MCAS_3rdGrade_Math_NI #:% MCAS_3rdGrade_Math_NI:MCAS_3rdGrade_Math_W/F #:% MCAS_3rdGrade_Math_W/F:MCAS_3rdGrade_Math_Stud. Incl. #:MCAS_3rdGrade_Math_CPI:MCAS_3rdGrade_Math_SGP:MCAS_3rdGrade_Math_Incl. in SGP(#):MCAS_4thGrade_Math_P+A #:% MCAS_4thGrade_Math_P+A:MCAS_4thGrade_Math_A #:% MCAS_4thGrade_Math_A:MCAS_4thGrade_Math_P #:% MCAS_4thGrade_Math_P:MCAS_4thGrade_Math_NI #:% MCAS_4thGrade_Math_NI:MCAS_4thGrade_Math_W/F #:% MCAS_4thGrade_Math_W/F:MCAS_4thGrade_Math_Stud. Incl. #:MCAS_4thGrade_Math_CPI:MCAS_4thGrade_Math_SGP:MCAS_4thGrade_Math_Incl. in SGP(#):MCAS_5thGrade_Math_P+A #:% MCAS_5thGrade_Math_P+A:MCAS_5thGrade_Math_A #:% MCAS_5thGrade_Math_A:MCAS_5thGrade_Math_P #:% MCAS_5thGrade_Math_P:MCAS_5thGrade_Math_NI #:% MCAS_5thGrade_Math_NI:MCAS_5thGrade_Math_W/F #:% MCAS_5thGrade_Math_W/F:MCAS_5thGrade_Math_Stud. Incl. #:MCAS_5thGrade_Math_CPI:MCAS_5thGrade_Math_SGP:MCAS_5thGrade_Math_Incl. in SGP(#):MCAS_6thGrade_Math_P+A #:% MCAS_6thGrade_Math_P+A:MCAS_6thGrade_Math_A #:% MCAS_6thGrade_Math_A:MCAS_6thGrade_Math_P #:% MCAS_6thGrade_Math_P:MCAS_6thGrade_Math_NI #:% MCAS_6thGrade_Math_NI:MCAS_6thGrade_Math_W/F #:% MCAS_6thGrade_Math_W/F:MCAS_6thGrade_Math_Stud. Incl. #:MCAS_6thGrade_Math_CPI:MCAS_6thGrade_Math_SGP:MCAS_6thGrade_Math_Incl. in SGP(#):MCAS_7thGrade_Math_P+A #:% MCAS_7thGrade_Math_P+A:MCAS_7thGrade_Math_A #:% MCAS_7thGrade_Math_A:MCAS_7thGrade_Math_P #:% MCAS_7thGrade_Math_P:MCAS_7thGrade_Math_NI #:% MCAS_7thGrade_Math_NI:MCAS_7thGrade_Math_W/F #:% MCAS_7thGrade_Math_W/F:MCAS_7thGrade_Math_Stud. Incl. #:MCAS_7thGrade_Math_CPI:MCAS_7thGrade_Math_SGP:MCAS_7thGrade_Math_Incl. in SGP(#):MCAS_8thGrade_Math_P+A #:% MCAS_8thGrade_Math_P+A:MCAS_8thGrade_Math_A #:% MCAS_8thGrade_Math_A:MCAS_8thGrade_Math_P #:% MCAS_8thGrade_Math_P:MCAS_8thGrade_Math_NI #:% MCAS_8thGrade_Math_NI:MCAS_8thGrade_Math_W/F #:% MCAS_8thGrade_Math_W/F:MCAS_8thGrade_Math_Stud. Incl. #:MCAS_8thGrade_Math_CPI:MCAS_8thGrade_Math_SGP:MCAS_8thGrade_Math_Incl. in SGP(#):MCAS_10thGrade_Math_P+A #:% MCAS_10thGrade_Math_P+A:MCAS_10thGrade_Math_A #:% MCAS_10thGrade_Math_A:MCAS_10thGrade_Math_P #:% MCAS_10thGrade_Math_P:MCAS_10thGrade_Math_NI #:% MCAS_10thGrade_Math_NI:MCAS_10thGrade_Math_W/F #:% MCAS_10thGrade_Math_W/F:MCAS_10thGrade_Math_Stud. Incl. #:MCAS_10thGrade_Math_CPI:MCAS_10thGrade_Math_SGP:MCAS_10thGrade_Math_Incl. in SGP(#):MCAS_3rdGrade_English_P+A #:% MCAS_3rdGrade_English_P+A:MCAS_3rdGrade_English_A #:% MCAS_3rdGrade_English_A:MCAS_3rdGrade_English_P #:% MCAS_3rdGrade_English_P:MCAS_3rdGrade_English_NI #:% MCAS_3rdGrade_English_NI:MCAS_3rdGrade_English_W/F #:% MCAS_3rdGrade_English_W/F:MCAS_3rdGrade_English_Stud. Incl. #:MCAS_3rdGrade_English_CPI:MCAS_3rdGrade_English_SGP:MCAS_3rdGrade_English_Incl. in SGP(#):MCAS_4thGrade_English_P+A #:% MCAS_4thGrade_English_P+A:MCAS_4thGrade_English_A #:% MCAS_4thGrade_English_A:MCAS_4thGrade_English_P #:% MCAS_4thGrade_English_P:MCAS_4thGrade_English_NI #:% MCAS_4thGrade_English_NI:MCAS_4thGrade_English_W/F #:% MCAS_4thGrade_English_W/F:MCAS_4thGrade_English_Stud. Incl. #:MCAS_4thGrade_English_CPI:MCAS_4thGrade_English_SGP:MCAS_4thGrade_English_Incl. in SGP(#):MCAS_5thGrade_English_P+A #:% MCAS_5thGrade_English_P+A:MCAS_5thGrade_English_A #:% MCAS_5thGrade_English_A:MCAS_5thGrade_English_P #:% MCAS_5thGrade_English_P:MCAS_5thGrade_English_NI #:% MCAS_5thGrade_English_NI:MCAS_5thGrade_English_W/F #:% MCAS_5thGrade_English_W/F:MCAS_5thGrade_English_Stud. Incl. #:MCAS_5thGrade_English_CPI:MCAS_5thGrade_English_SGP:MCAS_5thGrade_English_Incl. in SGP(#):MCAS_6thGrade_English_P+A #:% MCAS_6thGrade_English_P+A:MCAS_6thGrade_English_A #:% MCAS_6thGrade_English_A:MCAS_6thGrade_English_P #:% MCAS_6thGrade_English_P:MCAS_6thGrade_English_NI #:% MCAS_6thGrade_English_NI:MCAS_6thGrade_English_W/F #:% MCAS_6thGrade_English_W/F:MCAS_6thGrade_English_Stud. Incl. #:MCAS_6thGrade_English_CPI:MCAS_6thGrade_English_SGP:MCAS_6thGrade_English_Incl. in SGP(#):MCAS_7thGrade_English_P+A #:% MCAS_7thGrade_English_P+A:MCAS_7thGrade_English_A #:% MCAS_7thGrade_English_A:MCAS_7thGrade_English_P #:% MCAS_7thGrade_English_P:MCAS_7thGrade_English_NI #:% MCAS_7thGrade_English_NI:MCAS_7thGrade_English_W/F #:% MCAS_7thGrade_English_W/F:MCAS_7thGrade_English_Stud. Incl. #:MCAS_7thGrade_English_CPI:MCAS_7thGrade_English_SGP:MCAS_7thGrade_English_Incl. in SGP(#):MCAS_8thGrade_English_P+A #:% MCAS_8thGrade_English_P+A:MCAS_8thGrade_English_A #:% MCAS_8thGrade_English_A:MCAS_8thGrade_English_P #:% MCAS_8thGrade_English_P:MCAS_8thGrade_English_NI #:% MCAS_8thGrade_English_NI:MCAS_8thGrade_English_W/F #:% MCAS_8thGrade_English_W/F:MCAS_8thGrade_English_Stud. Incl. #:MCAS_8thGrade_English_CPI:MCAS_8thGrade_English_SGP:MCAS_8thGrade_English_Incl. in SGP(#):MCAS_10thGrade_English_P+A #:% MCAS_10thGrade_English_P+A:MCAS_10thGrade_English_A #:% MCAS_10thGrade_English_A:MCAS_10thGrade_English_P #:% MCAS_10thGrade_English_P:MCAS_10thGrade_English_NI #:% MCAS_10thGrade_English_NI:MCAS_10thGrade_English_W/F #:% MCAS_10thGrade_English_W/F:MCAS_10thGrade_English_Stud. Incl. #:MCAS_10thGrade_English_CPI:MCAS_10thGrade_English_SGP:MCAS_10thGrade_English_Incl. in SGP(#):Accountability and Assistance Level:Accountability and Assistance Description:School Accountability Percentile (1-99):Progress and Performance Index (PPI) - All Students:Progress and Performance Index (PPI) - High Needs Students:District_Accountability and Assistance Level:District_Accountability and Assistance Description:District_Progress and Performance Index (PPI) - All Students:District_Progress and Performance Index (PPI) - High Needs Students:",numeric:string:string:string:string:string:string:string:string:numeric:string:string:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:numeric:numeric:numeric:string:string:numeric:numeric:,
Trump Administration Financial Disclosures , Aleksey Bilogur , www.kaggle.com/residentmario/trump-financial-disclosures , Sat Sep 30 2017 00:24:55 GMT+0530 (IST) , Financial data submitted by Trump federal appointees ,30, united states- government- money- politics- ,Context Before joining the federal executive administration new government appointees must submit amongst other things detailed information regarding their finances and previous job history. Such disclosure rules are in place in order to prevent conflicts of interest and are a fundamental part of the work done by government ethics commissions. This dataset is a condensed collection of information recovered from these forms for a selection of top Trump administration appointees. Content This dataset is split into five separate CSV files   names_and_job_titles.csv -- The names and job titles of appointees. Not all appointees are included in this dataset. jobs_before_joining_admin.csv -- Positions held by administration members immediately prior to their joining the federal government. clients_before_joining_admin.csv -- Former appointee clients before joining the federal government. income_sources_and_assets.csv -- All acknowledged and disclosed income sources and assets. The most important file. debts.csv -- Known appointee debt obligations. This record is incomplete. employee_agreements.csv -- Agreements that the appointee made as part of the conditions of their entering employment with the federal government.  Acknowledgements ProPublica The New York Times the Associated Press and others pooled their resources to collect and condense disclosure forms for many prominent members of the Trump administration. These were in turn collected into a public spreadsheet. This dataset is a further condensation of this work. Inspiration What can you discover about the finances and potential conflicts of interest of members of the Trump administration by looking at the raw government record?,:NAME:FEDERAL AGENCY:NAME OF FORMER CLIENT:LOCATION:SERVICES PROVIDED:,numeric:string:string:string:string:string:,
One Week of Global Feeds - News Dataset , Rohk , www.kaggle.com/therohk/global-news-week , Sat Sep 30 2017 02:04:06 GMT+0530 (IST) , 7 days of tracking 20K news publishers worldwide ,82, news agencies- historiography- linguistics- internet- ,"Context This news dataset captures a snapshot of one week of most of the new news content published online. Includes ~1.4 million articles generated by over 20000 news sources worldwide in 20 languages. Date Range 1 week period in August 2017 [ Thursday 24th to Wednesday 30th ] Prepared by Rohit Kulkarni Content Records 1398431 Fields description  publish_time - earliest known time of the url appearing online in yyyyMMddHHmm format IST timezone feed_code - unique identifier for the publisher or domain source_url - url of the article headline_text - Headline of the article (UTF8 20 possible languages) Inspiration The sources include news sites government agencies tech journals blogs and wikipedia updates. The data has been collected by RSS feeds and by crawling other large news aggregators. There wasnt any downtime or internet outage during these 7 days; Apart from that no reason for picking this particular interval. Exploration Some Unix commands for basic exploration of the data. 2000 active feeds with more than 100 articles per week cat news-week-aug24.csv | cut -d"""" -f2 | sort | uniq -c | sort -n | tail -2000 Unique domains and their frequency in the dataset cat news-week-aug24.csv | cut -d"""" -f3 | cut -d""/"" -f3 | sort | uniq -c | sort -n",publish_time:feed_code:source_url:headline_text:,dateTime:string:string:string:,
Restaurant Data with Consumer Ratings , UCI Machine Learning , www.kaggle.com/uciml/restaurant-data-with-consumer-ratings , Thu Sep 28 2017 02:16:37 GMT+0530 (IST) , Data from a restaurant recommender prototype ,424, business- ,Context This dataset was used for a study where the task was to generate a top-n list of restaurants according to the consumer preferences and finding the significant features. Two approaches were tested a collaborative filter technique and a contextual approach (i) The collaborative filter technique used only one file i.e. rating_final.csv that comprises the user item and rating attributes.  (ii) The contextual approach generated the recommendations using the remaining eight data files. Content There are 9 data files and a README  and are grouped like this Restaurants  1 chefmozaccepts.csv 2 chefmozcuisine.csv 3 chefmozhours4.csv 4 chefmozparking.csv 5 geoplaces2.csv  Consumers  6 usercuisine.csv 7 userpayment.csv 8 userprofile.csv  User-Item-Rating  9 rating_final.csv  More detailed file descriptions can also be found in the README  1 chefmozaccepts.csv Instances 1314 Attributes 2 placeID Nominal Rpayment Nominal 12 2 chefmozcuisine.csv Instances 916 Attributes 2 placeID Nominal Rcuisine Nominal 59 3 chefmozhours4.csv Instances 2339 Attributes 3 placeID Nominal hours Nominal Range0000-2330 days Nominal 7  4 chefmozparking.csv Instances 702 Attributes 2 placeID Nominal parking_lot Nominal 7 5 geoplaces2.csv Instances 130 Attributes 21 placeID Nominal latitude Numeric longitude Numeric the_geom_meter Nominal (Geospatial) name Nominal address NominalMissing 27 city Nominal Missing 18 state Nominal Missing 18 country Nominal Missing 28 fax Numeric Missing 130 zip NominalMissing 74 alcohol Nominal Values 3  smoking_area Nominal 5  dress_code Nominal 3  accessibility Nominal 3  price Nominal 3  url Nominal Missing 116 Rambience Nominal 2 franchise Nominal 2  area Nominal 2 other_services Nominal 3 6 rating_final.csv Instances 1161 Attributes 5 userID Nominal placeID Nominal rating Numeric 3 food_rating Numeric 3  service_rating Numeric 3 7 usercuisine.csv Instances 330 Attributes 2 userID Nominal Rcuisine Nominal 103  8 userpayment.csv Instances 177 Attributes 2 userID Nominal Upayment Nominal 5  9 userprofile Instances 138 Attributes 19 userID Nominal latitude Numeric longitude Numeric the_geom_meter Nominal (Geospatial) smoker Nominal drink_level Nominal 3 dress_preferenceNominal 4 ambience Nominal 3 transport Nominal 3 marital_status Nominal 3 hijos Nominal 3 birth_year Nominal interest Nominal 5 personality Nominal 4 religion Nominal 5  activity Nominal 4 color Nominal 8  weight Numeric budget Nominal 3 height Numeric  Acknowledgements This dataset was originally downloaded from the UCI ML Repository UCI ML Creators  Rafael Ponce Medellín and Juan Gabriel González Serna rafaponce@cenidet.edu.mx gabriel@cenidet.edu.mx Department of Computer Science. National Center for Research and Technological Development CENIDET México Donors of database Blanca Vargas-Govea and Juan Gabriel González Serna blanca.vargas@cenidet.edu.mx/blanca.vg@gmail.com gabriel@cenidet.edu.mx Department of Computer Science. National Center for Research and Technological Development CENIDET México Inspiration Use this data to create a restaurant recommender or determine which restaurants a person is most likely to visit.,placeID:Rpayment:,numeric:string:,
eCommerce Item Data , cclark , www.kaggle.com/cclark/product-item-data , Thu Aug 18 2016 06:02:54 GMT+0530 (IST) , 500 SKUs and their descriptions. Great for content engine training! ,3836, business- ,500 actual SKUs from an outdoor apparel brand's product catalog. It's somewhat rare to get real item level data in a real-world format. Very useful for testing things like recommendation engines. In fact...maybe I'll publish some code along with this ),id:description:,numeric:string:,
Austin Crime Statistics , Jacob Boysen , www.kaggle.com/jboysen/austin-crime , Thu Aug 03 2017 23:56:08 GMT+0530 (IST) , 159k Crime Reports 2014-2016 ,99, crime- ,Context Crime in growing cities such as Austin changes with the population. This data covers individual crimes reported in Austin primarily 2014-2015. Content 159k rows of data on type of crime reported location by various attributes (lat/lon council district census tract) and time are included. Clearance status by Austin PD is also recorded where available. Acknowledgements Data was prepared from a txt file accessed via Google Cloud BigQuery Public Datasets. Image by Tobias Zils. Inspiration Are there any clear seasonal or hourly trends in certain crimes? Which crimes are most often cleared by Austin PD and which remain open? How long do clearances take?,address:census_tract:clearance_date:clearance_status:council_district_code:description:district:latitude:location:location_description:longitude:primary_type:timestamp:unique_key:x_coordinate:y_coordinate:year:zipcode:,string:numeric:dateTime:string:numeric:string:string:numeric:string:string:numeric:string:dateTime:numeric:numeric:numeric:numeric:numeric:,
Association of Tennis Professionals Matches , GMAdevs , www.kaggle.com/gmadevs/atp-matches-dataset , Tue Feb 07 2017 20:39:15 GMT+0530 (IST) , ATP tournament results from 2000 to 2017 ,945, tennis- ,Context A dataset of ATP matches including individual statistics. Content In these datasets there are individual csv files for ATP tournament from 2000 to 2017. The numbers in the last columns are absolute values using them you can calculate percentages. Dataset legend All the match statistics are in absolute number format you can convert to percentages using the total point number ace = absolute number of aces df = number of double faults svpt = total serve points 1stin = 1st serve in 1st won = points won on 1st serve 2ndwon = points won on 2nd serve SvGms = serve games bpSaved = break point saved bpFaced = break point faced  Acknowledgement Thanks to Jeff Sackmann for the excellent work. Be sure to visit his github profile https//github.com/JeffSackmann/tennis_atp Inspiration This dataset would be likely used to develop predictive modeling of tennis matches and to do statistic research. I'm planning to add historical odds and injuries data as soon as I have the time to get them.,tourney_id:tourney_name:surface:draw_size:tourney_level:tourney_date:match_num:winner_id:winner_seed:winner_entry:winner_name:winner_hand:winner_ht:winner_ioc:winner_age:winner_rank:winner_rank_points:loser_id:loser_seed:loser_entry:loser_name:loser_hand:loser_ht:loser_ioc:loser_age:loser_rank:loser_rank_points:score:best_of:round:minutes:w_ace:w_df:w_svpt:w_1stIn:w_1stWon:w_2ndWon:w_SvGms:w_bpSaved:w_bpFaced:l_ace:l_df:l_svpt:l_1stIn:l_1stWon:l_2ndWon:l_SvGms:l_bpSaved:l_bpFaced:,string:string:string:numeric:string:numeric:numeric:numeric:numeric:string:string:string:numeric:string:numeric:numeric:numeric:numeric:numeric:string:string:string:numeric:string:numeric:numeric:numeric:dateTime:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
The Academy Awards 1927-2015 , Academy of Motion Picture Arts and Sciences , www.kaggle.com/theacademy/academy-awards , Mon Feb 13 2017 23:00:48 GMT+0530 (IST) , What actors and films have received the most Oscars? ,1314, film- ,Context Each January the entertainment community and film fans around the world turn their attention to the Academy Awards. Interest and anticipation builds to a fevered pitch leading up to the Oscar telecast in February when hundreds of millions of movie lovers tune in to watch the glamorous ceremony and learn who will receive the highest honors in filmmaking. Achievements in up to 25 regular categories will be honored on February 26 2017 at the 89th Academy Awards presentation at the Dolby Theatre at Hollywood & Highland Center.  Content The Academy Awards Database contains the official record of past Academy Award winners and nominees. The data is complete through the 2015 (88th) Academy Awards presented on February 28 2016. Acknowledgements The awards data was scraped from the Official Academy Awards Database; nominees were listed with their name first and film following in some categories such as Best Actor/Actress and in the reverse for others. Inspiration Do the Academy Awards reflect the diversity of American films or are the #OscarsSoWhite? Which actor/actress has received the most awards overall or in a single year? Which film has received the most awards in a ceremony? Can you predict who will receive the 2016 awards?,Year:Ceremony:Award:Winner:Name:Film:,string:numeric:string:numeric:string:string:,
Internet Advertisements Data Set , UCI Machine Learning , www.kaggle.com/uciml/internet-advertisements-data-set , Fri Sep 01 2017 20:44:02 GMT+0530 (IST) , This dataset represents a set of possible advertisements on Internet pages ,251, ,"Context The task is to predict whether an image is an advertisement (""ad"") or not (""nonad""). Content There are 1559 columns in the data.Each row in the data represent one image which is tagged as ad or nonad in the last column.column 0 to 1557 represent the actual numerical attributes of the images Acknowledgements Lichman M. (2013). UCI Machine Learning Repository [http//archive.ics.uci.edu/ml]. Irvine CA University of California School of Information and Computer Science. Here is a BiBTeX citation as well @misc{Lichman2013  author = ""M. Lichman"" year = ""2013"" title = ""{UCI} Machine Learning Repository"" url = ""http//archive.ics.uci.edu/ml"" institution = ""University of California Irvine School of Information and Computer Sciences"" } https//archive.ics.uci.edu/ml/citation_policy.html",:0:1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:19:20:21:22:23:24:25:26:27:28:29:30:31:32:33:34:35:36:37:38:39:40:41:42:43:44:45:46:47:48:49:50:51:52:53:54:55:56:57:58:59:60:61:62:63:64:65:66:67:68:69:70:71:72:73:74:75:76:77:78:79:80:81:82:83:84:85:86:87:88:89:90:91:92:93:94:95:96:97:98:99:100:101:102:103:104:105:106:107:108:109:110:111:112:113:114:115:116:117:118:119:120:121:122:123:124:125:126:127:128:129:130:131:132:133:134:135:136:137:138:139:140:141:142:143:144:145:146:147:148:149:150:151:152:153:154:155:156:157:158:159:160:161:162:163:164:165:166:167:168:169:170:171:172:173:174:175:176:177:178:179:180:181:182:183:184:185:186:187:188:189:190:191:192:193:194:195:196:197:198:199:200:201:202:203:204:205:206:207:208:209:210:211:212:213:214:215:216:217:218:219:220:221:222:223:224:225:226:227:228:229:230:231:232:233:234:235:236:237:238:239:240:241:242:243:244:245:246:247:248:249:250:251:252:253:254:255:256:257:258:259:260:261:262:263:264:265:266:267:268:269:270:271:272:273:274:275:276:277:278:279:280:281:282:283:284:285:286:287:288:289:290:291:292:293:294:295:296:297:298:299:300:301:302:303:304:305:306:307:308:309:310:311:312:313:314:315:316:317:318:319:320:321:322:323:324:325:326:327:328:329:330:331:332:333:334:335:336:337:338:339:340:341:342:343:344:345:346:347:348:349:350:351:352:353:354:355:356:357:358:359:360:361:362:363:364:365:366:367:368:369:370:371:372:373:374:375:376:377:378:379:380:381:382:383:384:385:386:387:388:389:390:391:392:393:394:395:396:397:398:399:400:401:402:403:404:405:406:407:408:409:410:411:412:413:414:415:416:417:418:419:420:421:422:423:424:425:426:427:428:429:430:431:432:433:434:435:436:437:438:439:440:441:442:443:444:445:446:447:448:449:450:451:452:453:454:455:456:457:458:459:460:461:462:463:464:465:466:467:468:469:470:471:472:473:474:475:476:477:478:479:480:481:482:483:484:485:486:487:488:489:490:491:492:493:494:495:496:497:498:499:500:501:502:503:504:505:506:507:508:509:510:511:512:513:514:515:516:517:518:519:520:521:522:523:524:525:526:527:528:529:530:531:532:533:534:535:536:537:538:539:540:541:542:543:544:545:546:547:548:549:550:551:552:553:554:555:556:557:558:559:560:561:562:563:564:565:566:567:568:569:570:571:572:573:574:575:576:577:578:579:580:581:582:583:584:585:586:587:588:589:590:591:592:593:594:595:596:597:598:599:600:601:602:603:604:605:606:607:608:609:610:611:612:613:614:615:616:617:618:619:620:621:622:623:624:625:626:627:628:629:630:631:632:633:634:635:636:637:638:639:640:641:642:643:644:645:646:647:648:649:650:651:652:653:654:655:656:657:658:659:660:661:662:663:664:665:666:667:668:669:670:671:672:673:674:675:676:677:678:679:680:681:682:683:684:685:686:687:688:689:690:691:692:693:694:695:696:697:698:699:700:701:702:703:704:705:706:707:708:709:710:711:712:713:714:715:716:717:718:719:720:721:722:723:724:725:726:727:728:729:730:731:732:733:734:735:736:737:738:739:740:741:742:743:744:745:746:747:748:749:750:751:752:753:754:755:756:757:758:759:760:761:762:763:764:765:766:767:768:769:770:771:772:773:774:775:776:777:778:779:780:781:782:783:784:785:786:787:788:789:790:791:792:793:794:795:796:797:798:799:800:801:802:803:804:805:806:807:808:809:810:811:812:813:814:815:816:817:818:819:820:821:822:823:824:825:826:827:828:829:830:831:832:833:834:835:836:837:838:839:840:841:842:843:844:845:846:847:848:849:850:851:852:853:854:855:856:857:858:859:860:861:862:863:864:865:866:867:868:869:870:871:872:873:874:875:876:877:878:879:880:881:882:883:884:885:886:887:888:889:890:891:892:893:894:895:896:897:898:899:900:901:902:903:904:905:906:907:908:909:910:911:912:913:914:915:916:917:918:919:920:921:922:923:924:925:926:927:928:929:930:931:932:933:934:935:936:937:938:939:940:941:942:943:944:945:946:947:948:949:950:951:952:953:954:955:956:957:958:959:960:961:962:963:964:965:966:967:968:969:970:971:972:973:974:975:976:977:978:979:980:981:982:983:984:985:986:987:988:989:990:991:992:993:994:995:996:997:998:999:1000:1001:1002:1003:1004:1005:1006:1007:1008:1009:1010:1011:1012:1013:1014:1015:1016:1017:1018:1019:1020:1021:1022:1023:1024:1025:1026:1027:1028:1029:1030:1031:1032:1033:1034:1035:1036:1037:1038:1039:1040:1041:1042:1043:1044:1045:1046:1047:1048:1049:1050:1051:1052:1053:1054:1055:1056:1057:1058:1059:1060:1061:1062:1063:1064:1065:1066:1067:1068:1069:1070:1071:1072:1073:1074:1075:1076:1077:1078:1079:1080:1081:1082:1083:1084:1085:1086:1087:1088:1089:1090:1091:1092:1093:1094:1095:1096:1097:1098:1099:1100:1101:1102:1103:1104:1105:1106:1107:1108:1109:1110:1111:1112:1113:1114:1115:1116:1117:1118:1119:1120:1121:1122:1123:1124:1125:1126:1127:1128:1129:1130:1131:1132:1133:1134:1135:1136:1137:1138:1139:1140:1141:1142:1143:1144:1145:1146:1147:1148:1149:1150:1151:1152:1153:1154:1155:1156:1157:1158:1159:1160:1161:1162:1163:1164:1165:1166:1167:1168:1169:1170:1171:1172:1173:1174:1175:1176:1177:1178:1179:1180:1181:1182:1183:1184:1185:1186:1187:1188:1189:1190:1191:1192:1193:1194:1195:1196:1197:1198:1199:1200:1201:1202:1203:1204:1205:1206:1207:1208:1209:1210:1211:1212:1213:1214:1215:1216:1217:1218:1219:1220:1221:1222:1223:1224:1225:1226:1227:1228:1229:1230:1231:1232:1233:1234:1235:1236:1237:1238:1239:1240:1241:1242:1243:1244:1245:1246:1247:1248:1249:1250:1251:1252:1253:1254:1255:1256:1257:1258:1259:1260:1261:1262:1263:1264:1265:1266:1267:1268:1269:1270:1271:1272:1273:1274:1275:1276:1277:1278:1279:1280:1281:1282:1283:1284:1285:1286:1287:1288:1289:1290:1291:1292:1293:1294:1295:1296:1297:1298:1299:1300:1301:1302:1303:1304:1305:1306:1307:1308:1309:1310:1311:1312:1313:1314:1315:1316:1317:1318:1319:1320:1321:1322:1323:1324:1325:1326:1327:1328:1329:1330:1331:1332:1333:1334:1335:1336:1337:1338:1339:1340:1341:1342:1343:1344:1345:1346:1347:1348:1349:1350:1351:1352:1353:1354:1355:1356:1357:1358:1359:1360:1361:1362:1363:1364:1365:1366:1367:1368:1369:1370:1371:1372:1373:1374:1375:1376:1377:1378:1379:1380:1381:1382:1383:1384:1385:1386:1387:1388:1389:1390:1391:1392:1393:1394:1395:1396:1397:1398:1399:1400:1401:1402:1403:1404:1405:1406:1407:1408:1409:1410:1411:1412:1413:1414:1415:1416:1417:1418:1419:1420:1421:1422:1423:1424:1425:1426:1427:1428:1429:1430:1431:1432:1433:1434:1435:1436:1437:1438:1439:1440:1441:1442:1443:1444:1445:1446:1447:1448:1449:1450:1451:1452:1453:1454:1455:1456:1457:1458:1459:1460:1461:1462:1463:1464:1465:1466:1467:1468:1469:1470:1471:1472:1473:1474:1475:1476:1477:1478:1479:1480:1481:1482:1483:1484:1485:1486:1487:1488:1489:1490:1491:1492:1493:1494:1495:1496:1497:1498:1499:1500:1501:1502:1503:1504:1505:1506:1507:1508:1509:1510:1511:1512:1513:1514:1515:1516:1517:1518:1519:1520:1521:1522:1523:1524:1525:1526:1527:1528:1529:1530:1531:1532:1533:1534:1535:1536:1537:1538:1539:1540:1541:1542:1543:1544:1545:1546:1547:1548:1549:1550:1551:1552:1553:1554:1555:1556:1557:1558:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Weather data in New York City - 2016 , Mathijs Waegemakers , www.kaggle.com/mathijs/weather-data-in-new-york-city-2016 , Sun Sep 24 2017 23:36:20 GMT+0530 (IST) ," Added for the ""New York City Taxi Trip Duration"" challenge ",642, weather- ,Context As a former transportation student I know how the weather can influence traffic. Both the increase of traffic as well as the decrease of road conditions increases the travel time. Content Weather data collected from the National Weather Service. It contains the first six months of 2016 for a weather station in central park. It contains for each day the minimum temperature maximum temperature average temperature precipitation new snow fall and current snow depth. The temperature is measured in Fahrenheit and the depth is measured in inches. T means that there is a trace of precipitation. Acknowledgements The data was retrieved on 20th of July 2017 on the website http//w2.weather.gov/climate/xmacis.php?wfo=okx.,,,
Country Socioeconomic Status Scores: 1880-2010 , sdorius , www.kaggle.com/sdorius/globses , Tue Apr 18 2017 19:29:03 GMT+0530 (IST) , Population-weighted measures of SES ,245, demographics- economics- ,"This dataset contains estimates of the socioeconomic status (SES) position of each of 149 countries covering the period 1880-2010. Measures of SES which are in decades allow for a 130 year time-series analysis of the changing position of countries in the global status hierarchy. SES scores  are the average of each country’s income and education ranking and are reported as percentile rankings ranging from 1-99. As such they can be interpreted similarly to other percentile rankings such has high school standardized test scores. If country A has an SES score of 55 for example it indicates that 55 percent of the world’s people live in a country with a lower average income and education ranking than country A. ISO alpha and numeric country codes are included to allow users to merge these data with other variables such as those found in the World Bank’s World Development Indicators Database and the United Nations Common Database. See here for a working example of how the data might be used to better understand how the world came to look the way it does at least in terms of status position of countries.  VARIABLE DESCRIPTIONS UNID ISO numeric country code (used by the United Nations)  WBID ISO alpha country code (used by the World Bank)  SES Socioeconomic status score (percentile) based on GDP per capita and  educational attainment (n=174) country Short country name year Survey year SES Socioeconomic status score (1-99) for each of 174 countries  gdppc GDP per capita Single time-series (imputed) yrseduc Completed years of education in the adult (15+) population popshare Total population shares DATA SOURCES The dataset was compiled by Shawn Dorius (sdorius@iastate.edu) from a large number of data sources listed below. GDP per Capita 1.  Maddison Angus. 2004. 'The World Economy Historical Statistics'. Organization for Economic Co-operation and Development Paris. Maddison population data in 000s; GDP & GDP per capita data in (1990 Geary-Khamis dollars PPPs of currencies and average prices of commodities). Maddison data collected from http//www.ggdc.net/MADDISON/Historical_Statistics/horizontal-file_02-2010.xls.  2.  World Development Indicators Database Years of Education 1.  Morrisson and Murtin.2009. 'The Century of Education'. Journal of Human Capital(3)11-42. Data downloaded from http//www.fabricemurtin.com/ 2.  Cohen Daniel & Marcelo Cohen. 2007. 'Growth and human capital Good data good results' Journal of economic growth 12(1)51-76. Data downloaded from http//soto.iae-csic.org/Data.htm 3.  Barro Robert and Jong-Wha Lee 2013 ""A New Data Set of Educational Attainment in the World 1950-2010."" Journal of Development Economics vol 104 pp.184-198. Data downloaded from http//www.barrolee.com/  Total Population  1.  Maddison Angus. 2004. 'The World Economy Historical Statistics'. Organization for Economic Co-operation and Development Paris.  13.  2.  United Nations Population Division. 2009.",unid:wbid:country:year:SES:gdppc:yrseduc:popshare:,numeric:string:string:numeric:numeric:numeric:string:numeric:,
Chicago - Citywide Payroll Data , City of Chicago , www.kaggle.com/chicago/chicago-citywide-payroll-data , Wed Sep 13 2017 00:58:45 GMT+0530 (IST) , Salaries paid to Chicago employees ,85, cities- money- ,Context This dataset contains the name job title department and salary of every employee that was on the City of Chicago payroll at the time of capture in mid-2017. It provides a transparent lens into who gets paid how much and for what. Content This dataset provides columns for employee name the city department they work for their job title and various fields describing their compensation. Most employee salaries are covered by the Annual Salary field but some employees paid hourly are covered by a combination of Typical Hours and Hourly Rate fields. Acknowledgements This dataset is published as-is by the City of Chicago (here). Inspiration  How many people do the various city agencies employ and how much does each department spend on salary in total? What are the most numerous job titles in civic government employment? How do Chicago employee salaries compare against salaries of city employees in New York City? Is the difference more or less than the difference in cost of living between the two cities? ,Name:Job Titles:Department:Full or Part-Time:Salary or Hourly:Typical Hours:Annual Salary:Hourly Rate:,string:string:string:string:string:string:string:string:,
Bioassay Datasets , UCI Machine Learning , www.kaggle.com/uciml/bioassay-datasets , Thu Sep 07 2017 22:39:25 GMT+0530 (IST) , 21 assays from PubChem that measure compound activity ,51, biology- health sciences- scientific method- scientists- biotechnology- ,Context The drug-development process is time-consuming and expensive. In High-Throughput Screening (HTS) batches of compounds are tested against a biological target to test the compound's ability to bind to the target. Target's might be antibodies for example. If the compound binds to the target then it is active for that target and known as a hit.  Virtual screening is the computational or in silico screening of biological compounds and complements the HTS process. It is used to aid the selection of compounds for screening in HTS bioassays or for inclusion in a compound-screening library.  Drug discovery is the first stage of the drug-development process and involves finding compounds to test and screen against biological targets. This first stage is known as primary-screening and usually involves the screening of thousands of compounds.  This dataset is a collection of 21 bioassays (screens) that measure the activity of various compounds against different biological targets. Content Each bioassay is split into test and train files. Here are some descriptions of some of the assays compounds. The source unfortunately does not have descriptions for every assay. That's the nature of the beast for finding this kind data and was also pointed out in the original study. Primary screens  AID362 details the results of a primary screening bioassay for Formylpeptide Receptor Ligand Binding University from the New Mexico Center for Molecular Discovery. It is a relatively small dataset with 4279 compounds and with a ratio of 1 active to 70 inactive compounds (1.4% minority class). The compounds were selected on the basis of preliminary virtual screening of approximately 480000 drug-like small molecules from Chemical Diversity Laboratories.  AID604 is a primary screening bioassay for Rho kinase 2 inhibitors from the Scripps Research Institute Molecular Screening Center. The bioassay contains activity information of 59788 compounds with a ratio of 1 active compound to 281 inactive compounds (1.4%). 57546 of the compounds have known drug-like properties.  AID456 is a primary screen assay from the Burnham Center for Chemical Genomics for inhibition of TNFa induced VCAM-1 cell surface expression and consists of 9982 compounds with a ratio of 1 active compound to 368 inactive compounds (0.27% minority). The compounds have been selected for their known drug-like properties and 9431 meet the Rule of 5 [19].  AID688 is the result of a primary screen for Yeast eIF2B from the Penn Center for Molecular Discovery and contains activity information of 27198 compounds with a ratio of 1 active compound to 108 inactive compounds (0.91% minority). The screen is a reporter-gene assay and 25656 of the compounds have known drug-like properties.  AID373 is a primary screen from the Scripps Research Institute Molecular Screening Center for endothelial differentiation sphingolipid G-protein-coupled receptor 3. 59788 compounds were screened with a ratio of 1 active compound to 963 inactive compounds (0.1%). 57546 of the compounds screened had known drug-like properties.  AID746 is a primary screen from the Scripps Research Institute Molecular Screening Center for Mitogen-activated protein kinase. 59788 compounds were screened with a ratio of 1 active compound to 162 inactive compounds (0.61%). 57546 of the compounds screened had known drug-like properties.  AID687 is the result of a primary screen for coagulation factor XI from the Penn Center for Molecular Discovery and contains activity information of 33067 compounds with a ratio of 1 active compound to 350 inactive compounds (0.28% minority). 30353 of the compounds screened had known drug-like properties.   Primary and Confirmatory  AID604 (primary) with AID644 (confirmatory) AID746 (primary) with AID1284 (confirmatory) AID373 (primary) with AID439 (confirmatory) AID746 (primary) with AID721 (confirmatory)  Confirmatory  AID1608 is a different type of screening assay that was used to identify compounds that prevent HttQ103-induced cell death. National Institute of Neurological Disorders and Stroke Approved Drug Program. The compounds that prevent a release of a certain chemical into the growth medium are labelled as active and the remaining compounds are labelled as having inconclusive activity. AID1608 is a small dataset with 1033 compounds and a ratio of 1 active to 14 inconclusive compounds (6.58% minority class).  AID644 AID1284 AID439 AID721 AID1608 AID644 AID1284 AID439 AID721  Acknowledgements Original study https//www.ncbi.nlm.nih.gov/pmc/articles/PMC2820499/ Data downloaded form UCI ML repository Lichman M. (2013). UCI Machine Learning Repository [http//archive.ics.uci.edu/ml]. Irvine CA University of California School of Information and Computer Science. Inspiration Drug development is expensive. Use this virtual bio assay data to classify compounds as hits (active) against their biological targets.,ARC_01_ARC:ARC_02_ARC:ARC_03_ARC:ARC_04_ARC:ARC_05_ARC:ARC_06_ARC:ARC_07_ARC:ARC_01_POS:ARC_02_POS:ARC_03_POS:ARC_04_POS:ARC_05_POS:ARC_06_POS:ARC_07_POS:ARC_01_NEG:ARC_02_NEG:ARC_03_NEG:ARC_04_NEG:ARC_05_NEG:ARC_06_NEG:ARC_07_NEG:ARC_01_POL:ARC_02_POL:ARC_03_POL:ARC_04_POL:ARC_05_POL:ARC_06_POL:ARC_07_POL:ARC_01_HAL:ARC_02_HAL:ARC_03_HAL:ARC_04_HAL:ARC_05_HAL:ARC_06_HAL:ARC_07_HAL:ARC_01_DBL:ARC_02_DBL:ARC_03_DBL:ARC_04_DBL:ARC_05_DBL:ARC_06_DBL:ARC_07_DBL:ARC_01_TRI:ARC_02_TRI:ARC_03_TRI:ARC_04_TRI:ARC_05_TRI:ARC_06_TRI:ARC_07_TRI:ARC_01_-O-:ARC_02_-O-:ARC_03_-O-:ARC_04_-O-:ARC_05_-O-:ARC_06_-O-:ARC_07_-O-:ARC_01_-OH:ARC_02_-OH:ARC_03_-OH:ARC_04_-OH:ARC_05_-OH:ARC_06_-OH:ARC_07_-OH:ARC_01_3-7:ARC_02_3-7:ARC_03_3-7:ARC_04_3-7:ARC_05_3-7:ARC_06_3-7:ARC_07_3-7:ARC_01_AMD:ARC_02_AMD:ARC_03_AMD:ARC_04_AMD:ARC_05_AMD:ARC_06_AMD:ARC_07_AMD:ARC_01_TON:ARC_02_TON:ARC_03_TON:ARC_04_TON:ARC_05_TON:ARC_06_TON:ARC_07_TON:ARC_01_HY1:ARC_02_HY1:ARC_03_HY1:ARC_04_HY1:ARC_05_HY1:ARC_06_HY1:ARC_07_HY1:ARC_01_HY2:ARC_02_HY2:ARC_03_HY2:ARC_04_HY2:ARC_05_HY2:ARC_06_HY2:ARC_07_HY2:POS_01_POS:POS_02_POS:POS_03_POS:POS_04_POS:POS_05_POS:POS_06_POS:POS_07_POS:POS_01_NEG:POS_02_NEG:POS_03_NEG:POS_04_NEG:POS_05_NEG:POS_06_NEG:POS_07_NEG:POS_01_POL:POS_02_POL:POS_03_POL:POS_04_POL:POS_05_POL:POS_06_POL:POS_07_POL:POS_01_HAL:POS_02_HAL:POS_03_HAL:POS_04_HAL:POS_05_HAL:POS_06_HAL:POS_07_HAL:POS_01_DBL:POS_02_DBL:POS_03_DBL:POS_04_DBL:POS_05_DBL:POS_06_DBL:POS_07_DBL:POS_01_TRI:POS_02_TRI:POS_03_TRI:POS_04_TRI:POS_05_TRI:POS_06_TRI:POS_07_TRI:POS_01_-O-:POS_02_-O-:POS_03_-O-:POS_04_-O-:POS_05_-O-:POS_06_-O-:POS_07_-O-:POS_01_-OH:POS_02_-OH:POS_03_-OH:POS_04_-OH:POS_05_-OH:POS_06_-OH:POS_07_-OH:POS_01_3-7:POS_02_3-7:POS_03_3-7:POS_04_3-7:POS_05_3-7:POS_06_3-7:POS_07_3-7:POS_01_AMD:POS_02_AMD:POS_03_AMD:POS_04_AMD:POS_05_AMD:POS_06_AMD:POS_07_AMD:POS_01_TON:POS_02_TON:POS_03_TON:POS_04_TON:POS_05_TON:POS_06_TON:POS_07_TON:POS_01_HY1:POS_02_HY1:POS_03_HY1:POS_04_HY1:POS_05_HY1:POS_06_HY1:POS_07_HY1:POS_01_HY2:POS_02_HY2:POS_03_HY2:POS_04_HY2:POS_05_HY2:POS_06_HY2:POS_07_HY2:NEG_01_NEG:NEG_02_NEG:NEG_03_NEG:NEG_04_NEG:NEG_05_NEG:NEG_06_NEG:NEG_07_NEG:NEG_01_POL:NEG_02_POL:NEG_03_POL:NEG_04_POL:NEG_05_POL:NEG_06_POL:NEG_07_POL:NEG_01_HAL:NEG_02_HAL:NEG_03_HAL:NEG_04_HAL:NEG_05_HAL:NEG_06_HAL:NEG_07_HAL:NEG_01_DBL:NEG_02_DBL:NEG_03_DBL:NEG_04_DBL:NEG_05_DBL:NEG_06_DBL:NEG_07_DBL:NEG_01_TRI:NEG_02_TRI:NEG_03_TRI:NEG_04_TRI:NEG_05_TRI:NEG_06_TRI:NEG_07_TRI:NEG_01_-O-:NEG_02_-O-:NEG_03_-O-:NEG_04_-O-:NEG_05_-O-:NEG_06_-O-:NEG_07_-O-:NEG_01_-OH:NEG_02_-OH:NEG_03_-OH:NEG_04_-OH:NEG_05_-OH:NEG_06_-OH:NEG_07_-OH:NEG_01_3-7:NEG_02_3-7:NEG_03_3-7:NEG_04_3-7:NEG_05_3-7:NEG_06_3-7:NEG_07_3-7:NEG_01_AMD:NEG_02_AMD:NEG_03_AMD:NEG_04_AMD:NEG_05_AMD:NEG_06_AMD:NEG_07_AMD:NEG_01_TON:NEG_02_TON:NEG_03_TON:NEG_04_TON:NEG_05_TON:NEG_06_TON:NEG_07_TON:NEG_01_HY1:NEG_02_HY1:NEG_03_HY1:NEG_04_HY1:NEG_05_HY1:NEG_06_HY1:NEG_07_HY1:NEG_01_HY2:NEG_02_HY2:NEG_03_HY2:NEG_04_HY2:NEG_05_HY2:NEG_06_HY2:NEG_07_HY2:POL_01_POL:POL_02_POL:POL_03_POL:POL_04_POL:POL_05_POL:POL_06_POL:POL_07_POL:POL_01_HAL:POL_02_HAL:POL_03_HAL:POL_04_HAL:POL_05_HAL:POL_06_HAL:POL_07_HAL:POL_01_DBL:POL_02_DBL:POL_03_DBL:POL_04_DBL:POL_05_DBL:POL_06_DBL:POL_07_DBL:POL_01_TRI:POL_02_TRI:POL_03_TRI:POL_04_TRI:POL_05_TRI:POL_06_TRI:POL_07_TRI:POL_01_-O-:POL_02_-O-:POL_03_-O-:POL_04_-O-:POL_05_-O-:POL_06_-O-:POL_07_-O-:POL_01_-OH:POL_02_-OH:POL_03_-OH:POL_04_-OH:POL_05_-OH:POL_06_-OH:POL_07_-OH:POL_01_3-7:POL_02_3-7:POL_03_3-7:POL_04_3-7:POL_05_3-7:POL_06_3-7:POL_07_3-7:POL_01_AMD:POL_02_AMD:POL_03_AMD:POL_04_AMD:POL_05_AMD:POL_06_AMD:POL_07_AMD:POL_01_TON:POL_02_TON:POL_03_TON:POL_04_TON:POL_05_TON:POL_06_TON:POL_07_TON:POL_01_HY1:POL_02_HY1:POL_03_HY1:POL_04_HY1:POL_05_HY1:POL_06_HY1:POL_07_HY1:POL_01_HY2:POL_02_HY2:POL_03_HY2:POL_04_HY2:POL_05_HY2:POL_06_HY2:POL_07_HY2:HAL_01_HAL:HAL_02_HAL:HAL_03_HAL:HAL_04_HAL:HAL_05_HAL:HAL_06_HAL:HAL_07_HAL:HAL_01_DBL:HAL_02_DBL:HAL_03_DBL:HAL_04_DBL:HAL_05_DBL:HAL_06_DBL:HAL_07_DBL:HAL_01_TRI:HAL_02_TRI:HAL_03_TRI:HAL_04_TRI:HAL_05_TRI:HAL_06_TRI:HAL_07_TRI:HAL_01_-O-:HAL_02_-O-:HAL_03_-O-:HAL_04_-O-:HAL_05_-O-:HAL_06_-O-:HAL_07_-O-:HAL_01_-OH:HAL_02_-OH:HAL_03_-OH:HAL_04_-OH:HAL_05_-OH:HAL_06_-OH:HAL_07_-OH:HAL_01_3-7:HAL_02_3-7:HAL_03_3-7:HAL_04_3-7:HAL_05_3-7:HAL_06_3-7:HAL_07_3-7:HAL_01_AMD:HAL_02_AMD:HAL_03_AMD:HAL_04_AMD:HAL_05_AMD:HAL_06_AMD:HAL_07_AMD:HAL_01_TON:HAL_02_TON:HAL_03_TON:HAL_04_TON:HAL_05_TON:HAL_06_TON:HAL_07_TON:HAL_01_HY1:HAL_02_HY1:HAL_03_HY1:HAL_04_HY1:HAL_05_HY1:HAL_06_HY1:HAL_07_HY1:HAL_01_HY2:HAL_02_HY2:HAL_03_HY2:HAL_04_HY2:HAL_05_HY2:HAL_06_HY2:HAL_07_HY2:DBL_01_DBL:DBL_02_DBL:DBL_03_DBL:DBL_04_DBL:DBL_05_DBL:DBL_06_DBL:DBL_07_DBL:DBL_01_TRI:DBL_02_TRI:DBL_03_TRI:DBL_04_TRI:DBL_05_TRI:DBL_06_TRI:DBL_07_TRI:DBL_01_-O-:DBL_02_-O-:DBL_03_-O-:DBL_04_-O-:DBL_05_-O-:DBL_06_-O-:DBL_07_-O-:DBL_01_-OH:DBL_02_-OH:DBL_03_-OH:DBL_04_-OH:DBL_05_-OH:DBL_06_-OH:DBL_07_-OH:DBL_01_3-7:DBL_02_3-7:DBL_03_3-7:DBL_04_3-7:DBL_05_3-7:DBL_06_3-7:DBL_07_3-7:DBL_01_AMD:DBL_02_AMD:DBL_03_AMD:DBL_04_AMD:DBL_05_AMD:DBL_06_AMD:DBL_07_AMD:DBL_01_TON:DBL_02_TON:DBL_03_TON:DBL_04_TON:DBL_05_TON:DBL_06_TON:DBL_07_TON:DBL_01_HY1:DBL_02_HY1:DBL_03_HY1:DBL_04_HY1:DBL_05_HY1:DBL_06_HY1:DBL_07_HY1:DBL_01_HY2:DBL_02_HY2:DBL_03_HY2:DBL_04_HY2:DBL_05_HY2:DBL_06_HY2:DBL_07_HY2:TRI_01_TRI:TRI_02_TRI:TRI_03_TRI:TRI_04_TRI:TRI_05_TRI:TRI_06_TRI:TRI_07_TRI:TRI_01_-O-:TRI_02_-O-:TRI_03_-O-:TRI_04_-O-:TRI_05_-O-:TRI_06_-O-:TRI_07_-O-:TRI_01_-OH:TRI_02_-OH:TRI_03_-OH:TRI_04_-OH:TRI_05_-OH:TRI_06_-OH:TRI_07_-OH:TRI_01_3-7:TRI_02_3-7:TRI_03_3-7:TRI_04_3-7:TRI_05_3-7:TRI_06_3-7:TRI_07_3-7:TRI_01_AMD:TRI_02_AMD:TRI_03_AMD:TRI_04_AMD:TRI_05_AMD:TRI_06_AMD:TRI_07_AMD:TRI_01_TON:TRI_02_TON:TRI_03_TON:TRI_04_TON:TRI_05_TON:TRI_06_TON:TRI_07_TON:TRI_01_HY1:TRI_02_HY1:TRI_03_HY1:TRI_04_HY1:TRI_05_HY1:TRI_06_HY1:TRI_07_HY1:TRI_01_HY2:TRI_02_HY2:TRI_03_HY2:TRI_04_HY2:TRI_05_HY2:TRI_06_HY2:TRI_07_HY2:-O-_01_-O-:-O-_02_-O-:-O-_03_-O-:-O-_04_-O-:-O-_05_-O-:-O-_06_-O-:-O-_07_-O-:#NAME?:3-7_01_3-7:3-7_02_3-7:3-7_03_3-7:3-7_04_3-7:3-7_05_3-7:3-7_06_3-7:3-7_07_3-7:3-7_01_AMD:3-7_02_AMD:3-7_03_AMD:3-7_04_AMD:3-7_05_AMD:3-7_06_AMD:3-7_07_AMD:3-7_01_TON:3-7_02_TON:3-7_03_TON:3-7_04_TON:3-7_05_TON:3-7_06_TON:3-7_07_TON:3-7_01_HY1:3-7_02_HY1:3-7_03_HY1:3-7_04_HY1:3-7_05_HY1:3-7_06_HY1:3-7_07_HY1:3-7_01_HY2:3-7_02_HY2:3-7_03_HY2:3-7_04_HY2:3-7_05_HY2:3-7_06_HY2:3-7_07_HY2:AMD_01_AMD:AMD_02_AMD:AMD_03_AMD:AMD_04_AMD:AMD_05_AMD:AMD_06_AMD:AMD_07_AMD:AMD_01_TON:AMD_02_TON:AMD_03_TON:AMD_04_TON:AMD_05_TON:AMD_06_TON:AMD_07_TON:AMD_01_HY1:AMD_02_HY1:AMD_03_HY1:AMD_04_HY1:AMD_05_HY1:AMD_06_HY1:AMD_07_HY1:AMD_01_HY2:AMD_02_HY2:AMD_03_HY2:AMD_04_HY2:AMD_05_HY2:AMD_06_HY2:AMD_07_HY2:TON_01_TON:TON_02_TON:TON_03_TON:TON_04_TON:TON_05_TON:TON_06_TON:TON_07_TON:TON_01_HY1:TON_02_HY1:TON_03_HY1:TON_04_HY1:TON_05_HY1:TON_06_HY1:TON_07_HY1:TON_01_HY2:TON_02_HY2:TON_03_HY2:TON_04_HY2:TON_05_HY2:TON_06_HY2:TON_07_HY2:HY1_01_HY1:HY1_02_HY1:HY1_03_HY1:HY1_04_HY1:HY1_05_HY1:HY1_06_HY1:HY1_07_HY1:HY1_01_HY2:HY1_02_HY2:HY1_03_HY2:HY1_04_HY2:HY1_05_HY2:HY1_06_HY2:HY1_07_HY2:HY2_01_HY2:HY2_02_HY2:HY2_03_HY2:HY2_04_HY2:HY2_05_HY2:HY2_06_HY2:HY2_07_HY2:NEG_01_POS:NEG_02_POS:NEG_03_POS:NEG_04_POS:NEG_05_POS:NEG_06_POS:NEG_07_POS:NEG_01_HBD:NEG_02_HBD:NEG_03_HBD:NEG_04_HBD:NEG_05_HBD:NEG_06_HBD:NEG_07_HBD:NEG_01_HBA:NEG_02_HBA:NEG_03_HBA:NEG_04_HBA:NEG_05_HBA:NEG_06_HBA:NEG_07_HBA:NEG_01_ARC:NEG_02_ARC:NEG_03_ARC:NEG_04_ARC:NEG_05_ARC:NEG_06_ARC:NEG_07_ARC:NEG_01_HYP:NEG_02_HYP:NEG_03_HYP:NEG_04_HYP:NEG_05_HYP:NEG_06_HYP:NEG_07_HYP:POS_01_HBD:POS_02_HBD:POS_03_HBD:POS_04_HBD:POS_05_HBD:POS_06_HBD:POS_07_HBD:POS_01_HBA:POS_02_HBA:POS_03_HBA:POS_04_HBA:POS_05_HBA:POS_06_HBA:POS_07_HBA:POS_01_ARC:POS_02_ARC:POS_03_ARC:POS_04_ARC:POS_05_ARC:POS_06_ARC:POS_07_ARC:POS_01_HYP:POS_02_HYP:POS_03_HYP:POS_04_HYP:POS_05_HYP:POS_06_HYP:POS_07_HYP:HBD_01_HBD:HBD_02_HBD:HBD_03_HBD:HBD_04_HBD:HBD_05_HBD:HBD_06_HBD:HBD_07_HBD:HBD_01_HBA:HBD_02_HBA:HBD_03_HBA:HBD_04_HBA:HBD_05_HBA:HBD_06_HBA:HBD_07_HBA:HBD_01_ARC:HBD_02_ARC:HBD_03_ARC:HBD_04_ARC:HBD_05_ARC:HBD_06_ARC:HBD_07_ARC:HBD_01_HYP:HBD_02_HYP:HBD_03_HYP:HBD_04_HYP:HBD_05_HYP:HBD_06_HYP:HBD_07_HYP:HBA_01_HBA:HBA_02_HBA:HBA_03_HBA:HBA_04_HBA:HBA_05_HBA:HBA_06_HBA:HBA_07_HBA:HBA_01_ARC:HBA_02_ARC:HBA_03_ARC:HBA_04_ARC:HBA_05_ARC:HBA_06_ARC:HBA_07_ARC:HBA_01_HYP:HBA_02_HYP:HBA_03_HYP:HBA_04_HYP:HBA_05_HYP:HBA_06_HYP:HBA_07_HYP:ARC_01_HYP:ARC_02_HYP:ARC_03_HYP:ARC_04_HYP:ARC_05_HYP:ARC_06_HYP:ARC_07_HYP:HYP_01_HYP:HYP_02_HYP:HYP_03_HYP:HYP_04_HYP:HYP_05_HYP:HYP_06_HYP:HYP_07_HYP:WBN_GC_L_0.25:WBN_GC_H_0.25:WBN_GC_L_0.50:WBN_GC_H_0.50:WBN_GC_L_0.75:WBN_GC_H_0.75:WBN_GC_L_1.00:WBN_GC_H_1.00:WBN_EN_L_0.25:WBN_EN_H_0.25:WBN_EN_L_0.50:WBN_EN_H_0.50:WBN_EN_L_0.75:WBN_EN_H_0.75:WBN_EN_L_1.00:WBN_EN_H_1.00:WBN_LP_L_0.25:WBN_LP_H_0.25:WBN_LP_L_0.50:WBN_LP_H_0.50:WBN_LP_L_0.75:WBN_LP_H_0.75:WBN_LP_L_1.00:WBN_LP_H_1.00:XLogP:PSA:NumRot:NumHBA:NumHBD:MW:BBB:BadGroup:Outcome:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:,
City Payroll Data , City of Los Angeles , www.kaggle.com/cityofLA/city-payroll-data , Sun Nov 27 2016 08:23:42 GMT+0530 (IST) , Payroll information for all Los Angeles city departments since 2013 ,467, cities- income- ,Context The Los Angeles City Controller Office releases payroll information for all city employees on a quarterly basis since 2013. Content Data includes department titles job titles projected annual salaries (with breakdowns of quarterly pay) bonuses and benefits information.  Inspiration  How do benefits and salaries differ for employees across departments and titles? Are there any unusually large differences between lowest and highest employee salaries? How have salaries changed over the past three years? Have the costs of benefits changed dramatically since the passing of the Affordable Care Act? What is the most common government role in Los Angeles? ,,,
Los Angeles Crime Data 2012 to 2016 , LiamLarsen , www.kaggle.com/kingburrito666/los-angeles-crime , Thu Mar 30 2017 08:48:21 GMT+0530 (IST) , Combined raw crime data for 2012 through 2016 in Los Angeles California ,288, crime- ,Content This is the combined raw crime data for 2012 through 2016. Please note that it is missing a few weeks in both December 2015 and December 2016 (Winter break).,RD:Date.Rptd:DR.NO:DATE.OCC:TIME.OCC:AREA:AREA.NAME:Crm.Cd:CrmCd.Desc:Status:Status.Desc:LOCATION:Cross.Street:Location.1:,numeric:dateTime:numeric:dateTime:dateTime:dateTime:string:dateTime:string:string:string:string:numeric:numeric:,
California Electricity Capacity , LA Times Data Desk , www.kaggle.com/la-times/california-electricity-capacity , Thu Apr 06 2017 01:21:33 GMT+0530 (IST) , Are Californians paying for power they don't need? ,306, energy- electrical engineering- ,"This data and analysis originally provided information for the February 5 2017 Los Angeles Times story ""Californians are paying billions for power they don't need"" by documenting California's glut of power and the increasing cost to consumers. It also underpins a complementary interactive graphic. The data are drawn from the Energy Information Administration a branch of the United States government. Acknowledgements Data and analysis originally published by Ryan Menezes and Ben Welsh on the LA Times Data Desk GitHub.",Year:State Code:Producer Type:Fuel Source:Generators:Facilities:Nameplate Capacity (Megawatts):Summer Capacity (Megawatts):,numeric:string:string:string:string:numeric:numeric:numeric:,
Ubudehe Livestock 1 , Jean Pierre Rukundo , www.kaggle.com/jprukundo/ubudehelivestock1 , Fri Aug 04 2017 00:52:59 GMT+0530 (IST) , Ubudehe Livestock 1 from Rwanda NISR ,21, economics- ,Overview Identification COUNTRY Rwanda TITLE Integrated Household Living Conditions Survey 2010-2011 TRANSLATED TITLE Enquête Intégrale sur les conditions de vie des ménages 2010-2011 STUDY TYPE Income/Expenditure/Household Survey SERIES INFORMATION This is the third in a series of periodic standardized income and expenditure surveys. The Rwanda EICV is conducted with a periodicity of 5 years. The surveys in the series are as follows EICV1 2000-2001 EICV2 2005-2006 EICV3 2010-2011 ID NUMBER RWA-NISR-EICV3-02 Version VERSION DESCRIPTION Version 2.0 Final public-use dataset PRODUCTION DATE 2012-10-19 NOTES Version 2.0 The date of this version corresponds to the date of NISR approval of the final public-use datasets. Overview ABSTRACT The 2010/11 Integrated Household Living Conditions Survey or EICV3 (Enquête Intégrale sur les Conditions de Vie des Ménages) is the third in the series of surveys which started in 2000/01 and is designed to monitor poverty and living conditions in Rwanda. The survey methodology has changed little over its 10 years making it ideal for monitoring changes in the country. In 2010/11 for the first time the achieved sample size of 14308 households in the EICV3 was sufficient to provide estimates which are reliable at the level of the district. KIND OF DATA Sample survey data [ssd] UNITS OF ANALYSIS For the purposes of this study the following units of analysis are considered -communities -households -persons Scope NOTES The scope of survey is defined by the need to evaluate poverty determinants and effects of poverty in various domains. This includes gathering data in specific sectors and examning summary statistics and computed indicators by consumption indicator gender etc. The survey primarily seeks to compute household consumption aggregates and correlate consumption to the following areas are within the scope and integrated into the survey  Education (education expenditures) general education curriculum vocational training and higher learning school-leaving literacy and apprenticeship. Health (health expenditures) disability and health problems general health and preventative vaccination over the past 12 months. Migration (travel expenditures) rural-urban migration internal and external migration. Housing (expenditures on utilities rent etc.) status of the housing occupancy services and installations physical characteristics of the dwelling access and satisfaction towards basic services. Economic activity (revenue) unemployment underemployment and job search occupation wage or salaried employment characteristics VUP Activities all other activities domestic work. Non-agricultural activities (revenue) activity status formal and informal sector activity. Agriculture (income and expenditure)  livestock land and agricultural equipment details of holding parcels/blocs and agricultural policy changes crop harvests and use on a large and small scale crop production harvests and use transformation (processing) of agricultural products.  In addition to the specific sector information consumption and/or wealth holding information was collected  Consumption Expenditure on non food items food expenditure subsistence farming (own consumption) with different recall periods. Other cash flows  transfers out by household transfers received by the household income support programs & other revenues (excluding all incomes accrued from saving) VUP UBUDEHE & RSSP schemes other expenditure (excluding expenditures related to any form of saving). Stock items credit durable assets and savings (household assets and liabilities)  TOPICS Topic   Vocabulary  URI consumption/consumer behaviour [1.1]    CESSDA  http//www.nesstar.org/rdf/common economic conditions and indicators [1.2]    CESSDA  http//www.nesstar.org/rdf/common EDUCATION [6]   CESSDA  http//www.nesstar.org/rdf/common general health [8.4]    CESSDA  http//www.nesstar.org/rdf/common employment [3.1]    CESSDA  http//www.nesstar.org/rdf/common unemployment [3.5]  CESSDA  http//www.nesstar.org/rdf/common housing [10.1]  CESSDA  http//www.nesstar.org/rdf/common time use [13.9] CESSDA  http//www.nesstar.org/rdf/common migration [14.3]    CESSDA  http//www.nesstar.org/rdf/common information technology [16.2]   CESSDA  http//www.nesstar.org/rdf/common Coverage GEOGRAPHIC COVERAGE This is a national survey with representivity at the (5) provicial and (30) district level and includes urban and rural households. GEOGRAPHIC UNIT The cluster UNIVERSE All household members. Producers and Sponsors PRIMARY INVESTIGATOR(S) Name    Affiliation National Institute of Statistics of Rwanda (NISR)   Ministry of finance and economics planning (MINECOFIN) OTHER PRODUCER(S) Name    Affiliation Role Oxford Policy Management    DFID    Permanante assistance Geoffrey Greenwell  UNDP    Designer of data system David Megill    UNDP    Statistician Metadata Production METADATA PRODUCED BY Name    Abbreviation    Affiliation Role Juste NITIEMA       Oxford Policy Management (OPM)  Developed the document Geoffrey Greenwell      UNDP    Reviewed and edited document Ruben Muhayiteto        NISR    Revision of metadata DATE OF METADATA PRODUCTION 2011-06-02 DDI DOCUMENT VERSION Version 1.0 (Oct. 192012)  This version of the document represents the first draft of the public-use dataset of the EICV 3 study. Version 1.1 (June 28th 2016) Changed the title from French into English DDI DOCUMENT ID RWA-NISR-DDI-EICV3-02,HHID:PROVINCE:DISTRICT:URB2002:QUINTILE:POVERTY:HH_WT:CLUSTER:ITEM:S8A1Q2:S8A1Q3:S8A1Q4:S8A1Q5:S8A1Q6:S8A1Q7:S8A1Q8:S8A1Q9:S8A1Q10:S8A1Q11:S8A1Q12:S8A1Q13:S8A1Q14:S8A1Q15:S8A1Q16:,numeric:string:numeric:string:string:string:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:string:string:numeric:string:string:numeric:string:string:numeric:numeric:,
AWS Spot Pricing Market , Benji Visser , www.kaggle.com/noqcks/aws-spot-pricing-market , Tue May 16 2017 22:30:17 GMT+0530 (IST) , This includes price region instance size and OS for AWS Spot Instances ,218, business- computing- ,Context AWS spot Instances allow users to bid on spare server capacity. You set a bid threshold for an instance that is usually upwards of 30% cheaper than standard on-demand AWS instances. You can save a lot of money with AWS spot instances. Data Content I pulled this data from the AWS CLI with the describe-spot-price-history command. I took a lot of time to acquire and transform which is why I decided to provide it here.  There are various time periods per region (I acquired all that I could). The columns are all fairly self-evident. Please comment if you have any questions about the data or columns. The data includes the following column fields  price  the current Spot price  datetime the date and time instance_type the Spot instance type  os the Spot instance operating system  region the region and availability zone (AZ) for the Spot instance  Inspiration While AWS spot instances are significantly cheaper than on-demand instances there is only one problem with spot instances once the spot market price of an instance exceeds the bid threshold you purchased an instance for the instance is terminated and given to others with higher bids. So while hourly server costs are cheaper your server is liable to terminate without notice. But there is a difference between regions and spot pricing. Sometimes there is an arbitrage between regions and some regions have more stable prices than others (fewer price spikes). If you can find which region/AZ is most stable you can worry less about your instance terminating without notice.  I started collecting this data because I wanted answers to two questions  Which region/AZ is historically cheapest for instance X  Which region/AZ is historically most stable for instance X  We could also use this data to predict which regions are likely to stay under a certain $ Spot price which would allow you to say with some amount of certainty whether a SPOT instance lasts the next [61218]+ hours.,2017-05-08 21:46:36+00:00:c3.8xlarge:Windows:ap-northeast-1a:1.6503:,dateTime:string:string:string:numeric:,
Q & A Discussed in Parliament of India , Rajanand Ilangovan / இராஜ்ஆனந்த் இளங்கோவன் , www.kaggle.com/rajanand/rajyasabha , Mon Oct 02 2017 19:52:36 GMT+0530 (IST) , 88000+ Questions & answers discussed in Rajya Sabha from 2009 till date. ,54, india- politicians- government- politics- linguistics- ,Context The Rajya Sabha has published the questions and answers that were discussed in each session on their webiste. But one has to search by question/session/ministry wise to get the detail. There were no direct way to get all the quesions and answers in structured way(i.e csv) to do an analysis and find insights. So I've written a web scrapper in R to scrape the data from the Rajya Sabha website and created csv files for each year. Content This dataset helps one to understand what was being discussed in Parliament (Rajya Sabha) of India. There are over 88000+ questions and answers that were discussed in Rajya sabha from 2009 till date (Sep'2017). Variables detail  id - Unique identifier answer_date - Answer date ministry - Ministry name question_type - Type of question (Starred or Unstarred)* question_no - Question number. (This question no. is unique per session)    question_by - Minister who has raised the question. question_title - Discussion title   question_description - Detailed question. answer - Detailed answer to the above question.   *Starred Questions    These are Questions to which answers are desired to be given orally on the floor of the House during the Question Hour. These are distinguished in the printed lists by asterisks. 15 such questions are listed each day. Unstarred Questions   These are Questions to which written answers are given by Ministers which are deemed to have been laid on the Table of the House at the end of the Question Hour. Upto 160 such questions are listed each day in a separate list.  source Acknowledgements Thanks to Rajya Sabha for making the question and answers searchable. Inspiration The below are some of the questions can be answered from this dataset.  Which state or district names mentioned most in question/answer? Sentiment analysis No. of questions ministry wise No. of questions/answers per day. Typically it should be 175 per day. How many days were less productive? Who has raised more question? etc. ,question:answer_date:ministry:question_type:question_no:question_by:question_title:question_description:answer:,numeric:string:string:string:numeric:string:string:string:string:,
Import and Export by India from 2014 to 2017 , Rajanand Ilangovan / இராஜ்ஆனந்த் இளங்கோவன் , www.kaggle.com/rajanand/import-and-export-by-india , Sat Aug 05 2017 00:29:02 GMT+0530 (IST) , Commodity & country wise annual import and export data. ,455, india- business- industry- ,Context To better understand the imports and exports by India and how it changed in 3 years. Content Import and export data available by principle commodity and country wise for 3 years from Apr'2014 to Mar'2017. Column Descriptions  pc_code Integer Principal Commodity Code pc String Principal Commodity Name unit String measurement of quantity country_code  Integer country code country_name String country name quantity Integer quantify of export or import value Integer monetary valeu of the quantity (in million USD)  Acknowledgements Ministry of Commerce and Industry Govt of India has published these datasets in Open Govt Data Platform India portal under Govt. Open Data License - India. Inspiration Some of questions I would like to be answered are  Top countries by growth percentage. Top commodity by quantity or value. YoY growth of export and import. ,pc_code:pc_description:unit:country_code:country_name:quantity:value:,string:string:string:numeric:string:string:numeric:,
India Air Quality Data , Shruti Bhargava , www.kaggle.com/shrutibhargava94/india-air-quality-data , Sat Jul 22 2017 10:34:57 GMT+0530 (IST) , India's air pollution levels over the years ,256, india- pollution- ,Context Since industrialization there has been an increasing concern about environmental pollution. As mentioned in the WHO report 7 million premature deaths annually linked to air pollution  air pollution is the world's largest single environmental risk. Moreover as reported in the NY Times article India’s Air Pollution Rivals China’s as World’s Deadliest it has been found that India's air pollution is deadlier than even China's. Using this dataset one can explore India's air pollution levels at a more granular scale. Content This data is combined(across the years and states) and largely clean version of the Historical Daily Ambient Air Quality Data released by the Ministry of Environment and Forests and Central Pollution Control Board of India under the National Data Sharing and Accessibility Policy (NDSAP). Visualization of the Mean RSPM values over the years Inspiration Can we detect local trends? Can we relate the air quality changes to changes in Environmental policy in India? Acknowledgements Vishal Subbiah (Data downloading),stn_code:sampling_date:state:location:agency:type:so2:no2:rspm:spm:location_monitoring_station:pm2_5:date:,numeric:string:string:string:string:string:numeric:numeric:string:string:string:string:dateTime:,
Barcelona Accidents , Marc Velmer , www.kaggle.com/marcvelmer/barcelona-accidents , Fri Sep 15 2017 21:28:38 GMT+0530 (IST) , List of people who have been involved in an accident in Barcelona (2010 - 2016) ,136, road transport- ,"Context This dataset is a list of people who have been involved in an accident in the city of Barcelona (Spain) from year 2010 till 2016. This data is managed by the Police in the city of Barcelona and includes several information described below. Content This dataset is composed by 7 files each one containing between 10k-12k lines. Every row contains several information like the type of injury (slightly wounded serious injuries or death). It includes a description of the person (driver passenger or pedestrian) sex age location etc... Important This dataset is uploaded as it is so it's possible that some data in some rows is missing/not correct. Description of each column  Número d'expedient Case File Number Codi districte District code where the accident was. Barcelona is divided in several districts Nom districte Name of the district Codi barri Hood code where the accident was. Every district in Barcelona has several hoods Nom barri Name of the hood Codi carrer Street code (Every street has a code) Nom carrer Name of the street Num postal caption Postal number of the street Descripció dia setmana Day of the week in text (written in Catalan) Dia setmana Shortcode of the previous field (also in Catalan) Descripció tipus dia Description of the type of the day it can be ""labor"" or ""festive"" (also in Catalan) NK Any Number of the year Mes de any Number of the month (1-12) Nom mes Name of the month (in Catalan) Dia de mes Day of the month Descripció torn Type of round of the police. It can be ""Matí"" (Morning) ""Tarda"" (Evening) or ""Nit"" (Night) Hora de dia Hour of the day (0-23) Descripció causa vianant Text in catalan. Describes the accident in case the victim is a pedestrian. If not it says ""No és causa del vianant"" Desc. Tipus vehicle implicat Type of vehicle in the accident. Also in Catalan. Descripció sexe Sex of the victim. ""Home"" means man ""Dona"" means woman. Descripció tipus persona Type of role in the accident. It describes if the victim is the pilot (Conductor ) passenger (Passatger) pedestrian (Vianant) Edat Age of the victim Descripció victimització Type of injury in Catalan (slightly wounded (Ferit lleu) serious injuries (Ferit greu) or death (Mort)) Coordenada UTM (Y) UTM coordinate Y Coordenada UTM (X) UTM coordinate X  As you can see some columns could be removed and we wouldn't loose information. My experience working with these files tells me that some rows have no correct data or no data at all. So be careful! Acknowledgements This data can be found in ""Open Data BCN - Barcelona's City Hall Open Data Service"" which is the owner of the CSV files. Inspiration I have uploaded this information here because I believe that data should be shared with everybody! So do your own ""research"" and share it also! I'm always happy to get some feedback and help each other!",N�mero d'expedient:Codi districte:Nom districte:Codi barri:Nom barri:Codi carrer:Nom carrer:Num postal caption:Descripci� dia setmana:Dia setmana:Descripci� tipus dia:NK Any:Mes de any:Nom mes:Dia de mes:Descripci� torn:Hora de dia:Descripci� causa vianant:Desc. Tipus vehicle implicat:Descripci� sexe:Descripci� tipus persona:Edat:Descripci� victimitzaci�:Coordenada UTM (Y):Coordenada UTM (X):,string:numeric:string:numeric:string:numeric:string:string:string:string:string:numeric:numeric:string:numeric:string:numeric:string:string:string:string:numeric:string:numeric:numeric:,
Favicons , ColinMorris , www.kaggle.com/colinmorris/favicons , Wed Aug 23 2017 03:58:55 GMT+0530 (IST) , Image data and metadata for 360000 favicons scraped from popular websites ,304, internet- ,"Favicons are the (usually tiny) image files that browsers may use to represent websites in tabs in the URL bar or for bookmarks. Kaggle for example uses an image of a blue lowercase ""k"" as its favicon. This dataset contains about 360000 favicons from popular websites. Data collection and processing These favicons were scraped in July 2016. I wrote a crawler that went through Alexa's top 1 million sites and made a request for 'favicon.ico' at the site root. If I got a 200 response code I saved the result as ${site_url}.ico. For domains that were identical but for the TLD (e.g. google.com google.ca google.jp...) I scraped only one favicon. My scraping/cleaning code is on GitHub here. Of 1m sites crawled 540k responded with a 200 code. The dataset has 360k images which were the remains after filtering out  empty files (-140k) non-image files according to the file command (-40k). These mostly had type HTML ASCII or UTF-*. corrupt/malformed image files - i.e. those that were sufficiently messed up that ImageMagick failed to parse them. (-1k)  The remaining files are exactly as I received them from the site. They are mostly ICO files with the most common sizes being 16x16 32x32 and 48x48. But there's a long tail of more exotic formats and sizes (there is at least one person living among us who thought that 88x31 was a fine size for a favicon). Data format The favicon files are divided among 6 zip files full-0.zip full-1.zip... full-5.zip. (If you wish to download the full dataset as a single tarball you can do so from the Internet Archive) favicon_metadata.csv is a csv file with one row per favicon in the dataset. The split_index says which of the zip files the image landed in. For an example of loading and interacting with particular favicons in a kernel context check out the Favicon helper functions kernel. 16_16 subset As mentioned above the full dataset is a dog's breakfast of different file formats and dimensions. I've created 'standardized' subsets of the data that may be easier to work with (particularly for machine learning applications where it's necessary to have fixed dimensions). 16_16.tar.gz is a tarball containing all 16x16 favicons in the dataset converted to PNG. It has 290k images. ICO is a container format and many of the ico files in the raw dataset contain several versions of the same favicon at different resolutions. 16x16 favicons that were stuffed together in an ICO file with images of other sizes are included in this set. But I did no resizing - if a favicon has no 'native' 16x16 version it isn't in this set. 16_16_distinct.tar.gz is identical to the above but with 70k duplicate or near-duplicate images removed. There are a small number of commonly repeated favicons like the Blogger ""B"" that occur thousands of times which could be an annoyance depending on the use case - e.g. a generative model might get stuck in a local maximum of spitting out Blogger Bs. Inspiration I hope this dataset might be especially useful for small-scale deep learning experiments. Scaling photographs down to 16x16 would render many of them unintelligible but these favicons were born tiny. The 16_16 fold has more instances than MNIST and the images are even smaller! (Though unlike MNIST most of the images in this dataset are not grayscale.) Other stuff Alexa's top 1-million list includes 'adult' sites so some URLs and favicons may be NSFW or offensive. (It's pretty hard to make a credible depiction of nudity in 256 pixels but there are some occasional attempts.) If you liked this you should also check out the recently released Large Logo Dataset. They've currently made available 550k favicons resized to 32x32. Their data was collected more recently and their scraping process was more robust so their dataset should probably be preferred (though you might still want to use this one if you need the raw favicon files or if you prefer to use 16x16 non-resized images).",url:width:height:format:depth:tld:fname:file_size:color_mode:colorspace:compression:nimgs:split_index:,string:numeric:numeric:string:numeric:string:string:numeric:string:string:string:numeric:numeric:,
Synchronized brainwave dataset , BioSENSE @ UC Berkeley School of Information , www.kaggle.com/berkeley-biosense/synchronized-brainwave-dataset , Thu Oct 27 2016 04:14:31 GMT+0530 (IST) , Brainwave recordings from a group presented with a shared audio-visual stimulus ,879, human medicine- human-computer interaction- ,"EEG devices are becoming cheaper and more inconspicuous but few applications leverage EEG data effectively in part because there are few large repositories of EEG data.  The MIDS class at the UC Berkeley School of Information is sharing a dataset collected using consumer-grade brainwave-sensing headsets along with the software code and visual stimulus used to collect the data. The dataset includes all subjects' readings during the stimulus presentation as well as readings from before the start and after the end of the stimulus. Stimuli We presented two slightly different stimuli to two different groups. Stimuli 1 is available here and stimuli 2 is available here.  For both stimuli a group of about 15 people saw the stimuli at the same time while EEG data was being collected. The stimuli each person saw is available in the session field of subject-metadata.csv. (Subjects who saw stimulus 2 left the room during stimulus 1 and vice versa). Find the synchronized times for both stimuli in stimulus-timing.csv. Subject metadata For each participant we also anonymously collected some other metadata (1) whether or not they had previously seen the video displayed during the stimulus (a superbowl ad) (2) gender (3) whether or not they saw hidden icons displayed during the color counting exercise and (4) their chosen color during the color counting exercise. All of these can be found in subject-metadata.csv. We also collected the timing (in indra_time) of all stimulus events for both session 1 and session 2. These times are included in stimulus-times.csv. EEG data The server receives one data packet every second from each Mindwave Mobile device and stores the data in one row entry with the following 8 data fields id indra_time browser_latency reading_time attention_esense meditation_esense eeg_power raw_values signal_quality createdAt updatedAt label id Integer value in the range of 1 to 30 representing the subject. You can cross-reference these with subject-metadata.csv to learn more about each (anonymized) subject. label The task that the subject was doing at the time of the recording. See stimulus_times.csv or the stimulus videos for reference. Neurosky values The remaining five fields are defined by the Neurosky SDK raw_values Tuple containing raw sample values acquired by the sensor at a sampling rate of 512Hz. attention_esense and meditation_esense Neurosky's eSense meters for Attention and Meditation levels in integer values in the range of 0 to 100. The values represent the last values computed in the current period. eeg_power Represents the magnitude of 8 commonly-recognized types of EEG frequency bands -- delta (0.5 - 2.75Hz) theta (3.5 - 6.75Hz) low-alpha (7.5 - 9.25Hz) high-alpha (10 - 11.75Hz) low-beta (13 - 16.75Hz) high-beta (18 - 29.75Hz) low-gamma (31 - 39.75Hz) and mid-gamma (41 - 49.75Hz). These values have no units and are only meaningful for comparison to the values for the other frequency bands within a sample. signal_quality A zero value indicates good signal quality. A value of 128 greater corresponds to a situation where the headset is not being worn properly. Time values indra_time The synchronized timing of the reading. See browser_latency below. Use this for most analyses. NOTE The included CSV files are not necessarily sorted by time. browser_latency The difference between the time on the subject's computer and the time of our server. This value is used to calculate the synchronized indra_time above. So the time that a row was sent to the server from the browser-based client software is indra_time - browser_latency. createdAt This field represents the time the reading hit the database. reading_time The time at which the Neurosky data passed through the bluetooth connection onto the subject's computer. In ideal conditions where there is 0 latency between receiving this packet and sending the data to the server reading_time = indra_time - browser_latency. So you can use reading_time to estimate the delay between the actual reading and the time at which the reading was sent to the server. NOTE Readings in CSV may not be sorted in time! In total the dataset consists of 29480 rows an average of 982 per participant. Acknowledgements Please use the following citation if you publish your research results using this dataset or software code or stimulus file John Chuang Nick Merrill Thomas Maillart and Students of the UC Berkeley Spring 2015 MIDS Immersion Class. ""Synchronized Brainwave Recordings from a Group Presented with a Common Audio-Visual Stimulus (May 9 2015)."" May 2015.",,,
Computer Network Traffic , Chris Crawford , www.kaggle.com/crawford/computer-network-traffic , Fri Aug 18 2017 23:34:48 GMT+0530 (IST) , Traffic from workstation IPs where at least half were compromised ,197, ,"Context Computer Network Traffic Data - A ~500K CSV with summary of some real network traffic data from the past. The dataset has ~21K rows and covers 10 local workstation IPs over a three month period. Half of these local IPs were compromised at some point during this period and became members of various botnets.  Content Each row consists of four columns  date yyyy-mm-dd (from 2006-07-01 through 2006-09-30) l_ipn local IP (coded as an integer from 0-9) r_asn remote ASN (an integer which identifies the remote ISP) f flows (count of connnections for that day)  Reports of ""odd"" activity or suspicions about a machine's behavior triggered investigations on the following days (although the machine might have been compromised earlier) Date  IP 08-24  1 09-04  5 09-18  4 09-26  3 6 Acknowledgements This public dataset was found on http//statweb.stanford.edu/~sabatti/data.html Inspiration Can you discover when a compromise has occurred by a change in the pattern of communication?",date:l_ipn:r_asn:f:,dateTime:numeric:numeric:numeric:,
2017 State Assembly Election Results , Sid Shetty , www.kaggle.com/iamsidshetty/2017-state-assembly-election-results , Sun Apr 23 2017 23:28:27 GMT+0530 (IST) , 2017 Indian states assembly election results by constituency ,131, politics- ,The dataset contains the 2017 assembly elections results for 5 Indian States; Manipur (MR) Goa (GA) Uttar Pradesh (UP) Uttarakhand (UT) and Punjab (PB).  The data was scraped from Election Commission of India website ECI The Scrapper used for this data collection is here Data Fields The datasets contains 6 files; one for each state and the last one is the aggregated data for all 5 states. Each data file has the following 5 fields State Constituency Candidate Party Votes,State:Constituency:Candidate:Party:Votes:,string:string:string:string:numeric:,
California DDS Expenditures , WesDuckett , www.kaggle.com/wduckett/californiaddsexpenditures , Fri Sep 29 2017 23:00:51 GMT+0530 (IST) , Exploring Simpson's Paradox ,15, data analysis- ethnic groups- finance- health- demographics- ,Context This data set contains data regarding the allocation of funding from the Department of Developmental Services to developmentally-disabled individuals in California in 2014.  Content The variables included are  Id [int] Age Cohort (age group) [factor] Age [int] Gender [factor] Expenditures [int] Ethnicity [factor]  This data set is well suited for exploring the effects of Simpson's Paradox and confounding variables. Acknowledgements The data was originally retrieved from the California Department of Developmental Services (http//www.dds.ca.gov) by Stanley Taylor and Amy Mickel from California State University Sacremento. The names associated with each record have been removed to protect anonymity. Taylor and Mickel explored Simpson's Paradox using this data set after a discrimination lawsuit was filed against the California DDS. The lawsuit claimed that White Non-Hispanics were receiving more funding than Hispanics. To learn more about the analysis and findings of Taylor and Mickel read the paper they published together by following this link www.amstat.org/publications/jse/v22n1/mickel.pdf Inspiration Is there any basis to the claim of discrimination? What are the confounding variables? What are other ways to organize this data to gain an alternate perspective?,Id:Age Cohort:Age:Gender:Expenditures:Ethnicity:,numeric:string:numeric:string:numeric:string:,
Indian Startup Funding , SRK , www.kaggle.com/sudalairajkumar/indian-startup-funding , Fri Aug 11 2017 00:20:52 GMT+0530 (IST) , Funding details of the startups in India ,421, india- ,Context Interested in Indian Startup Ecosystem just like me? Wanted to know what type of startups are getting funded in the last few years? Wanted to know who are the important investors? Wanted to know the hot fields that get a lot of funding these days?  Then here is a chance to explore the Indian Startup funding data and derive insights.! Content This dataset has funding information of the Indian startups from January 2015 till date. The columns included are  SNo  Serial Number Date  Date of funding in format DD/MM/YYYY StartupName  Name of the startup which got funded IndustryVertical  Industry to which the startup belongs SubVertical  Sub category of the industry type CityLocation  City in which the startup is based out of InvestorsName  Name of the investors involved in the funding round AmountInUSD  Funding Amount in USD Remarks  Other information if any  Acknowledgements Thanks to trak.in who are generous enough to share the data publicly for free.  Image from this link  http//ncmedia.azureedge.net/ncmedia/2015/12/MS_BizSpark_StartupsFundingInfographic01.jpg Inspiration Possible questions which could be answered are 1. How does the funding ecosystem change with time? 2. Do cities play a major role in funding? 3. Which industries are favored by investors for funding? 4. Who are the important investors in the Indian Ecosystem? 5. How much funds does startups generally get in India? Potentially many more such questions could be explored. ,SNo:,numeric:,
Grasping Dataset , ugocupcic , www.kaggle.com/ugocupcic/grasping-dataset , Mon Sep 11 2017 15:47:19 GMT+0530 (IST) , A grasping dataset from simulation using Shadow Robot's Smart Grasping Sandbox ,72, robotics- ,Context At Shadow Robot we are leaders in robotic grasping and manipulation. As part of our Smart Grasping System development we're developing different algorithms using machine learning.  This first public dataset was created to investigate the use of machine learning to predict the stability of a grasp. Due to the limitations of the current simulation it is a restricted dataset - only grasping a ball. The dataset is annotated with an objective grasp quality and contains the different data gathered from the joints (position velocity effort). You can find all the explanations for this dataset over on Medium. Inspiration I'll be more than happy to discuss this dataset as well as which dataset you'd like to have to try your hands at solving real world robotic problems focused on grasping using machine learning. Let's connect on twitter (@ugocupcic)!,experiment_number:,numeric:,
Crime in Los Angeles , City of Los Angeles , www.kaggle.com/cityofLA/crime-in-los-angeles , Mon Sep 18 2017 22:17:08 GMT+0530 (IST) , Crime data from 2010 through September 2017 ,829, crime- ,This dataset reflects incidents of crime in the City of Los Angeles dating back to 2010. This data is transcribed from original crime reports that are typed on paper and therefore there may be some inaccuracies within the data. Some location fields with missing data are noted as (0° 0°). Address fields are only provided to the nearest hundred block in order to maintain privacy. Reporting District Shapefile Attributes REPDIST Number min 101   max 2199   avg 1162   count 1135 PREC Number min 1   max 21   avg 11   count 1135 APREC Text PACIFIC (74) DEVONSHIRE (70) WEST LOS ANGELES (69) NORTHEAST (64) HOLLENBECK (63) MISSION (62)... (15 more) BUREAU Text VALLEY BUREAU (399) WEST BUREAU (288) CENTRAL BUREAU (267) SOUTH BUREAU (181) BASICCAR Text 8A29 (17) 17A35 (17) 1A1 (15) 17A49 (14) 16A35 (14) 14A73 (14) 19A43 (13) 8A95 (12) 19A7 (12)... (160 more) TOOLTIP Text Bureau SOUTH BUREAU\nDistrict 562\nDivision HARBOR (1)... (1134 more) OBJECTID Unique ID Acknowledgements This dataset was kindly released by the City of Los Angeles. You can find the original dataset updated weekly here. Inspiration  Some of the MO codes seem unlikely or unrelated to crime. Can you find out what would lead to the use of code 0107 God or 1021 Repair? ,DR Number:Date Reported:Date Occurred:Time Occurred:Area ID:Area Name:Reporting District:Crime Code:Crime Code Description:MO Codes:Victim Age:Victim Sex:Victim Descent:Premise Code:Premise Description:Weapon Used Code:Weapon Description:Status Code:Status Description:Crime Code 1:Crime Code 2:Crime Code 3:Crime Code 4:Address:Cross Street:Location :,numeric:dateTime:dateTime:numeric:numeric:string:numeric:numeric:string:numeric:numeric:string:string:numeric:string:numeric:string:string:string:numeric:string:string:string:string:string:string:,
US Casualties of the Korean War , 0rangutan , www.kaggle.com/orangutan/koreanconflict , Fri Feb 17 2017 01:46:17 GMT+0530 (IST) , Data from The U.S. National Archives and Records Administration ,107, history- war- ,Context Information reproduced from the National Archives The Korean Conflict Extract Data File of the Defense Casualty Analysis System (DCAS) Extract Files contains records of U.S. military fatal casualties of the Korean War. These records were transferred into the custody of the National Archives and Records Administration in 2008. The Defense Casualty Analysis System Extract Files were created by the Defense Manpower Data Center (DMDC) of the Office of the Secretary of Defense. The records correspond to the Korean War Conflict statistics on the DMDC web site which is accessible online at https//www.dmdc.osd.mil/dcas/pages/main.xhtml .  A full series description for the Defense Casualty Analysis System (DCAS) Extract Files is accessible online via the National Archives Catalog under the National Archives Identifier 2240988. The Korean War Conflict Extract Data File is also accessible for direct download via the National Archives Catalog file-level description National Archives Identifier 2240988.  Content The raw data files have been cleaned and labelled as best as I can with reference to the accompanying Supplemental Code Lists. Names and ID numbers have been removed out of respect and to provide anonymity. Data fields * SERVICE_TYPE * SERVICE_CODE * ENROLLMENT * BRANCH * RANK * PAY_GRADE * POSITION * BIRTH_YEAR * SEX * HOME_CITY * HOME_COUNTY * HOME_STATE * STATE_CODE * NATIONALITY * MARITAL_STATUS  * ETHNICITY * ETHNICITY_1 * ETHNICITY_2 * DIVISION * FATALITY_YEAR * FATALITY_DATE * HOSTILITY_CONDITIONS * FATALITY * BURIAL_STATUS Acknowledgements Data provided by The U.S. National Archives and Records Administration. Raw data can be accessed via the following link https//catalog.archives.gov/id/2240988 Inspiration By cleaning the data I hope to give wider access to this resource.,SERVICE_TYPE:SERVICE_CODE:ENROLLMENT:BRANCH:RANK:PAY_GRADE:POSITION:BIRTH_YEAR:SEX:HOME_CITY:HOME_COUNTY:NATIONALITY:STATE_CODE:HOME_STATE:MARITAL_STATUS:ETHNICITY:ETHNICITY_1:ETHNICITY_2:DIVISION:INCIDENT_DATE:FATALITY_YEAR:FATALITY_DATE:HOSTILITY_CONDITIONS:FATALITY:BURIAL_STATUS:,string:string:string:string:string:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:string:string:string:,
Armenian Pub Survey , ErikHambardzumyan , www.kaggle.com/erikhambardzumyan/pubs , Fri Mar 17 2017 22:29:25 GMT+0530 (IST) , Data from online survey questionnaire about Armenian pubs ,202, food and drink- ,The dataset collected from an online survey questionnaire includes behavioral psychographic geographic and demographic about Armenian pubs. The data has been intended for an independent project organized by the students of the American University of Armenia solely for educational purposes. This data is unique as the pubs sector in Armenia has not been reasearched so far.,Timestamp:Age :Gender :Income : Occupation:Fav_Pub:WTS:Freq:Prim_Imp:Sec_Imp:Stratum:Lifestyle:Occasions:,string:numeric:string:numeric:string:string:numeric:string:string:string:string:string:string:,
Campaign Finance versus Election Results , danerbland , www.kaggle.com/danerbland/electionfinance , Thu Dec 08 2016 02:44:32 GMT+0530 (IST) , Can an election be predicted from the preceding campaign finance reports? ,405, finance- politics- ,Context This dataset was assembled to investigate the possibility of predicting congressional election results by campaign finance reports from the period leading up to the election. Content Each row represents a candidate with information on their campaign including the state district office total contributions total expenditures etc.  The content is specific to the year leading up to the 2016 election (1/1/2015 through 10/19/2016). Acknowledgements Campaign finance information came directly from FEC.gov. Election results and vote totals for house races were taken from CNN's election results page. Inspiration How much of an impact does campaign spending and fundraising have on an election?  Is the impact greater in certain areas?  Given this dataset to what degree of accuracy could we have predicted the election results?,can_id:can_nam:can_off:can_off_sta:can_off_dis:can_par_aff:can_inc_cha_ope_sea:can_str1:can_str2:can_cit:can_sta:can_zip:ind_ite_con:ind_uni_con:ind_con:par_com_con:oth_com_con:can_con:tot_con:tra_fro_oth_aut_com:can_loa:oth_loa:tot_loa:off_to_ope_exp:off_to_fun:off_to_leg_acc:oth_rec:tot_rec:ope_exp:exe_leg_acc_dis:fun_dis:tra_to_oth_aut_com:can_loa_rep:oth_loa_rep:tot_loa_rep:ind_ref:par_com_ref:oth_com_ref:tot_con_ref:oth_dis:tot_dis:cas_on_han_beg_of_per:cas_on_han_clo_of_per:net_con:net_ope_exp:deb_owe_by_com:deb_owe_to_com:cov_sta_dat:cov_end_dat:winner:votes:,string:string:string:string:numeric:string:string:string:string:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:dateTime:dateTime:string:numeric:,
Gene expression dataset (Golub et al.) , Chris Crawford , www.kaggle.com/crawford/gene-expression , Wed Aug 09 2017 02:26:48 GMT+0530 (IST) , Molecular Classification of Cancer by Gene Expression Monitoring ,311, health science- human genetics- biology- biotechnology- ,"Context This dataset comes from a proof-of-concept study published in 1999 by Golub et al. It showed how new cases of cancer could be classified by gene expression monitoring (via DNA microarray) and thereby provided a general approach for identifying new cancer classes and assigning tumors to known classes. These data were used to classify patients with acute myeloid leukemia (AML) and acute lymphoblastic leukemia (ALL). Content Golub et al ""Molecular Classification of Cancer Class Discovery and Class Prediction by Gene Expression Monitoring"" There are two datasets containing the initial (training 38 samples) and independent (test 34 samples) datasets used in the paper.  These datasets contain measurements corresponding to ALL and AML samples from Bone Marrow and Peripheral Blood. Intensity values have been re-scaled such that overall intensities for each chip are equivalent.  Acknowledgements Molecular Classification of Cancer Class Discovery and Class Prediction by Gene Expression Science 286531-537. (1999). Published 1999.10.14  T.R. Golub D.K. Slonim P. Tamayo C. Huard M. Gaasenbeek J.P. Mesirov H. Coller M. Loh J.R. Downing M.A. Caligiuri C.D. Bloomfield and E.S. Lander These datasets have been converted to a comma separated value files (CSV). Inspiration These datasets are great for classification problems. The original authors used the data to classify the type of cancer in each patient by their gene expressions.",patient:cancer:,numeric:string:,
Philadelphia Crime Data , Mike Chirico , www.kaggle.com/mchirico/philadelphiacrimedata , Fri Mar 24 2017 04:21:24 GMT+0530 (IST) , Ten Years of Crime Data by OpenDataPhilly ,4739, crime- ,Crime Data for Philadelphia To get started quickly take a look at  Philly Data Crime Walk-through. Data was provided by OpenDataPhilly ,,,
Data Lab , KrisMurphy , www.kaggle.com/krismurphy01/data-lab , Sat Aug 19 2017 01:15:54 GMT+0530 (IST) , To use for various exercises including multivariate analysis ,270, ,Context We are building a data set that can be used for building useful reports  understanding the difference between data and information and multivariate analysis. The data set we are building is similar to that used in several academic reports and what may be found in ERP HR subsystems. We will update the sample data set as we gain a better understanding of the data elements using the calculations that exist in scholarly journals. Specifically we will use the correlation tables to rebuild the data sets. Content The fields represent a fictitious data set where a survey was taken and actual employee metrics exist for a particular organization. None of this data is real. Acknowledgements We wouldn't be here without the help of others. If you owe any attributions or thanks include them here along with any citations of past research.  Prabhjot Singh contributed a portion of the data (the columns on the right before the survey data was added). https//www.kaggle.com/prabhjotindia https//www.kaggle.com/prabhjotindia/visualizing-employee-data/data About this Dataset Why are our best and most experienced employees leaving prematurely? Have fun with this database and try to predict which valuable employees will leave next. Fields in the dataset include Satisfaction Level Last evaluation Number of projects Average monthly hours Time spent at the company Whether they have had a work accident Whether they have had a promotion in the last 5 years Departments Salary Inspiration Your data will be in front of the world's largest data science community. What questions do you want to see answered?,ID:Name:Department:GEO:Role:Rising_Star:Will_Relocate:Critical:Trending Perf:Talent_Level:Validated_Talent_Level:Percent_Remote:EMP_Sat_OnPrem_1:EMP_Sat_OnPrem_2:EMP_Sat_OnPrem_3:EMP_Sat_OnPrem_4:EMP_Sat_OnPrem_5:EMP_Sat_Remote_1:EMP_Sat_Remote_2:EMP_Sat_Remote_3:EMP_Sat_Remote_4:EMP_Sat_Remote_5:EMP_Engagement_1:EMP_Engagement_2:EMP_Engagement_3:EMP_Engagement_4:EMP_Engagement_5:last_evaluation:number_project:average_montly_hours:time_spend_company:Work_accident:left_Company:CSR Factor:promotion_last_5years:sales:salary:Gender:LinkedIn_Hits:Emp_Work_Status2:Emp_Work_Status_3:Emp_Work_Status_4:Emp_Work_Status_5:Emp_Identity:Emp_Role:Emp_Position:Emp_Title:Women_Leave:Men_Leave:Emp_Competitive_1:Emp_Competitive_2:Emp_Competitive_3:Emp_Competitive_4:Emp_Competitive_5:Emp_Collaborative_1:Emp_Collaborative_2:Emp_Collaborative_3:Emp_Collaborative_4:Emp_Collaborative_5:Sensor_StepCount:Sensor_Heartbeat(Average/Min):Sensor_Proximity(1-highest/10-lowest):,numeric:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Melbourne Housing Market , Tony Pino , www.kaggle.com/anthonypino/melbourne-housing-market , Tue Sep 26 2017 05:50:37 GMT+0530 (IST) , Melbourne housing clearance data from Jan 2016 ,2525, housing- demographics- ,Melbourne is currently experiencing a housing bubble (some experts say it may burst soon). Maybe someone can find a trend or give a prediction? Which suburbs are the best to buy in? Which ones are value for money? Where's the expensive side of town? And more importantly where should I buy a 2 bedroom unit? Content & Acknowledgements This data was scraped from publicly available results posted every week from Domain.com.au I've cleaned it as best I can now it's up to you to make data analysis magic. The dataset includes Address Type of Real estate Suburb Method of Selling Rooms Price Real Estate Agent Date of Sale and distance from C.B.D. ....Now with extra data including including property size land size and council area you may need to change your code! Some Key Details Suburb Suburb Address Address Rooms Number of rooms Price Price in dollars Method                S - property sold;                SP - property sold prior;                PI - property passed in;                PN - sold prior not disclosed;                SN - sold not disclosed;                NB - no bid;                VB - vendor bid;                 W - withdrawn prior to auction;                 SA - sold after auction;                 SS - sold after auction price not disclosed.                 N/A - price or highest bid not available.  Type         br - bedroom(s);          h - housecottagevilla semiterrace;          u - unit duplex;         t - townhouse;          dev site - development site;          o res - other residential. SellerG Real Estate Agent Date Date sold Distance Distance from CBD Regionname General Region (West North West North North east ...etc)  Propertycount Number of properties that exist in the suburb. Bedroom2  Scraped # of Bedrooms (from different source) Bathroom Number of Bathrooms    Car Number of carspots  Landsize Land Size BuildingArea Building Size  YearBuilt Year the house was built  CouncilArea Governing council for the area  Lattitude Self explanitory  Longtitude Self explanitory,Suburb:Address:Rooms:Type:Price:Method:SellerG:Date:Distance:Postcode:Bedroom2:Bathroom:Car:Landsize:BuildingArea:YearBuilt:CouncilArea:Lattitude:Longtitude:Regionname:Propertycount:,string:string:numeric:string:numeric:string:string:dateTime:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:string:numeric:,
Breast Cancer Proteomes , kajot , www.kaggle.com/piotrgrabo/breastcancerproteomes , Sun Jul 03 2016 21:54:56 GMT+0530 (IST) , Dividing breast cancer patients into separate sub-classes ,3861, human medicine- ,"Context This data set contains published iTRAQ proteome profiling of 77 breast cancer samples generated by the Clinical Proteomic Tumor Analysis Consortium (NCI/NIH). It contains expression values for ~12.000 proteins for each sample with missing values present when a given protein could not be quantified in a given sample. Content File 77_cancer_proteomes_CPTAC_itraq.csv  RefSeq_accession_number RefSeq protein ID (each protein has a unique ID in a RefSeq database) gene_symbol a symbol unique to each gene (every protein is encoded by some gene) gene_name a full name of that gene Remaining columns log2 iTRAQ ratios for each sample (protein expression data most important) three last columns are from healthy individuals  File clinical_data_breast_cancer.csv First column ""Complete TCGA ID"" is used to match the sample IDs in the main cancer proteomes file (see example script). All other columns have self-explanatory names contain data about the cancer classification of a given sample using different methods. 'PAM50 mRNA' classification is being used in the example script.  File PAM50_proteins.csv Contains the list of genes and proteins used by the PAM50 classification system. The column RefSeqProteinID contains the protein IDs that can be matched with the IDs in the main protein expression data set. Past Research The original study http//www.nature.com/nature/journal/v534/n7605/full/nature18003.html (paywall warning) In brief the data were used to assess how the mutations in the DNA are affecting the protein expression landscape in breast cancer. Genes in our DNA are first transcribed into RNA molecules which then are translated into proteins. Changing the information content of DNA has impact on the behavior of the proteome which is the main functional unit of cells taking care of cell division DNA repair enzymatic reactions and signaling etc. They performed K-means clustering on the protein data to divide the breast cancer patients into sub-types each having unique protein expression signature. They found that the best clustering was achieved using 3 clusters (original PAM50 gene set yields four different subtypes using RNA data). Inspiration This is an interesting study and I myself wanted to use this breast cancer proteome data set for other types of analyses using machine learning that I am performing as a part of my PhD. However I though that the Kaggle community (or at least that part with biomedical interests) would enjoy playing with it. I added a simple K-means clustering example for that data with some comments the same approach as used in the original paper. One thing is that there is a panel of genes the PAM50 which is used to classify breast cancers into subtypes. This panel was originally based on the RNA expression data which is (in my opinion) not as robust as the measurement of mRNA's final product the protein. Perhaps using this data set someone could find a different set of proteins (they all have unique NP_/XP_ identifiers) that would divide the data set even more robustly? Perhaps into a higher numbers of clusters with very distinct protein expression signatures? Example K-means analysis script http//pastebin.com/A0Wj41DP",gene_symbol:gene_name:AO-A12D.01TCGA:C8-A131.01TCGA:AO-A12B.01TCGA:BH-A18Q.02TCGA:C8-A130.02TCGA:C8-A138.03TCGA:E2-A154.03TCGA:C8-A12L.04TCGA:A2-A0EX.04TCGA:AO-A12D.05TCGA:AN-A04A.05TCGA:BH-A0AV.05TCGA:C8-A12T.06TCGA:A8-A06Z.07TCGA:A2-A0CM.07TCGA:BH-A18U.08TCGA:A2-A0EQ.08TCGA:AR-A0U4.09TCGA:AO-A0J9.10TCGA:AR-A1AP.11TCGA:AN-A0FK.11TCGA:AO-A0J6.11TCGA:A7-A13F.12TCGA:BH-A0E1.12TCGA:A7-A0CE.13TCGA:A2-A0YC.13TCGA:AO-A0JC.14TCGA:A8-A08Z.14TCGA:AR-A0TX.14TCGA:A8-A076.15TCGA:AO-A126.15TCGA:BH-A0C1.16TCGA:A2-A0EY.16TCGA:AR-A1AW.17TCGA:AR-A1AV.17TCGA:C8-A135.17TCGA:A2-A0EV.18TCGA:AN-A0AM.18TCGA:D8-A142.18TCGA:AN-A0FL.19TCGA:BH-A0DG.19TCGA:AR-A0TV.20TCGA:C8-A12Z.20TCGA:AO-A0JJ.20TCGA:AO-A0JE.21TCGA:AN-A0AJ.21TCGA:A7-A0CJ.22TCGA:AO-A12F.22TCGA:A8-A079.23TCGA:A2-A0T3.24TCGA:A2-A0YD.24TCGA:AR-A0TR.25TCGA:AO-A03O.25TCGA:AO-A12E.26TCGA:A8-A06N.26TCGA:A2-A0YG.27TCGA:BH-A18N.27TCGA:AN-A0AL.28TCGA:A2-A0T6.29TCGA:E2-A158.29TCGA:E2-A15A.29TCGA:AO-A0JM.30TCGA:C8-A12V.30TCGA:A2-A0D2.31TCGA:C8-A12U.31TCGA:AR-A1AS.31TCGA:A8-A09G.32TCGA:C8-A131.32TCGA:C8-A134.32TCGA:A2-A0YF.33TCGA:BH-A0DD.33TCGA:BH-A0E9.33TCGA:AR-A0TT.34TCGA:AO-A12B.34TCGA:A2-A0SW.35TCGA:AO-A0JL.35TCGA:BH-A0BV.35TCGA:A2-A0YM.36TCGA:BH-A0C7.36TCGA:A2-A0SX.36TCGA:263d3f-I.CPTAC:blcdb9-I.CPTAC:c4155b-C.CPTAC:RefSeq_accession_number:,string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:,
Marvel Characters and Universes , Yan Ramos da Silva , www.kaggle.com/yrdasilva/marvel-characters-and-universes , Tue Jan 31 2017 19:58:14 GMT+0530 (IST) , All distinct Marvel characters and every universe where they appear ,251, comics- ,Context I have been a comic book fan for many years and when I started writing web scrapers for practice it was only natural that I did one inspired by my passion for Marvel. Content This dataset has 27.290 rows each one representing a distinct Marvel character such as Peter Parker Tony Stark or Jean Grey.  As for columns there are 1822 of them one for each Marvel universe. All the cells contain a boolean value true if there is a version of that character from that universe or false otherwise. Acknowledgements I would like to thank the Marvel Wikia for its amazing amount of information as well as very practical API and Marvel for having such a huge and diverse multiverse that inspires many possibilities of analysis. Inspiration This was my first attempt at data science. It was challenging but very fun and rewarding. I would really appreciate any feedback or suggestions for next works.,Character:2015:Age of X:Avengers Fairy Tales:Brilliant City:Earth-0:Earth-001:Earth-1000:Earth-10001:Earth-10001011:Earth-10003:Earth-10005:Earth-10011:Earth-1002:Earth-10021:Earth-10022:Earth-1003:Earth-1004:Earth-10041:Earth-1005:Earth-10051:Earth-1006:Earth-10063:Earth-1007:Earth-10071:Earth-1008:Earth-10081:Earth-10082:Earth-10083:Earth-1009:Earth-10091:Earth-1010:Earth-101001:Earth-10101:Earth-10102:Earth-1011:Earth-10112:Earth-1012:Earth-1013:Earth-1014:Earth-1015:Earth-1016:Earth-1017:Earth-1018:Earth-10182:Earth-1019:Earth-10190:Earth-10197:Earth-1020:Earth-10201:Earth-10208:Earth-1021:Earth-10219:Earth-1022:Earth-10221:Earth-10223:Earth-1023:Earth-10235:Earth-1024:Earth-10245:Earth-10246:Earth-1025:Earth-1026:Earth-10267:Earth-1027:Earth-1028:Earth-10280:Earth-1029:Earth-10298:Earth-1030:Earth-1031:Earth-10310:Earth-103173:Earth-1032:Earth-1033:Earth-10330:Earth-1034:Earth-1035:Earth-1036:Earth-10363:Earth-1037:Earth-1038:Earth-10382:Earth-1039:Earth-1040:Earth-1041:Earth-1042:Earth-1043:Earth-1044:Earth-1045:Earth-10508:Earth-10511:Earth-10515:Earth-105709:Earth-1059:Earth-1064:Earth-10710:Earth-10711:Earth-10724:Earth-107342:Earth-1078:Earth-1081:Earth-1082:Earth-1089:Earth-10919:Earth-10943:Earth-10995:Earth-11:Earth-110:Earth-1100:Earth-11010:Earth-1102:Earth-11021:Earth-11022:Earth-11029:Earth-11035:Earth-11041:Earth-11045:Earth-11051:Earth-11052:Earth-11053:Earth-11069:Earth-1108:Earth-11080:Earth-11081:Earth-11086:Earth-11099:Earth-111:Earth-11113:Earth-1112:Earth-11120:Earth-11124:Earth-11126:Earth-11127:Earth-11131:Earth-111347:Earth-1115:Earth-1119:Earth-112001:Earth-11201:Earth-11206:Earth-11209:Earth-1121:Earth-1122:Earth-11223:Earth-1123:Earth-11236:Earth-11313:Earth-11326:Earth-113500:Earth-1136:Earth-1137:Earth-11418:Earth-1145:Earth-11500:Earth-11511:Earth-1157:Earth-11623:Earth-11638:Earth-11704:Earth-11714:Earth-11831:Earth-1189:Earth-1191:Earth-11911:Earth-11920:Earth-1193:Earth-11947:Earth-11983:Earth-11993:Earth-12:Earth-12011:Earth-120185:Earth-12025:Earth-12034:Earth-12041:Earth-120703:Earth-12091:Earth-12101:Earth-1211:Earth-121193:Earth-12121:Earth-12122:Earth-12125:Earth-12128:Earth-12131:Earth-121347:Earth-12164:Earth-121698:Earth-121893:Earth-1219:Earth-12201:Earth-12218:Earth-12224:Earth-12245:Earth-1228:Earth-12311:Earth-12318:Earth-1237:Earth-1241:Earth-12433:Earth-12467:Earth-12591:Earth-12610:Earth-12665:Earth-127:Earth-12772:Earth-12812:Earth-1282:Earth-1287:Earth-1289:Earth-12919:Earth-12927:Earth-12928:Earth-12934:Earth-1294:Earth-12973:Earth-1298:Earth-13:Earth-13003:Earth-13016:Earth-13017:Earth-13021:Earth-13022:Earth-13027:Earth-13031:Earth-13034:Earth-13035:Earth-13044:Earth-13054:Earth-13059:Earth-13074:Earth-13121:Earth-13122:Earth-13133:Earth-13159:Earth-13264:Earth-13270:Earth-1331:Earth-13371:Earth-13393:Earth-13410:Earth-1347:Earth-13519:Earth-135263:Earth-13584:Earth-13625:Earth-1365:Earth-13660:Earth-13729:Earth-138:Earth-13819:Earth-13989:Earth-14026:Earth-14029:Earth-14031:Earth-14094:Earth-14112:Earth-14114:Earth-14118:Earth-14123:Earth-14132:Earth-14161:Earth-14219:Earth-14249:Earth-14254:Earth-14325:Earth-14412:Earth-14436:Earth-14512:Earth-14515:Earth-1462:Earth-14622:Earth-14702:Earth-148:Earth-14831:Earth-14845:Earth-14850:Earth-148611:Earth-15:Earth-15011:Earth-15061:Earth-1508:Earth-15083:Earth-15104:Earth-1519:Earth-15203:Earth-15312:Earth-155:Earth-15513:Earth-1556:Earth-15731:Earth-15797:Earth-15901:Earth-161:Earth-1610:Earth-1611:Earth-16111:Earth-16112:Earth-16191:Earth-16619:Earth-17021:Earth-17112:Earth-172:Earth-1720:Earth-17342:Earth-1735:Earth-1771:Earth-17893:Earth-18083:Earth-181:Earth-18119:Earth-1812:Earth-1815:Earth-18150:Earth-18451:Earth-1857:Earth-187319:Earth-1880:Earth-19141:Earth-1917:Earth-1946:Earth-1952:Earth-19776:Earth-198234:Earth-19828:Earth-1983:Earth-1987:Earth-19877:Earth-1991:Earth-19919:Earth-199406:Earth-199606:Earth-199673:Earth-199999:Earth-20007:Earth-200080:Earth-200111:Earth-20017:Earth-200500:Earth-200501:Earth-200502:Earth-200503:Earth-200505:Earth-200506:Earth-200507:Earth-200508:Earth-200509:Earth-20051:Earth-200510:Earth-200511:Earth-200512:Earth-200513:Earth-200515:Earth-200517:Earth-200519:Earth-200523:Earth-200524:Earth-200525:Earth-200526:Earth-200527:Earth-200529:Earth-200781:Earth-200782:Earth-200783:Earth-200784:Earth-2010:Earth-20110:Earth-20111:Earth-201163:Earth-2012:Earth-20132:Earth-20154:Earth-20198:Earth-2020:Earth-2021:Earth-20210:Earth-2022:Earth-2030:Earth-20318:Earth-20329:Earth-20476:Earth-205117:Earth-2055:Earth-20604:Earth-20712:Earth-20809:Earth-2081:Earth-2090:Earth-2098:Earth-21011:Earth-21050:Earth-2107:Earth-2108:Earth-2109:Earth-21101:Earth-2111:Earth-21110:Earth-21117:Earth-21119:Earth-21190:Earth-21195:Earth-2120:Earth-21205:Earth-2122:Earth-21261:Earth-21281:Earth-21320:Earth-21422:Earth-2149:Earth-21540:Earth-21611:Earth-21711:Earth-21722:Earth-21811:Earth-2182:Earth-2189:Earth-21901:Earth-21910:Earth-21919:Earth-21980:Earth-21993:Earth-22000:Earth-22020:Earth-22025:Earth-22073:Earth-22110:Earth-22142:Earth-22177:Earth-22191:Earth-22206:Earth-22214:Earth-22288:Earth-22301:Earth-22455:Earth-22490:Earth-22519:Earth-22626:Earth-22666:Earth-22791:Earth-22795:Earth-22799:Earth-2301:Earth-23099:Earth-231:Earth-2319:Earth-23201:Earth-23223:Earth-23238:Earth-23291:Earth-23373:Earth-23378:Earth-2344:Earth-23488:Earth-23492:Earth-238:Earth-23848:Earth-23884:Earth-23895:Earth-24015:Earth-24106:Earth-2411:Earth-24111:Earth-24133:Earth-24135:Earth-2419:Earth-242:Earth-24201:Earth-24221:Earth-24388:Earth-24838:Earth-24883:Earth-25:Earth-25158:Earth-253:Earth-2530:Earth-2532:Earth-25401:Earth-26:Earth-2600:Earth-26111:Earth-262626:Earth-26292:Earth-26320:Earth-26410:Earth-26431:Earth-26496:Earth-267:Earth-26749:Earth-27:Earth-2713:Earth-27536:Earth-27538:Earth-2772:Earth-2775:Earth-28019:Earth-2803:Earth-28121:Earth-2814:Earth-2818:Earth-2819:Earth-28348:Earth-28384:Earth-2841:Earth-28438:Earth-28483:Earth-28578:Earth-28744923048932:Earth-28758:Earth-28834:Earth-28843:Earth-28857:Earth-28875:Earth-28901:Earth-28909:Earth-28918:Earth-28927:Earth-29007:Earth-29011:Earth-29018:Earth-29101:Earth-29110:Earth-2912:Earth-29180:Earth-2920:Earth-29234:Earth-29283:Earth-2937:Earth-295:Earth-2988:Earth-2991:Earth-2992:Earth-3010:Earth-30122:Earth-3015:Earth-3031:Earth-305:Earth-3062:Earth-3071:Earth-30826:Earth-30847:Earth-30987:Earth-3100:Earth-311:Earth-31117:Earth-3112:Earth-31128:Earth-31198:Earth-312:Earth-31220:Earth-31223:Earth-3123:Earth-312500:Earth-3131:Earth-31310:Earth-313710:Earth-31393:Earth-31411:Earth-3145:Earth-31913:Earth-31916:Earth-32000:Earth-32012:Earth-3208:Earth-32081:Earth-32098:Earth-32125:Earth-32201:Earth-32323:Earth-3290:Earth-33:Earth-33 1/3:Earth-33124:Earth-33600:Earth-33629:Earth-33734:Earth-33900:Earth-341983:Earth-3459:Earth-3470:Earth-34828:Earth-3488:Earth-34882:Earth-3490:Earth-3492:Earth-34922:Earth-35125:Earth-3514:Earth-3515:Earth-355:Earth-35525:Earth-36:Earth-36231:Earth-36310:Earth-37072:Earth-371:Earth-374:Earth-3752:Earth-38119:Earth-3839:Earth-38909:Earth-3913:Earth-39259:Earth-3931:Earth-3933:Earth-3971:Earth-398:Earth-39811:Earth-4:Earth-400005:Earth-400083:Earth-40081:Earth-4011:Earth-40121:Earth-4023:Earth-40238:Earth-4040:Earth-40616:Earth-4080:Earth-40800:Earth-4096:Earth-4100:Earth-41001:Earth-4103:Earth-41101:Earth-41210:Earth-41222:Earth-41301:Earth-41483:Earth-4162:Earth-41620:Earth-4191:Earth-42015:Earth-421:Earth-4210:Earth-42122:Earth-42212:Earth-42221:Earth-42409:Earth-42413:Earth-42466:Earth-42610:Earth-4263:Earth-42777:Earth-4280:Earth-4290001:Earth-42992:Earth-4321:Earth-43312:Earth-4392:Earth-4400:Earth-449:Earth-45:Earth-45017:Earth-45162:Earth-45201:Earth-4542:Earth-45828:Earth-460:Earth-46031:Earth-46102:Earth-46127:Earth-47004:Earth-47111:Earth-4732:Earth-47322:Earth-47385383:Earth-4811:Earth-483:Earth-48909:Earth-4904:Earth-49121:Earth-4935:Earth-49487:Earth-4972:Earth-50101:Earth-5012:Earth-5013:Earth-5014:Earth-5019:Earth-5021:Earth-50302:Earth-50358:Earth-50701:Earth-5106:Earth-5113:Earth-51212:Earth-51412:Earth-51489:Earth-51518:Earth-51778:Earth-51834:Earth-51910:Earth-51914:Earth-51920:Earth-51977:Earth-520:Earth-5200:Earth-52012:Earth-5202:Earth-5211:Earth-522:Earth-523:Earth-523000:Earth-523001:Earth-523002:Earth-523003:Earth-523004:Earth-5309:Earth-5311:Earth-534834:Earth-538:Earth-53882:Earth-5391:Earth-53931:Earth-54201:Earth-5421:Earth-5423:Earth-5464:Earth-54828:Earth-55:Earth-5511:Earth-55133:Earth-552:Earth-5521:Earth-555:Earth-555326:Earth-5555:Earth-5556:Earth-5560:Earth-5582:Earth-55921:Earth-5631:Earth-5682:Earth-5692:Earth-5700:Earth-5701:Earth-5724:Earth-57288:Earth-57289:Earth-5764:Earth-57780:Earth-57828:Earth-57882:Earth-58161:Earth-58162:Earth-58163:Earth-58460:Earth-58470:Earth-58472:Earth-58627:Earth-58732:Earth-58942:Earth-5905:Earth-59433:Earth-59462:Earth-59661:Earth-59662:Earth-59663:Earth-597:Earth-59882:Earth-600001:Earth-600026:Earth-600043:Earth-6001:Earth-600123:Earth-60026:Earth-60059:Earth-60166:Earth-6023:Earth-60241:Earth-6025:Earth-602636:Earth-60672:Earth-6077:Earth-6078:Earth-60808:Earth-6091:Earth-6095:Earth-61011:Earth-61018:Earth-61029:Earth-6109:Earth-61108:Earth-6111:Earth-61112:Earth-6120:Earth-61211:Earth-6124:Earth-6141:Earth-61422:Earth-616:Earth-61610:Earth-617:Earth-6175:Earth-61828:Earth-6195:Earth-620021:Earth-62111:Earth-6215:Earth-6216:Earth-6232:Earth-62412:Earth-62882:Earth-6297:Earth-62992:Earth-6309:Earth-6311:Earth-63124:Earth-6315:Earth-63410:Earth-634962:Earth-635972:Earth-6375:Earth-6381:Earth-64087:Earth-6451:Earth-645978:Earth-6466:Earth-64894:Earth-65:Earth-6513:Earth-652975:Earth-653:Earth-6590:Earth-6606:Earth-66209:Earth-665:Earth-666:Earth-6676:Earth-669116:Earth-67:Earth-6706:Earth-6716:Earth-6730:Earth-6799:Earth-68091:Earth-689:Earth-68994:Earth-691:Earth-69413:Earth-6966:Earth-697064:Earth-69798:Earth-69901:Earth-6993:Earth-700:Earth-700029:Earth-700089:Earth-70019:Earth-700459:Earth-700974:Earth-70105:Earth-701306:Earth-70134:Earth-70213:Earth-70237:Earth-70395:Earth-7041:Earth-7044:Earth-704509:Earth-70518:Earth-70701:Earth-70766:Earth-70813:Earth-7082:Earth-7085:Earth-709077:Earth-70915:Earth-71002:Earth-71004:Earth-71016:Earth-71121:Earth-71124:Earth-7116:Earth-71166:Earth-712:Earth-71202:Earth-7121:Earth-7122:Earth-71224:Earth-7123:Earth-7124:Earth-71241:Earth-71246:Earth-714:Earth-7140:Earth-7144:Earth-715:Earth-7153:Earth-7161:Earth-71612:Earth-717:Earth-71778:Earth-7187:Earth-71912:Earth-7192:Earth-721:Earth-7212:Earth-7231:Earth-725:Earth-727:Earth-72911:Earth-7305:Earth-730784:Earth-730834:Earth-730911:Earth-7316:Earth-73595:Earth-741:Earth-74101:Earth-74121:Earth-744:Earth-74425:Earth-7475:Earth-7481:Earth-7484:Earth-74897:Earth-7490:Earth-75011:Earth-7511:Earth-751263:Earth-7528:Earth-7580:Earth-760207:Earth-7614:Earth-76216:Earth-76292:Earth-763:Earth-7642:Earth-7643:Earth-77013:Earth-770724:Earth-77105:Earth-7711:Earth-77119:Earth-7712:Earth-772:Earth-77211:Earth-7736:Earth-774:Earth-776:Earth-7794:Earth-77995:Earth-7812:Earth-78127:Earth-78227:Earth-7831:Earth-78327:Earth-7840:Earth-78411:Earth-7848:Earth-788:Earth-7888:Earth-78909:Earth-78922:Earth-78927:Earth-7901:Earth-791:Earth-7910:Earth-79101:Earth-79102:Earth-791021:Earth-791218:Earth-7918:Earth-79213:Earth-7930:Earth-794:Earth-7940:Earth-794282:Earth-7958:Earth-7964:Earth-797:Earth-79715:Earth-79816:Earth-800801:Earth-8009:Earth-8013:Earth-802:Earth-8020:Earth-80219:Earth-803:Earth-80324:Earth-80360:Earth-8038:Earth-804:Earth-8041:Earth-80521:Earth-80522:Earth-807128:Earth-80734:Earth-808:Earth-808122:Earth-80827:Earth-80911:Earth-80920:Earth-8096:Earth-8101:Earth-81029:Earth-81049:Earth-8107:Earth-811:Earth-8110:Earth-81101:Earth-81114:Earth-81122:Earth-81124:Earth-81141:Earth-81143:Earth-81156:Earth-8116:Earth-81191:Earth-8121:Earth-81211:Earth-81212:Earth-812145:Earth-81223:Earth-81225:Earth-81289:Earth-8130:Earth-81304:Earth-813191:Earth-81426:Earth-8149:Earth-81518:Earth-81551:Earth-81727:Earth-8180:Earth-8181:Earth-81834:Earth-818793:Earth-81999:Earth-820231:Earth-8206:Earth-8207:Earth-82081:Earth-821:Earth-82100:Earth-82101:Earth-8212:Earth-82121:Earth-821236:Earth-8222:Earth-8234:Earth-82348:Earth-82432:Earth-82528:Earth-82568:Earth-82578:Earth-82588:Earth-82618:Earth-82633:Earth-82648:Earth-8270:Earth-8280:Earth-82801:Earth-82802:Earth-82803:Earth-82804:Earth-82805:Earth-82806:Earth-82807:Earth-82808:Earth-82809:Earth-82810:Earth-82811:Earth-82812:Earth-82814:Earth-82815:Earth-82816:Earth-82817:Earth-82818:Earth-82819:Earth-82820:Earth-82821:Earth-82822:Earth-82823:Earth-82824:Earth-82825:Earth-82826:Earth-82827:Earth-82828:Earth-82829:Earth-82831:Earth-82832:Earth-82833:Earth-82834:Earth-829:Earth-82910:Earth-83036:Earth-83042:Earth-83088:Earth-8310:Earth-8311:Earth-8312:Earth-831911:Earth-8320:Earth-8321:Earth-83234:Earth-8327:Earth-833:Earth-8336:Earth-8342:Earth-83438:Earth-83482:Earth-8351:Earth-83600:Earth-8377:Earth-83840:Earth-8386:Earth-839:Earth-8396:Earth-84041:Earth-8406:Earth-840645:Earth-8408:Earth-8410:Earth-841047:Earth-8413:Earth-8417:Earth-84243:Earth-84309:Earth-84341:Earth-8436:Earth-8441:Earth-84444:Earth-8454:Earth-846:Earth-8466:Earth-84929:Earth-84999:Earth-8501:Earth-8510:Earth-85133:Earth-8545:Earth-85826:Earth-8591:Earth-86082:Earth-8610:Earth-8648:Earth-8649:Earth-86501:Earth-8657:Earth-8666:Earth-869371:Earth-87050:Earth-8710:Earth-8720:Earth-873:Earth-8734:Earth-8753:Earth-8763:Earth-8810:Earth-8812:Earth-88194:Earth-88197:Earth-8823:Earth-88234:Earth-88255:Earth-88263:Earth-88292:Earth-8834:Earth-8861:Earth-88896:Earth-889:Earth-8901:Earth-8908:Earth-8909:Earth-8910:Earth-89110:Earth-89112:Earth-8912:Earth-89120:Earth-89121:Earth-89122:Earth-89123:Earth-89124:Earth-89125:Earth-89145:Earth-892:Earth-89721:Earth-89771:Earth-8982:Earth-89923:Earth-89946:Earth-89947:Earth-9:Earth-900:Earth-9002:Earth-9006:Earth-900651:Earth-9009:Earth-9010:Earth-9011:Earth-90110:Earth-90111:Earth-90113:Earth-9012:Earth-901220:Earth-901237:Earth-9013:Earth-9014:Earth-9019:Earth-902:Earth-90200:Earth-90202:Earth-90203:Earth-9021:Earth-90211:Earth-902124:Earth-90213:Earth-90214:Earth-90221:Earth-90227:Earth-90231:Earth-90251:Earth-90266:Earth-9031:Earth-9032:Earth-90324:Earth-9033:Earth-9034:Earth-904:Earth-90411:Earth-9047:Earth-904913:Earth-905:Earth-9051:Earth-90512:Earth-906:Earth-9061:Earth-90613:Earth-90631:Earth-90659:Earth-907:Earth-90764:Earth-90816:Earth-909:Earth-9090:Earth-90907:Earth-9091:Earth-9092:Earth-9093:Earth-9094:Earth-9095:Earth-90984:Earth-9105:Earth-9108:Earth-91101:Earth-9111:Earth-91110:Earth-91111:Earth-91112:Earth-91119:Earth-9112:Earth-91122:Earth-91126:Earth-91172:Earth-9119:Earth-912:Earth-91210:Earth-91240:Earth-91274:Earth-913:Earth-91313:Earth-9134:Earth-9140:Earth-91418:Earth-9142:Earth-9151:Earth-91600:Earth-917:Earth-91731:Earth-919:Earth-9192:Earth-920:Earth-9200:Earth-9201:Earth-9202:Earth-9204:Earth-92051:Earth-9209:Earth-920942:Earth-921:Earth-92100:Earth-92101:Earth-92110:Earth-92124:Earth-92130:Earth-92131:Earth-92164:Earth-92201:Earth-92202:Earth-92207:Earth-92210:Earth-922349:Earth-92272:Earth-9230:Earth-92300:Earth-92323:Earth-92335:Earth-92352:Earth-924:Earth-9246:Earth-9250:Earth-9251:Earth-9260:Earth-92700:Earth-928:Earth-92800:Earth-929:Earth-9290:Earth-9291:Earth-92942:Earth-93027:Earth-93031:Earth-93060:Earth-93070:Earth-93074:Earth-9309:Earth-93091:Earth-931113:Earth-93112:Earth-93122:Earth-93124:Earth-93165:Earth-931811:Earth-932:Earth-9339:Earth-934:Earth-93411:Earth-93437:Earth-93545:Earth-9356:Earth-93563:Earth-93600:Earth-938:Earth-939:Earth-9390:Earth-9391:Earth-94:Earth-94000:Earth-94001:Earth-94024:Earth-94040:Earth-94041:Earth-94042:Earth-941066:Earth-9411:Earth-9413:Earth-94157:Earth-9418:Earth-9421:Earth-94241:Earth-943:Earth-944:Earth-9442:Earth-94561:Earth-94600:Earth-94626:Earth-94689:Earth-947:Earth-9470:Earth-9471:Earth-94831:Earth-94964:Earth-9500:Earth-95019:Earth-95022:Earth-95099:Earth-9510:Earth-9511:Earth-9512:Earth-95120:Earth-95121:Earth-95122:Earth-95126:Earth-95169:Earth-952:Earth-9528:Earth-95313:Earth-9532:Earth-95371:Earth-95397:Earth-956:Earth-9561:Earth-957:Earth-957145:Earth-9575:Earth-9576:Earth-958:Earth-9586:Earth-9590:Earth-9591:Earth-9601:Earth-9602:Earth-96020:Earth-96099:Earth-9610:Earth-9611:Earth-96111:Earth-961116:Earth-96115:Earth-9612:Earth-961212:Earth-96173:Earth-96190:Earth-9620:Earth-96211:Earth-96282:Earth-96283:Earth-9640:Earth-9655:Earth-96585:Earth-9666:Earth-967:Earth-9670:Earth-9684:Earth-969:Earth-9691:Earth-97061:Earth-97082:Earth-97102:Earth-971023:Earth-97103:Earth-9711:Earth-971123:Earth-97113:Earth-9712:Earth-971224:Earth-97143:Earth-97161:Earth-97193:Earth-97214:Earth-9722:Earth-97292:Earth-973:Earth-97315:Earth-97400:Earth-97416:Earth-97517:Earth-97534:Earth-97567:Earth-97597:Earth-976:Earth-97618:Earth-97751:Earth-97799:Earth-97820:Earth-97899:Earth-979:Earth-9791:Earth-9792:Earth-9793:Earth-9796:Earth-98:Earth-9801:Earth-9806:Earth-980681:Earth-9809:Earth-98091:Earth-9810:Earth-98101:Earth-98105:Earth-9811:Earth-98111:Earth-9812:Earth-98120:Earth-98121:Earth-98125:Earth-9815:Earth-98193:Earth-982:Earth-9828:Earth-983:Earth-983107:Earth-98311:Earth-985:Earth-98529:Earth-98570:Earth-98630:Earth-987:Earth-98702:Earth-9871:Earth-9881:Earth-989:Earth-9890:Earth-9891:Earth-989112:Earth-989192:Earth-9904:Earth-99062:Earth-9907:Earth-991:Earth-9910:Earth-9916:Earth-9921:Earth-9922:Earth-9927:Earth-9930:Earth-99315:Earth-9939:Earth-99476:Earth-9966:Earth-99751:Earth-998:Earth-999:Earth-9991:Earth-9992:Earth-9997:Earth-BW09:Earth-BW16:Earth-Glaxo Inc:Earth-Mars Colony 2011:Earth-Mesozoic24:Earth-N:Earth-Shi:Earth-TRN001:Earth-TRN003:Earth-TRN005:Earth-TRN006:Earth-TRN007:Earth-TRN008:Earth-TRN009:Earth-TRN010:Earth-TRN011:Earth-TRN012:Earth-TRN017:Earth-TRN018:Earth-TRN020:Earth-TRN022:Earth-TRN023:Earth-TRN025:Earth-TRN032:Earth-TRN033:Earth-TRN034:Earth-TRN035:Earth-TRN037:Earth-TRN038:Earth-TRN041:Earth-TRN042:Earth-TRN043:Earth-TRN044:Earth-TRN045:Earth-TRN047:Earth-TRN048:Earth-TRN049:Earth-TRN064:Earth-TRN080:Earth-TRN113:Earth-TRN116:Earth-TRN117:Earth-TRN118:Earth-TRN122:Earth-TRN125:Earth-TRN127:Earth-TRN129:Earth-TRN130:Earth-TRN131:Earth-TRN133:Earth-TRN135:Earth-TRN136:Earth-TRN137:Earth-TRN143:Earth-TRN148:Earth-TRN150:Earth-TRN157:Earth-TRN160:Earth-TRN161:Earth-TRN163:Earth-TRN165:Earth-TRN166:Earth-TRN167:Earth-TRN168:Earth-TRN169:Earth-TRN171:Earth-TRN172:Earth-TRN173:Earth-TRN174:Earth-TRN175:Earth-TRN178:Earth-TRN182:Earth-TRN183:Earth-TRN192:Earth-TRN193:Earth-TRN194:Earth-TRN196:Earth-TRN199:Earth-TRN201:Earth-TRN202:Earth-TRN203:Earth-TRN204:Earth-TRN205:Earth-TRN206:Earth-TRN207:Earth-TRN214:Earth-TRN215:Earth-TRN217:Earth-TRN218:Earth-TRN219:Earth-TRN220:Earth-TRN221:Earth-TRN222:Earth-TRN223:Earth-TRN224:Earth-TRN225:Earth-TRN234:Earth-TRN237:Earth-TRN238:Earth-TRN240:Earth-TRN241:Earth-TRN242:Earth-TRN243:Earth-TRN245:Earth-TRN246:Earth-TRN249:Earth-TRN251:Earth-TRN253:Earth-TRN254:Earth-TRN255:Earth-TRN257:Earth-TRN258:Earth-TRN263:Earth-TRN269:Earth-TRN271:Earth-TRN273:Earth-TRN277:Earth-TRN278:Earth-TRN279:Earth-TRN280:Earth-TRN281:Earth-TRN282:Earth-TRN285:Earth-TRN286:Earth-TRN287:Earth-TRN288:Earth-TRN289:Earth-TRN290:Earth-TRN291:Earth-TRN292:Earth-TRN293:Earth-TRN294:Earth-TRN295:Earth-TRN296:Earth-TRN297:Earth-TRN298:Earth-TRN299:Earth-TRN300:Earth-TRN301:Earth-TRN302:Earth-TRN303:Earth-TRN304:Earth-TRN306:Earth-TRN307:Earth-TRN308:Earth-TRN310:Earth-TRN312:Earth-TRN313:Earth-TRN314:Earth-TRN317:Earth-TRN318:Earth-TRN319:Earth-TRN321:Earth-TRN322:Earth-TRN323:Earth-TRN324:Earth-TRN332:Earth-TRN334:Earth-TRN335:Earth-TRN337:Earth-TRN338:Earth-TRN339:Earth-TRN342:Earth-TRN343:Earth-TRN344:Earth-TRN345:Earth-TRN346:Earth-TRN348:Earth-TRN349:Earth-TRN350:Earth-TRN351:Earth-TRN352:Earth-TRN353:Earth-TRN354:Earth-TRN356:Earth-TRN361:Earth-TRN362:Earth-TRN363:Earth-TRN365:Earth-TRN372:Earth-TRN375:Earth-TRN376:Earth-TRN379:Earth-TRN381:Earth-TRN382:Earth-TRN387:Earth-TRN388:Earth-TRN389:Earth-TRN391:Earth-TRN392:Earth-TRN393:Earth-TRN400:Earth-TRN404:Earth-TRN405:Earth-TRN406:Earth-TRN407:Earth-TRN408:Earth-TRN409:Earth-TRN410:Earth-TRN411:Earth-TRN412:Earth-TRN413:Earth-TRN414:Earth-TRN416:Earth-TRN417:Earth-TRN419:Earth-TRN420:Earth-TRN421:Earth-TRN422:Earth-TRN423:Earth-TRN425:Earth-TRN426:Earth-TRN427:Earth-TRN428:Earth-TRN429:Earth-TRN430:Earth-TRN431:Earth-TRN432:Earth-TRN433:Earth-TRN434:Earth-TRN435:Earth-TRN436:Earth-TRN437:Earth-TRN438:Earth-TRN439:Earth-TRN440:Earth-TRN446:Earth-TRN453:Earth-TRN454:Earth-TRN455:Earth-TRN456:Earth-TRN457:Earth-TRN458:Earth-TRN459:Earth-TRN460:Earth-TRN461:Earth-TRN476:Earth-TRN478:Earth-TRN480:Earth-TRN481:Earth-TRN482:Earth-TRN483:Earth-TRN484:Earth-TRN490:Earth-TRN491:Earth-TRN501:Earth-TRN502:Earth-TRN503:Earth-TRN509:Earth-TRN510:Earth-TRN513:Earth-TRN515:Earth-TRN517:Earth-TRN518:Earth-TRN520:Earth-TRN521:Earth-TRN522:Earth-TRN523:Earth-TRN524:Earth-TRN526:Earth-TRN533:Earth-TRN547:Earth-TRN550:Earth-TRN554:Earth-TRN556:Earth-TRN558:Earth-TRN559:Earth-TRN560:Earth-TRN561:Earth-TRN562:Earth-TRN563:Earth-TRN564:Earth-TRN565:Earth-TRN566:Earth-TRN567:Earth-TRN568:Earth-TRN573:Earth-TRN574:Earth-TRN576:Earth-TRN577:Earth-TRN578:Earth-TRN579:Earth-TRN580:Earth-TRN581:Earth-TRN582:Earth-TRN583:Earth-TRN588:Earth-TRN589:Earth-TRN590:Earth-TRN591:Earth-TRN599:Earth-TRN603:Earth-TRN604:Earth-TRN605:Earth-TRN609:Earth-TRN619:Earth-TRN621:Elsewhen:Eurth:Immortus Servant:Mojoverse:Multiverse:Omniverse:Otherworld:Panoptichron:Sachs & Violens:Saturnyne:Special Executive:Technet:Temporal Limbo:Utopian Parallel:War Toy:Weirdworld:,numeric:numeric:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:,
Wine Reviews , zackthoutt , www.kaggle.com/zynicide/wine-reviews , Thu Jun 22 2017 22:17:00 GMT+0530 (IST) , 150k wine reviews with variety location winery price and description ,1094, critical theory- food and drink- ,Context After watching Somm (a documentary on master sommeliers) I wondered how I could create a predictive model to identify wines through blind tasting like a master sommelier would. The first step in this journey was gathering some data to train a model. I plan to use deep learning to predict the wine variety using words in the description/review. The model still won't be able to taste the wine but theoretically it could identify the wine based on a description that a sommelier could give. If anyone has any ideas on how to accomplish this please post them! Content The data consists of 10 fields  Points the number of points WineEnthusiast rated the wine on a scale of 1-100 (though they say they only post reviews for wines that score >=80) Variety the type of grapes used to make the wine (ie Pinot Noir) Description a few sentences from a sommelier describing the wine's taste smell look feel etc. Country the country that the wine is from Province the province or state that the wine is from Region 1 the wine growing area in a province or state (ie Napa) Region 2 sometimes there are more specific regions specified within a wine growing area (ie Rutherford inside the Napa Valley) but this value can sometimes be blank Winery the winery that made the wine Designation the vineyard within the winery where the grapes that made the wine are from Price the cost for a bottle of the wine   Acknowledgements The data was scraped from WineEnthusiast during the week of June 15th 2017. The code for the scraper can be found here if you have any more specific questions about data collection that I didn't address. Inspiration I think that this dataset offers some great opportunities for sentiment analysis and other text related predictive models. My overall goal is to create a model that can identify the variety winery and location of a wine based on a description. If anyone has any ideas breakthroughs or other interesting insights/models please post them.,:country:description:designation:points:price:province:region_1:region_2:variety:winery:,numeric:string:string:string:numeric:numeric:string:string:string:string:string:,
Tobacco Use 1995-2010 , Centers for Disease Control and Prevention , www.kaggle.com/cdc/tobacco-use , Thu Nov 17 2016 10:39:41 GMT+0530 (IST) , Prevalence and Trends: Four Level Smoking Data ,1203, health- ,Context This dataset contains the prevalence and trends of tobacco use for 1995-2010. Percentages are weighted to population characteristics. Data are not available if it did not meet Behavioral Risk Factor Surveillance System (BRFSS) stability requirements. For more information on these requirements as well as risk factors and calculated variables see the Technical Documents and Survey Data for a specific year - http//www.cdc.gov/brfss/annual_data/annual_data.htm.  Content This dataset has 7 variables  Year State Smoke everyday Smoke some days Former smoker Never smoked Location 1  Acknowledgements The original dataset can be found here. Recommended citation Centers for Disease Control and Prevention (CDC). Behavioral Risk Factor Surveillance System. Atlanta Georgia U.S. Department of Health and Human Services Centers for Disease Control and Prevention [appropriate year]. Inspiration  How does tobacco use change over time? Does tobacco use differ by state? ,Year:State:Smoke everyday:Smoke some days:Former smoker:Never smoked:Location 1:,numeric:string:string:string:string:string:string:,
Board Game Data , mrpantherson , www.kaggle.com/mrpantherson/board-game-data , Fri Jun 16 2017 00:04:00 GMT+0530 (IST) , Data is a collection of board game information from Board Game Geek ,835, board games- ,Context Being a fan of board games I wanted to see if there was any correlation with a games rating and any particular quality the first step was to collect of this data. Content The data was collected in March of 2017 from the website https//boardgamegeek.com/ this site has an API to retrieve game information (though sadly XML not JSON). Acknowledgements Mainly I want to thank the people who run the board game geek website for maintaining such a great resource for those of us in the hobby. Inspiration I wish I had some better questions to ask of the data perhaps somebody else can think of some good ways to get some insight of this dataset.,rank:bgg_url:game_id:names:min_players:max_players:avg_time:min_time:max_time:year:avg_rating:geek_rating:num_votes:image_url:age:mechanic:owned:category:designer:weight:,numeric:string:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:string:numeric:string:string:numeric:,
Kabaddi World Cup 2016 , MANOJKUMAR PARMAR , www.kaggle.com/parmarmanojkumar/kabaddi-world-cup-2016 , Mon Oct 02 2017 22:19:08 GMT+0530 (IST) , 2016 Kabaddi World Cup the third standard-style Kabaddi World Cup dataset ,109, sports- ,Context Kabaddi is a contact sport that originated in ancient India. more information The standard style Kabaddi World Cup is an indoor international kabaddi competition conducted by the International Kabaddi Federation (IKF)contested by men's and women's national teams. The competition has been previously contested in 2004 2007 and 2016. All the tournaments have been won by India. more information The 2016 Kabaddi World Cup the third standard-style Kabaddi World Cup was an international kabaddi tournament governed by the International Kabaddi Federation contested from 7 to 22 October 2016 in Ahmedabad India. Twelve countries had competed in the tournament. more information 30 league matches played between teams. teams were deivided in 2 pools with 6 team in each pool. Top 2 teams from each team were qualifid for semifinals and winner of semifianls played in finals. This dataset contains data for all 33 matches at granualirity level of attack defense allout and extra points. Data set also includes toss results super tackle count and all out count along with match results. Content This dataset was manually prepared from taking necessary statistics from Kabaddi world cup site. Points acquired as per rules are main statistics.   This dataset contains necessary statistics  in today format and details of all variables are as per following.  gameNo  Match number. Sequential {Integer} team  Team name {Factor} oppTeam  Opposition team name {Factor} matchStage  Tournament stage at which match was played. (0 - League 1 - SemiFinal 2 - Final ) {Factor} tossResult  Results of toss to select either side or raid (0 - Loss 1 - Win) {Factor} alloutRec  No. of time team was all out yielding 2 point {Integer} alloutGiv  No. of time opposition team was all out yielding 2 point {Integer} sTackleRec  No. of times super tackle by team yielding 2 point {Integer} sTackleGiv  No. of times super tackle by opposition team yielding 2 point {Integer} touchPntsRec  No. of times player in raid touched opposition team player yiedling 1 point for every touch {Integer} touchPntsGiv  No. of times opposition player in raid touched team player yiedling 1 point for every touch {Integer} bonusPntsRec  No. of times player in raid crossed bonus line yiedling 1 point for every raid {Integer} bonusPntsGiv  No. of times opposition player in raid crossed bonus line yiedling 1 point for every raid {Integer} raidPntsRec  No. of total raid (attack) points by team sum of touch points and bonus points {Integer} raidPntsGiv  No. of total raid (attack) points by opposition team sum of touch points and bonus points {Integer} tacklePntsRec  No. of tackle (defense) points received by team yielding 1 point for normal tackle and 2 points for super tackle {Integer} tacklePntsGiv  No. of tackle (defense) points received by opposition team yielding 1 point for normal tackle and 2 points for super tackle {Integer} alloutPntsRec  No. of all out points received by team yielding 2 points per allout  {Integer} alloutPntsGiv  No. of all out points received by opposition team yielding 2 points per allout {Integer} extraPntsRec  No. of extra (technical penalty) points received by team {Integer} extraPntsGiv  No. of extra (technical penalty) points received by opposition team  {Integer} totalPntsRec  No. of total points received by team sum of raid points tackle points allout points & extra points {Integer} totalPntsGiv  No. of total points received by opposition team sum of raid points tackle points allout points & extra points {Integer} touchPntsDiff  No. of touch points difference from opposition team {Integer} bonusPntsDiff  No. of bonus points difference from opposition team {Integer} raidPntsDiff  No. of raid points difference from opposition team {Integer} tacklePntsDiff  No. of tackle points difference from opposition team {Integer} alloutPntsDiff  No. of allout points difference from opposition team {Integer} extraPntsDiff  No. of extra points difference from opposition team {Integer} totalPntsDiff  No. of total points difference from opposition team {Integer} matchResults  Results of the match (0 - Loss 1 - Win) {Factor}  Acknowledgements I would like to thank Kabaddi World Cup site for providing this data. Inspiration This dataset was prepared for my research paper which aims to answer following questions  Is attack is better than defence? Does bonus point lead to victory? What is the role of all out points on determining strength of attack? Can we build predictive model for winning? How strong establish teams are compared to new teams? ,gameNo:team:oppTeam:matchStage:tossResult:alloutRec:alloutGiv:sTackleRec:sTackleGiv:touchPntsRec:touchPntsGiv:bonusPntsRec:bonusPntsGiv:raidPntsRec:raidPntsGiv:tacklePntsRec:tacklePntsGiv:alloutPntsRec:alloutPntsGiv:extraPntsRec:extraPntsGiv:totalPntsRec:totalPntsGiv:touchPntsDiff:bonusPntsDiff:raidPntsDiff:tacklePntsDiff:alloutPntsDiff:extraPntsDiff:totalPntsDiff:matchResult:,numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
NBA Players stats since 1950 , DrGuillermo , www.kaggle.com/drgilermo/nba-players-stats , Tue Jun 06 2017 12:07:46 GMT+0530 (IST) , 3000+ Players over 60+ Seasons and 50+ features per player ,1405, basketball- ,Content The data-set contains aggregate individual statistics for 67 NBA seasons. from basic box-score attributes such as points assists rebounds etc. to more advanced money-ball like features such as Value Over Replacement. Acknowledgements The data was scraped from Basketball-reference Take a look in their glossary for a detailed column description Glossary,:Player:height:weight:collage:born:birth_city:birth_state:,numeric:string:numeric:numeric:string:numeric:string:string:,
Poverty and Equity Database , World Bank , www.kaggle.com/theworldbank/poverty-and-equity-database , Fri Nov 25 2016 04:56:43 GMT+0530 (IST) , Poverty and Inequality Indicators from International Sources ,585, income- international relations- ,Context Latest poverty and inequality indicators compiled from officially recognized international sources. Poverty indicators include the poverty headcount ratio poverty gap and number of poor at both international and national poverty lines. Inequality indicators include the Gini index and income or consumption distributions. The database includes national regional and global estimates. Content This dataset contains country names and indicator variables from 1974 until 2015. Additional materials and detailed descriptions of the datasets can be downloaded from here. Acknowledgement The original datasets and data dictionaries can be found here. Inspiration Some ideas for exploring the dataset  How does the poverty headcount ratio differ across countries? Can you visualize the temporal trend? Which countries have the highest or lowest GINI index as estimated by the World Bank? Is this indicator correlated with other indicators such as urban/rural poverty or income status? ,,,
Global Social Survey Programs: 1948-2014 , sdorius , www.kaggle.com/sdorius/gssi2017 , Tue Apr 18 2017 21:19:35 GMT+0530 (IST) , Analyze the worldwide  expansion of the social survey from 1948-2014 ,87, research- history- international relations- ,BACKGROUND The survey stands out as one of the most significant methodological innovations in the history of the social sciences. The instrument has made possible the efficient and reliable collection of measurements on individual attitudes beliefs values behaviors traits and states (Alwin 2009) and coupled with modern sampling techniques surveys have allowed researchers to generalize findings to much larger populations with remarkable precision. Survey data have helped governments to obtain essential descriptive information on for example their citizen’s living standards demographic attributes health status purchasing intentions. Such data have in turn been used to craft evidence-based social and economic policies more accurately forecast labor market participation and project population distributions and monitor poverty rates. Commercial firms especially those in the fields of market research and consumer behavior have also been influential in the development of methods and the production of designed data (Groves 2011). Social scientists use survey data to study a wide range of social economic political demographic and cultural topics and to collect measurements of voter preferences personality traits social networks and public opinions to name a few. Survey data are an essential component of evidence-based social policy-making and program monitoring and evaluation and vital tool for understanding the worldviews and aspirations of publics around the world. The progression of the social survey from its origins as a community and later national measuring device was attended by greater consensus and less variation in survey design and administration. Over the course of more than 60 years of cross-cultural survey research the standardized survey (Gobo and Mauceri 2014; Harkness 2010) became the de facto one with hallmark features including an almost exclusive reliance on input harmonized questionnaires and closed-ended questions English language parent survey back translated into local-language-administered surveys and best efforts at nationally representative sampling techniques that allow for generalization to in most cases the non-institutionalized adult population. With few exceptions survivor programs originated in rich western countries and among survey programs originating in non-western countries survey design and content has often been patterned after surveys designed to measure attitudes beliefs behaviors states and institutions endemic to western industrialized societies. This is not to say that cross-national survey programs are monolithic or lacking in variety of design content international membership and purposes.  THE DATA To get a clearer understanding of how the social survey has spread around the world over the last 60 years we collected information from just under 40 international survey programs and compiled it into a time-series data set that allows researchers to empirically evaluate the global social survey data infrastructure from a life-history perspective. Collectively these 40 survey programs have fielded over 7000 national social surveys comprising nearly 8 million completed interviews on a broad range of social economic and political topics.  Units of analysis in the data set are survey programs and national social surveys. Additional data about programs and surveys include samples sizes data collection methods fielding dates and countries surveyed to name a few. PARTICIPATING SOCIAL SURVEY PROGRAMS  How Nations See Each Other (HNSEO) Pattern of Human Concerns Data (PHCD) Civic Culture Study (CCS) Attitudes Toward Europe Study (ATE) Political Participation and Equality (PPE) Eurobarometer (EUROB) European Values Study (EVS) World Values Survey (WVS) International Social Survey Programme (ISSP) The Political Culture of Southern Europe (PCSE) Central and Eastern Eurobarometer (CEEB) Post-Communist Publics (PCP) New European Barometer (NEB) Comparative National Elections Project (CNEP) New Soviet Citizen Surveys (NSCS) Values and Political Change in Post-Communist Europe (VPCP) Latinobarometro (LATINB) Coping with Government in the Former Soviet Union (CGFE) Afrobarometer (AFROB) Asia Europe Survey (ASES) Voice of the People Surveys (VOTP) Asian Barometer (ASIANB) Candidate Countries Eurobarometer (CCEB) Comparative Study of Electoral Systems (CSES) European Social Survey (ESS) Pew Global Attitudes Surveys (PGAS) Worldviews 2002 (WORLD)* Asia Barometer (ASIAB) Transatlantic Trends Survey (TTS) AmericasBarometer (AMERAB) Arab Barometer (ARABB) East Asia Social Survey (EASS) The Globalization of Personal Data Project (GPD) A Quest for Citizenship in an Ever Closer Europe (INTUNE) Caucasus Barometer (CAUCAB) Transatlantic Trends Immigration (TTI) EU Neighbourhood Barometer (EUNB),survida:survidn:survproglab:survprogname:sampframe:wbid:unid:unidyear:wbidyear:year:wave:survversion:RegionUN:sampsize:Region5:Region6:Region7:Region10:continent:module:collectmode:collectlanguage:collectdates:weight:public:longitudinal:oldsurvid:popage:designeffect:marginerror:exclusion:nationalsurvey:resprate:founder:survecat:status:type:globbaro:active:progparent:oversampl:proglab:startyear:founder2:country:,string:numeric:string:string:string:string:string:numeric:string:numeric:numeric:numeric:string:numeric:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:string:numeric:numeric:string:string:string:string:string:string:string:numeric:numeric:string:string:string:numeric:string:string:,
UFC PPV Sales , DaveRosenman , www.kaggle.com/daverosenman/ufc-ppv-sales , Wed Aug 30 2017 04:14:39 GMT+0530 (IST) , Contains PPV Sales for UFC PPV's Dating Back to UFC 32 ,70, ,Context Dataset contains list of every UFC PPV event + the estimated number of PPV sales (source https//www.tapology.com/search/mma-event-figures/ppv-pay-per-view-buys-buyrate. Content UFC's 171 and 156 are missing because those events were cancelled. Acknowledgements Thanks to tapology.com for providing the raw data. Inspiration Your data will be in front of the world's largest data science community. What questions do you want to see answered?,Year:Month:Day:UFC_Number:Opponent1:Opponent2:PPV:,numeric:numeric:numeric:numeric:string:string:numeric:,
Periodic Table of Elements Mapped to Stocks , starmine.ai , www.kaggle.com/biomimic/periodic-table-of-elements-mapped-to-stocks , Thu May 25 2017 11:22:52 GMT+0530 (IST) , Elements & Minerals with known and hidden relationships to Stocks ,295, human medicine- chemistry- finance- ,Periodic Table of Elements & Minerals with known and hidden relationships to Stocks ETFs & Options  for additional signal boosting built with starmine.ai http//starmine.ai Rows contain stock symbols. Columns contain scores that represent known and hidden relationships between elements and stocks. How the scoring is calculated  What kind of things can be done with custom concept columns/features?   Create unique sectors or clusters based on concepts and hidden relationships and compare their gains to the S&P Determine if price correlations have similar concept or keyword    correlations Examine symbiotic parasitic and sympathetic relationships between    equities Automatically create baskets of stocks based on concepts and/or keywords Detach the custom columns and append them to other proprietary inhouse datasets Select a Data Context (e.g. Biological Chemical GeoPhysical and others) to derive different signals Use stock symbols as custom concept column labels and model cross-correlations between equities Create features using trending    terms anywhere on the internet ,Symbol:update-2017-04-01::concept:Hydrogen:concept:Helium:concept:Lithium:concept:Beryllium:concept:Boron:concept:Carbon:concept:Nitrogen:concept:Oxygen:concept:Fluorine:concept:Neon:concept:Sodium:concept:Magnesium:concept:Aluminum:concept:Silicon:concept:Phosphorus:concept:Sulfur:concept:Chlorine:concept:Argon:concept:Potassium:concept:Calcium:concept:Scandium:concept:Titanium:concept:Vanadium:concept:Chromium:concept:Manganese:concept:Iron:concept:Cobalt:concept:Nickel:concept:Copper:concept:Zinc:concept:Gallium:concept:Germanium:concept:Arsenic:concept:Selenium:concept:Bromine:concept:Krypton:concept:Rubidium:concept:Strontium:concept:Yttrium:concept:Zirconium:concept:Niobium:concept:Molybdenum:concept:Technetium:concept:Ruthenium:concept:Rhodium:concept:Palladium:concept:Silver:concept:Cadmium:concept:Indium:concept:Tin:concept:Antimony:concept:Tellurium:concept:Iodine:concept:Xenon:concept:Cesium:concept:Barium:concept:Lanthanum:concept:Cerium:concept:Praseodymium:concept:Neodymium:concept:Promethium:concept:Samarium:concept:Europium:concept:Gadolinium:concept:Terbium:concept:Dysprosium:concept:Holmium:concept:Erbium:concept:Thulium:concept:Ytterbium:concept:Lutetium:concept:Hafnium:concept:Tantalum:concept:Tungsten:concept:Rhenium:concept:Osmium:concept:Iridium:concept:Platinum:concept:Gold:concept:Mercury:concept:Thallium:concept:Lead:concept:Bismuth:concept:Polonium:concept:Astatine:concept:Radon:concept:Francium:concept:Radium:concept:Actinium:concept:Thorium:concept:Protactinium:concept:Uranium:concept:Neptunium:concept:Plutonium:concept:Americium:concept:Curium:concept:Berkelium:concept:Californium:concept:Einsteinium:concept:Fermium:concept:Mendelevium:concept:Nobelium:concept:Lawrencium:concept:Rutherfordium:concept:Dubnium:concept:Seaborgium:concept:Bohrium:concept:Hassium:concept:Meitnerium:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Top 500 Indian Cities , Arijit Mukherjee , www.kaggle.com/zed9941/top-500-indian-cities , Wed Dec 21 2016 15:41:07 GMT+0530 (IST) , What story do the top 500 cities of India tell to the world? ,2392, cities- sociology- ,Context I created this data set merging  the census 2011 of Indian Cities with Population more than 1 Lac and City wise number of Graduates from the Census 2011 to create a visualization of where the future cities of India stands today I will try to add more columns [ fertility rate religion distribution health standards number of schools Mortality rate ] in the future hope people will contribute. Content   Data of 500 Cities with population more than 1 Lac by Census 2011 'name_of_city'                   Name of the City  'state_code'                     State Code of the City 'state_name'                     State Name of the City 'dist_code'                      District Code where the city belongs ( 99 means multiple district )  'population_total'               Total Population 'population_male'                Male Population  'population_female'              Female Population '0-6_population_total'           0-6 Age Total Population '0-6_population_male'            0-6 Age Male Population '0-6_population_female'          0-6 Age Female Population 'literates_total'                Total Literates 'literates_male'                 Male Literates 'literates_female'               Female Literates  'sex_ratio'                      Sex Ratio  'child_sex_ratio'                Sex ratio in 0-6 'effective_literacy_rate_total'  Literacy rate over Age 7  'effective_literacy_rate_male'   Male Literacy rate over Age 7  'effective_literacy_rate_female' Female Literacy rate over Age 7  'location'                       LatLng 'total_graduates'                Total Number of Graduates 'male_graduates'                 Male Graduates  'female_graduates'               Female Graduates  Acknowledgements  Census 2011  http//censusindia.gov.in/2011-prov-results/paper2/data_files/India2/Table_2_PR_Cities_1Lakh_and_Above.xls  Google Geocoder for Location Fetching. Graduation Data Census 2011   http//www.censusindia.gov.in/2011census/C-series/DDWCT-0000C-08.xlsx Inspiration What story do the top 500 cities of India tell to the world? I wrote a post in my blog about the dataset . ,name_of_city:state_code:state_name:dist_code:population_total:population_male:population_female:0-6_population_total:0-6_population_male:0-6_population_female:literates_total:literates_male:literates_female:sex_ratio:child_sex_ratio:effective_literacy_rate_total:effective_literacy_rate_male:effective_literacy_rate_female:location:total_graduates:male_graduates:female_graduates:,string:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:,
NY Philharmonic Performance History , New York Philharmonic , www.kaggle.com/nyphil/perf-history , Wed Aug 16 2017 01:08:10 GMT+0530 (IST) , All Performances 1842-Present ,95, music- composers- musicians- ,Context The New York Philharmonic played its first concert on December 7 1842. Since then it has merged with the New York Symphony the New/National Symphony and had a long-running summer season at New York's Lewisohn Stadium. The Performance History database documents all known concerts of all of these organizations amounting to more than 20000 performances. Content Dataset is a single csv with over 800k rows. Data contains information on season orchestra venue date time conductor work title composer movement and soloists. Acknowledgements This dataset was compiled by the New York Philharmonic. Original json files hosted here. Original json files were flattened and joined on guid to form a single csv file. Image courtesy of Larisa Birta. Inspiration Nearly 175 years of performance history covering over 11k unique works--which composers are most popular? Have there been any trends in popularity by conductor or by season?,Date:Location:Time:Venue:eventType:season:programID:orchestra:id:,dateTime:string:dateTime:string:string:string:numeric:string:string:,
Twitter vs. Newsletter Impact , Rachael Tatman , www.kaggle.com/rtatman/twitter-vs-newsletter , Tue Sep 19 2017 01:51:24 GMT+0530 (IST) , Which format is best for getting the word out? ,87, marketing- internet- ,Context There are lots of really cool datasets getting added to Kaggle every day and as part of my job I want to help people find them. I’ve been tweeting about datasets on my personal Twitter accounts @rctatman and also releasing a weekly newsletter of interesting datasets. I wanted to know which method was more effective at getting the word out about new datasets Twitter or the newsletter? Content This dataset contains two .csv files. One has information on the impact of tweets with links to datasets while the other has information on the impact of the newsletter. Twitter The Twitter .csv has the following information  month The month of the tweet (1-12) day The day of the tweet (1-31) hour The hour of the tweet (1-24) impressions The number of impressions the tweet got engagement The number of total engagements clicks The number of URL clicks  Fridata Newsletter The Fridata .csv has the following information  date The Date the newsletter was sent out month The Month the newsletter was sent out (1-12) day The day the newsletter was sent out (1-31) # of dataset links How many links were in the newsletter recipients How many people received the email with the newsletter total opens How many times the newsletter was opened unique opens How many individuals opened the newsletter total clicks The total number of clicks on the newsletter unique clicks (unsure; provided by Tinyletter) notes notes on the newsletter  Acknowledgements This dataset was collected by the uploader Rachael Tatman. It is released here under a CC-BY-SA license. Inspiration  Which format receives more views? Which format receives more clicks? Which receives more clicks/view? What’s the best time of day to send a tweet? ,date:month:day:# of dataset links:recipients:total opens:unique opens:total clicks:unique clicks:notes:,dateTime:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:,
Diversity Index of US counties , Mike Johnson Jr , www.kaggle.com/mikejohnsonjr/us-counties-diversity-index , Mon Aug 22 2016 13:18:40 GMT+0530 (IST) , Simpson Diversity Index to quantify racial diversity of US counties ,678, demographics- ,Context Diversity of United States Counties Content Diversity Index of Every US County using the Simpson Diversity Index D = 1 - ∑(n/N)^2 (where n = number of people of a given race and N is the total number of people of all races to get the probability of randomly selecting two people and getting two people of different races (ecological entropy)),"Location:Diversity-Index:Black or African American alone, percent, 2013:American Indian and Alaska Native alone, percent, 2013:Asian alone, percent, 2013:Native Hawaiian and Other Pacific Islander alone, percent,:Two or More Races, percent, 2013:Hispanic or Latino, percent, 2013:White alone, not Hispanic or Latino, percent, 2013:",string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Chronic Disease Indicators , Centers for Disease Control and Prevention , www.kaggle.com/cdc/chronic-disease , Thu Aug 17 2017 23:31:41 GMT+0530 (IST) , Disease Data Across the US 2001-2016 ,209, human medicine- ,Context CDC's Division of Population Health provides cross-cutting set of 124 indicators that were developed by consensus and that allows states and territories and large metropolitan areas to uniformly define collect and report chronic disease data that are important to public health practice and available for states territories and large metropolitan areas. In addition to providing access to state-specific indicator data the CDI web site serves as a gateway to additional information and data resources. Content A variety of health-related questions were assessed at various times and places across the US over the past 15 years. Data is provided with confidence intervals and demographic stratification. Acknowledgements Data was compiled by the CDC. Inspiration  Any interesting trends in certain groups? Any correlation between disease indicators and locality hospital spending? ,YearStart:YearEnd:LocationAbbr:LocationDesc:DataSource:Topic:Question:Response:DataValueUnit:DataValueType:DataValue:DataValueAlt:DataValueFootnoteSymbol:DatavalueFootnote:LowConfidenceLimit:HighConfidenceLimit:StratificationCategory1:Stratification1:StratificationCategory2:Stratification2:StratificationCategory3:Stratification3:GeoLocation:ResponseID:LocationID:TopicID:QuestionID:DataValueTypeID:StratificationCategoryID1:StratificationID1:StratificationCategoryID2:StratificationID2:StratificationCategoryID3:StratificationID3:,numeric:numeric:string:string:string:string:string:string:string:string:numeric:numeric:string:string:numeric:numeric:string:string:string:string:string:string:string:string:numeric:string:string:string:string:string:string:string:string:string:,
Brazil's House of Deputies Reimbursements , epattaro , www.kaggle.com/epattaro/brazils-house-of-deputies-reimbursements , Fri Jan 27 2017 20:11:54 GMT+0530 (IST) , What Brazilian politicians spend 500000R$ (~160000USD) a year on ,351, brazil- finance- politics- ,"Context Brazilian politicians are entitled to refunds if they spend any of their money on an activity that is enabling them to ""better serve the people"". Those expenses are public data however there is little monitoring/data analysis of it. A quick look at it shows a deputy with over 800 flights in one year. Another deputy has over 140.000R$ expenses on mailing (old fashion mail) in one year. There are a lot of very suspicious data regarding the deputies expending behavior. Can you help spot outliers and companies charging unusual amounts of money for a service? Content Data is public. It was collected from the official government website http//www2.camara.leg.br/transparencia/cota-para-exercicio-da-atividade-parlamentar/dados-abertos-cota-parlamentar It was converted from xml to csv filtered out irrelevant columns and translated a few of the features to English. The uploaded data contains u'deputy_name' u'political_party'  u'deputy_state' u'company_name' u'company_id' u'refund_date' Inspiration Brazil is currently passing through thriving times. Its political group has always been public involved in many scandals but it is just now that a few brave men and women have started doing something about it. In 2016 we have had senators former ministers and many others formally charged and arrested for their crimes.",bugged_date:receipt_date:deputy_id:political_party:state_code:deputy_name:receipt_social_security_number:receipt_description:establishment_name:receipt_value:,numeric:dateTime:numeric:string:string:string:numeric:string:string:numeric:,
OpenAddresses - U.S. South , OpenAddresses , www.kaggle.com/openaddresses/openaddresses-us-south , Wed Aug 02 2017 04:13:31 GMT+0530 (IST) , Addresses and geo locations for the U.S. South ,92, ,Context OpenAddresses's goal is to connect the digital and physical worlds by sharing geographic coordinates street names house numbers and postal codes.  Content This dataset contains one datafile for each state in the U.S. South region (although some are arguably not in the South). States included in this dataset  Alabama - al.csv Arkansas - ar.csv Washington D.C. - dc.csv Delaware - de.csv Florida - fl.csv Georgia - ga.csv Kentucky - ky.csv Louisiana - la.csv Maryland - md.csv Mississippi - ms.csv North Carolina - nc.csv Oklahoma - ok.csv South carolina - sc.csv Tennessee - tn.csv Texas - tx.csv Virginia - va.csv West Virginia - wv.csv  Field descriptions  LON - Longitude LAT - Latitude NUMBER - Street number STREET - Street name UNIT - Unit or apartment number CITY - City name DISTRICT - ? REGION - ? POSTCODE - Postcode or zipcode ID - ? HASH - ?  Acknowledgements Data collected around 2017-07-25 by OpenAddresses (http//openaddresses.io). Address data is essential infrastructure. Street names house numbers and postal codes when combined with geographic coordinates are the hub that connects digital to physical places. Data licenses can be found in LICENSE.txt. Data source information can be found at https//github.com/openaddresses/openaddresses/tree/9ea72b079aaff7d322349e4b812eb43eb94d6d93/sources Inspiration Use this dataset to create maps in conjunction with other datasets for crime or weather,LON:LAT:NUMBER:STREET:UNIT:CITY:DISTRICT:REGION:POSTCODE:ID:HASH:,numeric:numeric:numeric:string:string:string:string:string:string:string:string:,
Online Job Postings , Mad Hab , www.kaggle.com/madhab/jobposts , Sat Apr 22 2017 18:36:59 GMT+0530 (IST) , Dataset of 19000 online job posts from 2004 to 2015 ,915, employment- linguistics- ,Job Posts dataset The dataset consists of 19000 job postings that were posted through the Armenian human resource portal CareerCenter. The data was extracted from the Yahoo! mailing group https//groups.yahoo.com/neo/groups/careercenter-am. This was the only online human resource portal in the early 2000s.  A job posting usually has some structure although some fields of the posting are not necessarily filled out by the client (poster). The data was cleaned by removing posts that were not job related or had no structure. The data consists of job posts from 2004-2015     Content jobpost – The original job post  date – Date it was posted in the group  Title – Job title  Company - employer  AnnouncementCode – Announcement code (some internal code is usually missing)  Term – Full-Time Part-time etc  Eligibility -- Eligibility of the candidates  Audience  --- Who can apply?  StartDate – Start date of work  Duration  - Duration of the employment  Location – Employment location  JobDescription – Job Description  JobRequirment  - Job requirements  RequiredQual   -Required Qualification  Salary      - Salary  ApplicationP – Application Procedure  OpeningDate – Opening date of the job announcement  Deadline – Deadline for the job announcement  Notes   - Additional Notes  AboutC  - About the company  Attach  - Attachments  Year -  Year of the announcement (derived from the field date)  Month - Month of the announcement (derived from the field date)  IT – TRUE if the job is an IT job. This variable is created by a simple     search of IT job titles within column “Title”    Acknowledgements The data collection and initial research was funded by the American University of Armenia’s research grant (2015).  Inspiration The online job market is a good indicator of overall demand for labor in the local economy. In addition online job postings data are easier and quicker to collect and they can be a richer source of information than more traditional job postings such as those found in printed newspapers.  The data can be used in the following ways  -Understand the demand for certain professions job titles or industries -Help universities with curriculum development -Identify skills that are most frequently required by employers and how the distribution of    necessary skills changes over time -Make recommendations to job seekers and employers Past research We have used association rules mining and simple text mining techniques to analyze the data. Some results can be found here (https//www.slideshare.net/HabetMadoyan/it-skills-analysis-63686238).,jobpost:date:Title:Company:AnnouncementCode:Term:Eligibility:Audience:StartDate:Duration:Location:JobDescription:JobRequirment:RequiredQual:Salary:ApplicationP:OpeningDate:Deadline:Notes:AboutC:Attach:Year:Month:IT:,string:dateTime:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:dateTime:string:string:string:numeric:numeric:boolean:,
Who Dies? Physics Puzzle Dataset , Christian Vorhemus , www.kaggle.com/christianvorhemus/physicspuzzlewhodies , Thu Jun 22 2017 19:18:56 GMT+0530 (IST) , Who can predict the outcome of a physics puzzle better - human or machine? ,37, video games- artificial intelligence- ,"The Game ""Who Dies?"" is a simple physics puzzle available for Android. Randomly a world full of stones monsters coil springs slingshots and other objects is created. The user has to guess which monster will get hit by a stone or falls of the platform when gravity is turned on. He gets point for every right guess the more points he collects the more complex the worlds will get.  The Development For development Phaser was used the game map is a 35x20 grid. Each tile in this grid can contain different blockers or objects.   The Data Every time a user is playing the game the position of all objects is recorded as well as the selection the user has made and the final set of monsters who died. The dataset consists of 5 columns DATETIME is a timestamp of when a user played the game. COMPLEXITY is a parameter that measures the difficulty of the game (1 = easy 100 = hard). MAP is a JSON array containing 3 arrays The first array contains immobile foreground objects described by a ""type"" property including x and y coordinates. The following list gives an overview about the the most commonly used types  The second array contains immobile background objects that don't interact with the game objects and are therefore not relevant. The third array contains movable foreground objects. These could be monsters (""guys"") balls (""smallball"" ""ball"" and ""bigball"" with or without an initial rotation to the left or right) spring (catapults boxes and balls up in the air but not monsters) box chain seesaw spin switch and switchwall (if a ball touches a switch all switchwalls with the same color as the switch change their visibility and become transparent to foreground objects or vice versa). Column ""MONSTERS_SELECTED"" contains all the monsters a player thought will get hit by a ball (ordered by the selection time) ""MONSTERS_HIT"" contains all monsters that were actually killed by balls or fell of the platform (ordered by time) The Goal There are several interesting outcomes for example  Creating a ML algorithm that is able to correctly predict the outcome of the game (which monster will die) Creating a ML algorithm that is able to correctly predict which monsters a user will most likely pick  Creating a ML algorithm that is able to create new (better?) game worlds ",DATETIME:COMPLEXITY:MAP:MONSTERS_SELECTED:MONSTERS_HIT:,dateTime:numeric:string:string:string:,
Home Price Index , Randy Betancourt , www.kaggle.com/PythonforSASUsers/hpindex , Wed Dec 07 2016 10:05:18 GMT+0530 (IST) , Housing indexed prices from January 1991 to August 2016 ,896, home- ,Context The Federal Housing Finance Agency House Price Index (HPI) is a broad measure of the movement of single-family house prices. The HPI is a weighted repeat-sales index meaning that it measures average price changes in repeat sales or refinancings on the same properties.  The technical methodology for devising the index collection and publishing the data is at http//www.fhfa.gov/PolicyProgramsResearch/Research/PaperDocuments/1996-03_HPI_TechDescription_N508.pdf Content Contains monthly and quarterly time series from January 1991 to August 2016 for the U.S. state and MSA categories.  Analysis variables are the aggregate non-seasonally adjusted value and seasonally adjusted index values.  The index value is 100 beginning January 1991.   Acknowledgements This data is found on Data.gov Inspiration Can this data be combined with the corresponding census growth projections either at the state or MSA level to forecast 24 months out the highest and lowest home index values?,hpi_type:hpi_flavor:frequency:level:place_name:place_id:yr:period:index_nsa:index_sa:,string:string:string:string:string:string:numeric:numeric:numeric:numeric:,
A millennium of macroeconomic data , Bank of England , www.kaggle.com/bank-of-england/a-millennium-of-macroeconomic-data , Wed Sep 20 2017 21:44:24 GMT+0530 (IST) , Economic Data for the UK from 1086-2016 ,152, history- finance- banking- economics- ,The dataset contains a broad set of macroeconomic and financial data for the UK stretching back in some cases to the C13th and with one or two benchmark estimates available for 1086 the year of the Domesday Book. The dataset was originally called the 'Three centuries of macroeconomic data' spreadsheet but has now been renamed given its broader coverage. Version 3 of the dataset has now been updated to 2016. Content The Excel file contains the original data. It contains hundreds of time series while the csv is an extract of several dozen headline time series. If you would like to see more of the data made available in CSV format; please let me know what you would like extracted and I'll be happy to add it. Please see excel_sheet_names.csv for details of what other data has yet to be unpacked. Acknowledgements This dataset was kindly made available by the Bank of England. You can find the original dataset here. Inspiration  Which metrics give similar answers about when the industrial revolution began? How clear is the cutoff point?  If you like If you enjoyed this dataset you might also like the Allen-Unger Global Commodity Prices dataset which provides historic commodity prices from locations around the world.,,,
Online Auctions Dataset , Modeling Online Auctions , www.kaggle.com/onlineauctions/online-auctions-dataset , Sun Nov 13 2016 06:15:57 GMT+0530 (IST) , Modeling Online Auctions Dataset from eBay ,688, business- internet- ,Context The datasets are from a companion website for the book Modeling Online Auctions by Wolfgang Jank and Galit Shmueli (Wiley and Sons ISBN 978-0-470-47565-2 July 2010). Content The datasets contain eBay auction information on Cartier wristwatches Palm Pilot M515 PDAs Xbox game consoles and Swarowski beads. auction.csv includes 9 variables  auctionid unique identifier of an auction bid the proxy bid placed by a bidder bidtime the time in days that the bid was placed from the start of the auction bidder eBay username of the bidder bidderrate eBay feedback rating of the bidder openbid the opening bid set by the seller price the closing price that the item sold for (equivalent to the second highest bid + an increment) item auction item auction_type  swarovski.csv includes 5 variables  Seller Bidder Weight Bidder.Volume Seller.Volume  Acknowledgements The original dataset can be found here. Inspiration Some ideas worth exploring  For each item what is the relationship between bids bid time and the closing price? Does this differ by length of the auction opening bid or by bidder rating? ,auctionid:bid:bidtime:bidder:bidderrate:openbid:price:item:auction_type:,numeric:numeric:numeric:string:numeric:numeric:numeric:string:string:,
Chicago Red Light Violations , Chicago Police Department , www.kaggle.com/chicagopolice/chicago-red-light-violations , Tue Sep 12 2017 23:37:04 GMT+0530 (IST) , 309k Records of Violations in Safety Zones ,74, government agencies- government- law- ,Context This dataset reflects the daily volume of violations created by the City of Chicago Red Light Program for each camera. The data reflects violations that occurred from July 1 2014 until present minus the most recent 14 days. This data may change due to occasional time lags between the capturing of a potential violation and the processing and determination of a violation. The most recent 14 days are not shown due to revised data being submitted to the City of Chicago during this period. The reported violations are those that have been collected by the camera system and reviewed by two separate City contractors. In some instances due to the inability the registered owner of the offending vehicle the violation may not be issued as a citation. However this dataset contains all violations regardless of whether a citation was actually issued which provides an accurate view into the Red Light Program. Because of occasional time lags between the capturing of a potential violation and the processing and determination of a violation as well as the occasional revision of the determination of a violation this data may change.  Content More information on the Red Light Program can be found here. Data covers July 1 2014 to Sept 7 2017. Rows include  Intersection Intersection of the location of the red light enforcement camera(s). There may be more than one camera at each intersection. Camera ID A unique ID for each physical camera at an intersection which may contain more than one camera. Address The address of the physical camera (CAMERA ID). The address may be the same for all cameras or different based on the physical installation of each camera. Violation Date The date of when the violations occurred. NOTE The citation may be issued on a different date. Violations Number of violations for each camera on a particular day. X Coordinate The X Coordinate measured in feet of the location of the camera. Geocoded using Illinois State Plane East (ESRI102671). Y Coordinate The Y Coordinate measured in feet of the location of the camera. Geocoded using Illinois State Plane East (ESRI102671). Latitude The latitude of the physical location of the camera(s) based on the ADDRESS column. Geocoded using the WGS84. Longitutde The longitude of the physical location of the camera(s) based on the ADDRESS column. Geocoded using the WGS84. Location The coordinates of the camera(s) based on the LATITUDE and LONGITUDE columns. Geocoded using the WGS84.  Acknowledgements Dataset compiled by City of Chicago here.  Inspiration  Which intersections have the most violations? When do most violations occur? ,INTERSECTION:CAMERA ID:ADDRESS:VIOLATION DATE:VIOLATIONS:X COORDINATE:Y COORDINATE:LATITUDE:LONGITUDE:LOCATION:,string:numeric:string:dateTime:numeric:string:string:string:string:string:,
Shanghai PM2.5 Air Pollution Historical Data , Team AI , www.kaggle.com/team-ai/shanghai-pm25-air-pollution-historical-data , Tue Aug 15 2017 17:10:28 GMT+0530 (IST) , Let's hack enviromental protection! ,97, environment- ,Context Coming soon. Content Historical PM2.5 data in Shanghai. Acknowledgements Special Thanks to UCI https//archive.ics.uci.edu/ml/datasets/PM2.5+Data+of+Five+Chinese+Cities Inspiration We need care more about environment. Let's use data science for social good.,No:,numeric:,
PM2.5 Data of Five Chinese Cities , Chris Crawford , www.kaggle.com/crawford/pm25-data-for-five-chinese-cities , Wed Aug 23 2017 02:27:19 GMT+0530 (IST) , Measurements for Shenyang Chengdu Beijing Guangzhou and Shanghai ,166, cities- pollution- ,Context PM2.5 readings are often included in air quality reports from environmental authorities and companies. PM2.5 refers to atmospheric particulate matter (PM) that have a diameter less than 2.5 micrometers. In other words it's used as a measure of pollution.  Content The time period for this data is between Jan 1st 2010 to Dec 31st 2015. Missing data are denoted as NA.   No row number  year year of data in this row  month month of data in this row  day day of data in this row  hour hour of data in this row  season season of data in this row  PM PM2.5 concentration (ug/m^3)  DEWP Dew Point (Celsius Degree)  TEMP Temperature (Celsius Degree)  HUMI Humidity (%)  PRES Pressure (hPa)  cbwd Combined wind direction  Iws Cumulated wind speed (m/s)  precipitation hourly precipitation (mm)  Iprec Cumulated precipitation (mm)  Acknowledgements Liang X. S. Li S. Zhang H. Huang and S. X. Chen (2016) PM2.5 data reliability consistency and air quality assessment in five Chinese cities J. Geophys. Res. Atmos. 121 10220â€“10236. The files were downloaded from the UCI Machine Learning Repository and have not been modified. https//archive.ics.uci.edu/ml/datasets/PM2.5+Data+of+Five+Chinese+Cities#,No:year:month:day:hour:season:PM_Dongsi:PM_Dongsihuan:PM_Nongzhanguan:PM_US Post:DEWP:HUMI:PRES:TEMP:cbwd:Iws:precipitation:Iprec:,numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:,
Rainfall in India , Rajanand Ilangovan / இராஜ்ஆனந்த் இளங்கோவன் , www.kaggle.com/rajanand/rainfall-in-india , Sat Aug 05 2017 16:06:12 GMT+0530 (IST) , Sub-division wise monthly data for 115 years from 1901-2015. ,505, india- weather- ,Context This data set contains monthly rainfall detail of 36 meteorological sub-divisions of India. Content Time Period 1901 - 2015 Granularity Monthly Location 36 meteorological sub-divisions in India  Rainfall unit mm  Acknowledgements India Meteorological Department(IMD) Govt. of India has shared this dataset  under Govt. Open Data License - India.,STATE_UT_NAME:DISTRICT:JAN:FEB:MAR:APR:MAY:JUN:JUL:AUG:SEP:OCT:NOV:DEC:ANNUAL:Jan-Feb:Mar-May:Jun-Sep:Oct-Dec:,string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
New York City - Buildings Database , City of New York , www.kaggle.com/new-york-city/nyc-buildings , Fri Sep 01 2017 20:37:59 GMT+0530 (IST) , The PLUTO master record of buildings in New York City. ,128, cities- civil engineering- ,Context PLUTO is a master record of the locations and characteristics of buildings in New York City. It’s published by the New York City Department of City Planning on an approximately quarterly-to-half-yearly basis and is one of the more important datasets for civic analysis in New York City. Content PLUTO includes information on building height square footage location type landmark status number of units owner year of construction and other related fields. Acknowledgements This dataset is published as-is by the New York City Department of Planning. Inspiration  What is the distribution of the heights of buildings in New York City? The age? Can you define neighborhoods by clustering similar buildings within them? What (and where) is the split between commercial residential and office space in New York City? ,Borough:Block:Lot:CD:CT2010:CB2010:SchoolDist:Council:ZipCode:FireComp:PolicePrct:HealthArea:SanitBoro:SanitDistrict:SanitSub:Address:ZoneDist1:ZoneDist2:ZoneDist3:ZoneDist4:Overlay1:Overlay2:SPDist1:SPDist2:SPDist3:LtdHeight:SplitZone:BldgClass:LandUse:Easements:OwnerType:OwnerName:LotArea:BldgArea:ComArea:ResArea:OfficeArea:RetailArea:GarageArea:StrgeArea:FactryArea:OtherArea:AreaSource:NumBldgs:NumFloors:UnitsRes:UnitsTotal:LotFront:LotDepth:BldgFront:BldgDepth:Ext:ProxCode:IrrLotCode:LotType:BsmtCode:AssessLand:AssessTot:ExemptLand:ExemptTot:YearBuilt:YearAlter1:YearAlter2:HistDist:Landmark:BuiltFAR:ResidFAR:CommFAR:FacilFAR:BoroCode:BBL:CondoNo:Tract2010:XCoord:YCoord:ZoneMap:ZMCode:Sanborn:TaxMap:EDesigNum:APPBBL:APPDate:PLUTOMapID:Version:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:numeric:string:numeric:dateTime:numeric:string:,
Aircraft Wildlife Strikes 1990-2015 , Federal Aviation Administration , www.kaggle.com/faa/wildlife-strikes , Wed Feb 08 2017 20:21:11 GMT+0530 (IST) , What bird species has caused the most damage to airplanes? ,388, animals- aviation- ,Content The dataset contains a record of each reported wildlife strike of a military commercial or civil aircraft between 1990 and 2015. Each row contains the incident date aircraft operator aircraft make and model engine make and model airport name and location species name and quantity and aircraft damage. Acknowledgements The wildlife strike database was compiled from reports received from airports airlines and pilots and published by the Federal Aviation Association.,Record ID:Incident Year:Incident Month:Incident Day:Operator ID:Operator:Aircraft:Aircraft Type:Aircraft Make:Aircraft Model:Aircraft Mass:Engine Make:Engine Model:Engines:Engine Type:Engine1 Position:Engine2 Position:Engine3 Position:Engine4 Position:Airport ID:Airport:State:FAA Region:Warning Issued:Flight Phase:Visibility:Precipitation:Height:Speed:Distance:Species ID:Species Name:Species Quantity:Flight Impact:Fatalities:Injuries:Aircraft Damage:Radome Strike:Radome Damage:Windshield Strike:Windshield Damage:Nose Strike:Nose Damage:Engine1 Strike:Engine1 Damage:Engine2 Strike:Engine2 Damage:Engine3 Strike:Engine3 Damage:Engine4 Strike:Engine4 Damage:Engine Ingested:Propeller Strike:Propeller Damage:Wing or Rotor Strike:Wing or Rotor Damage:Fuselage Strike:Fuselage Damage:Landing Gear Strike:Landing Gear Damage:Tail Strike:Tail Damage:Lights Strike:Lights Damage:Other Strike:Other Damage:,numeric:numeric:numeric:numeric:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:string:string:numeric:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
2015 Traffic  Fatalities , NHTSA , www.kaggle.com/nhtsa/2015-traffic-fatalities , Sat Nov 26 2016 00:17:45 GMT+0530 (IST) , National Highway Traffic Safety Administration ,2878, road transport- ,Quick Start For a quick introduction to this Dataset take a look at the Kernel Traffic Fatalities Getting Started. See the Fatality Analysis Reporting System FARS User’s Manual for understanding the column abbreviations and possible values.  Also see the following reference Original source of this data containing all files can be obtained here  Below are the files released by the (NHTSA) National Highway Traffic Safety Administration in their original format.   Additional files can be found in the extra folder.  Reference Traffic Fatalities Getting Started. for how to access this extra folder with contents. Data Compared to 2014 A few interesting notes about this data compared to 2014  Pedalcyclist fatalities increased by 89 (12.2 percent) Motorcyclist fatalities increased by 382 (8.3-percent increase) Alcohol-impaired driving fatalities increased by 3.2 percent from 9943 in 2014 to 10265 in 2015 Vehicle miles traveled (VMT) increased by 3.5 percent from 2014 to 2015 the largest increase since 1992 nearly 25 years ago.  See TRAFFIC SAFETY FACTS for more detail on the above findings.,ST_CASE:VE_TOTAL:VE_FORMS:PVH_INVL:PEDS:PERNOTMVIT:PERMVIT:PERSONS:COUNTY:CITY:DAY:MONTH:YEAR:DAY_WEEK:HOUR:MINUTE:NHS:RUR_URB:FUNC_SYS:RD_OWNER:ROUTE:TWAY_ID:TWAY_ID2:MILEPT:LATITUDE:LONGITUD:SP_JUR:HARM_EV:MAN_COLL:RELJCT1:RELJCT2:TYP_INT:WRK_ZONE:REL_ROAD:LGT_COND:WEATHER1:WEATHER2:WEATHER:SCH_BUS:RAIL:NOT_HOUR:NOT_MIN:ARR_HOUR:ARR_MIN:HOSP_HR:HOSP_MN:CF1:CF2:CF3:FATALS:DRUNK_DR:STATE:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Vehicle Fuel Economy , US Environmental Protection Agency , www.kaggle.com/epa/vehicle-fuel-economy , Thu Sep 14 2017 03:43:44 GMT+0530 (IST) , Mileage and more for 1948-2018 ,173, government agencies- vehicles- ,Fuel economy data are the result of vehicle testing done at the Environmental Protection Agency's National Vehicle and Fuel Emissions Laboratory in Ann Arbor Michigan and by vehicle manufacturers with oversight by EPA. Content Please see the csvs labeled with 'fields' for descriptions of the data fields; there are too many to list here. Acknowledgements This dataset was kindly provided by the US EPA. You can find the original dataset which is updated regularly here. Inspiration  How has the rate of change of fuel economy changed over time? Do simple clustering techniques on vehicles lead to the same groupings that are typically associated with manufacturers such as putting Porsche and BMW together in a luxury car group? ,efid:id:salesArea:score:scoreAlt:smartwayScore:standard:stdText:,string:numeric:numeric:numeric:numeric:numeric:string:string:,
US Traffic Violations - Montgomery County Police , jana , www.kaggle.com/jana36/us-traffic-violations-montgomery-county-polict , Mon Dec 26 2016 13:15:53 GMT+0530 (IST) , Factors contributing to traffic violations over the last few years ,301, crime- road transport- ,Context This data set contains traffic violation with their different categories  published in Montgomery county website.  The data set contains different categories of the traffic violations which should be useful for analyzing the data category wise.  Content The name of the fields are self explanatory. The data set contains geographical location details (latitude longitude) which might be useful for analyzing the data on the geographical maps. Acknowledgements I captured the data from the US govt website link https//data.montgomerycountymd.gov/Public-Safety/Traffic-Violations/4mse-ku6q Also I was looking for the full data set of the country - please let me know if anybody has the access of the  USA all state traffic violation data.  Inspiration Wanted to share the violations of the traffic rules - this might help people to avoid traffic violations as avoid road fatalities.,Date Of Stop:Time Of Stop:Agency:SubAgency:Description:Location:Latitude:Longitude:Accident:Belts:Personal Injury:Property Damage:Fatal:Commercial License:HAZMAT:Commercial Vehicle:Alcohol:Work Zone:State:VehicleType:Year:Make:Model:Color:Violation Type:Charge:Article:Contributed To Accident:Race:Gender:Driver City:Driver State:DL State:Arrest Type:Geolocation:,dateTime:dateTime:string:string:string:string:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:,
Baton Rouge Crime Incidents , John Ruth , www.kaggle.com/johnruth/baton-rouge-crime-incidents-through-09212017 , Fri Sep 22 2017 00:37:04 GMT+0530 (IST) , Through September 21st 2017 ,41, crime- ,Context Crimes reported in Baton Rouge and handled by the Baton Rouge Police Department. Crimes include Burglaries (Vehicle Residential and Non-residential) Robberies (Individual and Business) Theft Narcotics Vice Crimes Assault Nuisance Battery Firearm Homicides Criminal Damage to Property Sexual Assaults and Juvenile. Content Dataset only includes records through September 21st 2017 Columns included FILE NUMBER OFFENSE DATE OFFENSE TIME CRIME COMMITTED OFFENSE OFFENSE DESC ADDRESS ST NUMBER ST DIR ST NAME ST TYPE CITY STATE ZIP DISTRICT ZONE SUBZONE COMPLETE DISTRICT GEOLOCATION Acknowledgements This public domain data is provided by Open Data BR through Socrata.  See this dataset's official page for more information.  Public domain licensed banner image provided by GoodFreePhotos.com.,FILE NUMBER:OFFENSE DATE:OFFENSE TIME:CRIME:COMMITTED:OFFENSE:OFFENSE DESC:ADDRESS:ST NUMBER:ST DIR:ST NAME:ST TYPE:CITY:STATE:ZIP:DISTRICT:ZONE:SUBZONE:COMPLETE DISTRICT:GEOLOCATION:,numeric:dateTime:string:string:string:string:string:string:numeric:string:string:string:string:string:numeric:string:string:string:string:string:,
Istanbul Stock Exchange , UCI Machine Learning , www.kaggle.com/uciml/istanbul-stock-exchange , Wed Sep 20 2017 23:36:54 GMT+0530 (IST) , Exchange data from 2009 to 2011 ,40, finance- ,"Context This dataset was used in the paper ""A novel Hybrid RBF Neural Networks model as a forecaster Statistics and Computing"" (Akbilgic et al) to show off a new forecasting algorithm. The paper showed good results when using a HRBF-NN model for predicting daily stock movements.  Content The data was collected (by the owners) from imkb.gov.tr and finance.yahoo.com and is organized by working days in the Istanbul Stock Exchange. Columns  Istanbul stock exchange national 100 index Standard & poor's 500 return index Stock market return index of Germany Stock market return index of UK Stock market return index of Japan Stock market return index of Brazil MSCI European index MSCI emerging markets index  Acknowledgements Akbilgic O. Bozdogan H. Balaban M.E. (2013) A novel Hybrid RBF Neural Networks model as a forecaster Statistics and Computing. DOI 10.1007/s11222-013-9375-7  PhD Thesis Oguz Akbilgic (2011) Hibrit Radyal TabanlÄ± Fonksiyon AÄŸlarÄ± ile DeÄŸiÅŸken SeÃ§imi ve Tahminleme Menkul KÄ±ymet YatÄ±rÄ±m KararlarÄ±na Ä°liÅŸkin Bir Uygulama Istanbul University This dataset was downloaded from the UCI ML Repository https//archive.ics.uci.edu/ml/datasets/ISTANBUL+STOCK+EXCHANGE Inspiration Use this dataset to create predictive algorithms. Then get rich!",date:TL BASED ISE:USD BASED ISE:SP:DAX:FTSE:NIKKEI:BOVESPA:EU:EM:,dateTime:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Run or Walk , Viktor Malyi , www.kaggle.com/vmalyi/run-or-walk , Wed Jul 19 2017 01:31:37 GMT+0530 (IST) , A dataset containing labeled sensor data from accelerometer and gyroscope ,311, running- walking- ,"Context This dataset complements https//github.com/vmalyi/run-or-walk project which aims to detect whether the person is running or walking based on deep neural network and sensor data collected from iOS device. This dataset has been accumulated with help of ""Data Collection"" iOS app specially developed for this purpose https//github.com/vmalyi/run-or-walk/tree/master/ios_app_data_collection.  Please note that this app is not available in the AppStore yet. Content Currently the dataset contains a single file which represents 88588 sensor data samples collected from accelerometer and gyroscope from iPhone 5c in 10 seconds interval and ~5.4/second frequency. This data is represented by following columns (each column contains sensor data for one of the sensor's axes)   acceleration_x acceleration_y acceleration_z gyro_x gyro_y gyro_z  There is an activity type represented by ""activity"" column which acts as label and reflects following activities  ""0"" walking ""1"" running  Apart of that the dataset contains ""wrist"" column which represents the wrist where the device was placed to collect a sample on  ""0"" left wrist ""1"" right wrist  Additionally the dataset contains ""date"" ""time"" and ""username"" columns which provide information about the exact date time and user which collected these measurements.",date:,dateTime:,
Spotify Song Attributes , GeorgeMcIntire , www.kaggle.com/geomack/spotifyclassification , Sat Aug 05 2017 02:35:17 GMT+0530 (IST) , An attempt to build a classifier that can predict whether or not I like a song ,429, ,"Context A dataset of 2017 songs with attributes from Spotify's API. Each song is labeled ""1"" meaning I like it and ""0"" for songs I don't like. I used this to data to see if I could build a classifier that could predict whether or not I would like a song. I wrote an article about the project I used this data for. It includes code on how to grab this data from the Spotipy API wrapper and the methods behind my modeling. https//opendatascience.com/blog/a-machine-learning-deep-dive-into-my-spotify-data/ Content Each row represents a song. There are 16 columns. 13 of which are song attributes one column for song name one for artist and a column called ""target"" which is the label for the song. Here are the 13 track attributes acousticness danceability duration_ms energy instrumentalness key liveness loudness mode speechiness tempo time_signature valence. Information on what those traits mean can be found here https//developer.spotify.com/web-api/get-audio-features/ Acknowledgements I would like to thank Spotify for providing this readily accessible data. Inspiration I'm a music lover who's curious about why I love the music that I love.",acousticness:danceability:duration_ms:energy:instrumentalness:key:liveness:loudness:mode:speechiness:tempo:time_signature:valence:target:song_title:artist:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:,
Digimon Database , Rachael Tatman , www.kaggle.com/rtatman/digidb , Fri Jul 14 2017 04:03:37 GMT+0530 (IST) , A database of Digimon and their moves from Digimon Story CyberSleuth ,73, games and toys- ,Context Digimon short for “digital monsters” is a franchise which revolves around a core mechanic of capturing caring for and training monsters and then engaging in combat with them. It’s similar to Pokémon. This dataset contains information on digimon from “Digimon Digimon Story Cyber Sleuth” released for Playstation Vita in 2015 and Playstation 4 in 2016.  Content This database contains three files a list of all the digimon that can be captured or fought in Cyber Sleuth all the moves which Digimon can perform and all the Support Skills. (Support Skills are a passive stackable team-wide buff. Each species of Digimon is associated with a single Support Skill.) Acknowledgements This dataset was created by Mark Korsak and is used here with permission. You can find an interactive version of this database here. http//digidb.io/ Inspiration This dataset will help you theorycraft the ultimate team as well as ask interesting questions.  Which set of moves will get the best ratio of attack power to SP spent? Which team of 3 digimon have the highest attack? Defense? What’s the tradeoff between HP and SP? Are some types over- or under-represented? Both the moves and support skills have short text descriptions. Can an NLP analysis reveal underlying clusters of moves? Are different types and attributes evenly represented across stages? ,Number:Digimon:Stage:Type:Attribute:Memory:Equip Slots:Lv 50 HP:Lv50 SP:Lv50 Atk:Lv50 Def:Lv50 Int:Lv50 Spd:,numeric:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Universal Product Code Database , Rachael Tatman , www.kaggle.com/rtatman/universal-product-code-database , Sat Aug 19 2017 04:27:07 GMT+0530 (IST) , One million products & their UPC codes ,88, business- supply chain- product- product management- ,Context “The Universal Product Code (UPC) is a barcode symbology that is widely used in the United States Canada United Kingdom Australia New Zealand in Europe and other countries for tracking trade items in stores. “UPC (technically refers to UPC-A) consists of 12 numeric digits that are uniquely assigned to each trade item. Along with the related EAN barcode the UPC is the barcode mainly used for scanning of trade items at the point of sale per GS1 specifications.[1] UPC data structures are a component of GTINs and follow the global GS1 specification which is based on international standards. But some retailers (clothing furniture) do not use the GS1 system (rather other barcode symbologies or article number systems). On the other hand some retailers use the EAN/UPC barcode symbology but without using a GTIN (for products brands sold at such retailers only).” -- Tate. (n.d.). In Wikipedia. Retrieved August 18 2017 from https//en.wikipedia.org/wiki/Plagiarism. Text reproduced here under a CC-BY-SA 3.0 license. Content This dataset contains just over 1 million UPC codes and the names of the products associated with them. Acknowledgements While UPC’s themselves are not copyrightable the brand names and trademarks in this dataset remain the property of their respective owners. Inspiration  Can you use this dataset to generate new product names? Can you use this in conjunction with other datasets to disambiguate products? ,ean:name:,numeric:string:,
Santa Barbara Corpus of Spoken American English , Rachael Tatman , www.kaggle.com/rtatman/santa-barbara-corpus-of-spoken-american-english , Thu Sep 14 2017 23:30:14 GMT+0530 (IST) , Transcribed recordings of natural conversational speech ,27, languages- linguistics- ,Context The Santa Barbara Corpus of Spoken American English is based on hundreds of recordings of natural speech from all over the United States representing a wide variety of people of different regional origins ages occupations and ethnic and social backgrounds. It reflects many ways that people use language in their lives conversation gossip arguments on-the-job talk card games city council meetings sales pitches classroom lectures political speeches bedtime stories sermons weddings and more. The corpus was collected by the University of California Santa Barbara Center for the Study of Discourse Director John W. Du Bois (UCSB) Associate Editors Wallace L. Chafe (UCSB) Charles Meyer (UMass Boston) and Sandra A. Thompson (UCSB). Each speech file is accompanied by a transcript in which phrases are time stamped with respect to the audio recording. Personal names place names phone numbers etc. in the transcripts have been altered to preserve the anonymity of the speakers and their acquaintances and the audio files have been filtered to make these portions of the recordings unrecognizable. Pitch information is still recoverable from these filtered portions of the recordings but the amplitude levels in these regions have been reduced relative to the original signal. The audio data consists of MP3 format speech files recorded in two-channel pcm at 22050Hz. Contents This dataset contains part one of the corpus. The other three parts and additional information can be found here. The following information is included in this dataset  Recordings 14 recordings as .mp3 files Transcripts Time-aligned transcripts for all 14 recordings in the CHAT format Metadata A .csv with demographic information on speakers as well as which recordings they appear in. (Some talkers appear in more than one recording.)  Acknowledgements The Santa Barbara Corpus was compiled by researchers in the Linguistics Department of the University of California Santa Barbara. The Director of the Santa Barbara Corpus is John W. Du Bois working with Associate Editors Wallace L. Chafe and Sandra A. Thompson (all of UC Santa Barbara) and Charles Meyer (UMass Boston). For the publication of Parts 3 and 4 the authors are John W. Du Bois and Robert Englebretson. It is distributed here under an CC BY-ND 3.0 US license. Inspiration  Currently the transcriptions are close transcriptions and include disfluencies and overlaps. Can you use NLP to convert them to broad transcriptions without this information? Can you create a phone-aligned transcription of this dataset? You might find it helpful to use forced alignment.  ,NAME:GENDER:AGE:HOMETOWN:HOMESTATE:CURRENT STATE:EDUCATION:YEARS OF EDUCATION:OCUPATION:ETHNICITY:RECORDING:,string:string:numeric:string:string:string:string:numeric:string:string:numeric:,
HSE Thai Corpus , Rachael Tatman , www.kaggle.com/rtatman/hse-thai-corpus , Wed Sep 06 2017 03:50:21 GMT+0530 (IST) , A 35 Million Word Corpus of Thai ,15, languages- asia- linguistics- internet- ,Context The Thai language is the primary language of Thailand and a recognized minority language in Cambodia. It has approximately twenty million native speakers in addition to 44 million second language speakers. It is written in Thai script (also called the Thai alphabet) which is notable for being the first writing system to incorporate tonal markers. Thai is written without spaces between words. Content The HSE Thai Corpus is a corpus of modern texts written in Thai language. The texts containing in whole 50 million tokens were collected from various Thai websites (mostly news websites). To make it easier for non-Thai-speakers to comprehend and use texts in the corpus the researchers decided to separate words in each sentence with spaces. The data for the corpus was collected by means of Scrapy. To tokenize texts the Pythai module was used. The text in this dataset is encoded in UTF-8. The corpus can be searched using a web interface at this site. This dataset contains text from two sources Wikipedia and thaigov.go.th. The former is licensed under a standard Wikipedia license and the latter under an Open Government License for Thailand which can be viewed here (In Thai). Acknowledgements The Thai Corpus was developed by the team of students of HSE School of Linguistics in Moscow under the guidance of professor Boris Orekhov. The team consisted of Grigory Ignatyev Alexandra Ershova Anna Kuznetsova Tatyana Shalganova Daniil Kolomeytsev and Nikolai Mikulin. The consulting help on Thai language was provided by Nadezhda Motina. Natalia Filippova Elizaveta Kuzmenko Tatyana Gavrilova Elena Krotova Elmira Mustakimova Olga Sozinova Aleksandra Martynova Maria Sheyanova Marina Kustova and Julia Badryzlova also contributed to the project. Inspiration  In this corpus unlike in most written Thai words have been separated for you with spaces. Can you remove spaces and write an algorithm to identify word boundaries? ,article:text:,numeric:string:,
English Word Frequency , Rachael Tatman , www.kaggle.com/rtatman/english-word-frequency , Wed Sep 06 2017 23:51:27 GMT+0530 (IST) , ⅓ Million Most Frequent English Words on the Web ,101, languages- linguistics- internet- ,Context How frequently a word occurs in a language is an important piece of information for natural language processing and linguists. In natural language processing very frequent words tend to be less informative than less frequent one and are often removed during preprocessing. Human language users are also sensitive to  word frequency. How often a word is used affects language processing in humans. For example very frequent words are read and understood more quickly and can be understood more easily in background noise. Content This dataset contains the counts of the 333333 most commonly-used single words on the English language web as derived from the Google Web Trillion Word Corpus. Acknowledgements Data files were derived from the Google Web Trillion Word Corpus (as described by Thorsten Brants and Alex Franz and distributed by the Linguistic Data Consortium) by Peter Norvig. You can find more information on these files and the code used to generate them here. The code used to generate this dataset is distributed under the MIT License.  Inspiration  Can you tag the part of speech of these words? Which parts of speech are most frequent? Is this similar to other languages like Japanese? What differences are there between the very frequent words in this dataset and the the frequent words in other corpora such as the Brown Corpus or the TIMIT corpus? What might these differences tell us about how language is used?  ,word:count:,string:numeric:,
Popular websites across the globe , bpali26 , www.kaggle.com/bpali26/popular-websites-across-the-globe , Sat May 27 2017 16:48:54 GMT+0530 (IST) , General information on some of the most viewed sites country wise ,460, world- internet- ,Context This dataset includes some of the basic information of the websites we daily use.  While scrapping this info I learned quite a lot in R programming system speed memory usage etc. and developed my niche in Web Scrapping. It took about 4-5 hrs for scrapping this data through my system (4GB RAM) and nearly about 4-5 days working out my idea through this project.  Content The dataset contains Top 50 ranked sites from each 191 countries along with their traffic (global) rank. Here country_rank represent the traffic rank of that site within the country and traffic_rank represent the global traffic rank of that site.  Since most of the columns meaning can be derived from their name itself its pretty much straight forward to understand this dataset. However  there are some instances of confusion which I would like to explain in here 1) most of the numeric values are in character format hence contain spaces which you might need to clean on. 2) There are multiple instances of same website. for.e.g. Yahoo. com is present in 179 rows within this dataset. This is due to their different country rank in each country.  3)The information provided in this dataset is for the top 50 websites in 191 countries as on 25th May 2017 and is subjected to change in future time due to the dynamic structure of ranking. 4) The dataset inactual contains 9540 rows instead of 9550(50*191 rows). This was due to the unavailability of information for 10 websites.  PS in case if there are anymore queries comment on this I'll add an answer to that in above list. Acknowledgements I wouldn't have done this without the help of others. I've scrapped this information from publicly available (open to all) websites namely  1) http//data.danetsoft.com/  2) http//www.alexa.com/topsites   of which i'm highly grateful. I truly appreciate and thanks the owner of these sites for providing us with the information that I included today in this dataset. Inspiration I feel that there this a lot of scope for exploring & visualization this dataset to find out the trends in the attributes of these websites across countries. Also one could try predicting the traffic(global) rank being a dependent factor on the other attributes of the website. In any case this dataset will help you find out the popular sites in your area.,Country_Rank:Website:Trustworthiness:Avg_Daily_Visitors:Child_Safety:Avg_Daily_Pageviews:Privacy:Facebook_likes:Twitter_mentions:Google_pluses:LinkedIn_mentions:Pinterest_pins:StumbleUpon_views:Status:Traffic_Rank:Reach_Day:Month_Average_Daily_Reach:Daily_Pageviews:Month_Average_Daily_Pageviews:Daily_Pageviews_per_user:Reach_Day_percentage:Month_Average_Daily_Reach_percentage:Daily_Pageviews_percentage:Month_Average_Daily_Pageviews_percentage:Daily_Pageviews_per_user_percentage:Location:Hosted_by:Subnetworks:Registrant:Registrar:country:,numeric:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:,
Nobel Laureates 1901-Present , The Nobel Foundation , www.kaggle.com/nobelfoundation/nobel-laureates , Thu Feb 16 2017 06:01:00 GMT+0530 (IST) , Which country has won the most prizes in each category? ,433, researchers- ,"Context Between 1901 and 2016 the Nobel Prizes and the Prize in Economic Sciences were awarded 579 times to 911 people and organizations. The Nobel Prize is an international award administered by the Nobel Foundation in Stockholm Sweden and based on the fortune of Alfred Nobel Swedish inventor and entrepreneur. In 1968 Sveriges Riksbank established The Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel founder of the Nobel Prize. Each Prize consists of a medal a personal diploma and a cash award. A person or organization awarded the Nobel Prize is called Nobel Laureate. The word ""laureate"" refers to being signified by the laurel wreath. In ancient Greece laurel wreaths were awarded to victors as a sign of honor. Content This dataset includes a record for every individual or organization that was awarded the Nobel Prize since 1901. Acknowledgements The Nobel laureate data was acquired from the Nobel Prize API. Inspiration Which country has won the most prizes in each category? What words are most frequently written in the prize motivation? Can you predict the age gender and nationality of next year's Nobel laureates?",Year:Category:Prize:Motivation:Prize Share:Laureate ID:Laureate Type:Full Name:Birth Date:Birth City:Birth Country:Sex:Organization Name:Organization City:Organization Country:Death Date:Death City:Death Country:,numeric:string:string:string:dateTime:numeric:string:string:dateTime:string:string:string:string:string:string:dateTime:string:string:,
NFL Statistics , KendallGillies , www.kaggle.com/kendallgillies/nflstatistics , Fri Jun 09 2017 21:24:44 GMT+0530 (IST) , Basic NFL statistics career statistics and game logs ,836, american football- ,NFL-Statistics-Scrape Here are the basic statistics career statistics and game logs provided by the NFL on their website (http//www.nfl.com) for all players past and present.  Summary The data was scraped using a Python code.  The code can be located at Github https//github.com/kendallgillies/NFL-Statistics-Scrape Explanation of Data  The first main group of statistics is the basic statistics provided for each player.  This data is stored in the CSV file titled Basic_Stats.csv along with the player’s name and URL identifier.  If available the data pulled for each player is as follows Number Position Current Team Height Weight Age Birthday Birth Place College Attended High School Attended High School Location Experience The second main group of statistics gathered for each player are their career statistics.  While each player has a main position they play they will have statistics in other areas; therefore the career statistics are divided into statistics types.  The statistics are then stored in CSV files based on statistic type along with the player name URL identifier and position (if available).  The following are the career statistics types and accompanying CSV file names Defensive Statistics – Career_Stats_Defensive.csv Field Goal Kickers - Career_Stats_Field_Goal_Kickers.csv Fumbles - Career_Stats_Fumbles.csv Kick Return - Career_Stats_Kick_Return.csv Kickoff - Career_Stats_Kickoff.csv Offensive Line - Career_Stats_Offensive_Line.csv Passing - Career_Stats_Passing.csv Punt Return - Career_Stats_Punt_Return.csv Punting - Career_Stats_Punting.csv Receiving - Career_Stats_Receiving.csv Rushing - Career_Stats_Rushing.csv The final group of statistics is the game logs for each player.  The game logs are stored by position and have the player name URL identifier and position (if available).  The following are the game log types and accompanying CSV file names Quarterback – Game_Logs_Quarterback.csv Running back – Game_Logs_Runningback.csv Wide Receiver and Tight End – Game_Logs_Wide_Receiver_and_Tight_End.csv Offensive Line – Game_Logs_Offensive_Line.csv Defensive Lineman – Game_Logs_Defensive_Lineman.csv Kickers – Game_Logs_Kickers.csv Punters – Game_Logs_Punters.csv  Glossary While most of the abbreviations used by the NFL have been translated in the table headers in the data files there are still a couple of abbreviations used.  FG Field Goal TD Touchdown Int Interception ,Age:Birth Place:Birthday:College:Current Status:Current Team:Experience:Height (inches):High School:High School Location:Name:Number:Player Id:Position:Weight (lbs):Years Played:,numeric:string:dateTime:string:string:string:string:numeric:string:string:string:numeric:string:string:numeric:string:,
2016 US Presidential Election Vote By County , Steve Palley , www.kaggle.com/stevepalley/2016uspresidentialvotebycounty , Sun Nov 20 2016 00:47:05 GMT+0530 (IST) , County-level data on presidential voting ,673, geography- politics- ,This dataset includes county-level data from the 2016 US Presidential Election. Data are from Michael W. Kearney's GitHub page by way of Max Galka's County-Level Results Map on metrocosm.com.,,,
Mobile phone activity in a city , Marco De Nadai , www.kaggle.com/marcodena/mobile-phone-activity , Fri Nov 11 2016 19:06:14 GMT+0530 (IST) , Hourly phone calls SMS and Internet communication of an entire city ,1987, cities- internet- telecommunications- ,"Introduction The Mobile phone activity dataset is composed by one week of Call Details Records (CDRs) from the city of Milan and the Province of Trentino (Italy).  Description of the dataset Every time a user engages a telecommunication interaction a Radio Base Station (RBS) is assigned by the operator and delivers the communication through the network. Then a new CDR is created recording the time of the interaction and the RBS which handled it. The following activities are present in the dataset   received SMS sent SMS incoming calls outgoing calls Internet activity  In particular Internet activity is generated each time a user starts an Internet connection or ends an Internet connection. Moreover during the same connection a CDR is generated if the connection lasts for more than 15 min or the user transferred more than 5 MB.  The datasets is spatially aggregated in a square cells grid. The area of Milan is composed of a grid overlay of 1000 (squares with size of about 235×235 meters. This grid is projected with the WGS84 (EPSG4326) standard. For more details we link the original paper http//go.nature.com/2fcOX5E The data provides CellID CountryCode and all the aforementioned telecommunication activities aggregated every 60 minutes. Original datasource The Mobile phone activity dataset is a part of the Telecom Italia Big Data Challenge 2014 which is a rich and open multi-source aggregation of telecommunications weather news social networks and electricity data from the city of Milan and the Province of Trentino (Italy).  The original dataset has been created by Telecom Italia in association with EIT ICT Labs SpazioDati MIT Media Lab Northeastern University Polytechnic University of Milan Fondazione Bruno Kessler University of Trento and Trento RISE. In order to make it easy-to-use here we provide a subset of telecommunications data that allows researchers to design algorithms able to exploit an enormous number of behavioral and social indicators. The complete version of the dataset is available at the following link http//go.nature.com/2fz4AFr Relevant external data sources The presented datasets can be enriched by using census data provided by the Italian National Institute of Statistics (ISTAT) (http//www.istat.it/en/) a public research organization and the main provider of official statistics in Italy. The census data have been released for 1999 2001 and 2011.  The dataset (http//www.istat.it/it/archivio/104317) released in Italian is composed of four parts Territorial Bases (Basi Territoriali) Administrative Boundaries (Confini Amministrativi) Census Variables (Variabili Censuarie) and data about Toponymy (Dati Toponomastici). Motivational video https//www.youtube.com/watch?v=_d2_RWMsUKc Relevant papers Blondel Vincent D. Adeline Decuyper and Gautier Krings. ""A survey of results on mobile phone datasets analysis."" EPJ Data Science 4 no. 1 (2015) 1. Francesco Calabrese Laura Ferrari and Vincent D. Blondel. 2014. Urban Sensing Using Mobile Phone Network Data A Survey of Research. ACM Comput. Surv. 47 2 Article 25 (November 2014) 20 pages. Eagle Nathan Michael Macy and Rob Claxton. ""Network diversity and economic development."" Science 328 no. 5981 (2010) 1029-1031. Lenormand Maxime Miguel Picornell Oliva G. Cantú-Ros Thomas Louail Ricardo Herranz Marc Barthelemy Enrique Frías-Martínez Maxi San Miguel and José J. Ramasco. ""Comparing and modelling land use organization in cities."" Royal Society open science 2 no. 12 (2015) 150449. Louail Thomas Maxime Lenormand Oliva G. Cantu Ros Miguel Picornell Ricardo Herranz Enrique Frias-Martinez José J. Ramasco and Marc Barthelemy. ""From mobile phone data to the spatial structure of cities."" Scientific reports 4 (2014). De Nadai Marco Jacopo Staiano Roberto Larcher Nicu Sebe Daniele Quercia and Bruno Lepri. ""The Death and Life of Great Italian Cities A Mobile Phone Data Perspective."" WWW 2016. Citation We kindly ask people who use this dataset to cite the following paper where this aggregation comes from Barlacchi Gianni Marco De Nadai Roberto Larcher Antonio Casella Cristiana Chitic Giovanni Torrisi Fabrizio Antonelli Alessandro Vespignani Alex Pentland and Bruno Lepri. ""A multi-source dataset of urban life in the city of Milan and the Province of Trentino."" Scientific data 2 (2015).",PROVINCIA:P1:P2:P3:P4:P5:P6:P7:P8:P9:P10:P11:P12:P13:P14:P15:P16:P17:P18:P19:P20:P21:P22:P23:P24:P25:P26:P27:P28:P29:P30:P31:P32:P33:P34:P35:P36:P37:P38:P39:P40:P41:P42:P43:P44:P45:P46:P47:P48:P49:P50:P51:P52:P53:P54:P55:P56:P57:P58:P59:P60:P61:P62:P64:P65:P66:P128:P129:P130:P131:P132:P135:P136:P137:P138:P139:P140:ST1:ST2:ST3:ST4:ST5:ST6:ST7:ST8:ST9:ST10:ST11:ST12:ST13:ST14:ST15:A2:A3:A5:A44:A46:A47:A48:PF1:PF2:PF3:PF4:PF5:PF6:PF7:PF8:PF9:E1:E2:E3:E4:E5:E6:E7:E8:E9:E10:E11:E12:E13:E14:E15:E16:E17:E18:E19:E20:E21:E22:E23:E24:E25:E26:E27:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Biodiversity in National Parks , National Park Service , www.kaggle.com/nationalparkservice/park-biodiversity , Fri Jan 20 2017 20:30:26 GMT+0530 (IST) , Plant and animal species found in the American national park system ,687, animals- plants- ,Context The National Park Service publishes a database of animal and plant species identified in individual national parks and verified by evidence — observations vouchers or reports that document the presence of a species in a park. All park species records are available to the public on the National Park Species portal; exceptions are made for sensitive threatened or endangered species when widespread distribution of information could pose a risk to the species in the park. Content National Park species lists provide information on the presence and status of species in our national parks. These species lists are works in progress and the absence of a species from a list does not necessarily mean the species is absent from a park. The time and effort spent on species inventories varies from park to park which may result in data gaps. Species taxonomy changes over time and reflects regional variations or preferences; therefore records may be listed under a different species name. Each park species record includes a species ID park name taxonomic information scientific name one or more common names record status occurrence (verification of species presence in park) nativeness (species native or foreign to park) abundance (presence and visibility of species in park) seasonality (season and nature of presence in park) and conservation status (species classification according to US Fish & Wildlife Service). Taxonomic classes have been translated from Latin to English for species categorization; order family and scientific name (genus species subspecies) are in Latin. Acknowledgements The National Park Service species list database is managed and updated by staff at individual national parks and the systemwide Inventory and Monitoring department.,Park Code:,string:,
2012 and 2016 Presidential Elections , Joel Wilson , www.kaggle.com/joelwilson/2012-2016-presidential-elections , Mon Nov 28 2016 06:59:10 GMT+0530 (IST) , Election results with county information on race income and education ,2439, politics- ,These data files contain election results for both the 2012 and 2016 US Presidential Elections include proportions of votes cast for Romney Obama (2012) and Trump Clinton (2016). The election results were obtained from this Git repository https//github.com/tonmcg/County_Level_Election_Results_12-16 The county facts data was obtained from another Kaggle election data set https//www.kaggle.com/benhamner/2016-us-election,fips:area_name:state_abbreviation:PST045214:PST040210:PST120214:POP010210:AGE135214:AGE295214:AGE775214:SEX255214:RHI125214:RHI225214:RHI325214:RHI425214:RHI525214:RHI625214:RHI725214:RHI825214:POP715213:POP645213:POP815213:EDU635213:EDU685213:VET605213:LFE305213:HSG010214:HSG445213:HSG096213:HSG495213:HSD410213:HSD310213:INC910213:INC110213:PVY020213:BZA010213:BZA110213:BZA115213:NES010213:SBO001207:SBO315207:SBO115207:SBO215207:SBO515207:SBO415207:SBO015207:MAN450207:WTN220207:RTN130207:RTN131207:AFN120207:BPS030214:LND110210:POP060210:,numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
2016 Election Polls , FiveThirtyEight , www.kaggle.com/fivethirtyeight/2016-election-polls , Thu Nov 03 2016 10:13:25 GMT+0530 (IST) , Collection of Presidential Election Polls from 2015-2016 ,2043, news agencies- politics- ,Dataset Information This dataset is a collection of state and national polls conducted from November 2015-November 2016 on the 2016 presidential election. Data on the raw and weighted poll results by state date pollster and pollster ratings are included. Content There are 27 variables  cycle branch type matchup forecastdate state startdate enddate pollster grade samplesize populaion poll_wt rawpoll_clinton rawpoll_trump rawpoll_johnson rawpoll_mcmullin adjpoll_clinton adjpoll_trump adjpoll_johnson adjpoll_mcmullin multiversions url poll_id question_id createddate timestamp  Inspiration Some questions for exploring this dataset are  What are the trends of the polls over time (by day/week/month)? How do the trends vary by state? What is the probability that Trump/Clinton will win the 2016 election?  Acknowledgements The original dataset is from the FiveThirtyEight 2016 Election Forecast and can be downloaded from here. Poll results were aggregated from HuffPost Pollster RealClearPolitics polling firms and news reports.,,,
Suicides in India , Rajanand Ilangovan / இராஜ்ஆனந்த் இளங்கோவன் , www.kaggle.com/rajanand/suicides-in-india , Sun Jul 23 2017 18:21:45 GMT+0530 (IST) , Sucides in each state is classified according to various parameters from 2001-12 ,1198, india- mental health- death- health- ,Context This data set contains yearly suicide detail of all the states/u.t of India by various parameters from 2001 to 2012. Content Time Period 2001 - 2012  Granularity Yearly Location States and U.T's of India  Parameters a) Suicide causes b) Education status c) By means adopted d) Professional profile e) Social status Acknowledgements National Crime Records Bureau (NCRB) Govt of India has shared this dataset under Govt. Open Data License - India. NCRB has also shared the historical data on their website,Year:Type_code:Type:Age_group:State:Gender:Total:,numeric:string:string:string:string:string:numeric:,
Steam Video Games , Tamber , www.kaggle.com/tamber/steam-video-games , Thu Mar 09 2017 08:31:26 GMT+0530 (IST) , Recommend video games from 200k steam user interactions. ,1228, video games- ,Context Steam is the world's most popular PC Gaming hub with over 6000 games and a community of millions of gamers. With a massive collection that includes everything from AAA blockbusters to small indie titles great discovery tools are a highly valuable asset for Steam. How can we make them better? Content This dataset is a list of user behaviors with columns user-id game-title behavior-name value. The behaviors included are 'purchase' and 'play'. The value indicates the degree to which the behavior was performed - in the case of 'purchase' the value is always 1 and in the case of 'play' the value represents the number of hours the user has played the game. Acknowledgements This dataset is generated entirely from public Steam data so we want to thank Steam for building such an awesome platform and community! Inspiration The dataset is formatted to be compatible with Tamber. Build a Tamber engine and take it for a spin!  Combine our collaborative filter's results with your favorite Machine Learning techniques with Ensemble Learning or make Tamber do battle with something else you've built. Have fun The Tamber Team,The Elder Scrolls V Skyrim:purchase:1.0:0:151603712:,string:string:numeric:numeric:numeric:,
YouTube Comedy Slam , UCI Machine Learning , www.kaggle.com/uciml/youtube-comedy-slam , Wed Sep 20 2017 21:23:44 GMT+0530 (IST) , Votes for the funniest videos ,43, humor- ,Context This dataset provides user vote data on which video from a pair of videos was funnier. YouTube Comedy Slam was a discovery experiment running on YouTube 2011 and 2012. In the experiment pairs of videos were shown to users and the users voted for the video that they found funniest.  Content The datasets includes roughly 1.7 million votes recorded chronologically. The first 80% are provided here as the training dataset and the remaining 20% as the testing dataset.  Each row in this text file represents one anonymous user vote and there are three comma-separated fields.   The first two fields are YouTube video IDs.  The third field is either 'left' or 'right'.  Left indicates the first video from the pair was voted to be funnier than the second. Right indicates the opposite preference.  Acknowledgements Sanketh Shetty 'Quantifying comedy on YouTube why the number of o's in your LOL matter' Google Research Blog https//research.googleblog.com/2012/02/quantifying-comedy-on-youtube-why.html. Dataset was downloaded from UCI ML repository https//archive.ics.uci.edu/ml/datasets/YouTube+Comedy+Slam+Preference+Data Inspiration Predict which videos are going to be funny!,7VvBnz1Ngi4:1Y-Au-tnBLs:right:,string:string:string:,
WNBA Player stats Season 2016-2017 , Thomas De Jonghe , www.kaggle.com/jinxbe/wnba-player-stats-2017 , Fri Aug 25 2017 01:54:47 GMT+0530 (IST) , Points Assists Height Weight and other personal details and stats ,49, sports- ,Context Scraped and copied from http//www.wnba.com/stats/player-stats/#?Season=2017&SeasonType=Regular%20Season&PerMode=Totals + http//www.wnba.com/ in general for the bio data. Content Stats from all games of season 2016-2017  G = Games Played MIN = Minutes Played FGM = Field Goals Made FGA = Field Goals Attempts FG% = Field Goals % 3PM = 3Points Made  3PA = 3Points Attempts 3P% = 3Points % FTM = Free Throws made FTA = Free Throws Attempts FT% = Free Throws % OREB = Offensive Rebounds DREB = Defensive Rebounds REB = Total Rebounds AST = Assists STL = Steals BLK = Blocks TO = Turnovers PTS = Total points DD2 = Double doubles TD3 = Triple doubles  Inspiration Compare WNBA to NBA in best players average heights ...,Name:Team:Pos:Height:Weight:BMI:Birth_Place:Birthdate:Age:College:Experience:Games Played:FGM:FGA:FG%:15:00:3PA:3P%:FTM:FTA:FT%:OREB:DREB:REB:AST:STL:BLK:TO:PTS:MIN:DD2:TD3:,string:string:string:numeric:numeric:numeric:string:dateTime:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
U.S. Technology Jobs on Dice.com , PromptCloud , www.kaggle.com/PromptCloudHQ/us-technology-jobs-on-dicecom , Fri Sep 15 2017 13:46:39 GMT+0530 (IST) , 22000 US-based Technology Job Listings ,145, internet- ,Context This is a pre-crawled dataset taken as subset of a bigger dataset (more than 4.6 million job listings) that was created by extracting data from Dice.com a prominent US-based technology job board. Content This dataset has following fields  advertiserurl  company  employmenttype_jobstatus  jobdescription  joblocation_address  jobtitle  postdate  shift  skills  Acknowledgements This dataset was created by PromptCloud's in-house web-crawling service. Inspiration Analyses of the job description with respect to the job title and skills can be performed.,advertiserurl:company:employmenttype_jobstatus:jobdescription:jobid:joblocation_address:jobtitle:postdate:shift:site_name:skills:uniq_id:,string:string:string:string:string:string:string:string:string:string:string:string:,
Chinese Characters Generator , Dylan , www.kaggle.com/dylanli/chinesecharacter , Fri Jul 14 2017 12:55:37 GMT+0530 (IST) , Chinese fonts dataset which can be used for Chinese text OCR ,129, writing- linguistics- ,About This Dataset You can use this fonts file to generate some Chinese character. Use this image can train a machine learning model to recognize text. Dataset is updating Tell me if you have other font file or anything related to this topic.,0XX:1.50406699716e-06:,string:string:,
Men's Professional Basketball , Open Source Sports , www.kaggle.com/open-source-sports/mens-professional-basketball , Mon Nov 14 2016 01:26:44 GMT+0530 (IST) , Stats on players teams and coaches in men's pro basketball leagues 1937-2012 ,1420, basketball- ,This dataset contains stats on players coaches and teams in men's professional basketball leagues from 1937 to 2012. Acknowledgments This dataset was downloaded from the Open Source Sports website. It did not come with an explicit license but based on other datasets from Open Source Sports we treat it as follows This database is copyright 1996-2015 by Sean Lahman.  This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License. For details see http//creativecommons.org/licenses/by-sa/3.0/ The Data This dataset contains 11 files each corresponding to a data table. There are five main tables  master biographical information for all the players and coaches teams stats on each team per year players stats for each player per year coaches stats for each coach per year series_post information on post-season winners per year  And there are six supplementary tables  abbrev a key to the abbreviations used in other tables awards_coaches coaching awards per year awards_players player awards per year draft draft information per year hof Hall of Fame information per year player_allstar individual player stats for the All-Star Game per year ,abbrev_type:code:full_name:,string:string:string:,
USDA PLANTS Checklist , United States Department of Agriculture , www.kaggle.com/usdeptofag/usda-plants-checklist , Fri Sep 22 2017 23:38:57 GMT+0530 (IST) , Names of plants that grow in North America. ,30, plants- agriculture- ,Context This dataset is a checklist of plants known to grow in North America. The list is maintained by the United States Department of Agriculture. Content This data includes scientific names and common names of all plants in the United States. Acknowledgements This dataset is published as-is by the United States Department of Agriculture. Inspiration What words are commonly used in plant names? Can you detect any trends in say adjectives commonly used in plant names that are less commonly used in the English language?,Symbol:Synonym Symbol:Scientific Name with Author:Common Name:Family:,string:string:string:string:string:,
Elevators in New York City , City of New York , www.kaggle.com/new-york-city/nyc-elevators , Fri Sep 15 2017 22:43:29 GMT+0530 (IST) , All registered elevators in New York City ,65, cities- ,Context This is a dataset of every registered elevator in New York City. It was generated by the NYC Department of Buildings in September 2015 in response to a journalistic Freedom of Information Law request and contains information on elevator type status and function provided in the city's BISweb interface. Content The addresses locations and statuses of elevators in New York City. Acknowledgements This data is republished as-is from its public source on GitHub. That data in turn came from the NYC Department of Buildings. Inspiration Where are the elevators how many of them are functional and what floors do they go to?,DV_DEVICE_NUMBER:Device Status:DV_DEVICE_STATUS_DESCRIPTION:BIN:TAX_BLOCK:TAX_LOT:HOUSE_NUMBER:STREET_NAME:ZIP_CODE:Borough:Device Type:DV_LASTPER_INSP_DATE:DV_LASTPER_INSP_DISP:DV_APPROVAL_DATE:DV_MANUFACTURER:DV_TRAVEL_DISTANCE:DV_SPEED_FPM:DV_CAPACITY_LBS:DV_CAR_BUFFER_TYPE:DV_GOVERNOR_TYPE:DV_MACHINE_TYPE:DV_SAFETY_TYPE:DV_MODE_OPERATION:DV_STATUS_DATE:DV_FLOOR_FROM:DV_FLOOR_TO::LATITUDE:LONGITUDE:,string:string:string:numeric:numeric:numeric:numeric:string:numeric:string:string:numeric:string:numeric:string:string:string:string:string:string:string:string:string:numeric:string:string:string:numeric:numeric:,
General Election Results , Arizona Secretary of State , www.kaggle.com/arizonaSecofState/2016-statewide-general-election-results , Fri Sep 22 2017 23:17:01 GMT+0530 (IST) , November 8 2016 General Election for the State of Arizona ,89, politics- ,"Context The 2016 Statewide General Election results for Arizona. Arizona's 15 counties are required by statute to publish tabulated General Election results by precinct. This file represents a standardized and aggregated version of all 15 files. Please note that while the file is mostly standardized many of the attributes are relatable accross counties via a fuzzy match (the keyword ""Congress"" etc...). Content  County Abbreviation of Arizona's 15 counties AP Apache CH Cochise CN Coconino GI Gila GM Graham GN Greenlee LP La Paz MC Maricopa MO Mohave NA Navajo PM Pima PN Pinal SC Santa Cruz YA Yavapai YU Yuma PrecinctID Precinct identification number designated by the counties. County shorthand has been added. PrecinctName Precinct Name designated by the counties. This is directly passed from the tabulation files.  ContestID Contest Identification number designated by the counties. This is directly passed from the tabulation files and may not be standardized across counties. ContestTitle Title of race as designated by counties. This is directly passed from the tabulation files and may not be standardized across counties. CandidateID Candidate identification number designated by the counties. This is directly passed form the tabulation files and may not be standardized across counties. CandidateName Name of Candidate as desingated by the counties. This is directly passed form the tabulation files and may not be standardized across counties. TotalVotes Vote Total aggregated from the attributes ""PollVotes EarlyVotes Provisionals LatePoll LateEarly"".  PollVotes Total votes tabulated at a designated precinct location on election day. EarlyVotes Total votes tabulated by the counties during the 29 day early voting period. Provisionals Total votes tabulated at a designated precinct location that were deemed acceptable provisional ballots. 12 LateEarly Total votes tabulated by the counties of early votes that were dropped off at designated polling locations rather than received in the mail. (Note only a few counties separated this number from EarlyVote in their tabulation files). Registered The number of registered voters at the time of the election in each designated precinct. Undervote The number of ballots that did note cast the allowed number of votes for any given race. (Example voters are allowed to ""vote for 2"" in the Arizona House of Representatives race in this case these ballots were either left blank or only voted for 1) ContestTotal Total votes cast in a given contest. CandidateParty Party of candidate in a given contest. REP Republican DEM Democrat NP No Party GRN Green LBT Libertarian TotalTurnout Total turnout for a designated precinct. EDTurnout Total turnout for a designated precinct on election day. EarlyTurnout Total turnout for a designated precinct during the 29 day early voting period. (Note this number will include early ballots dropped off at the designated polling location.)  Final Note There are certain records in the file that are not part of any contest. They are normally designated by a contest ID that begins with a ""999"" These are records that the tabulators append to every file to provide background on each of the designated precincts.",County:PrecinctID:PrecinctName:ContestID:ContestTitle:CandidateID:CandidateName:TotalVotes:PollVotes:EarlyVotes:Provisionals:LatePoll:LateEarly:Registered:Undervote:ContestTotal:CandidateParty:TotalTurnout:EDTurnout:EarlyTurnout:,string:string:string:numeric:string:numeric:string:numeric:numeric:numeric:numeric:string:string:numeric:numeric:string:string:numeric:numeric:numeric:,
NFL Arrests 2000-2017 , Patrick Murphy , www.kaggle.com/patrickmurphy/nfl-arrests , Thu Apr 06 2017 04:46:02 GMT+0530 (IST) , A record of reported NFL Arrests with details about Crime Team and Player ,314, american football- ,"Context ""These are arrests charges and citations of NFL players for crimes more serious than common traffic violations. Almost all of the players belonged to an NFL roster at the time of the incident. In rare cases a free agent is included only if that player later signs with an NFL team. The data comes from media reports and public records. It cannot be considered fully complete because records of some player arrests might not have been found for various reasons including lack of media coverage or accessible public records. Many resolutions to these cases also are pending or could not be immediately found."" (Source) Content This data covers January 2000 to March 2017.  Like mentioned above it is not fully complete. In the future I hope to add files to add dimensions like USA crime rates team info player info team season records  Column Name | Description | Example data DATE | Date of the Incident | 3/7/2017 TEAM | Team Identifier at time of incident | SEA (35 total)  NAME | Player Name | Aldon Smith (627 total) POSITION | Player's Position at time of incident | TE (18 total) CASE | Incident Type | Cited (10 total) CATEGORY | Incident Crime Categories a comma separated list of crime types | DUI (103 unique sets) DESCRIPTION | A short text description of the incident | Suspected of stealing golf cart driving drunk resisting arrest in Scottsdale Ariz. OUTCOME | Incident outcome description | Resolution undetermined.  Acknowledgements The original database was conceived and created by sports writer Brent Schrotenboer of USA Today. http//www.usatoday.com/sports/nfl/arrests/ Past Research The Rate of Domestic Violence Arrests Among NFL Players - Benjamin Morris (FiveThirtyEight) I found this data set August of 2015 and created http//nflarrest.com/ that attempts to provide a visual tool to explore the data set and a RESTful API. Inspiration  Can the next arrest team or crime or date be predicted? Does the number of arrests in the previous season pre-season in season effect overall Team season record(Winslossesplayoff progression). How does the NFL arrest rate compare to the nation on average? How does the NFL arrest rate compare to populations with similar affluency? How do crime rates (e.g DUI rates) compare to the geographic area the team represents? ",DATE:TEAM:NAME:POSITION:CASE:CATEGORY:DESCRIPTION:OUTCOME:,dateTime:string:string:string:string:string:string:string:,
London Fire Brigade Calls , Jacob Boysen , www.kaggle.com/jboysen/london-fire , Fri Sep 01 2017 21:46:57 GMT+0530 (IST) , 32k Calls to London Fire Brigade ,95, government agencies- government- ,Context London's fire and rescue service is the busiest in England and one of the largest firefighting and rescue organisations in the world. In the aftermath of the Grenfell Tower fire it is critical that firefighting resources are accurately and appropriately deployed. Content This data covers Jan 01-April 30 2017 consisting of 32 columns containing information on time type and address of call as well the home station stay duration and arrival time of attending pumps. Acknowledgements This dataset was compiled by the City of London. You can use Kernels to analyze share and discuss this data on Kaggle but if you’re looking for real-time updates and bigger data check out the data on BigQuery too. Inspiration  Which boroughs have the shortest average call response? Longest? Which boroughs have the greatest volume of calls? ,address_qualifier:borough_code:borough_name:cal_year:date_of_call:easting_m:easting_rounded:first_pump_arriving_attendance_time:first_pump_arriving_deployed_from_station:frs:hour_of_call:incident_group:incident_number:incident_station_ground:northing_m:northing_rounded:num_pumps_attending:num_stations_with_pumps_attending:postcode_district:postcode_full:proper_case:property_category:property_type:second_pump_arriving_attendance_time:second_pump_arriving_deployed_from_station:special_service_type:stop_code_description:time_of_call:timestamp_of_call:ward_code:ward_name:ward_name_new:,string:string:string:numeric:dateTime:numeric:numeric:numeric:string:string:numeric:string:string:string:numeric:numeric:numeric:numeric:string:string:string:string:string:numeric:string:string:string:dateTime:dateTime:string:string:string:,
New York City Transport Statistics , MichaelStone , www.kaggle.com/stoney71/new-york-city-transport-statistics , Tue Jul 18 2017 18:46:24 GMT+0530 (IST) , Periodic data recorded from NYC Buses - Location Time Schedule & more ,150, transport- public transport- ,Context I wanted to find a better way to provide live traffic updates. We dont all have access to the data from traffic monitoring sensors or whatever gets uploaded from people's smart phones to Apple Google etc plus I question how accurate the traffic congestion is on Google Maps or other apps. So I figured that since buses are also in the same traffic and many buses stream their GPS location and other data live that would be an ideal source for traffic data. I investigated the data streams available from many bus companies around the world and found MTA in NYC to be very reliable.  Content This dataset is from the NYC MTA buses data stream service. In roughly 10 minute increments the bus location route bus stop and more is included in each row. The scheduled arrival time from the bus schedule is also included to give an indication of where the bus should be (how much behind schedule or on time or even ahead of schedule). Data for the entire month of June 2017 is included. Due to space limitations on Kaggle for datasets only selected bus routes have been included. Acknowledgements Data is recorded from the MTA SIRI Real Time data feed and the MTA GTFS Schedule data. Inspiration I want to see what exploratory & discovery people come up with from this data. Feel free to download this dataset for your own use however I would appreciate as many Kernals included on Kaggle as we can get.  Based on the interest this generates I plan to collect more data for subsequent months down the track.,RecordedAtTime:DirectionRef:JourneyPatternRef:PublishedLineName:OriginRef:DestinationRef:DestinationName:Bearing:ProgressRate:BlockRef:VehicleRef:OriginAimedDepartureTime:ProgressStatus:DatedVehicleJourneyRef:VehicleLocation.Longitude:VehicleLocation.Latitude:ExpectedArrivalTime:ArrivalProximityText:DistanceFromStop:NumberOfStopsAway:StopPointRef:VisitNumber:StopPointName:ScheduledArrivalTime:,dateTime:numeric:string:string:string:string:string:numeric:string:string:string:dateTime:string:string:numeric:numeric:dateTime:string:numeric:numeric:numeric:numeric:string:dateTime:,
Swedish Crime Rates , MGN , www.kaggle.com/mguzmann/swedishcrime , Sun Feb 19 2017 04:17:36 GMT+0530 (IST) , Reported crimes in Sweden from 1950 to 2015 ,562, crime- ,Context Swedish crime statistics from 1950 to 2015 Content This data set contains statistics on reported crimes in Sweden (by 100.000) from 1950 to 2015. It contains the following columns  crimes.total total number of reported crimes crimes.penal.code total number of reported crimes against the criminal code crimes.person total number of reported crimes against a person murder total number of reported murder sexual.offences total number of reported sexual offences rape total number of reported rapes assault total number of reported aggravated assaults stealing.general total number of reported crimes involving stealing or robbery robbery total number of reported armed robberies burglary total number of reported armed burglaries vehicle.theft total number of reported vehicle thefts house.theft total number of reported theft inside a house shop.theft total number of reported theft inside a shop out.of.vehicle.theft total number of reported theft from a vehicle criminal.damage total number of reported criminal damages other.penal.crimes number of other penal crime offenses fraud total number of reported frauds narcotics total number of reported narcotics abuses drunk.driving total number of reported drunk driving incidents Year the year population the total estimated population of Sweden at the time  Acknowledgements Raw data taken from https//www.bra.se/bra/bra-in-english/home/crime-and-statistics/crime-statistics.html,Year:,numeric:,
NYC Filming Permits , City of New York , www.kaggle.com/new-york-city/nyc-filming-permits , Tue Sep 19 2017 23:15:31 GMT+0530 (IST) , Information on ~40k Filming Locations ,23, government agencies- visual arts- ,"Context Dataset is a list of film and television permits received from the Mayor's Office of Media and Entertainment in response to a series of FOIL requests in 2015. The permits stretch from October 2011 through September 2015. Content  ProjectTitle The title of the film/television project. EventName A shorthand name for the specific shoot/event being permitted e.g. SunsetPark-010815. EventType One of the following Scouting Permit Rigging Permit Shooting Permit Film Shoot / Production DCAS Prep/Shoot/Wrap Permit Grid Request or Red Carpet Premiere.  According to the MOME Shooting Permit and Film Shoot / Production are interchangeable. EventStartDate and EventEndDate The start and end date and time of the permit. Location One or more locations covered by the permit. Boro What borough the listed locations are in. ProjectId An internal identifier. CategoryName Film or Television. SubCategoryName Includes values such as Pilot Student Film Variety Reality etc. This probably isn't a reliable classification for TV shows it's chosen by the permit applicant on the online form and is not vetted by the Mayor's Office. It also includes overlapping subcategories. For example a show could be both a Morning Show and a Talk Show but would have to choose one or the other. CompanyName The supplied production company name which can be useful in connecting a working title to an actual film/show. The project title is sometimes a variation on the actual title (e.g. Mozart in the Jungle S1 or The Wolf of Wall Street ReShoots) or a working title (e.g. Untitled Female Buddy Cop Movie instead of The Heat St James Place instead of Bridge of Spies). In some cases the locations listed actually span multiple boroughs and the Boro field only represents the primary borough or the borough of the first listed location.  In some cases the Boro field is blank. A given shooting permit can have any number of locations listed for a single day.  According to the guidelines the locations are supposed to be listed in the order they're used on that day.  Most locations are either an address or a range of blocks in the format of STREET 1 between STREET 2 and STREET 3. Permits are generally required when asserting the exclusive use of city property like a sidewalk a street or a park. A shooting permit on a street doesn't necessarily mean there is exterior shooting on the street.  It may just mean for example that something is being shot indoors and the crew needs special parking privileges for trucks. See ""When a Permit is Required"". Shooting on Department of Citywide Administrative Services (DCAS) property like in a city courthouse involves an additional permitting process. Shooting on MTA property or on state/federal property is subject to a different permitting process. A shooting permit is typically but not always for a single day or a single overnight period.  Acknowledgements Data was FOIL’d by WNYC Data Journalism team and hosted originally on GitHub here. Check out these great related resources  General MOME Permit Info The Made in NY Location Library DCAS Managed Public Buildings Metrocosm's NYC Film Permits Map 2015 BCG Report on Media and Entertainment in NYC  Inspiration  Where do most films occur in the city? When is the most common filming time? Who films the most in the city? ",ProjectTitle:EventName:EventType:EventStartDate:EventEndDate:Location:Boro:ProjectId:CategoryName:SubCategoryName:CompanyName:,string:string:string:dateTime:dateTime:string:string:numeric:string:string:string:,
Federal Air Marshal Misconduct , Dan Ofer , www.kaggle.com/danofer/air-marshal-misconduct , Tue Sep 19 2017 13:54:36 GMT+0530 (IST) , Misconduct and punishment of US Flight Marshals ,22, united states- crime- transport- ,"Context Federal air marshals fly undercover on passenger planes and are trained to intervene in the event of a hijacking. This database contains information on 5214 cases of misconduct committed by federal air marshals by date and field office and what discipline was meted out in response.  Content Data covers November 2002 to February 2012. I cleaned the data to remove some extraneous columns and to add an easier ""target"" column (disciplinary results with duplicates merged and the number of days in a suspension removed). The original ""Final Disposition"" columns remains unchanged. Columns Field Office    Allegation Date Case Opened  Final Disposition. Acknowledgements Data gathered and distributed from the Transportation Security Administration by ProPublica https//www.propublica.org/datastore/dataset/federal-air-marshal-misconduct-database ProPublica is an independent non-profit newsroom that produces investigative journalism in the public interest. Falls under ProPublica Data Terms of use. Inspiration  What types of misconduct can result in suspension or a ""slap on the wrist""?  What types of misconduct are ignored and occurred?  ",Field Office :Allegation :Date Case Opened:Final Disposition:target:,string:string:dateTime:string:string:,
UCDP Georeferenced Event Dataset , Kheirallah Samaha , www.kaggle.com/khsamaha/ucdp-georeferenced-event-dataset , Fri Aug 25 2017 23:59:28 GMT+0530 (IST) , UCDP Georeferenced Event Dataset Version 17.1 ,34, ,Context The basic unit of analysis for the UCDP GED dataset is the “event” i.e. an individual incident (phenomenon) of lethal violence occurring at a given time and place. This version authored by  Mihai Croicu  Ralph Sundberg Ph. D.  http//www.ucdp.uu.se/downloads/ please check the attached PDF Codebook  Content The dataset contains 135 181 events. GED 17.1 is a global dataset that covers the entirety of the Globe (excluding Syria) between 1989-01-01 and 2016-12-31.  The maximum (best) spatial resolution of the dataset is the individual village or town. The dataset is fully geocoded.  The maximum (best) temporal resolution of the dataset is the day.  Only events linkable to a UCDP/PRIO Armed Conflict a UCDP Non-State Conflict or a UCDP One-Sided Violence instance are included. Events are included for the entire period i.e. both for the years when such conflicts were active and for the years when such conflicts where not active.   UCDP GED 17.1 is compatible with the 17.1 series of UCDP datasets  The UCDP GED 17.1 is (mostly) backwards compatible with UCDP GED versions 1.0-5.0. Check the compatibility notes below for further details. Significant changes have been made in the actor dyad and actor/side id meaning these identifiers are no longer backwards compatible.  Acknowledgements We wouldn't be here without the help of others. If you owe any attributions or thanks include them here along with any citations of past research. The maximum (best) spatial resolution of the dataset is the individual village or town. The dataset is fully geocoded.  The maximum (best) temporal resolution of the dataset is the day.  Inspiration  Hopefully learn from wars. ,id:year:active_year:type_of_violence:conflict_new_id:conflict_name:dyad_new_id:dyad_name:side_a_new_id:gwnoa:side_a:side_b_new_id:gwnob:side_b:number_of_sources:source_article:source_office:source_date:source_headline:source_original:where_prec:where_coordinates:adm_1:adm_2:latitude:longitude:geom_wkt:priogrid_gid:country:country_id:region:event_clarity:date_prec:date_start:date_end:deaths_a:deaths_b:deaths_civilians:deaths_unknown:best:low:high:,numeric:numeric:numeric:numeric:numeric:string:numeric:string:numeric:numeric:string:numeric:string:string:numeric:string:string:string:string:string:numeric:string:string:string:numeric:numeric:string:numeric:string:numeric:string:numeric:numeric:dateTime:dateTime:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Breweries & Brew Pubs in the USA , Datafiniti , www.kaggle.com/datafiniti/breweries-brew-pubs-in-the-usa , Tue Sep 19 2017 22:30:33 GMT+0530 (IST) , A list of over 7000 breweries and brew pubs in the USA ,335, food and drink- ,About This Data This is a list of of over 7000 breweries and brew pubs in the USA.  The data is provided by Datafiniti's Business Database. The data is part of a larger data set that was used to determine which cities and states have the most breweries.  See Where is Craft Beer most Popular in America?. What You Can Do with This Data This data mostly provides geographical and categorical information for business locations.  Here are some possible questions you could answer  Which cities or states have the most breweries? What industry categories are typically grouped with breweries?  Data Schema A full schema for the data is available in our support documentation. About Datafiniti Datafiniti provides instant access to web data.  We compile data from thousands of websites to create standardized databases of business product and property information.  Learn more. Want More? If you're interested in more data like this please contact us.,address:categories:city:country:key:lat:long:name:phones:postalCode:province:websites:,string:string:string:string:string:numeric:numeric:string:numeric:numeric:string:string:,
Exchange Rates , Federal Reserve , www.kaggle.com/federalreserve/exchange-rates , Wed Sep 06 2017 01:59:37 GMT+0530 (IST) , Exchange rates as far back as 1971 between the USA and 23 countries ,139, finance- economics- ,The Federal Reserve's H.10 statistical release provides data on exchange rates between the US dollar 23 other currencies and three benchmark indexes. The data extend back to 1971 for several of these. Please note that the csv has six header rows. The first contains the  Acknowledgements This dataset was provided by the US Federal Reserve. If you need the current version you can find their weekly updates here. Inspiration  Venezuela is both unusually dependent on oil revenues and experiencing unusual degrees of political upheaval. Can you determine which movements in their currency were driven by changes in the oil price and which were driven by political events? ,"Series Description:SPOT EXCHANGE RATE - EURO AREA :UNITED KINGDOM -- SPOT EXCHANGE RATE, US$/POUND (1/RXI_N.B.UK):SPOT EXCHANGE RATE - BRAZIL :CHINA -- SPOT EXCHANGE RATE, YUAN/US$ P.R. :DENMARK -- SPOT EXCHANGE RATE, KRONER/US$ :INDIA -- SPOT EXCHANGE RATE, RUPEES/US$ :JAPAN -- SPOT EXCHANGE RATE, YEN/US$ :KOREA -- SPOT EXCHANGE RATE, WON/US$ :MALAYSIA -- SPOT EXCHANGE RATE, RINGGIT/US$ :MEXICO -- SPOT EXCHANGE RATE, PESOS/US$ :NORWAY -- SPOT EXCHANGE RATE, KRONER/US$ :SWEDEN -- SPOT EXCHANGE RATE, KRONOR/US$ :SOUTH AFRICA -- SPOT EXCHANGE RATE, RAND/$US:SINGAPORE -- SPOT EXCHANGE RATE, SINGAPORE $/US$ :SWITZERLAND -- SPOT EXCHANGE RATE, FRANCS/US$ :TAIWAN -- SPOT EXCHANGE RATE, NT$/US$ :THAILAND -- SPOT EXCHANGE RATE, BAHT/US$ :SPOT EXCHANGE RATE - VENEZUELA :Nominal Broad Dollar Index :Nominal Major Currencies Dollar Index :Nominal Other Important Trading Partners Dollar Index :AUSTRALIA -- SPOT EXCHANGE RATE US$/AU$ (RECIPROCAL OF RXI_N.B.AL):NEW ZEALAND -- SPOT EXCHANGE RATE, US$/NZ$ RECIPROCAL OF RXI_N.B.NZ :CANADA -- SPOT EXCHANGE RATE, CANADIAN $/US$ :HONG KONG -- SPOT EXCHANGE RATE, HK$/US$ :SRI LANKA -- SPOT EXCHANGE RATE, RUPEES/US$ :",dateTime:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Commercial Paper , Federal Reserve , www.kaggle.com/federalreserve/commercial-paper-rates , Tue Sep 19 2017 02:57:28 GMT+0530 (IST) , Rates & Volumes for 1998-2017 ,42, finance- banking- ,Commercial paper in the global financial market is an unsecured promissory note with a fixed maturity of not more than 270 days. Commercial paper is a money-market security issued (sold) by large corporations to obtain funds to meet short-term debt obligations (for example payroll) and is backed only by an issuing bank or company promise to pay the face amount on the maturity date specified on the note. Since it is not backed by collateral only firms with excellent credit ratings from a recognized credit rating agency will be able to sell their commercial paper at a reasonable price. Commercial paper is usually sold at a discount from face value and generally carries lower interest repayment rates than bonds due to the shorter maturities of commercial paper. Typically the longer the maturity on a note the higher the interest rate the issuing institution pays. Interest rates fluctuate with market conditions but are typically lower than banks' rates. Commercial paper – though a short-term obligation – is issued as part of a continuous rolling program which is either a number of years long (as in Europe) or open-ended (as in the U.S.) Acknowledgements This dataset was made available by the Federal Reserve. You can find the original dataset updated daily here. Inspiration  Based solely on this dataset when would you say the Great Recession financial crisis started? How does that compare with media reports? ,Series Description:Overnight AA Nonfinancial Commercial Paper Interest Rate:7-Day AA Nonfinancial Commercial Paper Interest Rate:15-Day AA Nonfinancial Commercial Paper Interest Rate:30-Day AA Nonfinancial Commercial Paper Interest Rate:60-Day AA Nonfinancial Commercial Paper Interest Rate:90-Day AA Nonfinancial Commercial Paper Interest Rate:Overnight A2/P2 Nonfinancial Commercial Paper Interest Rate:7-Day A2/P2 Nonfinancial Commercial Paper Interest Rate:15-Day A2/P2 Nonfinancial Commercial Paper Interest Rate:30-Day A2/P2 Nonfinancial Commercial Paper Interest Rate:60-Day A2/P2 Nonfinancial Commercial Paper Interest Rate:90-Day A2/P2 Nonfinancial Commercial Paper Interest Rate:Overnight AA Financial Commercial Paper Interest Rate:7-Day AA Financial Commercial Paper Interest Rate:15-Day AA Financial Commercial Paper Interest Rate:30-Day AA Financial Commercial Paper Interest Rate:60-Day AA Financial Commercial Paper Interest Rate:90-Day AA Financial Commercial Paper Interest Rate:Overnight AA Asset-backed Commercial Paper Interest Rate:7-Day AA Asset-backed Commercial Paper Interest Rate:15-Day AA Asset-backed Commercial Paper Interest Rate:30-Day AA Asset-backed Commercial Paper Interest Rate:60-Day AA Asset-backed Commercial Paper Interest Rate:90-Day AA Asset-backed Commercial Paper Interest Rate:,dateTime:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
A Recruiter Year in Review! , JBD  , www.kaggle.com/jdirmeitis/how-or-what-is-my-team-doing , Fri Jan 20 2017 04:07:47 GMT+0530 (IST) , Weekly recruiting activity ,129, employment- ,"Context I am the Director of a technical recruiting team and I would love to get a better look at their peaks valleys hurdles and hot spots to see how i can better manager and show them the value in process improvements. The data is dirty at best they didnt always track or enter in the correct pieces. I have been here for 6 months and it has been a steady improvement. I welcome any recommendations or data you can suggest. You will see our client numbers from open projects to the activity and team production Content I am attaching what i call the MBO form ""Management by Objective"". The form is completed weekly by my team to help track how they are doing from an activity perspective. Its a name i'm living with not loving just yet. This data is a year long look into how many people they screened how many people they submitted to projects and how many people they put on projects. The other issue is some of the data changed when i joined the team so please look at in in 2 pieces. Jan - June 2016 July - Dec 2016... I just started in June and added more granularity. There has also been some turn over so you will see partial data from some of my team Acknowledgements My team is responsible for data gathering im responsible for review and strategy adjustments  Inspiration I would like to get a better view into what their energy cycle looks like. (they work in waves).  I would like to know what the sweet spot for motivation might be. (early in the month-later in the month) I would like to identify activity trends on a week to week basis Help me understand if this is a constant - consistent level of activity or if i can get more juice from this orange I also dont know what i dont know... any insight is greatly appreciated",Q1::Q3:Quarter:# of Recruiters:Total Hires:Billable:Direct Hire:,string:numeric:string:numeric:numeric:numeric:numeric:numeric:,
Employee Attrition , People HR Analytics Repository , www.kaggle.com/HRAnalyticRepository/employee-attrition-data , Thu Apr 27 2017 00:09:14 GMT+0530 (IST) , Can you forecast employee attrition? ,1712, employment- business- ,Context This data was originally posted on my personal oneDrive account. It represent fictitious/fake data on terminations. For each of 10 years it show employees that are active and those that terminated. The intent is to see if  individual terminations can be predicted from the data provided. The thing to be predicted is status of active or terminated Content The data contains employee id employee record date ( year of data) birth date hire date termination date age length of service city department job title  store number gender termination reason termination type status year status business unit These might be typical types of data in hris Acknowledgements None- its fake data Inspiration A lot of turnover analyses occur at an aggregate level-such as turnover rates. But few analyses concentrate on trying to identify exactly which individuals might leave based on  patterns that might be present in existing data. Machine learning algorithms often showcase customer churn examples for telcos or product marketing. Those algorithms equally apply to employee churn.,EmployeeID:,numeric:,
PokemonGO , Alberto Barradas , www.kaggle.com/abcsds/pokemongo , Fri Aug 26 2016 10:27:19 GMT+0530 (IST) , 151 Pokemon and battle stats ,1215, video games- ,This is a database of the first 151 pokemon; the ones you can find in the PokemonGO game. The stats include Pokemon Number Name First and Second Type Max CP Max HP and a url from the bulbagarden.net gallery.  Pokemon No Number or ID of the pokemon. Name The original name of the pokemon. First Type What type of pokemon it is. Second Type Some pokemon can have two types if they don't this cell is empty. Max CP This is the maximum amount of damage a pokemon can infringe. Max HP The maximum amount of damage a pokemon can receive. URL This is a link to the pokemon's image on bulbagarden.  This database presents a great way of helping new generations of pokemon players learn about data science and pokemon at the same time. This data was scrapped from http//handbooks.bulbagarden.net/pokemongo/pokemon-index,Pokemon No.:Name:Type 1:Type 2:Max CP:Max HP:Image URL:,numeric:string:string:string:numeric:numeric:string:,
League of Legends Summoner Ids and Data - 2016 , Chris Pierse , www.kaggle.com/xenogearcap/league2016 , Thu Apr 27 2017 04:23:57 GMT+0530 (IST) , 480k summoner ids sorted by tier from October 2016. Game data from 130k players. ,151, video games- ,Context The summoner ids which are unique to each player were collected and sorted by ranked tier around October of last year. The game data was collected from only gold-ranked summoner ids. I originally collected this data to identify which champions top Quinn mains tend to play aside from Quinn. The strongest correlation I found was that top Quinn players tend to also play Graves in the top lane. I recently revisited this project to put together a simple recommender system with newer data and that system can be found here.  I am sharing the 2016 data here because Riot's API seems to only provide a summoner's current rank i.e. there is no rank history. This 2016 data could be useful for anyone interested in seeing how summoners have evolved over time. To get you started on working with champion data I also added the 2016 game data I collected from Gold-ranked summoners when I was investigating top Quinn players.  Content All data was collected through Riot Games' publicly available API.  SummIds2016 - 480421 summoner ids sorted by tier as of late October 2016.  GoldSummData2016 - Game data from 131552 Gold-ranked summoners. For each summoner all champions that were played in the 2016 season at the time of collection are presented and sorted by role. The roles are those provided by Riot's API. The columns are separated by commas while the champions in each role are separated by spaces.  ChampId2Name - Maps champion ids to champion names. Acknowledgements This data is only available because Riot provides a publicly accessible API. Thanks Riot! The banner image is also the property of Riot Games.  Inspiration Given that the unique aspect of this data set is the rank of each summoner in 2016 it would be interesting to see how many summoners improved their performance from 2016 to 2017. Perhaps you can identify an underlying trend that can explain why some summoner's went up/down in rank e.g. top Quinn players may have increased in rank due to the buffs to lethality.  Because League of Legends changes with each patch it would also be interesting to see how someone can leverage year-old data to make recommendations that are still relevant.,ChampId:ChampName:,numeric:string:,
Basic Income Survey - 2016 European Dataset , Dalia Research , www.kaggle.com/daliaresearch/basic-income-survey-european-dataset , Wed May 10 2017 15:50:49 GMT+0530 (IST) , A survey about Europeans' opinions toward basic income ,404, income- ,About this Dataset  Dalia Research conducted the first representative poll on basic income across Europe in the Spring of 2016. The results first presented together with NEOPOLIS at the Future of Work conference in Zurich showed that two thirds of Europeans would vote for basic income. Dalia's basic income poll is now an annual survey and the first wave of results from 2016 are now being made public. Although Dalia's latest research on basic income is not yet public you can visit here to see the results from the most recent Spring 2017 survey.  The study was conducted by Dalia Research in April 2016 on public opinion across 28 EU Member States. The sample of n=9.649 was drawn across all 28 EU Member States taking into account current population distributions with regard to age (14-65 years) gender and region/country. Enjoy perusing the dataset and exploring interesting connections between demographics and support for basic income.,country_code:uuid:age:gender:rural:dem_education_level:dem_full_time_job:dem_has_children:question_bbi_2016wave4_basicincome_awareness:question_bbi_2016wave4_basicincome_vote:question_bbi_2016wave4_basicincome_effect:question_bbi_2016wave4_basicincome_argumentsfor:question_bbi_2016wave4_basicincome_argumentsagainst:age_group:weight:,string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:numeric:,
International Debt Statistics , World Bank , www.kaggle.com/theworldbank/international-debt-statistics , Fri Nov 25 2016 04:56:17 GMT+0530 (IST) , Major Financial Indicators from Developing and Advanced Economies ,817, finance- ,Context Focuses on financial flows trends in external debt and other major financial indicators for developing and advanced economies (data from Quarterly External Debt Statistics and Quarterly Public Sector Debt databases). Includes over 200 time series indicators from 1970 to 2014 for most reporting countries and pipeline data for scheduled debt service payments on existing commitments to 2022. Content This dataset contains country names and indicator variables from 1970 until 2024. Additional materials and detailed descriptions of the datasets can be downloaded from here. Acknowledgement The original datasets and data dictionaries can be found here. Inspiration Few ideas for exploring the dataset  Compare the current account balance across countries. Is there a pattern associated with developing vs. advanced economies? How have the debt-related indicators changed over time? Are these strongly associated with other financial indicators? ,,,
FourSquare - NYC Restaurant Check-Ins , Dan Ofer , www.kaggle.com/danofer/foursquare-nyc-rest , Tue Sep 05 2017 13:04:14 GMT+0530 (IST) , Check-ins for New York City restaurants over 4 months ,54, ,Context Dataset includes check-in tip and tag data of restaurant venues in NYC collected from Foursquare from 24 October 2011 to 20 February 2012. It contains 3112 users 3298 venues with 27149 check-ins and 10377 tips. Content  NY_Restauraunts_checkins.csv {Originally dataset_ubicomp2013_checkins.txt} has two columns.  Each line represents a check-in event.  The first column is user ID while the second column is venue ID.  NY_Restauraunts_tips.csv {Originally dataset_ubicomp2013_tips.txt} has three columns.  Each line represents a tip/comment a user left on a venue.  The first and second columns are user ID and venue ID repsectively.  The third column is tip text. NY_Restauraunts_tags.csv {Originally dataset_ubicomp2013_tags.txt} has two columns.  Each line represents the tags users added to a venue.  The first column is venue ID while the second column is tag set of the corresponding venues. Empty tag sets may exist for a venue if no user has ever added a tag to it.  Acknowledgements Columns headers details and file formats added manually. Source Scraped from Foursquare and downloaded from https//sites.google.com/site/yangdingqi/home/foursquare-dataset  Dingqi Yang Daqing Zhang Zhiyong Yu and Zhiwen Yu Fine-Grained Preference-Aware Location Search Leveraging Crowdsourced Digital Footprints from LBSNs. In Proceeding of the 2013 ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp 2013) September 8-12 2013 in Zurich Switzerland.   Dingqi Yang  Daqing Zhang Zhiyong Yu and Zhu Wang A Sentiment-enhanced Personalized Location Recommendation System. In Proceeding of the 24th ACM Conference on Hypertext and Social Media (HT 2013) 1-3 May 2013 Paris France.  Dingqi Yang Daqing Zhang Zhiyong Yu Zhiwen Yu Djamal Zeghlache.  SESAME Mining User Digital Footprints for Fine-Grained Preference-Aware Social Media Search. ACM Trans. on Internet Technology (TOIT) 14(4) 28 2014.  Original README included (note that columns were added). Inspiration Interesting questions  Linkage to additional data. Sentiment analysis.  Recommender systems prediction of checkins to related venues or tags.  Use for augmenting other datasets with geospatial or geotemporal data (for that period). ,user_ID:venue_ID:,numeric:numeric:,
Romania Earthquake Historical Data , Daia Alexandru , www.kaggle.com/alexandrudaia/romania-earthquake-historical-data , Sat May 06 2017 00:34:52 GMT+0530 (IST) , Data from 1975  until   published  date ,275, geology- ,Romania   earthquakes from  1975  to   2017 In Romania   earthquakes   are   not very  powerful  but  sometimes     they  have a lot of victims See for example this   strike https//en.wikipedia.org/wiki/1977_Vrancea_earthquake For    other description of Romania   list of  eartquakes     please  see   this  https//en.wikipedia.org/wiki/List_of_earthquakes_in_Romania Inspiration It will be interesting if someone could find  hidden  patterns in  this data,time:latitude:longitude:depth:mag:magType:nst:gap:dmin:rms:net:id:updated:place:type:horizontalError:depthError:magError:magNst:status:locationSource:magSource:,dateTime:numeric:numeric:numeric:numeric:string:string:numeric:numeric:numeric:string:string:dateTime:string:string:numeric:numeric:numeric:numeric:string:string:string:,
Primetime Emmy Awards 1949-2017 , Paul Magda , www.kaggle.com/pmagda/primetime-emmy-awards , Tue Sep 19 2017 21:45:31 GMT+0530 (IST) , Which television show has won the most Emmy Awards? ,55, actors- entertainment- telecommunications- ,Context We are working on a project relating to predicting and voting for Academy Award. With the Primetime Emmy Awards coming up this week I thought it would be interesting to see if I could integrated those. I couldn't find too many well organized datasets relating to those awards.  I decided to spend the afternoon and build my own.  We probably won't use this information this year  but it might be something we could use in the future.  Content I created a simple web parser in Go and parsed the data from the Emmy Awards Website. The data is a representation of Primetime Emmy Nominees from the first Emmy Awards (1949)... to the current ones that will air Sunday September 17th 2017.  After this date the winner will have to be updated.  In work we've done with Academy Awards we used movie title and name as the main structure for the data. I kind of felt this was a little inconsistent as certain awards focus on one or the other. With the Emmy Nominees I made it more general with nominee and additional detail I believe this will make the data more consistent and easier to manipulate. Acknowledgements I based the structure of the data from the Kaggle dataset of the Academy Awards . I would also like to acknowledge the Academy of Television Arts & Sciences for providing the data on their website. Inspiration Who won the most Emmys for Outstanding Comedy Series? I think it would be cool if we could answer Who will win the Emmy for Outstanding Comedy Series in 2018?  But I think we more than just historical data. ,year:category:winner:nominee:detail:,numeric:string:numeric:string:string:,
Consumer Price Index , US Bureau of Labor Statistics , www.kaggle.com/bls/consumer-price-index , Wed Jun 28 2017 02:20:24 GMT+0530 (IST) , Statistical measures of change in prices of consumer goods ,243, business- finance- ,"Context The Bureau of Labor Statistics defines the Consumer Price Index (CPI) as “a statistical measure of change over time of the prices of goods and services in major expenditure groups--such as food housing apparel transportation and medical care--typically purchased by urban consumers.  Essentially it compares the cost of a sample of goods and services in a specific month relative to the cost of the same ""market basket"" in an earlier reference period.  Make sure to read the cu.txt for more descriptive summaries on each data file and how to use the unique identifiers. Content This dataset was collected June 27th 2017 and may not be up-to-date. The revised CPI introduced by the BLS in 1998 includes indexes for two populations; urban wage earners and clerical workers (CW) and all urban consumers (CU).  This dataset covers all urban consumers (CU). The Consumer Price Index (CPI) is a statistical measure of change over time of the prices of goods and services in major expenditure groups--such as food housing apparel transportation and medical care--typically purchased by urban consumers.  Essentially it compares the cost of a sample ""market basket"" of goods and services in a specific month relative to the cost of the same ""market basket"" in an earlier reference period.  This reference period is designated as the base period. As a result of the 1998 revision both the CW and the CU utilize updated expenditure weights based upon data tabulated from three years (1982 1983 and 1984) of the Consumer Expenditure Survey and incorporate a number of technical improvements including an updated and revised item structure. To construct the two indexes prices for about 100000 items and data on about 8300 housing units are collected in a sample of 91 urban places.  Comparison of indexes for individual CMSA's or cities show only the relative change over time in prices between locations.  These indexes cannot be used to measure interarea differences in price levels or living costs. Summary Data Available U.S. average indexes for both populations are available for about 305 consumer items and groups of items.  In addition over 100 of the indexes have been adjusted for seasonality.  The indexes are monthly with some beginning in 1913. Semi-annual indexes have been calculated for about 100 items for comparison with semi-annual areas mentioned below.  Semi-annual indexes are available from 1984 forward. Area indexes for both populations are available for 26 urban places.  For each area indexes are published for about 42 items and groups.  The indexes are published monthly for three areas bimonthly for eleven areas and semi-annually for 12 urban areas. Regional indexes for both populations are available for four regions with  about 55 items and groups per region.  Beginning with January 1987 indexes are monthly with some beginning as early as 1966.  Semi-annual indexes have been calculated for about 42 items for comparison with semi-annual areas mentioned above.  Semi-annual indexes have been calculated for about 42 items in the 27 urban places for comparison with semi-annual areas. City-size indexes for both populations are available for three size classes with about 55 items and groups per class.  Beginning with January 1987 indexes are monthly and most begin in 1977.  Semi-annual indexes have been calculated for about 42 items for comparison with semi-annual areas mentioned below. Region/city-size indexes for both populations are available cross classified by region and city-size class.  For each of 13 cross calculations about 42 items and groups are available.  Beginning with January 1987 indexes are monthly and most begin in 1977.  Semi-annual indexes have been calculated for about 42 items in the 26 urban places for comparison with semi-annual areas. Frequency of Observations  U.S. city average indexes some area indexes and regional indexes city-size indexes and region/city-size indexes for both populations are monthly.  Other area indexes for both populations are bimonthly or semi-annual. Annual Averages Annual averages are available for all unadjusted series in the CW and CU. Base Periods Most indexes have a base period of 1982-1984 = 100.  Other indexes mainly those which have been added to the CPI program with the 1998 revision are based more recently.  The base period value is 100.0 except for the ""Purchasing Power"" values (AAOR and SAOR) where the base period value is 1.000. Data Characteristics Indexes are stored to one decimal place except for the ""Purchasing Power"" values which are stored to three decimal places. References  BLS Handbook of Methods Chapter 17 ""Consumer Price Index""  BLS Bulletin 2285 April 1988. Acknowledgements This dataset was taken directly from the U.S. Bureau of Labor Statistics website at http//www.bls.gov/data/ and converted to CSV format. Inspiration The Bureau of Labor Statistics has done a great job of providing this source of information for the public to explore. You can use this information to compare the cost of living in urban areas around the United States. What are the top 10 most expensive places to live? Which cities have the most expensive snacks or college textbooks? Coffee? Beer?",area_code:,numeric:,
Forecasts for Product Demand , FelixZhao , www.kaggle.com/felixzhao/productdemandforecasting , Fri Aug 25 2017 08:12:57 GMT+0530 (IST) , Make Accurate Forecasts for Thousands of Different Products ,232, ,Context The dataset contains historical product demand for a manufacturing company with footprints globally. The company provides thousands of products within dozens of product categories. There are four central warehouses to ship products within the region it is responsible for. Since the products are manufactured in different locations all over the world it normally takes more than one month to ship products via ocean to different central warehouses. If forecasts for each product in different central with reasonable accuracy for the monthly demand for month after next can be achieved it would be beneficial to the company in multiple ways. This dataset is all real-life data and products/warehouse and category information encoded.  Content Product_Code The product name encoded. Warehouse Warehouse name encoded. Product_Category Product Category for each Product_Code encoded. Date The date customer needs the product. Order_Demand single order qty. Inspiration Is it possible to make forecasts for thousands of products (some of them are highly variable in terms of monthly demand) for the the month after next?,Product_Code:Warehouse:Product_Category:Date:Order_Demand:,string:string:string:dateTime:numeric:,
Flipkart Products , PromptCloud , www.kaggle.com/PromptCloudHQ/flipkart-products , Fri Sep 15 2017 15:05:02 GMT+0530 (IST) , 20000 products on Flipkart ,309, internet- ,Context This is a pre-crawled dataset taken as subset of a bigger dataset (more than 5.8 million products) that was created by extracting data from Flipkart.com a leading Indian eCommerce store. Content This dataset has following fields  product_url product_name product_category_tree pid retail_price discounted_price image is_FK_Advantage_product description product_rating overall_rating brand product_specifications  Acknowledgements This dataset was created by PromptCloud's in-house web-crawling service. Inspiration Analyses of the pricing product specification and brand can be performed.,uniq_id:crawl_timestamp:product_url:product_name:product_category_tree:pid:retail_price:discounted_price:image:is_FK_Advantage_product:description:product_rating:overall_rating:brand:product_specifications:,string:dateTime:string:string:string:string:numeric:numeric:string:boolean:string:string:string:string:string:,
Mapping the KKK 1921-1940 , Jacob Boysen , www.kaggle.com/jboysen/mapping-the-kkk , Sat Sep 16 2017 00:56:55 GMT+0530 (IST) , Location and Charter Date of over 2000 “Klaverns” ,19, united states- sociology- ,"Context Mapping the Klan is a rough timeline of the rise of the second Ku Klux Klan between 1915 and 1940. Each red dot shows a local unit or ""Klavern."" The official numbers for each Klavern indicate a basic chronology for the chartering of the Klaverns and they also reveal patterns of Klan organizing. Content The data for Mapping the Klan is based on a variety of sources mostly newspapers sponsored by or sympathetic to the Ku Klux Klan. These publications reported on the activities of local units known officially as Klaverns. Data includes approximate date of charter location(lat/lon) nickname source for data and related notes. Dates The dates for each Klavern come from the publication listed for that entry. So it is likely that the Klaverns identified were established even earlier than the date indicated. The Klan’s recruitment methods make it harder to accurately date the beginning of a Klavern. Each local group had to recruit a set number of members before it could get its charter and number. Numbers The Klaverns in each state were numbered in chronological order of their chartering. So we can assume that if a Klan number 40 is dated October 1923 Klans 1 to 39 were established before 1923. As historians agree the busiest years of Klan expansion were 1922-1924 with big declines thereafter. The large number of klaverns established after 1925 when the Ku Klux Klan largely disappeared from the national news media is intriguing. The continued organizing of Klaverns after 1925 is more difficult to study for lack of sources. That history remains to be explored. Learn more. Acknowledgements Source data here available through the VCU Library site. Data was compiled by  John Kneebone lead author and professor of History VCU Shariq Torres lead web developer and data co-author VCU Libraries Erin White project manager VCU Libraries Lauren Work digital collections VCU Libraries Alison Tinker web designer VCU Libraries John Glover digital humanities consultant VCU Libraries  Inspiration  Where was the densest concentrations of KKK? What years saw the biggest rises? ",id:state_id:city:klan_number:nickname:notes:latitude:longitude:year:,numeric:numeric:string:numeric:string:string:numeric:numeric:numeric:,
Real Time Bidding , Ricky , www.kaggle.com/zurfer/rtb , Mon Feb 27 2017 23:51:27 GMT+0530 (IST) , Predict clicks and handle imbalanced data ,407, business- artificial intelligence- ,Context This is real real-time bidding data that is used to predict if an advertiser should bid for a marketing slot e.g. a banner on a webpage. Explanatory variables are things like browser operation system or time of the day the user is online marketplace his identifiers were traded on earlier etc. The column 'convert' is 1 when the person clicked on the ad and 0 if this is not the case.  Content Unfortunately the data had to be anonymized so you basically can't do a lot of feature engineering. I just applied PCA and kept 0.99 of the linear explanatory power. However I think it's still really interesting data to just test your general algorithms on imbalanced data. ;) Inspiration Since it's heavily imbalanced data it doesn't make sense to train for accuracy but rather try to get obtain a good AUC F1Score MCC or recall rate by cross-validating your data.  It's interesting to compare different models (logistic regression decision trees svms ...) over these metrics and see the impact that your split in traintest data has on the data.  It might be good strategy to follow these  Tactics to combat imbalanced classes.,0:1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:19:20:21:22:23:24:25:26:27:28:29:30:31:32:33:34:35:36:37:38:39:40:41:42:43:44:45:46:47:48:49:50:51:52:53:54:55:56:57:58:59:60:61:62:63:64:65:66:67:68:69:70:71:72:73:74:75:76:77:78:79:80:81:82:83:84:85:86:87:convert:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Korean War Bombing Runs , United States Air Force , www.kaggle.com/usaf/korean-war-bombing-runs , Thu Sep 14 2017 00:52:29 GMT+0530 (IST) , Details on 12.8k Bombing Runs ,43, military- war- ,Context THOR is a painstakingly cultivated database of historic aerial bombings from World War I through Vietnam. THOR has already proven useful in finding unexploded ordinance in Southeast Asia and improving Air Force combat tactics. Our goal is to see where public discourse and innovation takes this data.  Each theater of warfare has a separate data file in addition to a THOR Overview. Content By June 1950 the U.S. Air Force had constructed a comprehensive historical program.  Over half the records in the Air Force Historical Archives consisted of World War II artifacts including unit histories and combat reports compiled by field historians as they received a steady flow of documents from operational squadrons and wings.  The archives team developed experience pouring through intelligence reports target folders bomb damage assessments and statistics to develop hard earned lessons on modern warfare.  So from the first day of combat 25 June historians embedded within operational commands in Korea knew recording events from the start would be important. In particular Albert F. Simpson the Archives' Director picked up the phone and directly called the headquarters of the Far East Air Forces (FEAF) to request they begin collecting data on all sorties generated in theater.  Their statistical services agreed and began regularly sending typed reports on 20 essential data items  Group and Squadron designations Operating base location Type and model of aircraft Aborted airborne and effective sorties Number of aircraft lost or damaged to enemy ground aircraft or other action Personnel Killed Wounded or Missing in Action Number of enemy aircraft destroyed or damaged Number of bombs rockets and bullets expended  Read more here on the Exteter database and consult the data dictionary here. Acknowledgements THOR is a dataset project initiated by  Lt Col Jenns Robertson and continued in partnership with Data.mil  an experimental project created by the Defense Digital Service in collaboration with the Deputy Chief Management Officer and data owners throughout the U.S. military.  Inspiration  Which campaigns saw the heaviest bombings? Which months saw the most runs? ,GLOSSARY_ID:AIRCRAFT:FULL_NAME:WEBSITE_LINK:AIRCRAFT_TYPE:,numeric:string:string:string:string:,
CartolaFC , Luiz Gustavo Schiller , www.kaggle.com/schiller/cartolafc , Wed Aug 09 2017 15:42:27 GMT+0530 (IST) , Data from the popular Brazilian Fantasy Football (2014 to 2017) ⚽️ ,331, association football- brazil- sports- ,"Context CartolaFC is the most popular fantasy football in Brazil. Before each round of the Brazilian Football League players choose which athletes they want for their teams and they score points based on their real-life performances.  Content Data is divided in 7 kinds of files Athletes (atletas)  ""atleta_id"" id ""nome"" athlete's full name ""apelido"" athlete's nickname  Clubs (clubes)  ""id"" id ""nome"" club's name ""abreviacao"" name abbreviation ""slug"" used for some API calls  Matches (partidas)  ""rodada_id"" current round ""clube_casa_id"" home team id ""clube_visitante_id"" away team id ""clube_casa_posicao"" home team's position on the league ""clube_visitante_posicao"" away team's position on the league ""aproveitamento_mandante"" home team's outcome on the last five matches (d loss e draw v victory) ""aproveitamento_visitante"" away team's outcome on the last five matches (d loss e draw v victory) ""placar_oficial_mandante"" home team's score ""placar_oficial_visitante"" away team's score ""partida_data"" match date ""local"" stadium ""valida"" match valid for scoring  Scouts  ""atleta_id"" reference to athlete ""rodada_id"" current round ""clube_id"" reference to club ""posicao_id"" reference to position ""status_id"" reference to status ""pontos_num"" points scored on current round ""preco_num"" current price ""variacao_num"" price variation from previous round ""media_num"" average points per played round ""jogos_num"" number of matches played ""FS"" suffered fouls ""PE"" missed passes ""A"" assistances ""FT"" shots on the post ""FD"" defended shots ""FF"" shots off target ""G"" goals ""I"" offsides ""PP"" missed penalties ""RB"" successful tackes ""FC"" fouls commited ""GC"" own goals ""CA"" yellow cards ""CV"" red cards ""SG"" clean sheets (only defenders) ""DD"" difficult defenses (only goalies) ""DP"" defended penalties (only goalies) ""GS"" suffered goals (only goalies)  Positions (posicoes)  ""id"" id ""nome"" name ""abreviacao"" abbreviation  Status  ""id"" id ""nome"" name  Points (pontuacao)  ""abreviacao"" abbreviation ""nome"" name ""pontuacao"" points earned for respective scout  Acknowledgements The datasets from 2014 to 2016 were taken from here https//github.com/thevtm/CartolaFCDados. Data from 2017 until round 11 was taken from this repo https//github.com/henriquepgomide/caRtola. From 2017 round 12 and on I've been extracting the data from CartolaFC's API (which is not officially public). Inspiration It would be interesting to see analyses on which factors make an athlete or team more likely to score points and also predictive models for future scores.",id:apelido:clube_id:posicao_id:,numeric:string:numeric:numeric:,
Hotel Reviews from Chennai India , RanjithaKorrapati , www.kaggle.com/ranjitha1/hotel-reviews-city-chennai , Sat Jun 24 2017 11:08:57 GMT+0530 (IST) , Reviews of over 500 hotels across the city of Chennai India ,174, cities- india- hotels- linguistics- ,Context The volume of text data is increasing at a humongous rate everyday which has made it almost impossible to evaluate the data manually.   In order to make the process of analyzing this text automatic there are various machine learning techniques that could be applied. This data set is for those enthusiasts who are willing to play with text data and perform  sentiment analysis / text classification. Content The data has been scraped from trivagoIndia.   A python script was run to examine the get requests and make those requests explicitly in order to obtain required data in JSON. This data was further parsed and written into a csv file. The data is in the form of a csv file with over 4000 reviews. There are 5 columns Column 1  Name of the hotel Column 2 Title of the review Column 3 Text of the review Column 4 Sentiment of the review*( 1 Negative  2Average 3Positive) Column 5 Rating percentage *There are three values for sentiment as mentioned above. A value of 1 represents a negative reviews whereas a value of 3 represents a positive one. Acknowledgements I would like to thank my friend iniquitouspsyche for helping me out in scraping the data from trivago. Inspiration This data set consists of actual reviews from real people. So this data set will give a real time experience as to how to deal with textual data .,Hotel_name:Review_Title:Review_Text:Sentiment:Rating_Percentage::,string:string:string:numeric:numeric:string:,
World Bank's Major Contracts  , World Bank , www.kaggle.com/theworldbank/world-banks-major-contracts , Wed Sep 13 2017 23:40:57 GMT+0530 (IST) , The largest supply contracts awarded by the World Bank ,79, international relations- ,"This set of contract awards includes data on commitments against contracts that were reviewed by the Bank before they were awarded (prior-reviewed Bank-funded contracts) under IDA/IBRD investment projects and related Trust Funds. This dataset does not list all contracts awarded by the Bank and should be viewed only as a guide to determine the distribution of major contract commitments among the Bank's member countries. ""Supplier Country"" represents place of supplier registration which may or not be the supplier's actual country of origin. Information does not include awards to subcontractors nor account for cofinancing. The Procurement Policy and Services Group does not guarantee the data included in this publication and accepts no responsibility whatsoever for any consequences of its use. The World Bank complies with all sanctions applicable to World Bank transactions. Acknowledgements This dataset was kindly made available by the World Bank. You can find the original dataset here. Inspiration  How do the contract awards compare to each nations's voting rights? Are there any unexpected consistent preferences? ",As of Date:Fiscal Year:Region:Borrower Country:Borrower Country Code:Project ID:Project Name:Procurement Type:Procurement Category:Procurement Method:Product line:Major Sector:WB Contract Number:Contract Description:Contract Signing Date:Supplier:Supplier Country:Supplier Country Code:Total Contract Amount (USD):Borrower Contract Reference Number:,dateTime:numeric:string:string:string:string:string:string:string:string:string:string:numeric:string:dateTime:string:string:string:string:string:,
Industrial Security Clearance Adjurations , Department of Defense , www.kaggle.com/usdod/dod-clearance-adjurations , Thu Sep 14 2017 01:26:58 GMT+0530 (IST) , Over 20000 security clearance appeals made to the Department of Defense ,33, military- ,Context Industry contractors that work for or with the United States Department of Defense and comes into contact with secret or privileged information must submit to a background check by the government as a part of their contractual obligations. Any employee who fails to get the necessary clearance will be unable to work. Employees may however appeal their decision; in this case the decision will be reviewed and finalized (or reversed) by the Department of Defense Office of Hearings and Appeals (DOHA). This dataset contains summaries of the deliberations and results of such hearings and provides a window into getting security clearance to work as a defense contractor in the United States. Content This data contains dates case numbers decisions and decisions summaries for over 20000 cases submitted for review between late 1996 and early 2016. Acknowledgements This data was published in an HTML format by the US Department of Defense. It has been converted into a CSV format before upload to Kaggle. Inspiration  What percentage of appeals were declined or upheld? What were the dominant reasons decisions were made? Have the factors behind decisions changed over times? What kinds of words appear in decision texts? ,:casenum:date:digest:keywords:,numeric:string:dateTime:string:string:,
Indirect Food Additives , Food and Drug Administration , www.kaggle.com/fda/indirect-food-additives , Tue Sep 12 2017 22:23:58 GMT+0530 (IST) , Chemicals indirectly added during processing regulated by the FDA ,53, food and drink- ,Context The vast majority of food and food ingredients eaten today is processed in some way before they arrived at the kitchen or dinner table. Food processing equipment may leave trace amounts of various industrial chemical compounds in the foods we eat and these chemicals classed indirect food additives are regulated by the United States Food and Drug Administration. This dataset is a list of indirect food additives approved by the FDA. Content This dataset contains the names of chemical compounds and references to the federal government regulatory code approving and controlling their usage. Acknowledgements This dataset is published by the FDA and available online as a for-Excel CSV file. A few errant header columns have been cleaned up prior to upload to Kaggle but otherwise the dataset is published as-is. Inspiration  What tokens most commonly appear amongst the names contained in this list? Any identifiable elements or compounds? ,ID:Substance:Reg01:Reg02:reg03:reg04:reg05:reg06:reg07:reg08:reg09:reg10:reg11:reg12:reg13:reg14:reg15:reg16:reg17:reg18:reg19:reg20:reg21:Other name:SYN1:SYN2:SYN3:SYN4:SYN5:SYN6:SYN7:SYN8:SYN9:SYN10:SYN11:SYN12:SYN13:SYN14:SYN15:SYN16:SYN17:SYN18:,dateTime:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:,
Chicago Towing Records , Chicago Police Department , www.kaggle.com/chicagopolice/chicago-towing , Tue Sep 12 2017 23:41:05 GMT+0530 (IST) , 5800 Violation Records July 7- Sept 7 2017 ,33, government agencies- government- ,Context This dataset displays location for vehicles that have been towed and impounded by the City of Chicago within the last 90 days. Illegally parked vehicles abandoned vehicles and vehicles used for illegal activities may be towed by the Chicago Police Department the Department of Streets and Sanitation the Department of Revenue Aviation and the office of the City Clerk. After a tow request is issued an inventory number is assigned by the Department of Streets and Sanitation and a truck is dispatched to tow the requested vehicle to a City auto pound. Disclaimer This dataset includes vehicles towed or relocated by the City of Chicago; it does not include vehicles towed by a private towing company.  Content Collected July 7-Sept 7. Updated data can be found here for past 90 days. Columns include  TowDate Make Style Model Color Plate State TowedToAddress TowFacilityPhone InventoryNumber  Acknowledgements Dataset was compiled by the City of Chicago here. Inspiration  When do most tows occur? What are the most commonly towed cars? Where are most tows occurring? ,Tow Date:Make:Style:Model:Color:Plate:State:Towed to Address:Tow Facility Phone:Inventory Number:,dateTime:string:string:string:string:numeric:string:string:string:numeric:,
An Open Dataset for Human Activity Analysis , Sasan Jafarnejad , www.kaggle.com/sasanj/human-activity-smart-devices , Fri Sep 01 2017 13:00:59 GMT+0530 (IST) , Data collected using Smartphone Smartwatch and Smartglasses ,332, consumer electronics- ,Context The study of human mobility and activities has opened up to an incredible number of studies in the past most of which included the use of sensors distributed on the body of the subject. More recently the use of smart devices has been particularly relevant because they are already everywhere and they come with accurate miniaturized sensors. Whether it is smartphones smartwatches or smartglasses each device can be used to describe complementary information such as emotions precise movements or environmental conditions. Content First of all a smartphone is used to capture mainly contextual data. Two applications are used a simple data collection application based on the SWIPE open-source sensing system (SWIPE) and a logbook application for obtaining real data on user activity (TimeLogger). SWIPE is a platform for sensing recording and processing human dynamics using smartwatches and smartphones. Then a smartwatch is used primarily to capture the user's heart rate. Motion data is also collected without being at the heart of the dataset due to its need to be configured with a low sampling frequency which would drastically increase the dataset and drain the battery as well. An application based on SWIPE is used. Finally JINS MEME smartglasses are used. This model has the advantage of being compact and simple to carry. It does not have a camera or a screen; it simply has three types of sensors an accelerometer (for detecting steps or activities) a gyroscope (for head movements) and an occulographic sensor (eye blinking eye orientation). The official DataLogger application from JINS MEME is used. For more information on the dataset please refer to the corresponding publication available at An Open Dataset for Human Activity Analysis using Smart Devices. The current dataset on Kaggle contains smartglasses data with 20ms interval (due to storage limitations) same data with 10ms interval is also available on demand. Contact sasan.jafarnejad [at] uni [dot] lu to receive the 10ms version. Acknowledgements This work was performed within the eGLASSES project which is partially funded by NCBiR FWF SNSF ANR and FNR under the ERA-NET CHIST-ERAII framework.,NUM:DATE:ACC_X:ACC_Y:ACC_Z:GYRO_X:GYRO_Y:GYRO_Z:EOG_L:EOG_R:EOG_H:EOG_V:,numeric:dateTime:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Robocall Complaints , Federal Communications Commission , www.kaggle.com/fcc/robocall-complaints , Wed Sep 13 2017 22:20:14 GMT+0530 (IST) , Consumer complaints filed with the FCC  ,25, telecommunications- ,Individual informal consumer complaint data detailing complaints filed with the Consumer Help Center beginning October 31 2014. This data represents information selected by the consumer. The FCC does not verify the facts alleged in these complaints. This dataset contains everything you need to analyze the jerk companies who call during dinner time mode of communication logged phone number (of the hassler) and what they were trying to do.  Acknowledgements This dataset was kindly made available by the FCC. You can find the original dataset here.,Ticket ID:Ticket Created:Date of Issue:Time of Issue:Form:Method:Issue:Caller ID Number:Type of Call or Messge:Advertiser Business Number:City:State:Zip:Location (Center point of the Zip Code):,numeric:dateTime:dateTime:dateTime:string:string:string:string:string:string:string:string:numeric:string:,
Barcelona Unemployment , Marc Velmer , www.kaggle.com/marcvelmer/barcelona-unemployment , Tue Sep 12 2017 17:42:17 GMT+0530 (IST) , Barcelona registered unemployment percentages by hood and month ,39, business- finance- ,"Context This dataset represents the % of registered unemployment in the city of Barcelona (Spain) from year 2012 till 2016. Registered unemployment corresponds to the job demands pending cover by the last day of each month excluding employees who want to change jobs the ones that do not have readily available or incompatible situation the ones that are asking for a specific occupation and the temporary agricultural beneficiaries special unemployment benefit.  Content All files in this dataset have the same format. Every row represents a hood from the city.  District number Hood name Number of citizens from this hood with ages between 16 and 64 (legal ages for having a job) 12 columns (one per month) % of unemployment  In Barcelona we have hoods and districts. Every hood belongs to a district. A district is formed by several hoods. Acknowledgements This data can be found in ""Open Data BCN - Barcelona's City Hall Open Data Service"" which is the owner of the CSV files. Inspiration A few weeks ago I needed this datasets for testing purposes. I have uploaded this information here because in my honest opinion ""data"" and ""research"" should be shared with everybody. Enjoy!",Dte.:Barris:Poblaci:16-64 anys:Gener:Febrer:Mar:Abril:Maig:Juny:Juliol:Agost:Setembre:Octubre:Novembre:Desembre:,numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
London Crime Data 2008-2016 , Jacob Boysen , www.kaggle.com/jboysen/london-crime , Thu Aug 03 2017 21:05:48 GMT+0530 (IST) , 13M Rows of Crime Counts by Borough Category and Month ,159, crime- ,Context Crime in major metropolitan areas such as London occurs in distinct patterns. This data covers the number of criminal reports by month LSOA borough and major/minor category from Jan 2008-Dec 2016. Content 13M rows containing counts of criminal reports by month LSOA borough and major/minor category. Acknowledgements Txt file was pulled from Google Cloud Platform and converted to csv. Photo by James Sutton. Inspiration Are there seasonal or time-of-week/day changes in crime occurrences? Any boroughs where particular crimes are increasing or decreasing? Policy makers use this data to plan upcoming budgets and deployment--can you use previous year crime reports to reliably predict later trends? If you normalize by borough population can you find any areas where crime is more or less likely?,lsoa_code:borough:major_category:minor_category:value:year:month:,string:string:string:string:numeric:numeric:numeric:,
UN General Assembly Votes 1946-2015 , United Nations , www.kaggle.com/unitednations/general-assembly , Fri Feb 17 2017 00:15:29 GMT+0530 (IST) , Votes by member states on individual resolutions and specific issues ,261, politics- international relations- ,Content This dataset documents all United Nations General Assembly votes since its establishment in 1946. The data is broken into three different files the first lists each UN resolution subject and vote records; the second records individual member state votes per resolution; and the third provides an annual summary of member state voting records with affinity scores and an ideal point estimate in relation to the United States. Acknowledgements The UN General Assembly voting data was compiled and published by Professor Erik Voeten of Georgetown University.,assembly_session:vote_id:resolution:amendment:vote_date:significant_vote:yes_votes:no_votes:abstain:colonization:human_rights:israel_palestine:disarmament:nuclear_weapons:economic_development:,numeric:numeric:string:numeric:dateTime:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Correlates of War: Interstate Wars , University of Michigan , www.kaggle.com/umichigan/interstate-wars , Fri Feb 03 2017 22:30:13 GMT+0530 (IST) , Countries dates and fatalities of all wars between 1816 and 2007 ,241, war- international relations- ,Content The Correlates of War (COW) Project has utilized a classification of wars that is based upon the status of territorial entities in particular focusing on those that are classified as members of the interstate system. Wars have been categorized by whether they primarily take place between/among states between/among a state and a non-state actor and within states. Within the COW war typology an interstate intrastate or extrastate war must meet same definitional requirements of all wars in that the war must involve sustained combat involving organized armed forces resulting in a minimum of 1000 battle-related combatant fatalities within a twelve month period. For a state to be considered a war participant the minimum requirement is that it has to either commit 1000 troops to the war or suffer 100 battle-related deaths. When Correlates of War scholars J. David Singer and Melvin Small first extended their study of war to include intrastate wars in Resort to Arms they established the requisite condition that for a conflict to be a war it must involve armed forces capable of “effective resistance” on both sides. They then developed two alternative criteria for defining effective resistance “both sides had to be initially organized for violent conflict and prepared to resist the attacks of their antagonists or the weaker side although initially unprepared is able to inflict upon the stronger opponents at least five percent of the number of fatalities it sustains.” The effective resistance criteria were specifically utilized to differentiate wars from massacres one-sided state killings or general riots by unorganized individuals. Acknowledgements The dataset was created by Meredith Reid Sarkees American University and Professor Frank Wayman University of Michigan-Dearborn and published by the Correlates of War Project.,war_id:war_name:war_type:side1_code:side1_name:side2_code:side2_name:start_year1:start_month1:start_day1:end_year1:end_month1:end_day1:start_year2:start_month2:start_day2:end_year2:end_month2:end_day2:previous_war:initiation:intervention:combat_location:state_fatalities:nonstate_fatalities:outcome:next_war:,numeric:string:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
National Wetlands Inventory , ArcGIS Open Data , www.kaggle.com/arcgisopendata/national-wetlands-inventory , Thu Nov 17 2016 09:48:02 GMT+0530 (IST) , Location and Type of Wetlands and Deepwater Habitats in the United States ,86, ecology- ,"Context The data delineate the areal extent of wetlands and surface waters as defined by Cowardin et al. (1979). Certain wetland habitats are excluded from the National mapping program because of the limitations of aerial imagery as the primary data source used to detect wetlands. These habitats include seagrasses or submerged aquatic vegetation that are found in the intertidal and subtidal zones of estuaries and near shore coastal waters. Some deepwater reef communities (coral or tuberficid worm reefs) have also been excluded from the inventory. These habitats because of their depth go undetected by aerial imagery. By policy the Service also excludes certain types of ""farmed wetlands"" as may be defined by the Food Security Act or that do not coincide with the Cowardin et al. definition. Contact the Service's Regional Wetland Coordinator for additional information on what types of farmed wetlands are included on wetland maps.  Content The dataset includes  OBJECTID ATTRIBUTE WETLAND_TYPE ACRES GLOBALID ShapeSTArea ShapeSTLength  Acknowledgement The original dataset and metadata can be found here. Inspiration  Can you visualizes the differences in the wetlands shape by type? ",,,
Crime in India , Rajanand Ilangovan / இராஜ்ஆனந்த் இளங்கோவன் , www.kaggle.com/rajanand/crime-in-india , Fri Sep 01 2017 02:07:56 GMT+0530 (IST) , State-wise data from 2001 is classified according to 40+factors. (75+ csv files) ,775, india- crime- ,Context This dataset contains complete information about various aspects of crimes happened in India from 2001. There are many factors that can be analysed from this dataset. Over all I hope this dataset helps us to understand better about India. Content  I  Cases Reported and their Disposal by Police and Court Indian Penal Code Special & Local Laws IA  SC/ST Cases Reported and their Disposal by Police and Court Crime against SCs Crime against STs IB  Children Cases Reported and their Disposal by Police and Court Abetment of Suicide (Section 305 IPC) Buying of Girls for Prostitution (Section 373 IPC) Child Marriage Restraint Act 1929 Exposure and Abandonment (Section 317 IPC) Foeticide (Section 315 and 316 IPC) Infanticide (Section 315 IPC) Kidnapping & Abduction (Section 360361363363-A 363 read with Section 384 366 367 & 369 IPC) Murder (Section 302 315 IPC) Other Crimes against Children  Other Murder of Children (Section 302 IPC) Procuration of Minor Girls (Section 366-A IPC) Rape (Section 376 IPC) Selling of Girls for Prostitution (Section 372 IPC) Total Crimes against Children  II  Persons Arrested and their Disposal by Police and Court Indian Penal Code Special and Local Laws IIA  SC/ST Persons Arrested and their Disposal by Police and Court Crime against SCs Crime against STs IIB  Children Persons Arrested and their Disposal by Police and Court Abetment of suicide (Section 305 IPC) Buying of girls for prostitution (Section 373 IPC) Child Marriage Restraint Act 1929 Exposure and Abandonment (Section 317 IPC) Foeticide (Section 315 and 316 IPC) Kidnapping & Abduction (Section 360361363363-A 366 367 & 369 IPC) Murder - Infanticide (Section 315 IPC) Murder - Other Murder of Children  Murder (Section 302 315 IPC) Other Crimes against Children Procuration of minor girls (Section 366-A IPC) Rape (Section 376 IPC) Selling of girls for prostitution (Section 372 IPC) Total Crimes against Children IV  Persons Arrested by Sex and Age Group Indian Penal Code Special & Local Laws V  Juveniles Apprehended Indian Penal Code Special & Local Laws VI  Juveniles Arrested and their Disposal VII  Property Stolen & Recovered (Crime Head) Dacoity Robbery Burglary Theft Criminal Breach of Trust Other Property Total Property Stolen & Recovered VIII  Property Stolen & Recovered (Nature of Property) Communation and Electricity Wire Cattle Cycle Motor Vehicles Motor Vehicles - Motor Cycle/Scooters Motor Vehicles - Motor Car/Taxi/Jeep Motor Vehicles - Other Motor Vehicles Fire Arms Explosives/Explosive Substances Electronic Components Cultural Property including Antiques Other kinds of Property Total Property Stolen & Recovered IX  Police Strength (Actual & Sanctioned) A) Actual Civil Police (Incl. District Armed Police and Women Police) A)  Acual Armed Police (Incl. Women Police) A)  Actual Police Strength (Incl. Women) B) Acual Women Civil Police (Incl. District Armed Force) B) Actual Women Armed Police B) Actual Women Police Strength C) Sanctioned Civil Police (Incl. District Armed Police) C) Santioned Armed Police (Incl. Women Police) C) Santioned Police Strength (Incl. Women) D) Sanctioned Women Civil Police (Incl. District Armed Police) D) Sanctioned Women Armed Police D) Sanctioned Women Police Strength X  Police Personnel Killed or Injured on duty Constables Head Constables Assistant Sub-Inspectos Sub-Inspectors Inspectors Gazetted Officers Total Police Killed or Injured X-B  Age Profile of Police Personnel Killed on Duty X-C  Natural Deaths and Suicides of Police Personnel Natural Deaths of Police Personnel (while in service) Police Personnel Committed Suicide XI  Casualties under Police Firing and LathiCharge Riot Control Anti Dacoity Operations Against Extremists & Terrorists Against Others Total Casualties XII  Cases Reported Value of Property Stolen under Dacoity Robbery Burglary and Theft by Place of Occurance Residential Premises Highways River and Sea Railways 4.1 In Running Trains 4.2 Others Banks Commercial Establishments (Shops etc.) Other Places Total  XIII  Particulars of Juveniles Arrested Education Economic Setup Family Background Recidivism XIV  Motive/Cause of Murder and Culpable Homicide not Amounting to Murder XV  Victims of Rape(Age Group-wise) Incest Rape Cases Other Rape Cases (Otherthan Incest) Total Rape Cases XV-A  Rape Offenders relation nearness to Rape Victims XVI  Persons Arrested under Recidivism XVII  Anti Corruption - Cases XVIII  Anti Corruption - Arrests XIX  Complaints/Cases Against Police Personnel Complaints Received/Cases Registered Police Personnel Involved/Action Taken Departmental Action/Punishments *XX  Police Budget and Infrastructure Equipments and Transport Support Distribution of Police Stations by Crime Incidences Distribution of Police Stations by Police Strength Organisational Set Up SCs/STs and Muslims in Police Force (Actual) XXI  1.  Nature of Complaints Received by Police XXI  2. Trial of Violent Crimes by Courts Murder Attempt to Murder C H Not Amounting to Murder Rape Kidnapping & Abduction 5.1 Kidnapping & Abduction of Women & Girls 5.2 Kidnapping & Abduction of Others Dacoity Preparation & Assembly for Dacoity Robbery Riots Arson Dowry Deaths Total Trials (Sum of 1-11 Above) XXI  3. Period of Trials by Courts District/Session Judge Additional Session Judge Chief Judicial Magistrate Judicial Magistrate (I) Judicial Magistrate (II) Special Judicial Magistrate Other courts  Total Trials (Sum of 1-7 Above) XXI  4.1 Autho Theft (Stolen & Recovered) Motor Cycles/ Scooters Motor Car/Taxi/Jeep Buses Goods carrying vehicles (Trucks/Tempo etc) Other Motor vehicles Total (Sum of 1-5 Above) XXI  4.2 Serious Fraud Criminal Breach of Trust Cheating  XXI  5.1 Victims of Murder (Age & Sex-Wise) Male Victims Female Victims Total XXI  5.2 Victims of CH not Amounting to Murder (Age & Sex-wise) Male Victims Female Victims Total XXI  5.3 Use of FireArms in Murder Cases XXI  6. Human Rights Violation by Police Disappearance of Persons Illegal Detention/Arrests Fake Encounter Killings Violation Against Terrorists/Extremists Extortion Torture False Implication Failure in Taking Action Indignity to Women Atrocities on SC/ST Others Total (Sum of 1-11 Above) XXI  7. Police Housing For Officers (Dy.SP & Above) Upper SubOrdinates (ASI to Inspectos) Lower SubOrdinates (Constables Head Constables & Class-IV Subordinate Staff) XXI  8. Home Guards and Auxilliary force XXI  9. Unidentified Deadbodies Recovered & Inquest conducted XXI  10. Victims of Kidnapping & Abduction for Specific Purpose For Adoption For Begging for Camel Racing For Illicit Intercourse For Marriage For Prostitution For Ransom For Revenge For Sale For Selling Bodyparts For Slavery For Unlawful Activity Other Purposes Total (Sum of 1-13 Above) XXI  11. Custodial Deaths Deaths in Custody/Lockup of Persons Remanded to Police Custody by Court Deaths in Custody/Lockup of Persons Not Remanded to Police Custody by Court Deaths in Custody during production/process in courts/journey connected with investigation Deaths during Hospitalisation/Treatment Deaths due to Other Reasons XXI  12. Escapes from Police Custody Cases under Crime Against Women Rape Kidnapping & Abduction of Women & Girls Dowry Deaths Molestation Sexual Harassment Cruelty by Husband and Relatives Importation of Girls Immoral Traffic Prevention Act 1956 Dowry Prohibition Act 1961 Indecent Representation of Women(Prohibition) Act 1986 Sati Prevention Act 1987 Total Crimes Against Women Arrests under Crime Against Women Rape Kidnapping & Abduction of Women & Girls Dowry Deaths Molestation Sexual Harassment Cruelty by Husband and Relatives Importation of Girls Immoral Traffic Prevention Act 1956 Dowry Prohibition 1961 Indecent Representation of Women(Prohibition) Act 1986 Sati Prevention Act 1987 Total Crimes Against Women  Some of the data contains district level data. The districts are police districts and also include special police unit. Therefore these may be different from revenue districts. Most of the data is from 2001 to 2010. But there are few files which has data only from 2011 and few are having 2001-14. Inspiration There could be many things one can understand by analyzing this dataset. Few inspirations for you to start with.  What is the major reason people being kidnapped in each and every state? Offenders relation to the rape victim Juveniles family background education and economic setup. Which state has more crime against children and women? Age group wise murder victim Crime by place of occurrence. Anti corruption cases vs arrests. Which state has more number of complaints against police? Which state is the safest for foreigners?  Acknowledgements National Crime Records Bureau (NCRB) Govt of India has published this dataset  on their website  and also has shared on Open Govt Data Platform India portal under Govt. Open Data License - India.,Area_Name:Year:Group_Name:Sub_Group_Name:Cases_Property_Recovered:Cases_Property_Stolen:Value_of_Property_Recovered:Value_of_Property_Stolen:,string:numeric:string:string:numeric:numeric:numeric:numeric:,
Car Insurance Cold Calls , GregKondla , www.kaggle.com/kondla/carinsurance , Fri Jun 16 2017 12:35:47 GMT+0530 (IST) , We help the guys and girls at the front to get out of Cold Call Hell ,488, business- ,"Introduction Here you find a very simple beginner-friendly data set. No sparse matrices no fancy tools needed to understand what's going on. Just a couple of rows and columns. Super simple stuff. As explained below this data set is used for a competition. As it turns out this competition tends to reveal a common truth in data science KISS - Keep It Simple Stupid What is so special about this data set is given it's simplicity it pays off to use ""simple"" classifiers as well. This year's competition was won by a C5.0 . Can you do better? Description We are looking at cold call results. Turns out same salespeople called existing insurance customers up and tried to sell car insurance. What you have are details about the called customers. Their age job marital status whether the have home insurance a car loan etc. As I said super simple. What I would love to see is some of you applying some crazy XGBoost classifiers which we can square off against some logistic regressions. It would be curious to see what comes out on top. Thank you for your time I hope you enjoy using the data set. Acknowledgements Thanks goes to the Decision Science and Systems Chair of Technical University of Munich (TUM) for getting the data set from a real world company and making it available to be shared publicly. Also Vladimir Fux who oversees the challenge associated with this data set. Inspiration This is a data set used for teaching entry level data mining skills at the TUM. Every year there is a competition as part of the curriculum of a particular course. This Data Mining Cup teaches some of the very fundamentals that are always worthy to be revisited especially by pros abundant at Kaggle. For some of my thoughts see the verbose comments in the Kernel.",Id:Age:Job:Marital:Education:Default:Balance:HHInsurance:CarLoan:Communication:LastContactDay:LastContactMonth:NoOfContacts:DaysPassed:PrevAttempts:Outcome:CallStart:CallEnd:CarInsurance:,numeric:numeric:string:string:string:numeric:numeric:numeric:numeric:string:numeric:string:numeric:numeric:numeric:string:dateTime:dateTime:string:,
Factorial Digit Frequencies , Ian Chu Te , www.kaggle.com/ianchute/factorial-number-frequencies , Sat Sep 09 2017 22:25:46 GMT+0530 (IST) , Frequencies of each digit from 0! to 8000! ,36, numbers- ,Context Digit frequencies of the values of well-known mathematical series are a curiousity within the field of number theory.  However some are quite costly to compute and may cause stack overflow and out-of-memory issues. I am publishing this factorial digit frequency dataset for the convenience of fellow data enthusiasts who are interested in the field of number theory. Content This dataset contains decimal digit (0-9) frequencies of the number 0! to 8000! (total of 8001 rows) There are 10 columns - one for each digit. NOTE The CSV file contains header (0-9). Acknowledgements This dataset was generated by using the Clojure language and the trampoline function which avoids annoying stack overflow issues when doing very deep recursion. I would like to thank Rich Hickey and his colleagues in creating the Clojure language. Replication The script to generate the numbers can be found here https//github.com/ianchute/Factorial-Number-Frequencies/blob/master/generate.clj (You may need to convert the resulting JSON file to CSV.),0:1:2:3:4:5:6:7:8:9:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Obama White House Budgets , Jacob Boysen , www.kaggle.com/jboysen/obama-budgets , Fri Sep 08 2017 22:19:30 GMT+0530 (IST) , 2016 & 2017 OMB Proposals ,53, government agencies- finance- government- ,Context Each year after the President's State of the Union address the Office of Management and Budget (OMB) releases the Administration's Budget offering proposals on key priorities and newly announced initiatives. In 2016 & 2017 Obama’s OMB released all of the data included in the President's budget in a machine-readable format here on GitHub. “The budget process should be a reflection of our values as a country so we think it's important that members of the public have as many tools as possible to see the data behind the President's proposals. And if people are motivated to create their own visualizations or products from the data they should have that chance as well.” Content This branch includes three data files that contain an extract of the Office of Management and Budget (OMB) budget database. These files can be used to reproduce many of the totals published in the budget and examine unpublished details below the levels of aggregation published in the budget. The user guide file contains detailed information about this data its format and its limitations. Acknowledgements Datasets were compiled by Obama White House officials and released at this Github repo.  Inspiration  What significant changes were there between 2016 and 2017 proposals? How was the federal budget distributed across agencies? Where there any interesting changes in federal receipts? ,Agency Code:Agency Name:Bureau Code:Bureau Name:Account Code:Account Name:Treasury Agency Code:Subfunction Code:Subfunction Title:BEA Category:On- or Off- Budget:1976:TQ:1977:1978:1979:1980:1981:1982:1983:1984:1985:1986:1987:1988:1989:1990:1991:1992:1993:1994:1995:1996:1997:1998:1999:2000:2001:2002:2003:2004:2005:2006:2007:2008:2009:2010:2011:2012:2013:2014:2015:2016:2017:2018:2019:2020:,numeric:string:numeric:string:numeric:string:numeric:numeric:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
New York City - East River Bicycle Crossings , City of New York , www.kaggle.com/new-york-city/nyc-east-river-bicycle-crossings , Wed Sep 06 2017 20:59:38 GMT+0530 (IST) , Daily bicycle counts for major bridges in NYC ,48, cities- road transport- ,Context The New York City Department of Transportation collects daily data about the number of bicycles going over bridges in New York City. This data is used to measure bike utilization as a part of transportation planning. This dataset is a daily record of the number of bicycles crossing into or out of Manhattan via one of the East River bridges (that is excluding Bronx thruways and the non-bikeable Hudson River tunnels) for a stretch of 9 months. Content A count of the number of bicycles on each of the bridges in question is provided on a day-by-day basis along with information on maximum and minimum temperature and precipitation. Acknowledgements This data is published in an Excel format by the City of New York (here). It has been processed into a CSV file for use on Kaggle. Inspiration  In this dataset how many bicycles cross into and out of Manhattan per day? How strongly do weather conditions affect bike volumes? What is the top bridge in terms of bike load? ,:Date:Day:High Temp (°F):Low Temp (°F):Precipitation:Brooklyn Bridge:Manhattan Bridge:Williamsburg Bridge:Queensboro Bridge:Total:,numeric:dateTime:dateTime:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Bitcoin Price Prediction (LightWeight CSV) , Team AI , www.kaggle.com/team-ai/bitcoin-price-prediction , Sun Aug 13 2017 11:16:49 GMT+0530 (IST) , Build Model from Market Data ,606, time series- finance- ,Context Coming Soon Content Coming Soon Acknowledgements This data is taken from coinmarketcap and it is free to use the data. https//coinmarketcap.com/ Warning 実際の取引にこの情報を使うときは十分ご注意ください。弊社およびコミュニティメンバーは損失の責任を取ることができません。,Date:Open:High:Low:Close:Volume:Market Cap:,dateTime:numeric:numeric:numeric:numeric:numeric:numeric:,
Star Cluster Simulations , Mario Pasquato , www.kaggle.com/mariopasquato/star-cluster-simulations , Sat Jan 07 2017 12:29:40 GMT+0530 (IST) , Direct N-body simulation of a star cluster: Position and velocities of stars ,910, astronomy- space- ,"Context Stars mostly form in clusters and associations rather than in isolation. Milky Way star clusters are easily observable with small telescopes and in some cases even with the naked eye. Depending on a variety of conditions star clusters may dissolve quickly or be very long lived. The dynamical evolution of star clusters is a topic of very active research in astrophysics. Some popular models of star clusters are the so-called direct N-body simulations [1 2] where every star is represented by a point particle that interacts gravitationally with every other particle. This kind of simulation is computationally expensive as it scales as O(N^2) where N is the number of particles in the simulated cluster. In the following the words ""particle"" and ""star"" are used interchangeably. Content This dataset contains the positions and velocities of simulated stars (particles) in a direct N-body simulation of a star cluster. In the cluster there are initially 64000 stars distributed in position-velocity space according to a King model [3]. Each .csv file named c_xxxx.csv corresponds to a snapshot of the simulation at time t = xxxx. For example c_0000.csv contains the initial conditions (positions and velocities of stars at time t=0). Times are measured in standard N-body units [4]. This is a system of units where G = M = −4E = 1 (G is the gravitational constant M the total mass of the cluster and E its total energy). x y z Columns 1 2 and 3 of each file are the x y z positions of the stars. They are also expressed in standard N-body units [4]. You can switch to units of the median radius of the cluster by finding the cluster center and calculating the median distance of stars from it and then dividing x y and z by this number. In general the median radius changes in time. The initial conditions are approximately spherically symmetric (you can check) so there is no particular physical meaning attached to the choice of x y and z.  vx vy vz Columns 4 5 and 6 contain the x y and z velocity also in N-body units. A scale velocity for the stars can be obtained by taking the standard deviation of velocity along one direction (e.g. z). You may check that the ratio between the typical radius (see above) and the typical velocity is of order unity. m Column 7 is the mass of each star. For this simulation this is identically 1.5625e-05 i.e. 1/64000. The total mass of the cluster is initially 1. More realistic simulations (coming soon) have a spectrum of different masses and live stelar evolution that results in changes in the mass of stars. This simulation is a pure N-body problem instead. Star id number The id numbers of each particle are listed in the last column (8) of the files under the header ""id"". The ids are unique and can be used to trace the position and velocity of a star across all files. There are initially 64000 particles. At end of the simulation there are 63970. This is because some particles escape the cluster. Acknowledgements This simulation was run on a Center for Galaxy Evolution Research (CGER) workstation at Yonsei University (Seoul Korea) using the NBODY6 software (https//www.ast.cam.ac.uk/~sverre/web/pages/nbody.htm). Inspiration Some stars hover around the center of the cluster while some other get kicked out to the cluster outskirts or even leave the cluster altogether. Can we predict where a star will be at any given time based on its initial position and velocity? Can we predict its velocity? How correlated are the motions of stars? Can we predict the velocity of a given star based on the velocity of its neighbours? The size of the cluster can be measured by defining a center (see below) and finding the median distance of stars from it. This is called the three-dimensional effective radius. Can we predict how it evolves over time? What are its properties as a time series? What can we say about other quantiles of the radius? How to define the cluster center? Just as the mode of a KDE of the distribution of stars? How does it move over time and how to quantify the properties of its fluctuations? Is the cluster symmetric around this center? Some stars leave the cluster over time they exchange energy in close encounters with other stars and reach the escape velocity. This can be seen by comparing later snapshots with the initial one some IDs are missing and there is overall a lower number of stars. Can we predict which stars are more likely to escape? When will a given star escape? References [1] Heggie D. Hut P. 2003 The Gravitational Million-Body Problem A Multidisciplinary Approach to Star Cluster Dynamics ~ Cambridge University Press 2003 [2] Aarseth S.~J. 2003 Gravitational N-Body Simulations - Cambridge University Press 2003 [3] King I. 1966 AJ 71 64 [4] Heggie D. C. Mathieu R. D. 1986 Lecture Notes in Physics Vol. 267 The Use of Supercomputers in Stellar Dynamics Berlin Springer",x:y:z:vx:vy:vz:m:id:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Near-Earth Comets , NASA , www.kaggle.com/nasa/near-earth-comets , Sat Nov 05 2016 04:11:54 GMT+0530 (IST) , Heliocentric orbital data for comets that make approaches near Earth's orbit ,299, space- ,NASA tracks about 15000 near-Earth objects -- small Solar System bodies whose orbits bring them less than 1.3 AU from the Sun (i.e. within 130% of the the average distance between the Earth and the Sun). Of these 15000 160 are comets. This dataset provides orbital data for these comets. The Data Notes on Time and Space Timing information for each of these comets is given in Barycentric Dynamical Time or TDB. This is very roughly the number of days since January 1st 4713 BC (see the Wikipedia article on Julian Day for more info). Check out those Wikipedia articles for details. For information on inclination argument and longitude of the ascending node look at this article. The non-gravitational forces are effects that accelerate or decelerate the comet such as jets of gas. This dataset contains the following fields  Object the name of the comet Epoch the epoch for the comet in TDB TP time of perihelion passage in TDB; this is the time when the comet was closest to the Sun e the orbital eccentricity of the comet i Inclination of the orbit with respect to the ecliptic plane and the equinox of J2000 (J2000-Ecliptic) in degrees w Argument of perihelion (J2000-Ecliptic) in degrees Node Longitude of the ascending node (J2000-Ecliptic) in degrees q comet's distance at perihelion in AU Q comet's distance at aphelion in AU P orbital period in Julian years A1 Non-gravitational force parameter A1 A2 Non-gravitational force parameter A2 A3 Non-gravitational force parameter A3 MOID (AU) Minimum orbit intersection distance (the minimum distance between the osculating orbits of the NEO and the Earth) ref Orbital solution reference  What Should We Try? What can we do with this dataset? - plot the comets' orbits - combine with Earth's orbital data to predict close approaches Acknowledgements This dataset was downloaded from the NASA data portal.,Object:Epoch:TP:e:i:w:Node:q:Q:P:MOID:A1:A2:A3:DT:ref:Object_name:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:,
NYC City Hall Library Catalog , City of New York , www.kaggle.com/new-york-city/nyc-city-hall-library-catalog , Sat Sep 09 2017 00:30:52 GMT+0530 (IST) , All official reports published by the City of New York ,22, cities- government- ,"Context This dataset compiles the titles publication dates and other data about all reports published in the official capacities of New York City government agency work are listed in the City Hall Library catalog. The catalog functions like a city-level equivalent of the national Library of Congress and goes back very far --- at least to the 1800s. Content Columns are provided for the report name and report sub-header the year the report was issued the name of the publisher compiling the report and some other smaller fields. Acknowledgements This data was originally published in a pound (""#"") delimited dataset on the New York City Open Data Portal. It has been restructured as a CSV and lightly cleaned up for formatting prior to being uploaded to Kaggle. Inspiration  Can you separate reporting publications by the City of New York into topics? Who are the most common report issuers and what causes do they represent? What are some common elements to report titles? ",:Corporate Name:Subordinate Unit:Title:Remainder Of Title:Remainder OF Title Page:Date Of Publication:Geographic Name:General Subdivision:,numeric:string:string:string:string:string:numeric:string:string:,
Independent Election Expenditures , Federal Election Commission , www.kaggle.com/fec/independent-campaign-expenditures , Thu Sep 07 2017 01:09:24 GMT+0530 (IST) , Spending by groups other than the candidates themselves ,12, politics- ,"This file contains ""24-hour"" and ""48-hour"" reports of independent expenditures filed during the current election cycle and for election cycles through 2010. The file contains detailed information about independent expenditures including who was paid the purpose of the disbursement date and amount of the expenditure and the candidate for or against whom the expenditure was made. Independent expenditures represent spending by individual people groups political committees corporations or unions expressly advocating the election or defeat of clearly identified federal candidates. These expenditures may not be made in concert or cooperation with or at the request or suggestion of a candidate the candidate's campaign or a political party. Any time up to 20 days before an election if these independent expenditures by a person or organization aggregate more than $10000 in a race they must be reported to the Commission before the end of the second day after the communication is publicly distributed. If the communications are distributed within the last 19 days before the election the expenditure must be reported within one day if they aggregate more than $1000 in any race. Acknowledgements This data comes from the US Federal Election Commission. You can find the original dataset here. If you like... If you enjoyed this dataset you might also like the Congressional Election Disbursements dataset.",can_id:can_nam:spe_id:spe_nam:ele_typ:can_off_sta:can_off_dis:can_off:can_par_aff:exp_amo:exp_dat:agg_amo:sup_opp:pur:pay:file_num:amn_ind:tra_id:ima_num:rec_dat:prev_file_num:dissem_dt:,string:string:string:string:string:string:numeric:string:string:string:dateTime:string:string:string:string:numeric:string:string:numeric:dateTime:string:string:,
ACLED African Conflicts 1997-2017 , Jacob Boysen , www.kaggle.com/jboysen/african-conflicts , Tue Aug 08 2017 22:07:07 GMT+0530 (IST) , Details on 165k Conflicts Across Africa Over Twenty Years ,59, war- ,Context The Armed Conflict Location and Event Data Project is designed for disaggregated conflict analysis and crisis mapping. This dataset codes the dates and locations of all reported political violence and protest events in dozens of developing countries in Africa. Political violence and protest includes events that occur within civil wars and periods of instability public protest and regime breakdown. The project covers all African countries from 1997 to the present. Content These data contain information on  Dates and locations of conflict events; Specific types of events including battles civilian killings riots protests and recruitment activities; Events by a range of actors including rebels governments militias armed groups protesters and civilians; Changes in territorial control; and Reported fatalities.  Event data are derived from a variety of sources including reports from developing countries and local media humanitarian agencies and research publications. Please review the codebook and user guide for additional information the codebook is for coders and users of ACLED whereas the brief guide for users reviews important information for downloading reviewing and using ACLED data. A specific user guide for development and humanitarian practitioners is also available as is a guide to our sourcing materials. Acknowledgements ACLED is directed by Prof. Clionadh Raleigh (University of Sussex). It is operated by senior research manager Andrea Carboni (University of Sussex) for Africa and Hillary Tanoff for South and South-East Asia. The data collection involves several research analysts including Charles Vannice James Moody Daniel Wigmore-Shepherd Andrea Carboni Matt Batten-Carew Margaux Pinaud Roudabeh Kishi Helen Morris Braden Fuller Daniel Moody and others. Please cite Raleigh Clionadh Andrew Linke Håvard Hegre and Joakim Karlsen. 2010. Introducing ACLED-Armed Conflict Location and Event Data. Journal of Peace Research 47(5) 651-660. Inspiration Do conflicts in one region predict future flare-ups? How do the individual actors interact across time? Do some sources report more often on certain actors?,ACTOR1:ACTOR1_ID:ACTOR2:ACTOR2_ID:ACTOR_DYAD_ID:ADMIN1:ADMIN2:ADMIN3:ALLY_ACTOR_1:ALLY_ACTOR_2:COUNTRY:EVENT_DATE:EVENT_ID_CNTY:EVENT_ID_NO_CNTY:EVENT_TYPE:FATALITIES:GEO_PRECISION:GWNO:INTER1:INTER2:INTERACTION:LATITUDE:LOCATION:LONGITUDE:NOTES:SOURCE:TIME_PRECISION:YEAR:,string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:string:string:numeric:numeric:,
U.S. Major League Soccer Salaries , Chris Crawford , www.kaggle.com/crawford/us-major-league-soccer-salaries , Fri Jul 14 2017 01:17:08 GMT+0530 (IST) , Salaries from 2007 to 2017 ,249, association football- income- ,Context The Major League Soccer Union releases the salaries of every MLS player each year. This is a collection of salaries from 2007 to 2017. Content Each file contains the following fields  club Team abbreviation last_name Player last name first_name Player first name position Position abbreviation base_salary Base salary guaranteed_compensation Guaranteed compensation  Acknowledgements Jeremy Singer-Vine over at Data is Plural scraped the PDF's released by the MLS Union and put the data in a nice little package of CSV files for everyone. I downloaded this dataset from https//github.com/data-is-plural/mls-salaries MIT License Inspiration Who in the MLS makes the most money? Are they worth it? I make about $900 bazillion each year can I afford a soccer team?,club:last_name:first_name:position:base_salary:guaranteed_compensation:,string:string:string:string:numeric:numeric:,
NBA Finals Team Stats , DaveRosenman , www.kaggle.com/daverosenman/nba-finals-team-stats , Fri Aug 25 2017 22:57:04 GMT+0530 (IST) , Contains team totals game by game from 1980-2017 NBA Finals ,279, ,'champsdata.csv' and runnerupsdata.csv' 'champs.csv' contains game-by-game team totals for the championship team from every finals game between 1980 and 2017. 'runnerups.csv' contains game-by-game team totals for the runner-up team from every finals game between 1980 and 2017. The 1980 NBA Finals was the first Finals series since the NBA added the three point line.  Content The data was scrapped from basketball-reference.com.  Variables in 'champs.csv' and 'runnerups.csv'  Year The year the series was played Team The name of the team. Win 1 = Win. 0 = Loss Home 1 = Home team. 0 = Away team. Game Game # MP - Total minutes played. Equals 240 (48x5=240) if game did not go to overtime. MP>240 if game went to overtime. FG - Field goals made FGA - Field goal attempts FGP - Field Goal Percentage TP - 3 Point Field Goals Made TPA - Three point attempts TPP - three point percentage FT - Free throws made FTA - Free throws attempted FTP - Free throw percentage ORB - Offensive rebounds DRB - Defensive rebounds TRB - Total rebounds AST - Assists STL - Steals BLK - Blocks TOV - Turnovers PF - Personal fouls PTS - points scored  Datasets created from 'champsionsdata.csv' and 'runnerupsdata.csv' The R code that I used to make  the three files listed below can be found here 'champs_and_runner_ups_series_averages.csv'  This data frame contains series averages for the champion and runnerup each year.  'champs_series_averages.csv'  This data frame contains series averages for just the champion each year.  'runner_ups_series_averages.csv' This data frame contains decade-by-decade averages for champions and runners up. ,X:,numeric:,
New York City - Citywide Payroll Data , City of New York , www.kaggle.com/new-york-city/nyc-citywide-payroll-data , Wed Sep 06 2017 01:32:49 GMT+0530 (IST) , Salaries paid to New York City employees over four years ,158, cities- money- ,"Context This dataset contains the salary pay rate and total compensation of every New York City employee. In this dataset this information is provided for the 2014 2015 2016 and 2017 fiscal years and provides a transparent lens into who gets paid how much and for what. Note that fiscal years in the New York City budget cycle start on July 1st and end on June 30th (see here). That means that this dataset contains in its sum compensation information for all City of New York employees for the period July 1 2014 to June 30 2017. Content This dataset provides columns for fiscal year employee name the city department they work for their job title and various fields describing their compensation. The most important of these fields is ""Regular Gross Pay"" which provides that employee's total compensation. Acknowledgements This information was published as-is by the City of New York. Inspiration  How many people do the various city agencies employ and how much does each department spend on salary in total? What are the most numerous job titles in civic government employment? Where does overtime pay seem to be especially common? How much of it is there? How do New York City employee salaries compare against salaries of city employees in Chicago? Is the difference more or less than the difference in cost of living between the two cities? ",Fiscal Year:Agency Name:Last Name:First Name:Mid Init:Agency Start Date:Work Location Borough:Title Description:Leave Status as of June 30:Base Salary:Pay Basis:Regular Hours:Regular Gross Paid:OT Hours:Total OT Paid:Total Other Pay:,numeric:string:string:string:string:dateTime:string:string:string:string:string:numeric:string:numeric:string:string:,
Zoo Animal Classification , UCI Machine Learning , www.kaggle.com/uciml/zoo-animal-classification , Sat Dec 24 2016 23:35:10 GMT+0530 (IST) , Use Machine Learning Methods to Correctly Classify Animals Based Upon Attributes ,1791, animals- ,This dataset consists of 101 animals from a zoo.  There are 16 variables with various traits to describe the animals.  The 7 Class Types are Mammal Bird Reptile Fish Amphibian Bug and Invertebrate The purpose for this dataset is to be able to predict the classification of the animals based upon the variables.  It is the perfect dataset for those who are new to learning Machine Learning. zoo.csv Attribute Information (name of attribute and type of value domain)  animal_name      Unique for each instance hair        Boolean feathers        Boolean eggs        Boolean milk        Boolean airborne        Boolean aquatic     Boolean predator        Boolean toothed     Boolean backbone       Boolean breathes       Boolean venomous       Boolean fins       Boolean legs      Numeric (set of values {024568}) tail      Boolean domestic      Boolean catsize      Boolean class_type       Numeric (integer values in range [17])   class.csv This csv describes the dataset  Class_Number               Numeric (integer values in range [17]) Number_Of_Animal_Species_In_Class     Numeric Class_Type                 character -- The actual word description of the class Animal_Names          character -- The list of the animals that fall in the category of the class  Acknowledgements UCI Machine Learning https//archive.ics.uci.edu/ml/datasets/Zoo Source Information    -- Creator Richard Forsyth    -- Donor Richard S. Forsyth               8 Grosvenor Avenue              Mapperley Park              Nottingham NG3 5DX              0602-621676    -- Date 5/15/1990 Inspiration What are the best machine learning ensembles/methods for classifying these animals based upon the variables given?,Class_Number:Number_Of_Animal_Species_In_Class:Class_Type:Animal_Names:,numeric:numeric:string:string:,
Cuneiform Digital Library Initiative , Myles O'Neill , www.kaggle.com/mylesoneill/cuneiform-digital-library-initiative , Wed May 10 2017 05:30:50 GMT+0530 (IST) , Explore thousands of ancient tablet transliterations ,80, languages- history- linguistics- ,"What is CDLI? The Cuneiform Digital Library Initiative (CDLI) is an international digital library project aimed at putting text and images of an estimated 500000 recovered cuneiform tablets created from between roughly 3350 BC and the end of the pre-Christian era online. The initiative is a joint project of the University of California Los Angeles the University of Oxford and the Max Planck Institute for the History of Science Berlin.  This dataset includes the full CDLI catalogue (metadata) transliterations of tablets in the catalogue and word/sign lists from old akkadian and Ur III. This data was downloaded on the 9th of May 2017. Transliterations are in .atf format find out more about this format here http//oracc.museum.upenn.edu/doc/help/editinginatf/cdliatf/index.html Find more about CDLI here http//cdli.ucla.edu/ What is Cuneiform? Cuneiform script one of the earliest systems of writing was invented by the Sumerians. It is distinguished by its wedge-shaped marks on clay tablets made by means of a blunt reed for a stylus. The name cuneiform itself simply means ""wedge shaped"". Cuneiform is not a language nor is it an alphabet. Cuneiform uses between 600-1000 characters to write words or syllables. It has been used by many different cultural groups to represent many different languages but it was primarily used to write Sumerian and Akkadian. Deciphering cuneiform is very difficult to this day though the difficulty varies depending on the language. https//en.wikipedia.org/wiki/Cuneiform_script What is Assyriology? Assyriology is the study of the languages history and culture of the people who used the ancient writing system called cuneiform. Cuneiform was used primarily in an area called the Near East centred on Mesopotamia (modern Iraq and eastern Syria) where cuneiform was invented but including the Northern Levant (Western Syria and Lebanon) parts of Anatolia and western Iran. The sources for Assyriology are all archaeological and include both inscribed and uninscribed objects. Most Assyriologists focus on the rich textual record from the ancient Near East and specialise in either the study of language literature or history of the ancient Near East. Assyriology began as an academic discipline with the recovery of the monuments of ancient Assyria and the decipherment of cuneiform in the middle of the 19th century. Large numbers of archaeological objects including texts were brought to museums in Europe and later the US following the early excavations of Nineveh Kalhu Babylon Girsu Assur and so forth. Today Assyriology is studied in universities across the globe both as an undergraduate and a graduate subject and knowledge from the ancient Near East informs students of numerous other disciplines such as the History of Science Archaeology Classics Biblical studies and more.",accession_no:accounting_period:acquisition_history:alternative_years:ark_number:atf_source:atf_up:author:author_remarks:cdli_collation:cdli_comments:citation:collection:composite:condition_description:date_entered:date_of_origin:date_remarks:date_updated:dates_referenced:db_source:designation:dumb:dumb2:electronic_publication:elevation:excavation_no:external_id:findspot_remarks:findspot_square:genre:google_earth_collection:google_earth_provenience:height:id:id_text2:id_text:join_information:language:lineart_up:material:museum_no:object_preservation:object_type:period:period_remarks:photo_up:primary_publication:provenience:provenience_remarks:publication_date:publication_history:published_collation:seal_id:seal_information:stratigraphic_level:subgenre:subgenre_remarks:surface_preservation:text_remarks:thickness:translation_source:width:,string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:dateTime:string:string:dateTime:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:string:string:string:string:string:string:string:string:string:numeric:string:numeric:,
Armors Exoskeletons & Mecchas , NMIN , www.kaggle.com/nicolasmin/armors-exoskeletons-mecchas , Fri Sep 08 2017 21:56:47 GMT+0530 (IST) , 300 heroes listed 80 fully detailed ,80, ,"Context The file presents a listing of characters wearing powered armor / mini or giant meccha in movies comics animation etc.  The purpose was to analyse our imaginaries in a specific field (i.e armors in this case) in order to see what are the macro elements see how they evolve around time and if they are close to what is used in real life. Content Each armor is analyzed according to 13 characteristics (uses an AI or not what kind or power where is the weapon its capacities (does is fly gives enhanced strength etc.). Being a social science professor and not a data analysts I went on marvel wikia DC wikia etc. to compile it. Something like 80 heroes are fully presented and a list of almost 300 been found.  Inspiration Coming from social science I compiled that data during my free time but I understand that it is highly limiting and that there must be a way to aggregate much more data & faster. Also I am sure that it does not meet some of the standards for such work. Being a newbie here please tell me how to improve this & I will. The question after is to know if we can ""predict"" what future armors will look like  is there a trend showing that AI is used more and more ? That they all fly ? Once this done it would allow to ""delineate"" the ideal characteristics of a super hero and hence where we could innovate if we do not want to reproduce things that already done while imagining them ? The last questions correlate to social trends  do some characteristics appear during a certain period ? If yes is it correlated to some specific social context ? (new type of wars impacting how we imagine our heroes ?).",ID;nom;Year;Source;Types of armor;Nationality;Weight in Kg;Height of armor;Speed;Type of control;Cognitive assistance;Source of energy;Weapons;Means of production;Limitations / vulnerabilities;Capacities;Enhancement;Created to work in groupes;Protection f:nom:Year:Source:Types of armor:Nationality:Weight in Kg:Height of armor:Speed:Type of control:Cognitive assistance:Source of energy:Weapons:Means of production:Limitations / vulnerabilities:Capacities:Enhancement:Created to work in groupes:Protection from:Fields of operations:Type of informations produced by the armor:Life support:,string:string:numeric:string:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:,
UFC Fight Data , Karmanya Aggarwal , www.kaggle.com/calmdownkarm/ufcdataset , Mon Jun 12 2017 10:00:45 GMT+0530 (IST) , Fight-by-fight list of all UFC fights from 2013 ,586, sports- ,Context List of all UFC fights since 2013 with summed up entries of each fighter's round by round record preceding that fight. Created in the attempt to create a UFC fight winner predictor. Dataset may not be great I'm still new to this thing so appreciate any tips on cleaning up the set.  Content Each row represents a single fight - with each fighter's previous records summed up  prior to the fight. blank stats mean its the fighter's first fight since 2013 which is where granular data for UFC fights beings Acknowledgements https//github.com/valish/ufc-api for the UFC api  Beautifulsoup and it's creators and Hitkul my partner in crime Inspiration Can we draw decent predictions from this dataset?,BPrev:BStreak:B_Age:B_Height:B_HomeTown:B_ID:B_Location:B_Name:B_Weight:B__Round1_Grappling_Reversals_Landed:B__Round1_Grappling_Standups_Landed:B__Round1_Grappling_Submissions_Attempts:B__Round1_Grappling_Takedowns_Attempts:B__Round1_Grappling_Takedowns_Landed:B__Round1_Strikes_Body Significant Strikes_Attempts:B__Round1_Strikes_Body Significant Strikes_Landed:B__Round1_Strikes_Body Total Strikes_Attempts:B__Round1_Strikes_Body Total Strikes_Landed:B__Round1_Strikes_Clinch Body Strikes_Attempts:B__Round1_Strikes_Clinch Body Strikes_Landed:B__Round1_Strikes_Clinch Head Strikes_Attempts:B__Round1_Strikes_Clinch Head Strikes_Landed:B__Round1_Strikes_Clinch Leg Strikes_Attempts:B__Round1_Strikes_Clinch Leg Strikes_Landed:B__Round1_Strikes_Clinch Significant Kicks_Attempts:B__Round1_Strikes_Clinch Significant Kicks_Landed:B__Round1_Strikes_Clinch Significant Punches_Attempts:B__Round1_Strikes_Clinch Significant Punches_Landed:B__Round1_Strikes_Clinch Significant Strikes_Attempts:B__Round1_Strikes_Clinch Significant Strikes_Landed:B__Round1_Strikes_Clinch Total Strikes_Attempts:B__Round1_Strikes_Clinch Total Strikes_Landed:B__Round1_Strikes_Distance Body Kicks_Attempts:B__Round1_Strikes_Distance Body Kicks_Landed:B__Round1_Strikes_Distance Body Punches_Attempts:B__Round1_Strikes_Distance Body Punches_Landed:B__Round1_Strikes_Distance Body Strikes_Attempts:B__Round1_Strikes_Distance Body Strikes_Landed:B__Round1_Strikes_Distance Head Kicks_Attempts:B__Round1_Strikes_Distance Head Kicks_Landed:B__Round1_Strikes_Distance Head Punches_Attempts:B__Round1_Strikes_Distance Head Punches_Landed:B__Round1_Strikes_Distance Head Strikes_Attempts:B__Round1_Strikes_Distance Head Strikes_Landed:B__Round1_Strikes_Distance Leg Kicks_Attempts:B__Round1_Strikes_Distance Leg Kicks_Landed:B__Round1_Strikes_Distance Leg Strikes_Attempts:B__Round1_Strikes_Distance Leg Strikes_Landed:B__Round1_Strikes_Distance Strikes_Attempts:B__Round1_Strikes_Distance Strikes_Landed:B__Round1_Strikes_Ground Body Strikes_Attempts:B__Round1_Strikes_Ground Body Strikes_Landed:B__Round1_Strikes_Ground Head Strikes_Attempts:B__Round1_Strikes_Ground Head Strikes_Landed:B__Round1_Strikes_Ground Leg Strikes_Attempts:B__Round1_Strikes_Ground Leg Strikes_Landed:B__Round1_Strikes_Ground Significant Kicks_Attempts:B__Round1_Strikes_Ground Significant Kicks_Landed:B__Round1_Strikes_Ground Significant Punches_Attempts:B__Round1_Strikes_Ground Significant Punches_Landed:B__Round1_Strikes_Ground Significant Strikes_Attempts:B__Round1_Strikes_Ground Significant Strikes_Landed:B__Round1_Strikes_Ground Total Strikes_Attempts:B__Round1_Strikes_Ground Total Strikes_Landed:B__Round1_Strikes_Head Significant Strikes_Attempts:B__Round1_Strikes_Head Significant Strikes_Landed:B__Round1_Strikes_Head Total Strikes_Attempts:B__Round1_Strikes_Head Total Strikes_Landed:B__Round1_Strikes_Kicks_Attempts:B__Round1_Strikes_Kicks_Landed:B__Round1_Strikes_Knock Down_Landed:B__Round1_Strikes_Leg Total Strikes_Attempts:B__Round1_Strikes_Leg Total Strikes_Landed:B__Round1_Strikes_Legs Significant Strikes_Attempts:B__Round1_Strikes_Legs Significant Strikes_Landed:B__Round1_Strikes_Legs Total Strikes_Attempts:B__Round1_Strikes_Legs Total Strikes_Landed:B__Round1_Strikes_Punches_Attempts:B__Round1_Strikes_Punches_Landed:B__Round1_Strikes_Significant Strikes_Attempts:B__Round1_Strikes_Significant Strikes_Landed:B__Round1_Strikes_Total Strikes_Attempts:B__Round1_Strikes_Total Strikes_Landed:B__Round1_TIP_Back Control Time:B__Round1_TIP_Clinch Time:B__Round1_TIP_Control Time:B__Round1_TIP_Distance Time:B__Round1_TIP_Ground Control Time:B__Round1_TIP_Ground Time:B__Round1_TIP_Guard Control Time:B__Round1_TIP_Half Guard Control Time:B__Round1_TIP_Misc. Ground Control Time:B__Round1_TIP_Mount Control Time:B__Round1_TIP_Neutral Time:B__Round1_TIP_Side Control Time:B__Round1_TIP_Standing Time:B__Round2_Grappling_Reversals_Landed:B__Round2_Grappling_Standups_Landed:B__Round2_Grappling_Submissions_Attempts:B__Round2_Grappling_Takedowns_Attempts:B__Round2_Grappling_Takedowns_Landed:B__Round2_Strikes_Body Significant Strikes_Attempts:B__Round2_Strikes_Body Significant Strikes_Landed:B__Round2_Strikes_Body Total Strikes_Attempts:B__Round2_Strikes_Body Total Strikes_Landed:B__Round2_Strikes_Clinch Body Strikes_Attempts:B__Round2_Strikes_Clinch Body Strikes_Landed:B__Round2_Strikes_Clinch Head Strikes_Attempts:B__Round2_Strikes_Clinch Head Strikes_Landed:B__Round2_Strikes_Clinch Leg Strikes_Attempts:B__Round2_Strikes_Clinch Leg Strikes_Landed:B__Round2_Strikes_Clinch Significant Kicks_Attempts:B__Round2_Strikes_Clinch Significant Kicks_Landed:B__Round2_Strikes_Clinch Significant Punches_Attempts:B__Round2_Strikes_Clinch Significant Punches_Landed:B__Round2_Strikes_Clinch Significant Strikes_Attempts:B__Round2_Strikes_Clinch Significant Strikes_Landed:B__Round2_Strikes_Clinch Total Strikes_Attempts:B__Round2_Strikes_Clinch Total Strikes_Landed:B__Round2_Strikes_Distance Body Kicks_Attempts:B__Round2_Strikes_Distance Body Kicks_Landed:B__Round2_Strikes_Distance Body Punches_Attempts:B__Round2_Strikes_Distance Body Punches_Landed:B__Round2_Strikes_Distance Body Strikes_Attempts:B__Round2_Strikes_Distance Body Strikes_Landed:B__Round2_Strikes_Distance Head Kicks_Attempts:B__Round2_Strikes_Distance Head Kicks_Landed:B__Round2_Strikes_Distance Head Punches_Attempts:B__Round2_Strikes_Distance Head Punches_Landed:B__Round2_Strikes_Distance Head Strikes_Attempts:B__Round2_Strikes_Distance Head Strikes_Landed:B__Round2_Strikes_Distance Leg Kicks_Attempts:B__Round2_Strikes_Distance Leg Kicks_Landed:B__Round2_Strikes_Distance Leg Strikes_Attempts:B__Round2_Strikes_Distance Leg Strikes_Landed:B__Round2_Strikes_Distance Strikes_Attempts:B__Round2_Strikes_Distance Strikes_Landed:B__Round2_Strikes_Ground Body Strikes_Attempts:B__Round2_Strikes_Ground Body Strikes_Landed:B__Round2_Strikes_Ground Head Strikes_Attempts:B__Round2_Strikes_Ground Head Strikes_Landed:B__Round2_Strikes_Ground Leg Strikes_Attempts:B__Round2_Strikes_Ground Leg Strikes_Landed:B__Round2_Strikes_Ground Significant Kicks_Attempts:B__Round2_Strikes_Ground Significant Kicks_Landed:B__Round2_Strikes_Ground Significant Punches_Attempts:B__Round2_Strikes_Ground Significant Punches_Landed:B__Round2_Strikes_Ground Significant Strikes_Attempts:B__Round2_Strikes_Ground Significant Strikes_Landed:B__Round2_Strikes_Ground Total Strikes_Attempts:B__Round2_Strikes_Ground Total Strikes_Landed:B__Round2_Strikes_Head Significant Strikes_Attempts:B__Round2_Strikes_Head Significant Strikes_Landed:B__Round2_Strikes_Head Total Strikes_Attempts:B__Round2_Strikes_Head Total Strikes_Landed:B__Round2_Strikes_Kicks_Attempts:B__Round2_Strikes_Kicks_Landed:B__Round2_Strikes_Knock Down_Landed:B__Round2_Strikes_Leg Total Strikes_Attempts:B__Round2_Strikes_Leg Total Strikes_Landed:B__Round2_Strikes_Legs Significant Strikes_Attempts:B__Round2_Strikes_Legs Significant Strikes_Landed:B__Round2_Strikes_Legs Total Strikes_Attempts:B__Round2_Strikes_Legs Total Strikes_Landed:B__Round2_Strikes_Punches_Attempts:B__Round2_Strikes_Punches_Landed:B__Round2_Strikes_Significant Strikes_Attempts:B__Round2_Strikes_Significant Strikes_Landed:B__Round2_Strikes_Total Strikes_Attempts:B__Round2_Strikes_Total Strikes_Landed:B__Round2_TIP_Back Control Time:B__Round2_TIP_Clinch Time:B__Round2_TIP_Control Time:B__Round2_TIP_Distance Time:B__Round2_TIP_Ground Control Time:B__Round2_TIP_Ground Time:B__Round2_TIP_Guard Control Time:B__Round2_TIP_Half Guard Control Time:B__Round2_TIP_Misc. Ground Control Time:B__Round2_TIP_Mount Control Time:B__Round2_TIP_Neutral Time:B__Round2_TIP_Side Control Time:B__Round2_TIP_Standing Time:B__Round3_Grappling_Reversals_Landed:B__Round3_Grappling_Standups_Landed:B__Round3_Grappling_Submissions_Attempts:B__Round3_Grappling_Takedowns_Attempts:B__Round3_Grappling_Takedowns_Landed:B__Round3_Strikes_Body Significant Strikes_Attempts:B__Round3_Strikes_Body Significant Strikes_Landed:B__Round3_Strikes_Body Total Strikes_Attempts:B__Round3_Strikes_Body Total Strikes_Landed:B__Round3_Strikes_Clinch Body Strikes_Attempts:B__Round3_Strikes_Clinch Body Strikes_Landed:B__Round3_Strikes_Clinch Head Strikes_Attempts:B__Round3_Strikes_Clinch Head Strikes_Landed:B__Round3_Strikes_Clinch Leg Strikes_Attempts:B__Round3_Strikes_Clinch Leg Strikes_Landed:B__Round3_Strikes_Clinch Significant Kicks_Attempts:B__Round3_Strikes_Clinch Significant Kicks_Landed:B__Round3_Strikes_Clinch Significant Punches_Attempts:B__Round3_Strikes_Clinch Significant Punches_Landed:B__Round3_Strikes_Clinch Significant Strikes_Attempts:B__Round3_Strikes_Clinch Significant Strikes_Landed:B__Round3_Strikes_Clinch Total Strikes_Attempts:B__Round3_Strikes_Clinch Total Strikes_Landed:B__Round3_Strikes_Distance Body Kicks_Attempts:B__Round3_Strikes_Distance Body Kicks_Landed:B__Round3_Strikes_Distance Body Punches_Attempts:B__Round3_Strikes_Distance Body Punches_Landed:B__Round3_Strikes_Distance Body Strikes_Attempts:B__Round3_Strikes_Distance Body Strikes_Landed:B__Round3_Strikes_Distance Head Kicks_Attempts:B__Round3_Strikes_Distance Head Kicks_Landed:B__Round3_Strikes_Distance Head Punches_Attempts:B__Round3_Strikes_Distance Head Punches_Landed:B__Round3_Strikes_Distance Head Strikes_Attempts:B__Round3_Strikes_Distance Head Strikes_Landed:B__Round3_Strikes_Distance Leg Kicks_Attempts:B__Round3_Strikes_Distance Leg Kicks_Landed:B__Round3_Strikes_Distance Leg Strikes_Attempts:B__Round3_Strikes_Distance Leg Strikes_Landed:B__Round3_Strikes_Distance Strikes_Attempts:B__Round3_Strikes_Distance Strikes_Landed:B__Round3_Strikes_Ground Body Strikes_Attempts:B__Round3_Strikes_Ground Body Strikes_Landed:B__Round3_Strikes_Ground Head Strikes_Attempts:B__Round3_Strikes_Ground Head Strikes_Landed:B__Round3_Strikes_Ground Leg Strikes_Attempts:B__Round3_Strikes_Ground Leg Strikes_Landed:B__Round3_Strikes_Ground Significant Kicks_Attempts:B__Round3_Strikes_Ground Significant Kicks_Landed:B__Round3_Strikes_Ground Significant Punches_Attempts:B__Round3_Strikes_Ground Significant Punches_Landed:B__Round3_Strikes_Ground Significant Strikes_Attempts:B__Round3_Strikes_Ground Significant Strikes_Landed:B__Round3_Strikes_Ground Total Strikes_Attempts:B__Round3_Strikes_Ground Total Strikes_Landed:B__Round3_Strikes_Head Significant Strikes_Attempts:B__Round3_Strikes_Head Significant Strikes_Landed:B__Round3_Strikes_Head Total Strikes_Attempts:B__Round3_Strikes_Head Total Strikes_Landed:B__Round3_Strikes_Kicks_Attempts:B__Round3_Strikes_Kicks_Landed:B__Round3_Strikes_Knock Down_Landed:B__Round3_Strikes_Leg Total Strikes_Attempts:B__Round3_Strikes_Leg Total Strikes_Landed:B__Round3_Strikes_Legs Significant Strikes_Attempts:B__Round3_Strikes_Legs Significant Strikes_Landed:B__Round3_Strikes_Legs Total Strikes_Attempts:B__Round3_Strikes_Legs Total Strikes_Landed:B__Round3_Strikes_Punches_Attempts:B__Round3_Strikes_Punches_Landed:B__Round3_Strikes_Significant Strikes_Attempts:B__Round3_Strikes_Significant Strikes_Landed:B__Round3_Strikes_Total Strikes_Attempts:B__Round3_Strikes_Total Strikes_Landed:B__Round3_TIP_Back Control Time:B__Round3_TIP_Clinch Time:B__Round3_TIP_Control Time:B__Round3_TIP_Distance Time:B__Round3_TIP_Ground Control Time:B__Round3_TIP_Ground Time:B__Round3_TIP_Guard Control Time:B__Round3_TIP_Half Guard Control Time:B__Round3_TIP_Misc. Ground Control Time:B__Round3_TIP_Mount Control Time:B__Round3_TIP_Neutral Time:B__Round3_TIP_Side Control Time:B__Round3_TIP_Standing Time:B__Round4_Grappling_Reversals_Landed:B__Round4_Grappling_Standups_Landed:B__Round4_Grappling_Submissions_Attempts:B__Round4_Grappling_Takedowns_Attempts:B__Round4_Grappling_Takedowns_Landed:B__Round4_Strikes_Body Significant Strikes_Attempts:B__Round4_Strikes_Body Significant Strikes_Landed:B__Round4_Strikes_Body Total Strikes_Attempts:B__Round4_Strikes_Body Total Strikes_Landed:B__Round4_Strikes_Clinch Body Strikes_Attempts:B__Round4_Strikes_Clinch Body Strikes_Landed:B__Round4_Strikes_Clinch Head Strikes_Attempts:B__Round4_Strikes_Clinch Head Strikes_Landed:B__Round4_Strikes_Clinch Leg Strikes_Attempts:B__Round4_Strikes_Clinch Leg Strikes_Landed:B__Round4_Strikes_Clinch Significant Kicks_Attempts:B__Round4_Strikes_Clinch Significant Kicks_Landed:B__Round4_Strikes_Clinch Significant Punches_Attempts:B__Round4_Strikes_Clinch Significant Punches_Landed:B__Round4_Strikes_Clinch Significant Strikes_Attempts:B__Round4_Strikes_Clinch Significant Strikes_Landed:B__Round4_Strikes_Clinch Total Strikes_Attempts:B__Round4_Strikes_Clinch Total Strikes_Landed:B__Round4_Strikes_Distance Body Kicks_Attempts:B__Round4_Strikes_Distance Body Kicks_Landed:B__Round4_Strikes_Distance Body Punches_Attempts:B__Round4_Strikes_Distance Body Punches_Landed:B__Round4_Strikes_Distance Body Strikes_Attempts:B__Round4_Strikes_Distance Body Strikes_Landed:B__Round4_Strikes_Distance Head Kicks_Attempts:B__Round4_Strikes_Distance Head Kicks_Landed:B__Round4_Strikes_Distance Head Punches_Attempts:B__Round4_Strikes_Distance Head Punches_Landed:B__Round4_Strikes_Distance Head Strikes_Attempts:B__Round4_Strikes_Distance Head Strikes_Landed:B__Round4_Strikes_Distance Leg Kicks_Attempts:B__Round4_Strikes_Distance Leg Kicks_Landed:B__Round4_Strikes_Distance Leg Strikes_Attempts:B__Round4_Strikes_Distance Leg Strikes_Landed:B__Round4_Strikes_Distance Strikes_Attempts:B__Round4_Strikes_Distance Strikes_Landed:B__Round4_Strikes_Ground Body Strikes_Attempts:B__Round4_Strikes_Ground Body Strikes_Landed:B__Round4_Strikes_Ground Head Strikes_Attempts:B__Round4_Strikes_Ground Head Strikes_Landed:B__Round4_Strikes_Ground Leg Strikes_Attempts:B__Round4_Strikes_Ground Leg Strikes_Landed:B__Round4_Strikes_Ground Significant Kicks_Attempts:B__Round4_Strikes_Ground Significant Kicks_Landed:B__Round4_Strikes_Ground Significant Punches_Attempts:B__Round4_Strikes_Ground Significant Punches_Landed:B__Round4_Strikes_Ground Significant Strikes_Attempts:B__Round4_Strikes_Ground Significant Strikes_Landed:B__Round4_Strikes_Ground Total Strikes_Attempts:B__Round4_Strikes_Ground Total Strikes_Landed:B__Round4_Strikes_Head Significant Strikes_Attempts:B__Round4_Strikes_Head Significant Strikes_Landed:B__Round4_Strikes_Head Total Strikes_Attempts:B__Round4_Strikes_Head Total Strikes_Landed:B__Round4_Strikes_Kicks_Attempts:B__Round4_Strikes_Kicks_Landed:B__Round4_Strikes_Knock Down_Landed:B__Round4_Strikes_Leg Total Strikes_Attempts:B__Round4_Strikes_Leg Total Strikes_Landed:B__Round4_Strikes_Legs Significant Strikes_Attempts:B__Round4_Strikes_Legs Significant Strikes_Landed:B__Round4_Strikes_Legs Total Strikes_Attempts:B__Round4_Strikes_Legs Total Strikes_Landed:B__Round4_Strikes_Punches_Attempts:B__Round4_Strikes_Punches_Landed:B__Round4_Strikes_Significant Strikes_Attempts:B__Round4_Strikes_Significant Strikes_Landed:B__Round4_Strikes_Total Strikes_Attempts:B__Round4_Strikes_Total Strikes_Landed:B__Round4_TIP_Back Control Time:B__Round4_TIP_Clinch Time:B__Round4_TIP_Control Time:B__Round4_TIP_Distance Time:B__Round4_TIP_Ground Control Time:B__Round4_TIP_Ground Time:B__Round4_TIP_Guard Control Time:B__Round4_TIP_Half Guard Control Time:B__Round4_TIP_Misc. Ground Control Time:B__Round4_TIP_Mount Control Time:B__Round4_TIP_Neutral Time:B__Round4_TIP_Side Control Time:B__Round4_TIP_Standing Time:B__Round5_Grappling_Reversals_Landed:B__Round5_Grappling_Standups_Landed:B__Round5_Grappling_Submissions_Attempts:B__Round5_Grappling_Takedowns_Attempts:B__Round5_Grappling_Takedowns_Landed:B__Round5_Strikes_Body Significant Strikes_Attempts:B__Round5_Strikes_Body Significant Strikes_Landed:B__Round5_Strikes_Body Total Strikes_Attempts:B__Round5_Strikes_Body Total Strikes_Landed:B__Round5_Strikes_Clinch Body Strikes_Attempts:B__Round5_Strikes_Clinch Body Strikes_Landed:B__Round5_Strikes_Clinch Head Strikes_Attempts:B__Round5_Strikes_Clinch Head Strikes_Landed:B__Round5_Strikes_Clinch Leg Strikes_Attempts:B__Round5_Strikes_Clinch Leg Strikes_Landed:B__Round5_Strikes_Clinch Significant Kicks_Attempts:B__Round5_Strikes_Clinch Significant Kicks_Landed:B__Round5_Strikes_Clinch Significant Punches_Attempts:B__Round5_Strikes_Clinch Significant Punches_Landed:B__Round5_Strikes_Clinch Significant Strikes_Attempts:B__Round5_Strikes_Clinch Significant Strikes_Landed:B__Round5_Strikes_Clinch Total Strikes_Attempts:B__Round5_Strikes_Clinch Total Strikes_Landed:B__Round5_Strikes_Distance Body Kicks_Attempts:B__Round5_Strikes_Distance Body Kicks_Landed:B__Round5_Strikes_Distance Body Punches_Attempts:B__Round5_Strikes_Distance Body Punches_Landed:B__Round5_Strikes_Distance Body Strikes_Attempts:B__Round5_Strikes_Distance Body Strikes_Landed:B__Round5_Strikes_Distance Head Kicks_Attempts:B__Round5_Strikes_Distance Head Kicks_Landed:B__Round5_Strikes_Distance Head Punches_Attempts:B__Round5_Strikes_Distance Head Punches_Landed:B__Round5_Strikes_Distance Head Strikes_Attempts:B__Round5_Strikes_Distance Head Strikes_Landed:B__Round5_Strikes_Distance Leg Kicks_Attempts:B__Round5_Strikes_Distance Leg Kicks_Landed:B__Round5_Strikes_Distance Leg Strikes_Attempts:B__Round5_Strikes_Distance Leg Strikes_Landed:B__Round5_Strikes_Distance Strikes_Attempts:B__Round5_Strikes_Distance Strikes_Landed:B__Round5_Strikes_Ground Body Strikes_Attempts:B__Round5_Strikes_Ground Body Strikes_Landed:B__Round5_Strikes_Ground Head Strikes_Attempts:B__Round5_Strikes_Ground Head Strikes_Landed:B__Round5_Strikes_Ground Leg Strikes_Attempts:B__Round5_Strikes_Ground Leg Strikes_Landed:B__Round5_Strikes_Ground Significant Kicks_Attempts:B__Round5_Strikes_Ground Significant Kicks_Landed:B__Round5_Strikes_Ground Significant Punches_Attempts:B__Round5_Strikes_Ground Significant Punches_Landed:B__Round5_Strikes_Ground Significant Strikes_Attempts:B__Round5_Strikes_Ground Significant Strikes_Landed:B__Round5_Strikes_Ground Total Strikes_Attempts:B__Round5_Strikes_Ground Total Strikes_Landed:B__Round5_Strikes_Head Significant Strikes_Attempts:B__Round5_Strikes_Head Significant Strikes_Landed:B__Round5_Strikes_Head Total Strikes_Attempts:B__Round5_Strikes_Head Total Strikes_Landed:B__Round5_Strikes_Kicks_Attempts:B__Round5_Strikes_Kicks_Landed:B__Round5_Strikes_Knock Down_Landed:B__Round5_Strikes_Leg Total Strikes_Attempts:B__Round5_Strikes_Leg Total Strikes_Landed:B__Round5_Strikes_Legs Significant Strikes_Attempts:B__Round5_Strikes_Legs Significant Strikes_Landed:B__Round5_Strikes_Legs Total Strikes_Attempts:B__Round5_Strikes_Legs Total Strikes_Landed:B__Round5_Strikes_Punches_Attempts:B__Round5_Strikes_Punches_Landed:B__Round5_Strikes_Significant Strikes_Attempts:B__Round5_Strikes_Significant Strikes_Landed:B__Round5_Strikes_Total Strikes_Attempts:B__Round5_Strikes_Total Strikes_Landed:B__Round5_TIP_Back Control Time:B__Round5_TIP_Clinch Time:B__Round5_TIP_Control Time:B__Round5_TIP_Distance Time:B__Round5_TIP_Ground Control Time:B__Round5_TIP_Ground Time:B__Round5_TIP_Guard Control Time:B__Round5_TIP_Half Guard Control Time:B__Round5_TIP_Misc. Ground Control Time:B__Round5_TIP_Mount Control Time:B__Round5_TIP_Neutral Time:B__Round5_TIP_Side Control Time:B__Round5_TIP_Standing Time:Date:Event_ID:Fight_ID:Last_round:Max_round:RPrev:RStreak:R_Age:R_Height:R_HomeTown:R_ID:R_Location:R_Name:R_Weight:R__Round1_Grappling_Reversals_Landed:R__Round1_Grappling_Standups_Landed:R__Round1_Grappling_Submissions_Attempts:R__Round1_Grappling_Takedowns_Attempts:R__Round1_Grappling_Takedowns_Landed:R__Round1_Strikes_Body Significant Strikes_Attempts:R__Round1_Strikes_Body Significant Strikes_Landed:R__Round1_Strikes_Body Total Strikes_Attempts:R__Round1_Strikes_Body Total Strikes_Landed:R__Round1_Strikes_Clinch Body Strikes_Attempts:R__Round1_Strikes_Clinch Body Strikes_Landed:R__Round1_Strikes_Clinch Head Strikes_Attempts:R__Round1_Strikes_Clinch Head Strikes_Landed:R__Round1_Strikes_Clinch Leg Strikes_Attempts:R__Round1_Strikes_Clinch Leg Strikes_Landed:R__Round1_Strikes_Clinch Significant Kicks_Attempts:R__Round1_Strikes_Clinch Significant Kicks_Landed:R__Round1_Strikes_Clinch Significant Punches_Attempts:R__Round1_Strikes_Clinch Significant Punches_Landed:R__Round1_Strikes_Clinch Significant Strikes_Attempts:R__Round1_Strikes_Clinch Significant Strikes_Landed:R__Round1_Strikes_Clinch Total Strikes_Attempts:R__Round1_Strikes_Clinch Total Strikes_Landed:R__Round1_Strikes_Distance Body Kicks_Attempts:R__Round1_Strikes_Distance Body Kicks_Landed:R__Round1_Strikes_Distance Body Punches_Attempts:R__Round1_Strikes_Distance Body Punches_Landed:R__Round1_Strikes_Distance Body Strikes_Attempts:R__Round1_Strikes_Distance Body Strikes_Landed:R__Round1_Strikes_Distance Head Kicks_Attempts:R__Round1_Strikes_Distance Head Kicks_Landed:R__Round1_Strikes_Distance Head Punches_Attempts:R__Round1_Strikes_Distance Head Punches_Landed:R__Round1_Strikes_Distance Head Strikes_Attempts:R__Round1_Strikes_Distance Head Strikes_Landed:R__Round1_Strikes_Distance Leg Kicks_Attempts:R__Round1_Strikes_Distance Leg Kicks_Landed:R__Round1_Strikes_Distance Leg Strikes_Attempts:R__Round1_Strikes_Distance Leg Strikes_Landed:R__Round1_Strikes_Distance Strikes_Attempts:R__Round1_Strikes_Distance Strikes_Landed:R__Round1_Strikes_Ground Body Strikes_Attempts:R__Round1_Strikes_Ground Body Strikes_Landed:R__Round1_Strikes_Ground Head Strikes_Attempts:R__Round1_Strikes_Ground Head Strikes_Landed:R__Round1_Strikes_Ground Leg Strikes_Attempts:R__Round1_Strikes_Ground Leg Strikes_Landed:R__Round1_Strikes_Ground Significant Kicks_Attempts:R__Round1_Strikes_Ground Significant Kicks_Landed:R__Round1_Strikes_Ground Significant Punches_Attempts:R__Round1_Strikes_Ground Significant Punches_Landed:R__Round1_Strikes_Ground Significant Strikes_Attempts:R__Round1_Strikes_Ground Significant Strikes_Landed:R__Round1_Strikes_Ground Total Strikes_Attempts:R__Round1_Strikes_Ground Total Strikes_Landed:R__Round1_Strikes_Head Significant Strikes_Attempts:R__Round1_Strikes_Head Significant Strikes_Landed:R__Round1_Strikes_Head Total Strikes_Attempts:R__Round1_Strikes_Head Total Strikes_Landed:R__Round1_Strikes_Kicks_Attempts:R__Round1_Strikes_Kicks_Landed:R__Round1_Strikes_Knock Down_Landed:R__Round1_Strikes_Leg Total Strikes_Attempts:R__Round1_Strikes_Leg Total Strikes_Landed:R__Round1_Strikes_Legs Significant Strikes_Attempts:R__Round1_Strikes_Legs Significant Strikes_Landed:R__Round1_Strikes_Legs Total Strikes_Attempts:R__Round1_Strikes_Legs Total Strikes_Landed:R__Round1_Strikes_Punches_Attempts:R__Round1_Strikes_Punches_Landed:R__Round1_Strikes_Significant Strikes_Attempts:R__Round1_Strikes_Significant Strikes_Landed:R__Round1_Strikes_Total Strikes_Attempts:R__Round1_Strikes_Total Strikes_Landed:R__Round1_TIP_Back Control Time:R__Round1_TIP_Clinch Time:R__Round1_TIP_Control Time:R__Round1_TIP_Distance Time:R__Round1_TIP_Ground Control Time:R__Round1_TIP_Ground Time:R__Round1_TIP_Guard Control Time:R__Round1_TIP_Half Guard Control Time:R__Round1_TIP_Misc. Ground Control Time:R__Round1_TIP_Mount Control Time:R__Round1_TIP_Neutral Time:R__Round1_TIP_Side Control Time:R__Round1_TIP_Standing Time:R__Round2_Grappling_Reversals_Landed:R__Round2_Grappling_Standups_Landed:R__Round2_Grappling_Submissions_Attempts:R__Round2_Grappling_Takedowns_Attempts:R__Round2_Grappling_Takedowns_Landed:R__Round2_Strikes_Body Significant Strikes_Attempts:R__Round2_Strikes_Body Significant Strikes_Landed:R__Round2_Strikes_Body Total Strikes_Attempts:R__Round2_Strikes_Body Total Strikes_Landed:R__Round2_Strikes_Clinch Body Strikes_Attempts:R__Round2_Strikes_Clinch Body Strikes_Landed:R__Round2_Strikes_Clinch Head Strikes_Attempts:R__Round2_Strikes_Clinch Head Strikes_Landed:R__Round2_Strikes_Clinch Leg Strikes_Attempts:R__Round2_Strikes_Clinch Leg Strikes_Landed:R__Round2_Strikes_Clinch Significant Kicks_Attempts:R__Round2_Strikes_Clinch Significant Kicks_Landed:R__Round2_Strikes_Clinch Significant Punches_Attempts:R__Round2_Strikes_Clinch Significant Punches_Landed:R__Round2_Strikes_Clinch Significant Strikes_Attempts:R__Round2_Strikes_Clinch Significant Strikes_Landed:R__Round2_Strikes_Clinch Total Strikes_Attempts:R__Round2_Strikes_Clinch Total Strikes_Landed:R__Round2_Strikes_Distance Body Kicks_Attempts:R__Round2_Strikes_Distance Body Kicks_Landed:R__Round2_Strikes_Distance Body Punches_Attempts:R__Round2_Strikes_Distance Body Punches_Landed:R__Round2_Strikes_Distance Body Strikes_Attempts:R__Round2_Strikes_Distance Body Strikes_Landed:R__Round2_Strikes_Distance Head Kicks_Attempts:R__Round2_Strikes_Distance Head Kicks_Landed:R__Round2_Strikes_Distance Head Punches_Attempts:R__Round2_Strikes_Distance Head Punches_Landed:R__Round2_Strikes_Distance Head Strikes_Attempts:R__Round2_Strikes_Distance Head Strikes_Landed:R__Round2_Strikes_Distance Leg Kicks_Attempts:R__Round2_Strikes_Distance Leg Kicks_Landed:R__Round2_Strikes_Distance Leg Strikes_Attempts:R__Round2_Strikes_Distance Leg Strikes_Landed:R__Round2_Strikes_Distance Strikes_Attempts:R__Round2_Strikes_Distance Strikes_Landed:R__Round2_Strikes_Ground Body Strikes_Attempts:R__Round2_Strikes_Ground Body Strikes_Landed:R__Round2_Strikes_Ground Head Strikes_Attempts:R__Round2_Strikes_Ground Head Strikes_Landed:R__Round2_Strikes_Ground Leg Strikes_Attempts:R__Round2_Strikes_Ground Leg Strikes_Landed:R__Round2_Strikes_Ground Significant Kicks_Attempts:R__Round2_Strikes_Ground Significant Kicks_Landed:R__Round2_Strikes_Ground Significant Punches_Attempts:R__Round2_Strikes_Ground Significant Punches_Landed:R__Round2_Strikes_Ground Significant Strikes_Attempts:R__Round2_Strikes_Ground Significant Strikes_Landed:R__Round2_Strikes_Ground Total Strikes_Attempts:R__Round2_Strikes_Ground Total Strikes_Landed:R__Round2_Strikes_Head Significant Strikes_Attempts:R__Round2_Strikes_Head Significant Strikes_Landed:R__Round2_Strikes_Head Total Strikes_Attempts:R__Round2_Strikes_Head Total Strikes_Landed:R__Round2_Strikes_Kicks_Attempts:R__Round2_Strikes_Kicks_Landed:R__Round2_Strikes_Knock Down_Landed:R__Round2_Strikes_Leg Total Strikes_Attempts:R__Round2_Strikes_Leg Total Strikes_Landed:R__Round2_Strikes_Legs Significant Strikes_Attempts:R__Round2_Strikes_Legs Significant Strikes_Landed:R__Round2_Strikes_Legs Total Strikes_Attempts:R__Round2_Strikes_Legs Total Strikes_Landed:R__Round2_Strikes_Punches_Attempts:R__Round2_Strikes_Punches_Landed:R__Round2_Strikes_Significant Strikes_Attempts:R__Round2_Strikes_Significant Strikes_Landed:R__Round2_Strikes_Total Strikes_Attempts:R__Round2_Strikes_Total Strikes_Landed:R__Round2_TIP_Back Control Time:R__Round2_TIP_Clinch Time:R__Round2_TIP_Control Time:R__Round2_TIP_Distance Time:R__Round2_TIP_Ground Control Time:R__Round2_TIP_Ground Time:R__Round2_TIP_Guard Control Time:R__Round2_TIP_Half Guard Control Time:R__Round2_TIP_Misc. Ground Control Time:R__Round2_TIP_Mount Control Time:R__Round2_TIP_Neutral Time:R__Round2_TIP_Side Control Time:R__Round2_TIP_Standing Time:R__Round3_Grappling_Reversals_Landed:R__Round3_Grappling_Standups_Landed:R__Round3_Grappling_Submissions_Attempts:R__Round3_Grappling_Takedowns_Attempts:R__Round3_Grappling_Takedowns_Landed:R__Round3_Strikes_Body Significant Strikes_Attempts:R__Round3_Strikes_Body Significant Strikes_Landed:R__Round3_Strikes_Body Total Strikes_Attempts:R__Round3_Strikes_Body Total Strikes_Landed:R__Round3_Strikes_Clinch Body Strikes_Attempts:R__Round3_Strikes_Clinch Body Strikes_Landed:R__Round3_Strikes_Clinch Head Strikes_Attempts:R__Round3_Strikes_Clinch Head Strikes_Landed:R__Round3_Strikes_Clinch Leg Strikes_Attempts:R__Round3_Strikes_Clinch Leg Strikes_Landed:R__Round3_Strikes_Clinch Significant Kicks_Attempts:R__Round3_Strikes_Clinch Significant Kicks_Landed:R__Round3_Strikes_Clinch Significant Punches_Attempts:R__Round3_Strikes_Clinch Significant Punches_Landed:R__Round3_Strikes_Clinch Significant Strikes_Attempts:R__Round3_Strikes_Clinch Significant Strikes_Landed:R__Round3_Strikes_Clinch Total Strikes_Attempts:R__Round3_Strikes_Clinch Total Strikes_Landed:R__Round3_Strikes_Distance Body Kicks_Attempts:R__Round3_Strikes_Distance Body Kicks_Landed:R__Round3_Strikes_Distance Body Punches_Attempts:R__Round3_Strikes_Distance Body Punches_Landed:R__Round3_Strikes_Distance Body Strikes_Attempts:R__Round3_Strikes_Distance Body Strikes_Landed:R__Round3_Strikes_Distance Head Kicks_Attempts:R__Round3_Strikes_Distance Head Kicks_Landed:R__Round3_Strikes_Distance Head Punches_Attempts:R__Round3_Strikes_Distance Head Punches_Landed:R__Round3_Strikes_Distance Head Strikes_Attempts:R__Round3_Strikes_Distance Head Strikes_Landed:R__Round3_Strikes_Distance Leg Kicks_Attempts:R__Round3_Strikes_Distance Leg Kicks_Landed:R__Round3_Strikes_Distance Leg Strikes_Attempts:R__Round3_Strikes_Distance Leg Strikes_Landed:R__Round3_Strikes_Distance Strikes_Attempts:R__Round3_Strikes_Distance Strikes_Landed:R__Round3_Strikes_Ground Body Strikes_Attempts:R__Round3_Strikes_Ground Body Strikes_Landed:R__Round3_Strikes_Ground Head Strikes_Attempts:R__Round3_Strikes_Ground Head Strikes_Landed:R__Round3_Strikes_Ground Leg Strikes_Attempts:R__Round3_Strikes_Ground Leg Strikes_Landed:R__Round3_Strikes_Ground Significant Kicks_Attempts:R__Round3_Strikes_Ground Significant Kicks_Landed:R__Round3_Strikes_Ground Significant Punches_Attempts:R__Round3_Strikes_Ground Significant Punches_Landed:R__Round3_Strikes_Ground Significant Strikes_Attempts:R__Round3_Strikes_Ground Significant Strikes_Landed:R__Round3_Strikes_Ground Total Strikes_Attempts:R__Round3_Strikes_Ground Total Strikes_Landed:R__Round3_Strikes_Head Significant Strikes_Attempts:R__Round3_Strikes_Head Significant Strikes_Landed:R__Round3_Strikes_Head Total Strikes_Attempts:R__Round3_Strikes_Head Total Strikes_Landed:R__Round3_Strikes_Kicks_Attempts:R__Round3_Strikes_Kicks_Landed:R__Round3_Strikes_Knock Down_Landed:R__Round3_Strikes_Leg Total Strikes_Attempts:R__Round3_Strikes_Leg Total Strikes_Landed:R__Round3_Strikes_Legs Significant Strikes_Attempts:R__Round3_Strikes_Legs Significant Strikes_Landed:R__Round3_Strikes_Legs Total Strikes_Attempts:R__Round3_Strikes_Legs Total Strikes_Landed:R__Round3_Strikes_Punches_Attempts:R__Round3_Strikes_Punches_Landed:R__Round3_Strikes_Significant Strikes_Attempts:R__Round3_Strikes_Significant Strikes_Landed:R__Round3_Strikes_Total Strikes_Attempts:R__Round3_Strikes_Total Strikes_Landed:R__Round3_TIP_Back Control Time:R__Round3_TIP_Clinch Time:R__Round3_TIP_Control Time:R__Round3_TIP_Distance Time:R__Round3_TIP_Ground Control Time:R__Round3_TIP_Ground Time:R__Round3_TIP_Guard Control Time:R__Round3_TIP_Half Guard Control Time:R__Round3_TIP_Misc. Ground Control Time:R__Round3_TIP_Mount Control Time:R__Round3_TIP_Neutral Time:R__Round3_TIP_Side Control Time:R__Round3_TIP_Standing Time:R__Round4_Grappling_Reversals_Landed:R__Round4_Grappling_Standups_Landed:R__Round4_Grappling_Submissions_Attempts:R__Round4_Grappling_Takedowns_Attempts:R__Round4_Grappling_Takedowns_Landed:R__Round4_Strikes_Body Significant Strikes_Attempts:R__Round4_Strikes_Body Significant Strikes_Landed:R__Round4_Strikes_Body Total Strikes_Attempts:R__Round4_Strikes_Body Total Strikes_Landed:R__Round4_Strikes_Clinch Body Strikes_Attempts:R__Round4_Strikes_Clinch Body Strikes_Landed:R__Round4_Strikes_Clinch Head Strikes_Attempts:R__Round4_Strikes_Clinch Head Strikes_Landed:R__Round4_Strikes_Clinch Leg Strikes_Attempts:R__Round4_Strikes_Clinch Leg Strikes_Landed:R__Round4_Strikes_Clinch Significant Kicks_Attempts:R__Round4_Strikes_Clinch Significant Kicks_Landed:R__Round4_Strikes_Clinch Significant Punches_Attempts:R__Round4_Strikes_Clinch Significant Punches_Landed:R__Round4_Strikes_Clinch Significant Strikes_Attempts:R__Round4_Strikes_Clinch Significant Strikes_Landed:R__Round4_Strikes_Clinch Total Strikes_Attempts:R__Round4_Strikes_Clinch Total Strikes_Landed:R__Round4_Strikes_Distance Body Kicks_Attempts:R__Round4_Strikes_Distance Body Kicks_Landed:R__Round4_Strikes_Distance Body Punches_Attempts:R__Round4_Strikes_Distance Body Punches_Landed:R__Round4_Strikes_Distance Body Strikes_Attempts:R__Round4_Strikes_Distance Body Strikes_Landed:R__Round4_Strikes_Distance Head Kicks_Attempts:R__Round4_Strikes_Distance Head Kicks_Landed:R__Round4_Strikes_Distance Head Punches_Attempts:R__Round4_Strikes_Distance Head Punches_Landed:R__Round4_Strikes_Distance Head Strikes_Attempts:R__Round4_Strikes_Distance Head Strikes_Landed:R__Round4_Strikes_Distance Leg Kicks_Attempts:R__Round4_Strikes_Distance Leg Kicks_Landed:R__Round4_Strikes_Distance Leg Strikes_Attempts:R__Round4_Strikes_Distance Leg Strikes_Landed:R__Round4_Strikes_Distance Strikes_Attempts:R__Round4_Strikes_Distance Strikes_Landed:R__Round4_Strikes_Ground Body Strikes_Attempts:R__Round4_Strikes_Ground Body Strikes_Landed:R__Round4_Strikes_Ground Head Strikes_Attempts:R__Round4_Strikes_Ground Head Strikes_Landed:R__Round4_Strikes_Ground Leg Strikes_Attempts:R__Round4_Strikes_Ground Leg Strikes_Landed:R__Round4_Strikes_Ground Significant Kicks_Attempts:R__Round4_Strikes_Ground Significant Kicks_Landed:R__Round4_Strikes_Ground Significant Punches_Attempts:R__Round4_Strikes_Ground Significant Punches_Landed:R__Round4_Strikes_Ground Significant Strikes_Attempts:R__Round4_Strikes_Ground Significant Strikes_Landed:R__Round4_Strikes_Ground Total Strikes_Attempts:R__Round4_Strikes_Ground Total Strikes_Landed:R__Round4_Strikes_Head Significant Strikes_Attempts:R__Round4_Strikes_Head Significant Strikes_Landed:R__Round4_Strikes_Head Total Strikes_Attempts:R__Round4_Strikes_Head Total Strikes_Landed:R__Round4_Strikes_Kicks_Attempts:R__Round4_Strikes_Kicks_Landed:R__Round4_Strikes_Knock Down_Landed:R__Round4_Strikes_Leg Total Strikes_Attempts:R__Round4_Strikes_Leg Total Strikes_Landed:R__Round4_Strikes_Legs Significant Strikes_Attempts:R__Round4_Strikes_Legs Significant Strikes_Landed:R__Round4_Strikes_Legs Total Strikes_Attempts:R__Round4_Strikes_Legs Total Strikes_Landed:R__Round4_Strikes_Punches_Attempts:R__Round4_Strikes_Punches_Landed:R__Round4_Strikes_Significant Strikes_Attempts:R__Round4_Strikes_Significant Strikes_Landed:R__Round4_Strikes_Total Strikes_Attempts:R__Round4_Strikes_Total Strikes_Landed:R__Round4_TIP_Back Control Time:R__Round4_TIP_Clinch Time:R__Round4_TIP_Control Time:R__Round4_TIP_Distance Time:R__Round4_TIP_Ground Control Time:R__Round4_TIP_Ground Time:R__Round4_TIP_Guard Control Time:R__Round4_TIP_Half Guard Control Time:R__Round4_TIP_Misc. Ground Control Time:R__Round4_TIP_Mount Control Time:R__Round4_TIP_Neutral Time:R__Round4_TIP_Side Control Time:R__Round4_TIP_Standing Time:R__Round5_Grappling_Reversals_Landed:R__Round5_Grappling_Standups_Landed:R__Round5_Grappling_Submissions_Attempts:R__Round5_Grappling_Takedowns_Attempts:R__Round5_Grappling_Takedowns_Landed:R__Round5_Strikes_Body Significant Strikes_Attempts:R__Round5_Strikes_Body Significant Strikes_Landed:R__Round5_Strikes_Body Total Strikes_Attempts:R__Round5_Strikes_Body Total Strikes_Landed:R__Round5_Strikes_Clinch Body Strikes_Attempts:R__Round5_Strikes_Clinch Body Strikes_Landed:R__Round5_Strikes_Clinch Head Strikes_Attempts:R__Round5_Strikes_Clinch Head Strikes_Landed:R__Round5_Strikes_Clinch Leg Strikes_Attempts:R__Round5_Strikes_Clinch Leg Strikes_Landed:R__Round5_Strikes_Clinch Significant Kicks_Attempts:R__Round5_Strikes_Clinch Significant Kicks_Landed:R__Round5_Strikes_Clinch Significant Punches_Attempts:R__Round5_Strikes_Clinch Significant Punches_Landed:R__Round5_Strikes_Clinch Significant Strikes_Attempts:R__Round5_Strikes_Clinch Significant Strikes_Landed:R__Round5_Strikes_Clinch Total Strikes_Attempts:R__Round5_Strikes_Clinch Total Strikes_Landed:R__Round5_Strikes_Distance Body Kicks_Attempts:R__Round5_Strikes_Distance Body Kicks_Landed:R__Round5_Strikes_Distance Body Punches_Attempts:R__Round5_Strikes_Distance Body Punches_Landed:R__Round5_Strikes_Distance Body Strikes_Attempts:R__Round5_Strikes_Distance Body Strikes_Landed:R__Round5_Strikes_Distance Head Kicks_Attempts:R__Round5_Strikes_Distance Head Kicks_Landed:R__Round5_Strikes_Distance Head Punches_Attempts:R__Round5_Strikes_Distance Head Punches_Landed:R__Round5_Strikes_Distance Head Strikes_Attempts:R__Round5_Strikes_Distance Head Strikes_Landed:R__Round5_Strikes_Distance Leg Kicks_Attempts:R__Round5_Strikes_Distance Leg Kicks_Landed:R__Round5_Strikes_Distance Leg Strikes_Attempts:R__Round5_Strikes_Distance Leg Strikes_Landed:R__Round5_Strikes_Distance Strikes_Attempts:R__Round5_Strikes_Distance Strikes_Landed:R__Round5_Strikes_Ground Body Strikes_Attempts:R__Round5_Strikes_Ground Body Strikes_Landed:R__Round5_Strikes_Ground Head Strikes_Attempts:R__Round5_Strikes_Ground Head Strikes_Landed:R__Round5_Strikes_Ground Leg Strikes_Attempts:R__Round5_Strikes_Ground Leg Strikes_Landed:R__Round5_Strikes_Ground Significant Kicks_Attempts:R__Round5_Strikes_Ground Significant Kicks_Landed:R__Round5_Strikes_Ground Significant Punches_Attempts:R__Round5_Strikes_Ground Significant Punches_Landed:R__Round5_Strikes_Ground Significant Strikes_Attempts:R__Round5_Strikes_Ground Significant Strikes_Landed:R__Round5_Strikes_Ground Total Strikes_Attempts:R__Round5_Strikes_Ground Total Strikes_Landed:R__Round5_Strikes_Head Significant Strikes_Attempts:R__Round5_Strikes_Head Significant Strikes_Landed:R__Round5_Strikes_Head Total Strikes_Attempts:R__Round5_Strikes_Head Total Strikes_Landed:R__Round5_Strikes_Kicks_Attempts:R__Round5_Strikes_Kicks_Landed:R__Round5_Strikes_Knock Down_Landed:R__Round5_Strikes_Leg Total Strikes_Attempts:R__Round5_Strikes_Leg Total Strikes_Landed:R__Round5_Strikes_Legs Significant Strikes_Attempts:R__Round5_Strikes_Legs Significant Strikes_Landed:R__Round5_Strikes_Legs Total Strikes_Attempts:R__Round5_Strikes_Legs Total Strikes_Landed:R__Round5_Strikes_Punches_Attempts:R__Round5_Strikes_Punches_Landed:R__Round5_Strikes_Significant Strikes_Attempts:R__Round5_Strikes_Significant Strikes_Landed:R__Round5_Strikes_Total Strikes_Attempts:R__Round5_Strikes_Total Strikes_Landed:R__Round5_TIP_Back Control Time:R__Round5_TIP_Clinch Time:R__Round5_TIP_Control Time:R__Round5_TIP_Distance Time:R__Round5_TIP_Ground Control Time:R__Round5_TIP_Ground Time:R__Round5_TIP_Guard Control Time:R__Round5_TIP_Half Guard Control Time:R__Round5_TIP_Misc. Ground Control Time:R__Round5_TIP_Mount Control Time:R__Round5_TIP_Neutral Time:R__Round5_TIP_Side Control Time:R__Round5_TIP_Standing Time:winby:winner:,numeric:numeric:numeric:numeric:string:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:dateTime:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:,
Adult Census Income with AI , Maxime Fuccellaro , www.kaggle.com/blackbee2016/adult-census-income-with-ai , Tue Aug 08 2017 19:03:21 GMT+0530 (IST) , Artificial Intelligence to boost data science ,67, finance- politics- demographics- ,Context This data was extracted from the 1994 Census bureau database by Ronny Kohavi and Barry Becker (Data Mining and Visualization Silicon Graphics). A set of reasonably clean records was extracted using the following conditions ((AAGE>16) && (AGI>100) && (AFNLWGT>1) && (HRSWK>0)). The prediction task is to determine whether a person makes over $50K a year. In order to make the job better we used artificial Intelligence to automatically modify the columns.  Content This Dataset contains the initial Dataset columns as well as the new ones obtained by feeding the original US Census Dataset to PredicSis.ai in order to automatically   1. Discretise continuous variables into relevant intervals.  2. Group values of categorical variables together in order to reduce the modality of the variables. Acknowledgements https//archive.ics.uci.edu/ml/datasets/Census+Income https//www.kaggle.com/uciml/adult-census-income https//predicsis.ai Inspiration We want to see by how much auto ML/AI improves the data scientist work quality.,:KEY:LABEL:age:capital_gain:capital_loss:education:education_num:fnlwgt:hours_per_week:marital_status:native_country:occupation:race:relationship:sex:workLABEL:LabelPage:LabelPcapital_gain:LabelPcapital_loss:LabelPeducation:LabelPeducation_num:LabelPhours_per_week:LabelPmarital_status:LabelPnative_country:LabelPoccupation:LabelPrace:LabelPrelationship:LabelPsex:LabelPworkLABEL:,numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:,
Football Matches of Spanish League , Ricardo Moya , www.kaggle.com/ricardomoya/football-matches-of-spanish-league , Wed Jun 14 2017 18:15:33 GMT+0530 (IST) , Soccer matches of 1st and 2nd division from season 1970-71 to 2016-17 ,280, association football- ,Context Data Set with the football matches of the Spanish league of the 1st and 2nd division from the 1970-71 to 2016-17 season has been created with the aim of opening a line of research in the Machine Learning for the prediction of results (1X2) of football matches. Content This file contains information about a football matches with the follow features  48081977-7818Rayo VallecanoReal Madrid3230/10/1977247014000   id (4808) Unique identifier of football match season (1977-78) Season in which the match was played division (1) División in which the match was played (1st '1' 2nd '2') round (8) round in which the match was played localTeam (Rayo Vallecano) Local Team name visitorTeam (Real Madrid) Visitor Team name localGoals (3) Goals scored by the local team visitorGoals (2) Goals scored by the visitor team fecha (30/10/1977) Date in which the match was played date (247014000) Timestamp in which the match was played  Acknowledgements Scraping made from  http//www.bdfutbol.com http//www.resultados-futbol.com ,id:season:division:round:localTeam:visitorTeam:localGoals:visitorGoals:date:timestamp:,numeric:string:numeric:numeric:string:string:numeric:numeric:dateTime:numeric:,
Cervical cancer tumor vs matched control , Thomas Nelson , www.kaggle.com/thomasnelson/cervical-cancer-tumor-vs-matched-control , Mon May 08 2017 20:30:49 GMT+0530 (IST) , gene expression profiling data from tumor and matched normal samples (29 each) ,260, human medicine- ,Context Cervical cancer tumor vs matched control data.  Data set is gene expression profiling data from tumor and matched normal samples (29 each).  The data are the raw read counts (not normalized) from sequencing of microRNA.  This is not my data but was published by Witten D. et al. (2010) Ultra-high throughput sequencing-based small RNA discovery and discrete statistical biomarker analysis in a collection of cervical tumours and matched controls. BMC Biology 858 Content The rows are each micro RNA name and the columns are the sample names (N=normal T=tumor).  The values are raw read counts. Acknowledgements Witten D. et al. (2010) Ultra-high throughput sequencing-based small RNA discovery and discrete statistical biomarker analysis in a collection of cervical tumours and matched controls. BMC Biology 858 Inspiration Use this data to practice making predictive models from machine learning/deep learning algorithms on gene expression profiling data.,ID:N1:N2:N3:N4:N5:N6:N7:N8:N9:N10:N11:N12:N13:N14:N15:N16:N17:N18:N19:N20:N21:N22:N23:N24:N25:N26:N27:N28:N29:T1:T2:T3:T4:T5:T6:T7:T8:T9:T10:T11:T12:T13:T14:T15:T16:T17:T18:T19:T20:T21:T22:T23:T24:T25:T26:T27:T28:T29:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
SF Beaches Water Quality , Jacob Boysen , www.kaggle.com/jboysen/sf-beaches-water , Wed Sep 06 2017 21:31:17 GMT+0530 (IST) , Contaminant Sampling Across 15 Beaches Summer 2017 ,47, bodies of water- safety- ,Context Shoreline bacteria are routinely monitored at fifteen stations around the perimeter of San Francisco where water contact recreation may occur. These include three stations within the Candlestick Point State Recreation Area one station at Islais Creek two stations at Aquatic Park two stations along Crissy Field Beach three stations at Baker Beach one station at China Beach and three stations along Ocean Beach. Content Dataset represents 552 samples taken across 15 locations over summer of 2017. Additional monitoring is conducted whenever a treated discharge from the City’s Combined sewer system occurs that affects a monitored beach. Acknowledgements The beach monitoring program is a cooperative effort between the San Francisco Public Utilities Commission and the San Francisco Department of Public Health. Samples are collected weekly year round.  READ MORE about the combined sewer system and a detailed explanation of the Beach Monitoring Program. Inspiration  Are there any patterns in beach water quality? ,,,
Uttar Pradesh Assembly Elections 2017 , Ankit , www.kaggle.com/ankit2106/uttar-pradesh-assembly-elections-2017 , Sat Apr 22 2017 19:16:27 GMT+0530 (IST) , Dataset for constituency wise results for all candidates ,357, politics- ,Context The assembly election results for Uttar Pradesh(UP) were surprising to say the least. Never in the past has any single party secured a similar mandate. UP with a population of around 220 million is as big as the whole of united states. It has 403 constituencies each having its own demographic breakup. The election was conducted in 7 phases. Content The dataset has 8 variables seat_allotment As some of you might be aware that there was a coalition between INC and SP which materialized pretty late into the campaign. Hence in a few constituencies the high command of the 2 parties could not convince contestants to forfeit their nomination. In such constituencies there is a situation that is called a friendly fight(FF) where candidates from both parties INC and SP are contesting instead of just one.  These constituencies are marked by the flag FF (Friendly Fight). Others are INC (contested by INC) SP(Contested by SP) and DNC(Contested by none) phase The phase in which the election was conducted. ac_no Assembly constituency number ac Assembly constituency name district District to which the ac belongs candidate Candidate name party Party name votes votes for each candidate Source Scraped from eciresults.nic.in,seat_allotment:phase:ac_no:ac:district:candidate:party:votes:,string:numeric:numeric:string:string:string:string:numeric:,
New Car Sales in Norway , dmi3kno , www.kaggle.com/dmi3kno/newcarsalesnorway , Sat Feb 18 2017 23:28:17 GMT+0530 (IST) , Monthly car sales for 2007-2017 by make and most popular models ,1607, business- automobiles- ,"Context On the morning of 10 January 2017 Opplysningsrådet for Veitrafikken (OFV) Norwegian road association  held a business breakfast for its member organizations where they presented the annual presentation under the title ""Car Year 2016. Status and trends"" (Bilåret 2016 – status og trender).  Among the highlights for the year OFV reported all-time-high sales of electric cars with fully electric and plug-in hybrid cars accounting for 402% of all new car sales (compare to 7.4% for Sweden and 3.6% for Denmark). No other country in the world has this level of popularity of battery-equipped vehicles! In November 2016 12 out of 15 most popular cars sold in Norway were either hybrids of fully electric vehicles with BWM-i3 snapping the title as the most popular car in Norway ahead of undisputed leader of the last decade VW Golf (including eGolf) according to bilnorge.no. Among 10 most popular cars for the year OFV reported there was only one(!) fossil fuel vehicle. OFV makes annual forecast of new passenger car sales. Short summary of their methodology  Based on OFV statistics over several years Taking into account the actual monthly figures for the last four years Actual same-month sales for the previous year is combined with the average for the eight previous months  weighed by the month's proportion in a year adjusted by year's actual sales compared with those of the last year.  OFV forecast for 2016 was 157 500 new passenger cars. Actual sales were 154 603 cars. Applying the same model for 2017 OFV forecasts 152 400 new passenger cars to be sold in Norway. Content Dataset includes two tables  1) Monthly sales of new passenger cars by make (manufacturer brand) - norway_new_car_sales_by_make.csv  Year - year of sales Month - month of sales Make - car make (e.g. Volkswagen Toyota Tesla) Quantity - number of units sold Pct - percent share in monthly total  2) Monthly summary of top-20 most popular models (by make and model) - norway_new_car_sales_by_model.csv  Year - year of sales Month - month of sales Make - car make (e.g. Volkswagen Toyota Tesla) Model - car model (e.g. BMW-i3 Volkswagen Golf Tesla S75) Quantity - number of units sold Pct - percent share in monthly total  3) Summary stats for car sales in Norway by month - norway_new_car_sales_by_month.csv  Year - year of sales Month - month of sales Quantity - total number of units sold Quantity_YoY - change YoY in units Import - total number of units imported (used cars) Import_YoY - change YoY in units Used - total number of units owner changes inside the country (data available from 2012) Used_YoY - change YoY in units Avg_CO2 - average CO2 emission of all cars sold in a given month (in g/km) Bensin_CO2 - average CO2 emission of bensin-fueled cars sold in a given month (in g/km) Diesel_CO2 - average CO2 emission of diesel-fueled cars sold in a given month (in g/km) Quantity_Diesel - number of diesel-fueled cars sold in the country in a given month Diesel_Share - share of diesel cars in total sales (Quantity_Diesel / Quantity) Diesel_Share_LY - share of diesel cars in total sales a year ago Quantity_Hybrid - number of new hybrid cars sold in the country (both PHEV and BV) Quantity_Electric - number of new electric cars sold in the country (zero emission vehicles) Import_Electric - number of used electric cars imported to the country (zero emission vehicles)  Note The numbers on sales of hybrid and electric cars is unavailable prior to 2011. Data is complied from monthly tables published on OFV website (example here). Additional datapoints added from summary tables published on dinside.no Acknowledgements Opplysningsrådet for Veitrafikken (OFV) is a politically independent membership organization that works to get politicians and authorities to build safer and more efficient roads in Norway. The organization has about 60 members representing different types of road users. Members are leading players in road safety car owner associations public transportation companies shippers car dealers oil companies banking finance and insurance road builders and general contractors.  Site http//www.ofvas.no and http//www.ofv.no  Monthly summary statistics and market news http//www.dinside.no/emne/bilsalget and http//statistikk.ofv.no/ofv_bilsalg_small.asp Detailed sales per model http//www.ofvas.no/co2-utslippet/category406.html (using http//www.newocr.com/)  Inspiration 1) How did Norway get here? When did they start on the journey towards electric-powered vehicles and what might have contributed? 2) Did you now that until recently (September 2016) Norway has been second most important market for Tesla Motors (after US)? 3) Can you beat the forecast accuracy of OFV for 2016 and produce a better estimate for 2017?",Year:,numeric:,
Chess Game Dataset (Lichess) , Mitchell J , www.kaggle.com/datasnaek/chess , Mon Sep 04 2017 08:39:09 GMT+0530 (IST) , 20000+ Lichess Games including moves victor rating opening details and more ,178, board games- internet- ,General Info This is a set of just over 20000 games collected from a selection of users on the site Lichess.org and how to collect more. I will also upload more games in the future as I collect them. This set contains the  Game ID; Rated (T/F); Start Time; End Time; Number of Turns; Game Status; Winner; Time Increment; White Player ID; White Player Rating; Black Player ID; Black Player Rating; All Moves in Standard Chess Notation; Opening Eco (Standardised Code for any given opening list here); Opening Name; Opening Ply (Number of moves in the opening phase)  For each of these separate games from Lichess. I collected this data using the Lichess API which enables collection of any given users game history. The difficult part was collecting usernames to use however the API also enables dumping of all users in a Lichess team. There are several teams on Lichess with over 1500 players so this proved an effective way to get users to collect games from. Possible Uses Lots of information is contained within a single chess game let alone a full dataset of multiple games. It is primarily a game of patterns and data science is all about detecting patterns in data which is why chess has been one of the most invested in areas of AI in the past. This dataset collects all of the information available from 20000 games and presents it in a format that is easy to process for analysis of for example what allows a player to win as black or white how much meta (out-of-game) factors affect a game the relationship between openings and victory for black and white and more.,id:rated:created_at:last_move_at:turns:victory_status:winner:increment_code:white_id:white_rating:black_id:black_rating:moves:opening_eco:opening_name:opening_ply:,string:boolean:numeric:numeric:numeric:string:string:string:string:numeric:string:numeric:string:string:string:numeric:,
Penn World Table , Jacob Boysen , www.kaggle.com/jboysen/penn-world-table , Wed Sep 06 2017 01:43:47 GMT+0530 (IST) , Compare Economic Growth Across Countries ,94, finance- money- economics- ,"Context The Penn World Table has long been a standard data source for those interested in comparing living standards across countries and explaining differences in cross-country growth. The article describing version 5.6 (Summers and Heston 1991) is among the most widely cited papers in economics with well over 1000 citations. This version (9.0) attempts to mitigate many concerns raised since. See this article for additional discussion. Content Database with information on relative levels of income output input and productivity covering 182 countries between 1950 and 2014. See legend user guide and source for additional information. Acknowledgements This file contains the data of PWT 9.0 as available on www.ggdc.net/pwt. Please refer to www.ggdc.net/pwt for extensive documentation of the different concepts and how these data were constructed. When using these data please refer to the following paper available for download at www.ggdc.net/pwt Feenstra Robert C. Robert Inklaar and Marcel P. Timmer (2015) ""The Next Generation of the Penn World Table"""" American Economic Review 105(10) 3150-3182.",countrycode:country:currency_unit:year:rgdpe:rgdpo:pop:emp:avh:hc:ccon:cda:cgdpe:cgdpo:ck:ctfp:cwtfp:rgdpna:rconna:rdana:rkna:rtfpna:rwtfpna:labsh:delta:xr:pl_con:pl_da:pl_gdpo:i_cig:i_xm:i_xr:i_outlier:cor_exp:statcap:csh_c:csh_i:csh_g:csh_x:csh_m:csh_r:pl_c:pl_i:pl_g:pl_x:pl_m:pl_k:,string:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:,
Salem Witchcraft Dataset , Rachael Tatman , www.kaggle.com/rtatman/salem-witchcraft-dataset , Fri Sep 01 2017 23:04:46 GMT+0530 (IST) , Explore and visualize the Salem witchcraft trials ,166, united states- history- crime- violence- ,"Context Few events in American history are better known than the Salem witchcraft trials of 1692. Its popularity is doubtless attributable to a number of things a persistent fascination with the occult; a perverse pleasure to expose the underbelly of an American culture that boasts of toleration social harmony and progress; and an appreciation for a compelling dramatic narrative replete with heroes and villains. Skeptics like the preeminent twentieth-century historian Perry Miller question whether the Salem trials constituted anything more than an inconsequential episode in colonial history. But most historians consider Salem worthy of continuing investigation even if it was less than a major turning point in history. Indeed Salem has been an unusually fertile field for historical research because it readily lends itself to new approaches insights and methodologies. To understand what happened in Salem historians have profitably applied the perspectives of politics anthropology economic and social analysis religion social psychology and demography. If the ultimate meaning of Salem is still elusive these investigations have broadened and deepened our understanding of the 1692 witchcraft outbreak. Content The Salem Witchcraft Website contains eight data sets. They provide only a small portion of the historical record about Salem. They do not contain transcripts of examinations or trials or contemporary narrative accounts for example. Instead they provide information primarily of a quantitative nature about three major aspects of the outbreak its chronology its geographic spread and the social and economic divisions in Salem Village that shaped events. The data were derived primarily from four published sources Paul Boyer and Stephen Nissenbaum's three-volume transcription of the legal records of the witchcraft trials The Salem Witchcraft Papers; the new and now authoritative Records of the Salem Witch-Hunt edited by Bernard Rosenthal et. al.; Boyer and Nissenbaum's edited collection of documents Salem-Village Witchcraft; and Salem Village's Book of Record which contain tax records and other information relating to Salem Village. Photocopies of the original Salem Village record book and church records were examined at the Danvers Archival Center.  The Accused Witches Data Set contains information about those who were formally accused of witchcraft during the Salem episode. This means that there exists evidence of some form of direct legal involvement such as a complaint made before civil officials an arrest warrant an examination or court record. Accused witches were almost always detained in jail to await further action by a grand jury which had the authority to indict and hold the accused for trial. Trials by a special Court of Oyer and Terminer began in June 1692. In October 1692 this court was discontinued due to mounting criticism of its methods. It was replaced by another court the Superior Court of Judicature which held trials from January to May 1693. The ""Accused Witch"" column records the names of the 152 people mentioned in legal records as having been formally accused of witchcraft. Their names are alphabetically arranged. Spelling generally follows that of Paul Boyer and Stephen Nissenbaum Salem Witchcraft Papers but has been sometimes changed in accordance with the newer Records of the Salem Witch-Hunt and other sources. ""Residence"" identifies the community in which the accused person was living when accused of witchcraft. In a few cases the residence of an accused witch is problematic. For Elizabeth How for example some records cite Ipswich while others name Topsfield as her home. In such cases the most likely residence has been used. In a few instances the residence entry does not reflect the actual geographic relationship of the accused with the trials. George Burroughs was living in Wells Maine in 1692 but he had been a controversial minister in Salem Village in the early 1680s. ""Month of Accusation"" numerically expresses the month of the year in which an alleged witch was accused ""1""=January 1692; ""6""=June 1692; and ""13""=January 1693. A negative 1 (-1) indicates that the actual month of accusation is not known with sufficient certainty to be included. Some of these ""unknowns"" can be approximated from available records and users may choose to substitute their estimate. Users should also recognize an artificial quality to this data those accused in one month May (5) for example may have been charged only a day or two before someone in June (6). ""Month of Execution"" numerically expresses the month in which an alleged witch was executed as a result of the legal process. The data do not include entries for those who died as a result of their incarceration. In one case Giles Corey the month of execution does record the month in which he was pressed to death for refusing to plead to the charges against him. The Towns Data Set provides a convenient way to construct histograms of the communities whose residents were charged with witchcraft in 1692. It contains 25 columns Twenty-four columns record each town for which at least one formal accusation occurred (Salem Village and Salem Town are listed separately). Each cell lists the month of an accusation numerically expressed 1=January 1692 2=February 1692 and so forth.  The negative number -1 indicates that the month of accusation is unknown. A ""Bin"" column contains the range of months of witchcraft accusations from 1 (January 1692) to 12 (December 1692) with -1 for unknown months of accusation. Both the Pro-Parris and Anti-Parris data sets contain the same four columns ""Name"" identifies each signer of the pro-Parris petition. ""Identification"" indicates the category in the petition under which the signer was placed. ""Sex"" indicates whether the signer was male or female. ""Sort"" locates each signer in the data set so that it can be returned to its original order. To compare the social make-up of Salem Village's pro- and anti-Parris factions to the village's general population download the Salem Village Data Set. The data set contains four columns ""Name"" lists every person in Salem Village who appeared on any village tax assessments for 1690 1695 and 1697. The 137 names are a good though imperfect indicator of the village's adult male population in the period of the witch hunt. Only a few women all widows appear. Young men not yet independent or paying taxes do not appear. ""Petition"" notes whether the taxpayer signed either the pro- or anti-Parris petition in 1695. ""NoS"" (no signature) means that the person did not sign either petition. ""Church to 1696"" indicates whether a person was a church member though 1696. No distinction is made as to whether a person was a member of the Salem Village church or another church.  The list is compiled from the pro- and anti-Parris petitions as well as from the records of the Salem Village church as recorded by Samuel Parris.  Additional information came from the published records of the First Church in Salem Town. ""Sort"" permits data to be easily restored to their original order after a statistical manipulation. The Committee Yearly Data Set contains information about Salem Village's committees from 1685 to 1698 a period that covers the last years Deodat Lawson's ministry and the entire tenure of Samuel Parris. The data set contains three columns of information for each committee ""Committee"" lists the names of committeemen for a particular year (in 1688 only four men were elected). ""Petition"" indicates whether the committeeman signed either the pro- or anti-Parris petition in 1695. ""NoS"" (no signature) means that this committeeman did not sign either petition. Signing a petition strongly suggests but does not conclusively establish a petitioner's earlier position regarding Parris or the witchcraft outbreak. ""Social"" indicates whether the committeeman was a church member or a householder.  Three committeemen (William Sibley James Smith and Jacob Fuller) have been listed as householders in the absence of information linking them to a church.) The Committee List Data Set provides information about all Salem Village committee members who held office from 1685 to 1698. The data set contains 18 columns ""Committee Members"" records the names of the thirty-one villagers who held committee office from 1685-1698. They are listed in the order in which they first appeared in the village's Book of Record. ""Petition"" notes whether the committeeman signed either the pro- or anti-Parris petition in 1695. ""NoS"" (no signature) means that this committeeman did not sign either petition. ""Social"" indicates whether the committeeman was a church member or a householder.  (Three committeemen William Sibley James Smith and Jacob Fuller have been listed as householders in the absence of information linking them to a church; the three did not sign either petition.) Columns 4-17 indicate committee membership for each year. ""Sort"" permits data to be easily restored to their original order. The Tax Comparison Data Set was compiled by listing all Salem Village taxpayers who were assessed rates in the period between 1681 and 1700. The rates are recorded in Salem Village's Book of Record (see Bibliography). ""Name"" lists in alphabetical order all assessments on Salem Village's tax lists for 1681 1690 1694 1695 1697 and 1700. ""Tax"" records the taxpayer's assessment in shillings. Since the village's revenue needs changed the total assessment (and individual allocations) changed accordingly. ""Petition"" indicates whether the taxpayer signed either the pro- or anti-Parris petition in 1695. ""NoS"" (no signature) means that this taxpayer did not sign either petition. ""Sort"" permits data to be easily restored to their original order after a statistical manipulation.  Acknowledgements Users who copy share adapt and re-publish any of the content in Salem Witchcraft Dataset should credit Professor Richard Latner of Tulane University for making this material available. More information and guided exercises can be found on this website. Inspiration  What was the relationship between economic success and support for Parris? Can you split the list of accused witches and predict who would be accused based on other acquisitions? ",Accused Witch: Residence :Month of Accusation:Month of Execution:Sort:,string:string:numeric:string:numeric:,
Fortune 500 Diversity , Fortune , www.kaggle.com/fortune-inc/f500-diversity , Mon Jun 26 2017 23:11:37 GMT+0530 (IST) , Detailed diversity metrics for the Fortune 500 companies ,181, demographics- ,Context Workforce diversity is an increasingly salient issue but it can be difficult to easily check how a specific company is performing. This dataset was created by Fortune to show what was discoverable by someone considering employment with one of the Fortune 500 firms and curious about their commitment to diversity and inclusion could find. Content This dataset contains the name of each firm its rank in the 2017 Fortune 500 a link to its diversity and inclusion page or equal opportunity statement and whether the company releases full partial or no data about the gender race and ethnicity of its employees. Additional detail is included where it was available. As there are over 200 fields in this dataset; please consult the data dictionary for details about specific features. Acknowledgements This dataset was assembled by Fortune.com data reporter Grace Donnelly. The details of her data preparation process can be found here. Inspiration Are the companies that release the most information more or less diverse than their peers? Are there any particular industries that stand out?,f500-2017-rank:name:data-avail:data-url:diversity-pg-url:data-year:PAYROLL_START:PAYROLL_END:HISPM1:HISPM1_2:HISPM2:HISPM3:HISPM4:HISPM5:HISPM6:HISPM7:HISPM8:HISPM9:HISPM10:HISPM11:HISPF1:HISPF1_2:HISPF2:HISPF3:HISPF4:HISPF5:HISPF6:HISPF7:HISPF8:HISPF9:HISPF10:HISPF11:WHM1:WHM1_2:WHM2:WHM3:WHM4:WHM5:WHM6:WHM7:WHM8:WHM9:WHM10:WHM11:BLKM1:BLKM1_2:BLKM2:BLKM3:BLKM4:BLKM5:BLKM6:BLKM7:BLKM8:BLKM9:BLKM10:BLKM11:NHOPIM1:NHOPIM1_2:NHOPIM2:NHOPIM3:NHOPIM4:NHOPIM5:NHOPIM6:NHOPIM7:NHOPIM8:NHOPIM9:NHOPIM10:NHOPIM11:ASIANM1:ASIANM1_2:ASIANM2:ASIANM3:ASIANM4:ASIANM5:ASIANM6:ASIANM7:ASIANM8:ASIANM9:ASIANM10:ASIANM11:AIANM1:AIANM1_2:AIANM2:AIANM3:AIANM4:AIANM5:AIANM6:AIANM7:AIANM8:AIANM9:AIANM10:AIANM11:TOMRM1:TOMRM1_2:TOMRM2:TOMRM3:TOMRM4:TOMRM5:TOMRM6:TOMRM7:TOMRM8:TOMRM9:TOMRM10:TOMRM11:WHF1:WHF1_2:WHF2:WHF3:WHF4:WHF5:WHF6:WHF7:WHF8:WHF9:WHF10:WHF11:BLKF1:BLKF1_2:BLKF2:BLKF3:BLKF4:BLKF5:BLKF6:BLKF7:BLKF8:BLKF9:BLKF10:BLKF11:NHOPIF1:NHOPIF1_2:NHOPIF2:NHOPIF3:NHOPIF4:NHOPIF5:NHOPIF6:NHOPIF7:NHOPIF8:NHOPIF9:NHOPIF10:NHOPIF11:ASIANF1:ASIANF1_2:ASIANF2:ASIANF3:ASIANF4:ASIANF5:ASIANF6:ASIANF7:ASIANF8:ASIANF9:ASIANF10:ASIANF11:AIANF1:AIANF1_2:AIANF2:AIANF3:AIANF4:AIANF5:AIANF6:AIANF7:AIANF8:AIANF9:AIANF10:AIANF11:TOMRF1:TOMRF1_2:TOMRF2:TOMRF3:TOMRF4:TOMRF5:TOMRF6:TOMRF7:TOMRF8:TOMRF9:TOMRF10:TOMRF11:FT1:FT1_2:FT2:FT3:FT4:FT5:FT6:FT7:FT8:FT9:FT10:FT11:MT1:MT1_2:MT2:MT3:MT4:MT5:MT6:MT7:MT8:MT9:MT10:MT11:TOTAL1:TOTAL1_2:TOTAL2:TOTAL3:TOTAL4:TOTAL5:TOTAL6:TOTAL7:TOTAL8:TOTAL9:TOTAL10:TOTAL11:,numeric:string:string:string:string:numeric:dateTime:dateTime:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
2016 Global Ecological Footprint , Global Footprint Network , www.kaggle.com/footprintnetwork/ecological-footprint , Thu Mar 02 2017 20:30:03 GMT+0530 (IST) , Does your country consume more resources than it produces in a year? ,465, ecology- ,Context The ecological footprint measures the ecological assets that a given population requires to produce the natural resources it consumes (including plant-based food and fiber products livestock and fish products timber and other forest products space for urban infrastructure) and to absorb its waste especially carbon emissions. The footprint tracks the use of six categories of productive surface areas cropland grazing land fishing grounds built-up (or urban) land forest area and carbon demand on land. A nation’s biocapacity represents the productivity of its ecological assets including cropland grazing land forest land fishing grounds and built-up land. These areas especially if left unharvested can also absorb much of the waste we generate especially our carbon emissions. Both the ecological footprint and biocapacity are expressed in global hectares — globally comparable standardized hectares with world average productivity. If a population’s ecological footprint exceeds the region’s biocapacity that region runs an ecological deficit. Its demand for the goods and services that its land and seas can provide — fruits and vegetables meat fish wood cotton for clothing and carbon dioxide absorption — exceeds what the region’s ecosystems can renew. A region in ecological deficit meets demand by importing liquidating its own ecological assets (such as overfishing) and/or emitting carbon dioxide into the atmosphere. If a region’s biocapacity exceeds its ecological footprint it has an ecological reserve. Acknowledgements The ecological footprint measure was conceived by Mathis Wackernagel and William Rees at the University of British Columbia. Ecological footprint data was provided by the Global Footprint Network. Inspiration Is your country running an ecological deficit consuming more resources than it can produce per year? Which countries have the greatest ecological deficits or reserves? Do they consume less or produce more than the average country? When will Earth Overshoot Day the day on the calendar when humanity has used one year of natural resources occur in 2017?,Country:Region:Population (millions):HDI:GDP per Capita:Cropland Footprint:Grazing Footprint:Forest Footprint:Carbon Footprint:Fish Footprint:Total Ecological Footprint:Cropland:Grazing Land:Forest Land:Fishing Water:Urban Land:Total Biocapacity:Biocapacity Deficit or Reserve:Earths Required:Countries Required:Data Quality:,string:string:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Douban Movie Short Comments Dataset , utmhikari , www.kaggle.com/utmhikari/doubanmovieshortcomments , Mon Mar 06 2017 15:09:06 GMT+0530 (IST) , DMSCD producted by utmhikari ,352, film- internet- ,"Douban Movie Short Comments Dataset V2 Introduction Douban Movie is a Chinese website that allows Internet users to share their comments and viewpoints about movies. Users are able to post short or long comments on movies and give them marks. This dataset contains more than 2 million short comments of 28 movies in Douban Movie website. It can be used on text classification text clustering sentiment analysis semantic web construction and some other fields that relate to web mining or NLP (of Chinese lol). Metadata ID the ID of the comment (start from 0)  Movie_Name_EN the English name of the movie  Movie_Name_CN the Chinese name of the movie  Crawl_Date the date that the data are crawled  Number the number of the comment  Username the username of the account  Date the date that the comment posted  Star the star that users give to the movie (from 1 to 5 5 grades)  Comment the content of the comment  Like the count of ""like"" on the comment ",ID:Movie_Name_EN:Movie_Name_CN:Crawl_Date:Number:Username:Date:Star:Comment:Like:,numeric:string:string:dateTime:numeric:string:dateTime:numeric:string:numeric:,
Social Power NBA , Noah Gift , www.kaggle.com/noahgift/social-power-nba , Tue Aug 01 2017 08:09:55 GMT+0530 (IST) , NBA on the court performance with Social Influence Popularity and Power ,219, basketball- social groups- ,Context This data set compares on the court performance in the NBA during the 2016-2017 Season with Salary Twitter engagement and Wikipedia Traffic Further information can be found in this series of articles for IBM Developerworks https//www.ibm.com/developerworks/library/ba-social-influence-python-pandas-machine-learning-r-1/ https//www.ibm.com/developerworks/analytics/library/ba-social-influence-python-pandas-machine-learning-r-2/ Python and R Source Code can be found here at Github  https//github.com/noahgift/socialpowernba Links to more writing can be found at noahgift.com  http//noahgift.com Content NBA 2016-2017 Stats Salary Endorsements Twitter Median Engagement Wikipedia Median Daily Pageviews and advanced stats like ELO and RPM. Acknowledgements ESPN Basketball-Reference Twitter Five-ThirtyEight Wikipedia Inspiration Do NBA fans know more about who the best players are or do Owners?  What is the true worth of the social media presence of athletes in the NBA? Example Visualizations    ,PLAYER_ID:PLAYER_NAME:TEAM_ID:TEAM_ABBREVIATION:AGE:GP:W:L:W_PCT:MIN:OFF_RATING:DEF_RATING:NET_RATING:AST_PCT:AST_TO:AST_RATIO:OREB_PCT:DREB_PCT:REB_PCT:TM_TOV_PCT:EFG_PCT:TS_PCT:USG_PCT:PACE:PIE:FGM:FGA:FGM_PG:FGA_PG:FG_PCT:GP_RANK:W_RANK:L_RANK:W_PCT_RANK:MIN_RANK:OFF_RATING_RANK:DEF_RATING_RANK:NET_RATING_RANK:AST_PCT_RANK:AST_TO_RANK:AST_RATIO_RANK:OREB_PCT_RANK:DREB_PCT_RANK:REB_PCT_RANK:TM_TOV_PCT_RANK:EFG_PCT_RANK:TS_PCT_RANK:USG_PCT_RANK:PACE_RANK:PIE_RANK:FGM_RANK:FGA_RANK:FGM_PG_RANK:FGA_PG_RANK:FG_PCT_RANK:CFID:CFPARAMS:WIKIPEDIA_HANDLE:TWITTER_HANDLE:SALARY_MILLIONS:PTS:ACTIVE_TWITTER_LAST_YEAR:TWITTER_FOLLOWER_COUNT_MILLIONS:,numeric:string:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:,
Uniqlo (FastRetailing) Stock Price Prediction , Daisuke Ishii , www.kaggle.com/daiearth22/uniqlo-fastretailing-stock-price-prediction , Mon Aug 07 2017 10:24:01 GMT+0530 (IST) , Tokyo Stock Exchange Data (LightWeight CSV) in 2016 for Beginners ,181, time series- finance- ,"Context We are doing Fintech data hakathon in Tokyo everyweek. Let's predict stock price in Tokyo Stock Exchange. 毎週水曜日東京・渋谷で開催している、Team AI ""FinTech Data Hackathon""の題材として、 身近なユニクロ(ファーストリテイリング)の株価予測モデルをオープンイノベーションで構築します。 https//www.meetup.com/Machine-Learning-Meetup-by-team-ai/events/242154425/ Content Training; 5 year daily stock price info of FastRetailing(Uniqlo). You should predict ""close"" price. Test 1 week daily stock price Acknowledgements Thanks to open market data http//k-db.com/ Inspiration Let's build basic stock prediction model together!  公開されたモデルを実際の取引に使う場合は十分注意ください。弊社側やコミュニティメンバー側では損失の責任は持てません。",Date:Open:High:Low:Close:Volume:Stock Trading:,dateTime:numeric:numeric:numeric:numeric:numeric:numeric:,
Fantasy Premier League - 2017/18 , Thomas , www.kaggle.com/thomasd9/fantasy-premier-league-201718 , Mon Aug 14 2017 00:14:44 GMT+0530 (IST) , Data for the 2017/18 season of the Fantasy Premier League ,135, association football- ,Context The Fantasy Premier League has become more popular every year. In the FPL people pick fantasy teams of real-life players and every week receive points based on their picks' real-life performance. Within this dataset we have some historical data for the player performance in previous seasons as well as future match fixtures. Content The three main components currently in this dataset are  The individual players' current performance stats. The individual players' past performance stats (how much historical data depends on the player). A list of future match fixtures.  All the data was taken from the Official Fantasy Premier League website. N.B. A lot of the data was cobbled together from the output of publicly accessible JSON endpoints therefore there are a lot of duplications (as fixture data was initially from the perspective of the individual players). Also since a lot of this data is used to drive the UI of a Web Application there are a lot of redundancies all of which could do with being cleaned up. Inspiration A lot of my friends are massively into all aspects of the Premier League (fantasy or otherwise) so my main motivation in putting this dataset together was to see was it possible to gain a competitive advantage over my very domain knowledgeable friends with little to no domain knowledge myself. The obvious questions that could be answered with this data correspond to predicting the future performance of players based on historical metrics.,game_week:event_name:home_team_id:home_team_name:home_team_short_name:away_team_id:away_team_name:away_team_short_name:,numeric:string:numeric:string:string:numeric:string:string:,
How ISIS Uses Twitter , Fifth Tribe , www.kaggle.com/fifthtribe/how-isis-uses-twitter , Wed May 18 2016 05:23:32 GMT+0530 (IST) , Analyze how ISIS fanboys have been using Twitter since 2015 Paris Attacks ,4510, crime- twitter- internet- ,"We scraped over 17000 tweets from 100+ pro-ISIS fanboys from all over the world since the November 2015 Paris Attacks. We are working with content producers and influencers to develop effective counter-messaging measures against violent extremists at home and abroad. In order to maximize our impact we need assistance in quickly analyzing message frames.  The dataset includes the following  Name Username Description Location Number of followers at the time the tweet was downloaded Number of statuses by the user when the tweet was downloaded Date and timestamp of the tweet The tweet itself  Based on this data here are some useful ways of deriving insights and analysis   Social Network Cluster Analysis Who are the major players in the pro-ISIS twitter network? Ideally we would like this visualized via a cluster network with the biggest influencers scaled larger than smaller influencers.  Keyword Analysis Which keywords derived from the name username description location and tweets were the most commonly used by ISIS fanboys? Examples include ""baqiyah"" ""dabiq"" ""wilayat"" ""amaq"" Data Categorization of Links Which websites are pro-ISIS fanboys linking to? Categories include Mainstream Media Altermedia Jihadist Websites Image Upload Video Upload  Sentiment Analysis Which clergy do pro-ISIS fanboys quote the most and which ones do they hate the most? Search the tweets for names of prominent clergy and classify the tweet as positive negative or neutral and if negative include the reasons why.  Examples of clergy they like the most ""Anwar Awlaki"" ""Ahmad Jibril"" ""Ibn Taymiyyah"" ""Abdul Wahhab"". Examples of clergy that they hate the most ""Hamza Yusuf"" ""Suhaib Webb"" ""Yaser Qadhi"" ""Nouman Ali Khan"" ""Yaqoubi"".  Timeline View Visualize all the tweets over a timeline and identify peak moments  Further Reading ""ISIS Has a Twitter Strategy and It is Terrifying [Infographic]"" About Fifth Tribe Fifth Tribe is a digital agency based out of DC that serves businesses non-profits and government agencies. We provide our clients with product development branding web/mobile development and digital marketing services. Our client list includes Oxfam Ernst and Young Kaiser Permanente Aetna Innovation Health the U.S. Air Force and the U.S. Peace Corps. Along with Goldman Sachs International and IBM we serve on the Private Sector Committee of the Board of the Global Community Engagement and Resilience Fund (GCERF) the first global effort to support local community-level initiatives aimed at strengthening resilience against violent extremism. In December 2014 we won the anti-ISIS ""Hedaya Hack"" organized by Affinis Labs and hosted at the ""Global Countering Violent Extremism (CVE) Expo "" in Abu Dhabi. Since then we've been actively involved in working with the open-source community and community content producers in developing counter-messaging campaigns and tools. ",,,
SF Street Trees , Jacob Boysen , www.kaggle.com/jboysen/sf-street-trees , Fri Sep 01 2017 22:07:31 GMT+0530 (IST) , 188k Street Trees Around SF ,31, geography- nature- climate- civil engineering- ,Context Prop. E was a measure on the November 8 2016 San Francisco ballot regarding responsibility for maintaining street trees and surrounding sidewalks. Voters were asked if the City should amend the City Charter to transfer responsibility from property owners to the City for maintaining trees on sidewalks adjacent to their property as well for repairing sidewalks damaged by the trees. Prop E passed with almost 80% of the voters’ support. As part of this proposition a SF tree census was conducted by SF Public Works. Content 18 columns of data includes address (including lat/longs) caretaker details legal details size of plot time of planting surrounding site context and species. Acknowledgements This data was collected by SF Public Works. You can use Kernels to analyze share and discuss this data on Kaggle but if you’re looking for real-time updates and bigger data check out the data on BigQuery too. Inspiration  SF is notorious for it’s microclimates--can you identify zones from particular trees that thrive there? Combine this data with the NYC Tree Census--which species are most common? least? ,address:care_assistant:care_taker:dbh:latitude:legal_status:location:longitude:permit_notes:plant_date:plant_type:plot_size:site_info:site_order:species:tree_id:x_coordinate:y_coordinate:,string:string:string:numeric:numeric:string:string:numeric:string:dateTime:string:string:string:numeric:string:numeric:numeric:numeric:,
Midas Project ," Marcell ""Mazuh"" Guilherme Costa da Silva ", www.kaggle.com/mazuh69/midas-project , Tue Sep 05 2017 13:38:27 GMT+0530 (IST) , Federal colleges expenses (RN BR) ,14, universities and colleges- brazil- education- politics- economics- ,"Context Scraped data from our local federal colleges UFRN and IFRN mostly about their expenses. Soon there will be data about any other federal college.  This project (without the datasets only scripts) is available on GitHub https//github.com/mazuh/midas  Content At first there will be only data about all IFRN's workers their contractual profile and positions. Soon there will be data about their salary and remunerations. Acknowledgements Here in Brazil since 2011 the law 12.527/2011 specifies the constitutional right of every citizen to know better the public expenses. Therefore this project is entirely legal and isn't ""leaking"" anything.  Inspiration My first question about this dataset is to check remuneration profiles of our teachers. They often complain about their salary and college budget.",index:name:cpf:campus:class:situationBond:organizationalUnit:hasTrustPosition:employeeSince:urlRemunerationSufix:,numeric:string:string:string:string:string:string:boolean:dateTime:string:,
New York City - Certificates of Occupancy , City of New York , www.kaggle.com/new-york-city/nyc-certificates-of-occupancy , Fri Sep 01 2017 20:54:34 GMT+0530 (IST) , New and newly reconstructed buildings in New York City. ,27, cities- civil engineering- ,Context The City of New York issues Certificates of Occupancy to newly constructed (and newly reconstructed e.g. “gut renovated”) buildings in New York City. These documents assert that the city has deemed the building habitable and safe to move into. Content This dataset includes all temporary (expirable) and final (permanent) Certificates of Occupancies issues to newly habitable buildings in New York City split between new (Job Type NB) and reconstructed (Job Type A1) buildings issued between July 12 2012 and August 29 2017. Acknowledgements This data is published as-is by the New York City Department of Buildings. Inspiration  In what areas of New York City are the newly constructed buildings concentrated? What is the difference in distribution between buildings that are newly built and ones that are newly rebuilt? In combination with the New York City Buildings Database dataset what are notable differences in physical characteristics between recently constructed buildings and existing ones? ,JOB_NUMBER:JOB_TYPE:C_O_ISSUE_DATE:BIN_NUMBER:BOROUGH:NUMBER:STREET:BLOCK:LOT:POSTCODE:PR_DWELLING_UNIT:EX_DWELLING_UNIT:APPLICATION_STATUS_RAW:FILING_STATUS_RAW:ITEM_NUMBER:ISSUE_TYPE:LATITUDE:LONGITUDE:COMMUNITY_BOARD:COUNCIL_DISTRICT:CENSUS_TRACT:BIN:BBL:NTA:LOCATION:,numeric:string:dateTime:numeric:string:numeric:string:numeric:numeric:numeric:numeric:numeric:string:string:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:,
Question-Answer Jokes , Jiri Roznovjak , www.kaggle.com/jiriroz/qa-jokes , Fri Jan 06 2017 01:22:43 GMT+0530 (IST) , Jokes of the question-answer form from Reddit's r/jokes ,660, humor- linguistics- ,"This dataset contains 38269 jokes of the question-answer form obtained from the r/Jokes subreddit. The dataset contains a csv file where a row contains a question  (""Why did the chicken cross the road"") the corresponding answer (""To get to the other side"") and a unique ID. The data comes from the end of 2016 all the way to 2008. The entries with a higher ID correspond to the ones submitted earlier. An example of what one might do with the data is build a sequence-to-sequence model where the input is a question and the output is an answer. Then given a question the model should generate a funny answer. This is what I did as the final project for my fall 2016 machine learning class. The project page can be viewed here. Disclaimer The dataset contains jokes that some may find inappropriate. License Released under reddit's API terms",ID:Question:Answer:,numeric:string:string:,
Short Jokes , Abhinav Moudgil , www.kaggle.com/abhinavmoudgil95/short-jokes , Tue Feb 07 2017 03:22:21 GMT+0530 (IST) , Collection of over 200000 short jokes for humour research ,538, humor- linguistics- ,Context Generating humor is a complex task in the domain of machine learning and it requires the models to understand the deep semantic meaning of a joke in order to generate new ones. Such problems however are difficult to solve due to a number of reasons one of which is the lack of a database that gives an elaborate list of jokes. Thus a large corpus of over 0.2 million jokes has been collected by scraping several websites containing funny and short jokes. Visit my Github repository for more information regarding collection of data and the scripts used.  Content This dataset is in the form of a csv file containing 231657 jokes. Length of jokes ranges from 10 to 200 characters. Each line in the file contains a unique ID and joke.  Disclaimer It has been attempted to keep the jokes as clean as possible. Since the data has been collected by scraping websites it is possible that there may be a few jokes that are inappropriate or offensive to some people.,ID:Joke:,numeric:string:,
NBA Players Stats - 2014-2015 , DrGuillermo , www.kaggle.com/drgilermo/nba-players-stats-20142015 , Wed May 03 2017 23:16:24 GMT+0530 (IST) , Points Assists Height Weight and other personal details and stats ,594, basketball- ,Context This data set can be paired with the shot logs data set from the same season. Content Full players stats from the 2014-2015 season + personal details such as height. weight etc. The data was scraped and copied from http//www.basketball-reference.com/teams/ and  http//stats.nba.com/leaders#!?Season=2014-15&SeasonType=Regular%20Season&StatCategory=MIN&CF=MIN*G*2&PerMode=Totals,Name:Games Played:MIN:PTS:FGM:FGA:FG%:3PM:3PA:3P%:FTM:FTA:FT%:OREB:DREB:REB:AST:STL:BLK:TOV:PF:EFF:AST/TOV:STL/TOV:Age:Birth_Place:Birthdate:Collage:Experience:Height:Pos:Team:Weight:BMI:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:dateTime:string:numeric:numeric:string:string:numeric:numeric:,
Top 100 Global Steel Producers (2011-2016) , David Rubal , www.kaggle.com/drubal/top-100-global-steel-producers-20112016 , Thu Aug 17 2017 20:38:23 GMT+0530 (IST) , Steel is being produced on a global level in places that might surprise you ,66, ,Context The production of steel has shifted from a just few primary countries to many countries all over the world. This dataset provides statistics and insight into the locations and volumes of steel production for years 2011-2016 with specific ranking in 2015 and 2016. Acknowledgements The data source is worldsteel Association. www.worldsteel.org Inspiration Some questions are trends predictive analytics/forecasting/consolidation possibilities and global supply chain. While the steel industry is 'flat' where steel is produced and shipped globally. There may an opportunity for a new model where steel is increasingly produced locally to save shipping and logistics costs.,Companies:Headquarters:2011 Tonnage (Millions):2012 Tonnage (Millions):2013 Tonnage (Millions):2014 Tonnage (Millions):2015 Tonnage (Millions):2016 Tonnage (Millions):2015 Ranking:2016 Ranking:,string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Austin Waste and Diversion , Jacob Boysen , www.kaggle.com/jboysen/austin-waste , Sat Aug 26 2017 00:36:53 GMT+0530 (IST) , Garbage In Garbage Out ,46, government agencies- ,Context This dataset is trash. Who in Austin makes it who takes it and where does it go? Content Data ranges 2008-2016 and includes dropoff site load id time of load type of load weight of load date route number and route type (recycling street cleaning garbage etc). Acknowledgements This dataset was created by Austin city government and hosted on Google Cloud Platform. You can use Kernels to analyze share and discuss this data on Kaggle but if you’re looking for real-time updates and bigger data check out the data on BigQuery too Inspiration  How much trash is Austin generating? Which are the trashiest routes? Who recycles the best? Any seasonal changes? Try to predict trash route usage from historical trash data ,dropoff_site:load_id:load_time:load_type:load_weight:report_date:route_number:route_type:,string:numeric:dateTime:string:numeric:dateTime:string:string:,
New York City Crimes , Adam Schroeder , www.kaggle.com/adamschroeder/crimes-new-york-city , Fri Aug 11 2017 10:24:29 GMT+0530 (IST) , 2014-2015 Crimes reported in all 5 boroughs of New York City ,195, crime- ,"Context With this dataset I hope to raise awareness on the trends in crime. Content For NYPD Complaint Data each row represents a crime. For information on the columns please see the attached csv ""Crime_Column_Description"". Reported crime go back 5 years but I only attached reported crime from 2014-2015 due to file size. The full report can be found at NYC Open Data (https//data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Historic/qgea-i56i) Acknowledgements I would like to thank NYC Open Data for the dataset. Inspiration Additional things I would like to better understand 1.  Differences in crime that exist between the 5 boroughs 2. A mapping of the crimes per borough 3. Where do the most dangerous crimes happen and what time?",Column:Description:,string:string:,
The ExtraSensory Dataset , Yonatan Vaizman , www.kaggle.com/yvaizman/the-extrasensory-dataset , Wed Jun 07 2017 04:21:07 GMT+0530 (IST) , Behavioral Context Recognition In-the-Wild ,117, psychology- ,"Context Behavioral Context refers to a wide range of attributes describing what is going on with you where you are (home school work at the beach at a restaurant) what you are doing (sleeping eating in a meeting computer work exercising shower) who you are with (family friends co-workers) your body posture state (sitting standing walking running) and so on. The ability to automatically (effortlessly frequently objectively) recognize behavioral context can serve many domains. Medical applications can monitor physical activity or eating habits; aging-at-home programs can log older adults' physical social and mental behavior; personal assistant systems can better server the user if they are aware of the context. In-the-wild (in real life) natural behavior is complex composed of different aspects and has high variability. You can run outside at the beach with friends with your phone in the pocket; you can also run indoors at the gym on a treadmill with your phone motionless next to you. This high variability makes context-recognition a hard task to perform in-the-wild. Content The ExtraSensory Dataset was collected from 60 participants where each person participated approximately 7 days. We installed our data-collection mobile app on their personal phone and it was used to collect both sensor-measurements and context-labels. The sensor-measurements were recorded automatically for a window of 20-seconds every minute. This included accelerometer gyroscope magnetometer audio location and phone-state from the person's phone as well as accelerometer and compass from an additional smartwatch that we provided. In addition the app's interface had many mechanisms for self-reporting the relevant context-labels including reporting past context near future responding to notifications and more. The flexible interface allowed to collect many labels with minimal effort and interaction-time to avoid interfering with the natural behavior. The data was collected in-the-wild participants used their phone in any way that was convenient to them they engaged in their regular behavior and reported an combinations of labels that fit their context. For every participant (or ""user"") the dataset has a CSV file with pre-computed features that we extracted from the sensors and with labels.  Each row has a separate example (representing 1 minute) and is indexed by the timestamp (seconds since the epoch). There are columns for the sensor-features with the prefix of the column name indicating the sensor it came from (e.g. prefix ""raw_acc"" indicating a feature came from the raw phone accelerometer measurements). There are columns for 51 diverse context-labels and the value for an example-label pair is either 1 (the label is relevant for the example) 0 (the label is not relevant) or 'NaN' (missing information). Here we provide data for 2 of the 60 participants. You can use this partial data to get familiar with the data and practice algorithms. The full dataset is publicly available at http//extrasensory.ucsd.edu. The website has additional parts of the data (such as a wider range of the original reported labels location coordinates mood labels from part of the participants). If you use the data for your publications you are required to cite our original paper Vaizman Y. Ellis K. and Lanckriet G. ""Recognizing Detailed Human Context In-the-Wild from Smartphones and Smartwatches"". IEEE Pervasive Computing vol. 16 no. 4 October-December 2017 pp. 62-74. Read the information at http//extrasensory.ucsd.edu and the original paper for more details. Acknowledgements The dataset was collected by Yonatan Vaizman and Katherine Ellis under the supervision of prof. Gert Lanckriet all from the department of Electrical and Computer Engineering University of California San Diego. Inspiration The ExtraSensory Dataset can serve as a benchmark to compare methods for context-recognition (or context-awareness activity recognition daily activity detection). You can focus on specific sensors or on specific context-labels. You can suggest new models and classifiers train them on the data and evaluate their performance on the data.",timestamp:raw_acc:magnitude_stats:mean:raw_acc:magnitude_stats:std:raw_acc:magnitude_stats:moment3:raw_acc:magnitude_stats:moment4:raw_acc:magnitude_stats:percentile25:raw_acc:magnitude_stats:percentile50:raw_acc:magnitude_stats:percentile75:raw_acc:magnitude_stats:value_entropy:raw_acc:magnitude_stats:time_entropy:raw_acc:magnitude_spectrum:log_energy_band0:raw_acc:magnitude_spectrum:log_energy_band1:raw_acc:magnitude_spectrum:log_energy_band2:raw_acc:magnitude_spectrum:log_energy_band3:raw_acc:magnitude_spectrum:log_energy_band4:raw_acc:magnitude_spectrum:spectral_entropy:raw_acc:magnitude_autocorrelation:period:raw_acc:magnitude_autocorrelation:normalized_ac:raw_acc:3d:mean_x:raw_acc:3d:mean_y:raw_acc:3d:mean_z:raw_acc:3d:std_x:raw_acc:3d:std_y:raw_acc:3d:std_z:raw_acc:3d:ro_xy:raw_acc:3d:ro_xz:raw_acc:3d:ro_yz:proc_gyro:magnitude_stats:mean:proc_gyro:magnitude_stats:std:proc_gyro:magnitude_stats:moment3:proc_gyro:magnitude_stats:moment4:proc_gyro:magnitude_stats:percentile25:proc_gyro:magnitude_stats:percentile50:proc_gyro:magnitude_stats:percentile75:proc_gyro:magnitude_stats:value_entropy:proc_gyro:magnitude_stats:time_entropy:proc_gyro:magnitude_spectrum:log_energy_band0:proc_gyro:magnitude_spectrum:log_energy_band1:proc_gyro:magnitude_spectrum:log_energy_band2:proc_gyro:magnitude_spectrum:log_energy_band3:proc_gyro:magnitude_spectrum:log_energy_band4:proc_gyro:magnitude_spectrum:spectral_entropy:proc_gyro:magnitude_autocorrelation:period:proc_gyro:magnitude_autocorrelation:normalized_ac:proc_gyro:3d:mean_x:proc_gyro:3d:mean_y:proc_gyro:3d:mean_z:proc_gyro:3d:std_x:proc_gyro:3d:std_y:proc_gyro:3d:std_z:proc_gyro:3d:ro_xy:proc_gyro:3d:ro_xz:proc_gyro:3d:ro_yz:raw_magnet:magnitude_stats:mean:raw_magnet:magnitude_stats:std:raw_magnet:magnitude_stats:moment3:raw_magnet:magnitude_stats:moment4:raw_magnet:magnitude_stats:percentile25:raw_magnet:magnitude_stats:percentile50:raw_magnet:magnitude_stats:percentile75:raw_magnet:magnitude_stats:value_entropy:raw_magnet:magnitude_stats:time_entropy:raw_magnet:magnitude_spectrum:log_energy_band0:raw_magnet:magnitude_spectrum:log_energy_band1:raw_magnet:magnitude_spectrum:log_energy_band2:raw_magnet:magnitude_spectrum:log_energy_band3:raw_magnet:magnitude_spectrum:log_energy_band4:raw_magnet:magnitude_spectrum:spectral_entropy:raw_magnet:magnitude_autocorrelation:period:raw_magnet:magnitude_autocorrelation:normalized_ac:raw_magnet:3d:mean_x:raw_magnet:3d:mean_y:raw_magnet:3d:mean_z:raw_magnet:3d:std_x:raw_magnet:3d:std_y:raw_magnet:3d:std_z:raw_magnet:3d:ro_xy:raw_magnet:3d:ro_xz:raw_magnet:3d:ro_yz:raw_magnet:avr_cosine_similarity_lag_range0:raw_magnet:avr_cosine_similarity_lag_range1:raw_magnet:avr_cosine_similarity_lag_range2:raw_magnet:avr_cosine_similarity_lag_range3:raw_magnet:avr_cosine_similarity_lag_range4:watch_acceleration:magnitude_stats:mean:watch_acceleration:magnitude_stats:std:watch_acceleration:magnitude_stats:moment3:watch_acceleration:magnitude_stats:moment4:watch_acceleration:magnitude_stats:percentile25:watch_acceleration:magnitude_stats:percentile50:watch_acceleration:magnitude_stats:percentile75:watch_acceleration:magnitude_stats:value_entropy:watch_acceleration:magnitude_stats:time_entropy:watch_acceleration:magnitude_spectrum:log_energy_band0:watch_acceleration:magnitude_spectrum:log_energy_band1:watch_acceleration:magnitude_spectrum:log_energy_band2:watch_acceleration:magnitude_spectrum:log_energy_band3:watch_acceleration:magnitude_spectrum:log_energy_band4:watch_acceleration:magnitude_spectrum:spectral_entropy:watch_acceleration:magnitude_autocorrelation:period:watch_acceleration:magnitude_autocorrelation:normalized_ac:watch_acceleration:3d:mean_x:watch_acceleration:3d:mean_y:watch_acceleration:3d:mean_z:watch_acceleration:3d:std_x:watch_acceleration:3d:std_y:watch_acceleration:3d:std_z:watch_acceleration:3d:ro_xy:watch_acceleration:3d:ro_xz:watch_acceleration:3d:ro_yz:watch_acceleration:spectrum:x_log_energy_band0:watch_acceleration:spectrum:x_log_energy_band1:watch_acceleration:spectrum:x_log_energy_band2:watch_acceleration:spectrum:x_log_energy_band3:watch_acceleration:spectrum:x_log_energy_band4:watch_acceleration:spectrum:y_log_energy_band0:watch_acceleration:spectrum:y_log_energy_band1:watch_acceleration:spectrum:y_log_energy_band2:watch_acceleration:spectrum:y_log_energy_band3:watch_acceleration:spectrum:y_log_energy_band4:watch_acceleration:spectrum:z_log_energy_band0:watch_acceleration:spectrum:z_log_energy_band1:watch_acceleration:spectrum:z_log_energy_band2:watch_acceleration:spectrum:z_log_energy_band3:watch_acceleration:spectrum:z_log_energy_band4:watch_acceleration:relative_directions:avr_cosine_similarity_lag_range0:watch_acceleration:relative_directions:avr_cosine_similarity_lag_range1:watch_acceleration:relative_directions:avr_cosine_similarity_lag_range2:watch_acceleration:relative_directions:avr_cosine_similarity_lag_range3:watch_acceleration:relative_directions:avr_cosine_similarity_lag_range4:watch_heading:mean_cos:watch_heading:std_cos:watch_heading:mom3_cos:watch_heading:mom4_cos:watch_heading:mean_sin:watch_heading:std_sin:watch_heading:mom3_sin:watch_heading:mom4_sin:watch_heading:entropy_8bins:location:num_valid_updates:location:log_latitude_range:location:log_longitude_range:location:min_altitude:location:max_altitude:location:min_speed:location:max_speed:location:best_horizontal_accuracy:location:best_vertical_accuracy:location:diameter:location:log_diameter:location_quick_features:std_lat:location_quick_features:std_long:location_quick_features:lat_change:location_quick_features:long_change:location_quick_features:mean_abs_lat_deriv:location_quick_features:mean_abs_long_deriv:audio_naive:mfcc0:mean:audio_naive:mfcc1:mean:audio_naive:mfcc2:mean:audio_naive:mfcc3:mean:audio_naive:mfcc4:mean:audio_naive:mfcc5:mean:audio_naive:mfcc6:mean:audio_naive:mfcc7:mean:audio_naive:mfcc8:mean:audio_naive:mfcc9:mean:audio_naive:mfcc10:mean:audio_naive:mfcc11:mean:audio_naive:mfcc12:mean:audio_naive:mfcc0:std:audio_naive:mfcc1:std:audio_naive:mfcc2:std:audio_naive:mfcc3:std:audio_naive:mfcc4:std:audio_naive:mfcc5:std:audio_naive:mfcc6:std:audio_naive:mfcc7:std:audio_naive:mfcc8:std:audio_naive:mfcc9:std:audio_naive:mfcc10:std:audio_naive:mfcc11:std:audio_naive:mfcc12:std:audio_properties:max_abs_value:audio_properties:normalization_multiplier:discrete:app_state:is_active:discrete:app_state:is_inactive:discrete:app_state:is_background:discrete:app_state:missing:discrete:battery_plugged:is_ac:discrete:battery_plugged:is_usb:discrete:battery_plugged:is_wireless:discrete:battery_plugged:missing:discrete:battery_state:is_unknown:discrete:battery_state:is_unplugged:discrete:battery_state:is_not_charging:discrete:battery_state:is_discharging:discrete:battery_state:is_charging:discrete:battery_state:is_full:discrete:battery_state:missing:discrete:on_the_phone:is_False:discrete:on_the_phone:is_True:discrete:on_the_phone:missing:discrete:ringer_mode:is_normal:discrete:ringer_mode:is_silent_no_vibrate:discrete:ringer_mode:is_silent_with_vibrate:discrete:ringer_mode:missing:discrete:wifi_status:is_not_reachable:discrete:wifi_status:is_reachable_via_wifi:discrete:wifi_status:is_reachable_via_wwan:discrete:wifi_status:missing:lf_measurements:light:lf_measurements:pressure:lf_measurements:proximity_cm:lf_measurements:proximity:lf_measurements:relative_humidity:lf_measurements:battery_level:lf_measurements:screen_brightness:lf_measurements:temperature_ambient:discrete:time_of_day:between0and6:discrete:time_of_day:between3and9:discrete:time_of_day:between6and12:discrete:time_of_day:between9and15:discrete:time_of_day:between12and18:discrete:time_of_day:between15and21:discrete:time_of_day:between18and24:discrete:time_of_day:between21and3:label:LYING_DOWN:label:SITTING:label:FIX_walking:label:FIX_running:label:BICYCLING:label:SLEEPING:label:LAB_WORK:label:IN_CLASS:label:IN_A_MEETING:label:LOC_main_workplace:label:OR_indoors:label:OR_outside:label:IN_A_CAR:label:ON_A_BUS:label:DRIVE_-_I_M_THE_DRIVER:label:DRIVE_-_I_M_A_PASSENGER:label:LOC_home:label:FIX_restaurant:label:PHONE_IN_POCKET:label:OR_exercise:label:COOKING:label:SHOPPING:label:STROLLING:label:DRINKING__ALCOHOL_:label:BATHING_-_SHOWER:label:CLEANING:label:DOING_LAUNDRY:label:WASHING_DISHES:label:WATCHING_TV:label:SURFING_THE_INTERNET:label:AT_A_PARTY:label:AT_A_BAR:label:LOC_beach:label:SINGING:label:TALKING:label:COMPUTER_WORK:label:EATING:label:TOILET:label:GROOMING:label:DRESSING:label:AT_THE_GYM:label:STAIRS_-_GOING_UP:label:STAIRS_-_GOING_DOWN:label:ELEVATOR:label:OR_standing:label:AT_SCHOOL:label:PHONE_IN_HAND:label:PHONE_IN_BAG:label:PHONE_ON_TABLE:label:WITH_CO-WORKERS:label:WITH_FRIENDS:label_source:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:string:string:string:string:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:string:string:numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:string:numeric:numeric:string:string:string:numeric:numeric:numeric:,
Nearest Cities for NYC Taxi Trips , ps , www.kaggle.com/ps2811/nearest-cities-for-nyc-taxi-trips , Thu Aug 31 2017 07:03:24 GMT+0530 (IST) , Pickup and Dropoff Cities for NYC Taxi Trips Dataset ,44, ,"Context This dataset includes the nearest pickup and drop off city names for each trip record from New York City Taxi Trip Duration Competition.  Content The dataset introduces two new columns namely ""Nearest_PickupCity"" and ""Nearest_DropoffCity"" in addition to the original trip features. The city names may not be the exact geo cities in some cases they are the nearest city to the trip records therefore the term ""Nearest"" describes them best.  Acknowledgements Implemented the offline package Reverse Geocoder (author - Ajay Thampi ) to get these data attributes. The original package is developed by Richard Pennman. Inspiration The idea is that this extension to the NYC Trip data can provide interesting and informative city trends about the taxi trips in NYC area.  Which cities drive the taxi trip demand ?  Does the trip demand vary based on city as the day moves from morning to night? Can pickup and drop off city information improve trip duration prediction ?  All feedback is welcome",id:vendor_id:pickup_datetime:passenger_count:pickup_longitude:pickup_latitude:dropoff_longitude:dropoff_latitude:store_and_fwd_flag:,string:numeric:dateTime:numeric:numeric:numeric:numeric:numeric:string:,
Kwici Welsh Wikipedia Corpus , Rachael Tatman , www.kaggle.com/rtatman/kwici-welsh-wikipedia-corpus , Tue Aug 29 2017 23:19:24 GMT+0530 (IST) , A 4 million word corpus of contemporary Welsh ,18, languages- europe- linguistics- ,"Content Kwici is a 4m-word corpus drawn from the Welsh Wikipedia as it was on 30 December 2013.  The final pages and articles dump for 2013 was downloaded from the Wikimedia dump page. The WikiExtractor tool written by Giuseppe Attardi and Antonio Fuschetto was then used to extract plain text (discarding markup etc) from the 165Mb dump resulting in a 33Mb output file. This was tidied by removing remaining XML blank lines and blocks of English text. The text was then split to give into a total of 360477 sentences and these were imported into a PostgreSQL database table. The sentences were pruned by removing all items  less than 50 characters long all items containing numbers only (eg timelines) and all duplicates to give a final total of 204789 sentences in the corpus.  The file contains the following fields  id unique identifier for the sentence; welsh the sentence in Welsh; word_w the number of words in the Welsh sentence.  Acknowledgements This dictionary was created by  Kevin Donnell. If using Kwici in research please use the following citation Kevin Donnelly (2014). ""Kwici a 4m-word corpus drawn from the Welsh Wikipedia."" http//cymraeg.org.uk/kwici. (BibTeX) Inspiration  Can you use this corpus to add frequency information to this Welsh dictionary? Can you use this corpus to create a stemmer for Welsh? ",id:welsh:word_w:,numeric:string:numeric:,
Short Track Speed Skating Database , xWang , www.kaggle.com/seniorwx/shorttrack , Wed Dec 28 2016 22:30:18 GMT+0530 (IST) , Detailed lap data of each game in the last 5 seasons ,130, sports- ,"Short Track Speed Skating Database for Sports Data Analysis What is short track speed skating? Maybe some people have never heard of this sport. Short track is a competitive and strategic game in which skaters race on ice. Sometimes the smartest or the luckiest guy rather than the strongest wins the game (for example). What's in the data? The database covers all the international short track games in the last 5 years. Currently it contains only men's 500m but I will keep updating it.  Detailed lap data including personal time and ranking in each game from seasons 2012/2013 to present . The final time results ranking starting position qualified or penalized information of each athlete in each game. All series of World Cup World Championship European Championship and Olympic Games.  Original data source The data is collected from the ISU's (International Skating Union) official website. I have already done the cleaning procedure.  Please make sure that the data are only for personal and non-commercial use.  Explore the data Interesting questions may be like  What will happen in a game when there are more than one athlete from the same team? Are there performance all improved? How does the performance of athletes change within a season and over seasons? Do some athletes have special patterns in terms of time allocation and surpassing opportunity? What is the influence of the implementation of ""no toe starts"" rules on athletes since July 2015?  Is there also home advantage like in other sports? Who are the most ""dangerous"" guys that always get penalty?  ",Season:Series:City:Country:Year:Month:Day:Distance:Round:Group:Num_Skater:Name:Nationality:Rank_In_Group:Start_Position:Time:Qualification:rank_lap1:time_lap1:rank_lap2:time_lap2:rank_lap3:time_lap3:rank_lap4:time_lap4:rank_lap5:time_lap5:Time_Event:,string:string:string:string:numeric:numeric:numeric:string:string:numeric:numeric:string:string:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Top 1000 Golf Players Historical , Kelvin Wellington , www.kaggle.com/odartey/top-1000-golf-players-historical , Tue Jul 18 2017 13:56:34 GMT+0530 (IST) , The Top 1000 ranked players in Golf from 2000 to 2015 ,78, golf- sports- ,Context Rankings are a constant phenomenon in society with a persistent interest in the stratification of items in a set across various disciplines. In sports rankings are a direct representation of the performance of a team or player over a certain period. Given the straightforward nature of rankings in sports (points based system) there is the opportunity to statistically explore rankings of sports disciplines. Content The dataset comprises weekly rankings data of the Top 1000 golf players between Sep 2000 and June April 2015. The data is housed in a single csv file. Acknowledgements Data was sourced from the Official Golf World Rankings (OGWR) website ogwr.com Inspiration This dataset could be of use to anyone interested in the distribution of rankings in competitive events,date:rank:name:avg_points:,dateTime:numeric:string:numeric:,
Horses For Courses , lukebyrne , www.kaggle.com/lukebyrne/horses-for-courses , Wed Jan 11 2017 13:11:30 GMT+0530 (IST) , Daily horse racing (thoroughbred) data machine learning for fun and profit ,2945, horse racing- ,Context Daily horse racing (thoroughbred) information that has(is) being actively collected and aggregated from a variety of sources. Years covered are just 2016 country is irrelevant to the dataset. Acknowledgements This data has(is) being actively collected and aggregated from a variety of sources all in the public domain. Past Research None of merit data is used currently to influence some betting decisions but no solid machine learning model(s) have been developed. Have thrown various versions of the data into  Google Prediction Amazon Machine Learning Azure Machine Learning Watson Analytics as a way to learn how these systems work. Inspiration Probably one of the hardest things to do is pick stocks and horses. I have been involved in the stocks and horses industry for many years and through publishing previous libraries and software I have met many interesting people and also one of my long term clients/friends. I am currently trying enhance my software development skills by learning data science / machine learning. I have a done a few tutorials and I am hoping that by publishing this data I can learn and collaborate with members of the Kaggle Community. Content markets.csv id start_time what time did the race start datetime in UTC venue_id race_number distance(m) condition_id track condition see conditions.csv weather_id weather on day see weathers.csv total_pool_win_one rough $ amount wagered across all runners for win market total_pool_place_one rough $ amount wagered across all runners for place market total_pool_win_two total_pool_place_two total_pool_win_three total_pool_place_three runners.csv id collected what time was this row created/data collected datetime in UTC market_id position THIS IS THE FIELD WE WANT TO PREDICT!!!! Will either be 123456 etc or 0/null if the horse was scratched or failed to finish If all positions for a market_id are null it means we were unable to match up the positional data for this market place_paid Will either be 1/0 or null If you see a race that only has 2 booleans of 1 it means that the race only paid out places on the first two positions margin If the runner didnt win how many lengths behind the 1st place was it horse_id see horses.csv trainer_id rider_id see riders.csv handicap_weight number barrier blinkers emergency did it come into the race at the last minute form_rating_one form_rating_two form_rating_three last_five_starts favourite_odds_win from one of the odds sources will it win  - true/false favourite_odds_place from one of the odds sources  will it win  - true/false favourite_pool_win favourite_pool_place tip_one_win from a tipster will it win    - true/false tip_one_place from a tipster will it place  - true/false tip_two_win tip_two_place tip_three_win tip_three_place tip_four_win tip_four_place tip_five_win tip_five_place tip_six_win tip_six_place tip_seven_win tip_seven_place tip_eight_win tip_eight_place tip_nine_win tip_nine_place odds.csv (collected for every runner 10 minutes out from race start until race starts) runner_id collected what time was this row created/data collected datetime in UTC odds_one_win from odds source win odds odds_one_win_wagered from odds source rough $ amount wagered on win odds_one_place from odds source place odds odds_one_place_wagered from odds source rough $ amount wagered on place odds_two_win odds_two_win_wagered odds_two_place odds_two_place_wagered odds_three_win odds_three_win_wagered odds_three_place odds_three_place_wagered odds_four_win odds_four_win_wagered odds_four_place odds_four_place_wagered forms.csv collected what time was this row created/data collected datetime in UTC market_id horse_id runner_number last_twenty_starts e.g. f9x726x753x92222x35 f = failed to finish 7 = finished 7th 6 = finished 6th  7 = finished 7th x = runner was scratched class_level_id 1 = eq (in same class as other horses) 2 = up (up in class) 3 = dn (down in class) field_strength days_since_last_run runs_since_spell overall_starts overall_wins overall_places track_starts track_wins track_places firm_starts firm_wins firm_places good_starts good_wins good_places dead_starts dead_wins dead_places slow_starts slow_wins slow_places soft_starts soft_wins soft_places heavy_starts heavy_wins heavy_places distance_starts distance_wins distance_places class_same_starts class_same_wins class_same_places class_stronger_starts class_stronger_wins class_stronger_places first_up_starts first_up_wins first_up_places second_up_starts second_up_wins second_up_places track_distance_starts track_distance_wins track_distance_places conditions.csv id name weathers.csv id name riders.csv (jockeys) id sex horses.csv id age sex_id see horse_sexes.csv sire_id not related to horses.id there is another table called horse_sires that is not present here dam_id not related to horses.id there is another table called horse_dams that is not present here prize_money total aggregate prize money horse_sexes.csv id name ,,,
Global Food Prices , Jacob Boysen , www.kaggle.com/jboysen/global-food-prices , Fri Aug 04 2017 02:22:44 GMT+0530 (IST) , 743k Rows of Monthly Market Food Prices Across Developing Countries ,494, food and drink- economics- ,Context Global food price fluctuations can cause famine and large population shifts. Price changes are increasingly critical to policymakers as global warming threatens to destabilize the food supply. Content Over 740k rows of prices obtained in developing world markets for various goods. Data includes information on country market price of good in local currency quantity of good and month recorded. Acknowledgements Compiled by the World Food Program and distributed by HDX. Inspiration This data would be particularly interesting to pair with currency fluctuations weather patterns and/or refugee movements--do any price changes in certain staples predict population upheaval? Do certain weather conditions influence market prices? License Released under CC BY-IGO.,adm0_id:adm0_name:adm1_id:adm1_name:mkt_id:mkt_name:cm_id:cm_name:cur_id:cur_name:pt_id:pt_name:um_id:um_name:mp_month:mp_year:mp_price:mp_commoditysource:,numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:numeric:numeric:string:,
State Energy System Data 1960-2014 , Nathan , www.kaggle.com/nathanto/seds-1960-2014F , Tue Mar 14 2017 21:05:43 GMT+0530 (IST) , State Energy Data Systems (SEDS) data for all US states including DC ,188, energy- ,"State Energy Data Systems (SEDS) data for all US states including DC from 1960 to 2014F Context This dataset is derived from my general interest in energy systems. It was originally composed for this exercise as part of this Coursera/John Hopkins Data Science Specilisation. The code that produced this dataset is in https//www.kaggle.com/nathanto/d/nathanto/seds-1960-2014F/data-wrangling-code-for-seds-1960-2014f Content The data is a composition of the State Energy Data Systems (SEDS) data for all US states including DC from 2016 to 2014F for data released June 29 2016. It has been tidied from a wide format to a long format and includes unit codes for the values associated with the observations for each MSN code for each state for each year.  The ""F"" in the final year number indicates that these are the final observations. There is a lag of some 18 months after year end and final readings. The columns are  state - State postal code composed from the function states.abb and including ""DC"". msn - A mnemonic series name identifying the value being observed. year - Year of the observation. value - Of the observation. units_code representing the units of the value e.g. BBtu is Billion British Thermal Units.  Note that the units_codes are mostly my own invention based on the EIA Writng Style Guide. Acknowledgements Thank you to the US Energy Information Administration for making the data available. Special thanks to Yvonne Taylor for guidance on style for the codes. Inspiration The first goal for this data was to support some plotting and forecast testing exercises which is a work in progress. To what extent do past observations predict future observations? Since the data is readily available and consistent within limits over a long period this format is a good basis for experimenting with techniques in that space. ",state:msn:year:value:units_code:,string:string:numeric:numeric:string:,
Weather in Szeged 2006-2016 , NorbertBudincsevity , www.kaggle.com/budincsevity/szeged-weather , Sun Jan 08 2017 14:27:29 GMT+0530 (IST) , Hourly/daily summary with temperature pressure wind speed and more ,253, climate- ,Context This is a dataset for a larger project I have been working on. My idea is to analyze and compare real historical weather with weather folklore. Content The CSV file includes a hourly/daily summary for Szeged Hungary area between 2006 and 2016. Data available in the hourly response  time summary precipType temperature apparentTemperature humidity windSpeed windBearing visibility loudCover pressure  Acknowledgements Many thanks to Darksky.net team for their awesome API.,Formatted Date:Summary:Precip Type:Temperature (C):Apparent Temperature (C):Humidity:Wind Speed (km/h):Wind Bearing (degrees):Visibility (km):Loud Cover:Pressure (millibars):Daily Summary:,dateTime:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:,
Eurfa Welsh Dictionary , Rachael Tatman , www.kaggle.com/rtatman/eurfa-welsh-dictionary , Tue Aug 29 2017 22:51:14 GMT+0530 (IST) , 212403 word dictionary of Welsh ,25, languages- europe- linguistics- ,"Context Welsh is a member of the Brittonic branch of the Celtic languages. It is spoken natively in Wales by some in England and in Y Wladfa (the Welsh colony in Chubut Province Argentina). Historically it has also been known in English as ‘Cambrian’ ‘Cambric’ and ‘Cymric’. The current number of Welsh speakers in Wales is over 562000. Content Eurfa is the largest Welsh dictionary under a free license and it was the first dictionary of a Celtic language to list verbal inflections and mutated forms. It also includes in-context citations for most words from a number of corpora Bilingual (Welsh-English Welsh-Spanish)  The 18m-word Kynulliad3 corpus (K3). This contains formal written Welsh (the majority of it translated from English). The 450k-word Siarad corpus (S). These transcribed conversations contain ""Welsh as she is spoke"" including English codeswitches. For readability the version here (download) removes much of the transcription marking. The 200k-word Patagonia corpus (P). These transcribed conversations contain spoken Welsh from Patagonia. This has fewer codeswitches and many of them are in Spanish rather than English. For readability the version here (download) removes much of the transcription marking. The 200k-word Korrect/Kywiro corpus (Ko). This contains Welsh translations of English text in free/open software programs.  Monolingual (Welsh only)  A 220k-word subset of the 300k-word CIG1 child (18-30 months) language acquisition corpus (Kig1) containing non-child utterances only. The version here removes much of the transcription marking. A 100k-word subset of the 560k-word CIG2 child (3-7 years) language acquisition corpus (Kig2) containing non-child utterances only. The version here removes much of the transcription marking.  Acknowledgements This dictionary was created by  Kevin Donnelly and is redistributed here under the GNU General Public License. For more information see the attached LICENSE file. You may also like  4 million word corpus of contemporary Welsh ",,,
Automatic generation of Guard roles , Paul Larmuseau , www.kaggle.com/plarmuseau/geowacht , Tue Aug 29 2017 17:25:48 GMT+0530 (IST) , lets build an primer for an automated guard distribution system ,13, human medicine- business- ,Context There are 4933 pharmacies in Belgium and each pharmacy (in groups) are obliged to create a network of night-guard pharmacies covering complete Belgium. Compare it with a hospital that has 2000 nurses and want's to distribute the burden of the 'night' shift or 'weekend' shifts over the 2000 nurses on an 'equal foot' basis but here we add a geographical aspect. So its a maximal covering location problem combined with an typical 'personel' planning problem  The challenge... The distribution of the pharmacies follows certain rules 11million inhabitants having access to 5000 pharmacies you can estimate that each pharmacy serves 2200 inhabitants. This is approximately true. You see a glimpse of the guard kalender  blackpoints feast days day/night guard (sun/moon)  Each pharmacy is equal and has to do equal number of guards. That is in this description rounded 12 days guard. We give each pharmacy a guard-capital. Meaning when at the end of the year one pharmacy has done 10 days guard the next year the pharmacy has to do two days guard more.  On average each pharmacy is doing 12 days per year. So starting with an equal guard capital. We try to minimize the difference from the mean (mse). The guard is divided in a day part from 900u-2200 and from 2200pm to 900am as night guard. Each Pharmacy can choose to do guard during 1 day having 12 days and 6 nights  distributed over the year. With at least 2 sunday guards per year and one sunday night.  Or each pharmacy can choose to do his guard in blocks of 4 weekdays (Mo-Tu-We-Th  /// Fr-Sa-So) Doing at least two midweek blocks and two weekendblocks ending up with 2 day's too much guard capital. From those blocks he get alternating fe the Mo and We a nightshift. Or by example the Fr/So or Sa as nightshift . The nightshifts are also equally distributed.  The choice for midweek/weekend or day guard is a freedom indicated in the database. We filled in a random example. Usually the freedom collides with regions.  So a dayblock and a nightblock each get one guard point. Each customer has to find a pharmacy within 20 minutes from his home. On average this rule is easily obeyed since its possible to find 3-5 pharmacies within 20 minutes in 'city' zones. Its only in very rural zones this rule can be violated. We use a GISS database to correctly calculate the distance and travelling time between each pharmacy. You can use google-api or haversine internally we have exact data. But within this proof of concept this doesn't matter.  Actually highway's are draining more people to a pharmacy and the algorithm shows the pharmacy as a faster alternative than geographic haversine closer pharmacies. So a very fine tuned model takes this driving speed into account in function of that 20 minutes rule. But here the haversine distance between the closest clusters should give a good approximation. It actually counts only for the case where the 20 minutes rule is 'violated' If we divide Belgium in 165 clusters there are 30 pharmacies per cluster. Each cluster has  1 pharmacy available for 66000 inhabitants within 20 minutes. This during DAYTIME. (Daytime is defined until 2200u)   At night the scheme HALVES. 82 clusters with 60 pharmacies per cluster. Each night cluster has then 132.000 inhabitants. The same rule each cluster has 1 pharmacy available. We search to MAXIMIZE the DISTANCE between each guard-pharmacy  so that there is an maximal SPREAD for the guard. This guarantees that customers find very fast a pharmacy. If you think about iton the Belgium card you can superimpose a  'grid' that is shifting each day and each night selecting a pharmacy in the intersections of the grid. The only interfering element here is that 50% of the pharmacies chooses to have guard in weekend/midweek scheme and 50% wants day/night guards hence you have to swap the guard between neighbouring pharmacy's so the distance rule remains respected.  Each Pharmacy can block 3 weeks of vacation that is typical during school vacations periods that pharmacy's tend to block periods. We call it black-points; You can generate random 3 weeks school/holiday vacation weeks that are blocked for each pharmacy.  The database is filled in with a manual created sample.. Actually the pharmacist can block 3weeks or 6 weekend and mid/week blocks. Here i simplified to three week (number of week  week of year) Doing guard on a holiday like Christmas New Year Eastern Sinksen National Feast Day is rewarded  with an extra guard capital point. Those pharmacies can do as such 1 day less guard. This as a last twitch   What do we need at the end 1° a database of all pharmacy's and their guard capital points. We tend to minimize the difference with the mean capital points. And usually the current algorithm selects the first the pharmacies in a cluster with the lowest capital points as prime candidate. 2°  a list of guards for all the 165clusters for all 365days or 60225 guards per year. And a measurement that estimates the distance between all pharmacies. for that day.. The Mean square error of the distance between the pharmacies has to be minimized,pharmacyID:Latitude:Longitude:Capital:Day1_week2:vacationweek1:vacationweek2:vacationweek3:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Space walking , NASA , www.kaggle.com/nasa/space-walking-russian-and-us-evas , Mon Aug 28 2017 21:29:27 GMT+0530 (IST) , A record of Russian and U.S. extra-vehicular actvity ,63, space- astronauts- aerospace engineering- spaceflight- ,"Context Extra-vehicular activities are activities done by an astronaut or cosmonaut outside a spacecraft beyond the Earth's appreciable atmosphere. I like to just call it space walking )  It's unclear if this is a complete record of spacewalks. So keep that in mind. Content  EVA # Country Crew Crew members separated with | Vehicle Space craft space ship space station etc. If multiple vehicles they are separated with | Date Duration Purpose Description of the EVA. Some of these have internal commas and are enclosed with double quotes ("")  Acknowledgements These data were collected from here The original CSV was modified slightly to remove extra spaces ",EVA #:,numeric:,
Coal Production Referenced from data.gov.in , VineetKothari , www.kaggle.com/vineetkothari/coalproduction , Sun Nov 06 2016 14:04:37 GMT+0530 (IST) , Data about coal production from diffrent sectors in India ,185, energy- ,Data from data.gov.in about the coal production in diffrent sectors india,Mineral:States:Unit:Quantity 2010-11:Value 2010-11:Quantity 2011-12:Value 2011-12:Quantity 2012-13:Value 2012-13:Quantity 2013-14:Value 2013-14:Quantity 2014-15(P):Value 2014-15(P):,string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Top Ranked English Movies Of This Decade. , Sai Pranav , www.kaggle.com/saipranava/top-ranked-enlglish-movies-of-this-decade , Sat Aug 26 2017 23:56:53 GMT+0530 (IST) , Understanding the success of movies with high ratings. ,122, ,About this project This is my first pet project ever. In this project I'm going to do exploratory analysis on the top rated IMDb movies of all time. I wanted  to analyse the the box office success of a highly rated movie and its relationship with various variables like the age gender of user/voter.  For this purpose I looked at the top 100 Movies of all time on IMDb. I used Octoparse for scraping. I realized that it would be too complicated to analyse movies over various generations because the tastes of every generation is different so I narrowed down onto movies of this decade i.e. movies released between 2010-2016 ) both years included I know 2010 doesn't really fall in to this decade but included it in order to have a decent sized data set. Then I narrowed down to movies targeting a particular culture because Indian movies and American movies are quite different and trying to predict what people like with both kinds of movies mixed up didn't seem like a good idea. I excluded movies released in 2017 as it takes time for ratings to stabilize and box office reports to be finalized. So from this list I further shortened the list to  movies made in English and finally ended up with a dataset of 118 movies and 55 variables. One of the most important variable the box office collections of each movie could not be scraped due to technical difficulties this is an area I  really need help with so if someone can contribute here it would be great! Objectives What are the goals or questions you're investigating with this project?  Visualize and Analyse the ratings given by different age groups for a genre. Visualize and Analyse the ratings given by male and female groups for a genre. Visualize and Analyse the number of votes given by different age groups for a genre. Visualize and Analyse the number of votes given by male and female groups for a genre. Visualize and Analyse the Box office success of a movie in U.S. with various variables. Visualize and Analyse the Box office success of a movie outside the U.S. with various variables. Visualize and Analyse the overall Box office success of a movie  with various variables. Revisit the project after a couple of years and see if any of the models we built have made any accurate predictions.  Get involved How can others contribute to this project? Are there tasks that need to be done or skills you're looking for?  Scrape data to get the U.S. box office data and non-U.S. box office data of each movie. Integrate that data into our dataset. Clean the data. Work on the objectives.  External resources  https//github.com/saipranava/IMDB  Photo by Jakob Owens on Unsplash,:Title:Rating:TotalVotes:Genre1:Genre2:Genre3:MetaCritic:Budget:Runtime:�..CVotes10:CVotes09:CVotes08:CVotes07:CVotes06:CVotes05:CVotes04:CVotes03:CVotes02:CVotes01:CVotesMale:CVotesFemale:CVotesU18:CVotesU18M:CVotesU18F:CVotes1829:CVotes1829M:CVotes1829F:CVotes3044:CVotes3044M:CVotes3044F:CVotes45A:CVotes45AM:CVotes45AF:CVotes1000:CVotesUS:CVotesnUS:VotesM:VotesF:VotesU18:VotesU18M:VotesU18F:Votes1829:Votes1829M:Votes1829F:Votes3044:Votes3044M:Votes3044F:Votes45A:Votes45AM:Votes45AF:VotesIMDB:Votes1000:VotesUS:VotesnUS:,numeric:string:numeric:numeric:string:string:string:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:,
OECD Productivity Data , Jessica Yung , www.kaggle.com/jessicayung/oecd-productivity-data , Thu May 04 2017 18:31:08 GMT+0530 (IST) , Productivity labour costs and GDP per capita for 32 OECD countries ,178, economics- ,Context The data was obtained from the OECD website's Productivity Statistics section on 4 May 2017. Productivity = output per units of input. To be expanded on. Content To be filled in. Acknowledgements The data in this dataset is the property of the Organisation for Economic Co-operation and Development (the “OECD”).  The OECD makes data (the “Data”) available for use and consultation by   the public.  As stated in Section I(a) above Data may be subject to   restrictions beyond the scope of these Terms and Conditions either   because specific terms apply to those Data or because third parties   may have ownership interests. It is the User’s responsibility to   verify either in the metadata or source information whether the Data   is fully or partially owned by third parties and/or whether additional   restrictions may apply and to contact the owner of the Data before   incorporating it in your work in order to secure the necessary   permissions. The OECD in no way represents or warrants that it owns or   controls all rights in all Data and the OECD will not be liable to   any User for any claims brought against the User by third parties in   connection with the use of any Data.  Permitted use Except where additional restrictions apply as stated above You can extract from download copy adapt print distribute   share and embed Data for any purpose even for commercial use. You   must give appropriate credit to the OECD by using the citation   associated with the relevant Data or if no specific citation is   available You must cite the source information using the following   format OECD (year) (dataset name)(data source) DOI or URL (accessed   on (date)). When sharing or licensing work created using the Data You   agree to include the same acknowledgment requirement in any   sub-licenses that You grant along with the requirement that any   further sub-licensees do the same.  Inspiration Research Questions  Why is productivity growth slowing down in many advanced and emerging economies? ,LOCATION:Country:SUBJECT:Subject:MEASURE:Measure:TIME:Time:Unit Code:Unit:PowerCode Code:PowerCode:Reference Period Code:Reference Period:Value:Flag Codes:Flags:,string:string:string:string:string:string:numeric:numeric:string:string:numeric:string:string:string:numeric:string:string:,
Global Population Estimates , World Bank , www.kaggle.com/theworldbank/global-population-estimates , Mon Aug 14 2017 22:40:19 GMT+0530 (IST) , The World Bank's global population estimates ,123, ,This database presents population and other demographic estimates and projections from 1960 to 2050. They are disaggregated by age-group and gender and cover approximately 200 economies. This dataset was kindly made available by the World Bank.,Country Name:Country Code:Series Name:Series Code:1960 [YR1960]:1961 [YR1961]:1962 [YR1962]:1963 [YR1963]:1964 [YR1964]:1965 [YR1965]:1966 [YR1966]:1967 [YR1967]:1968 [YR1968]:1969 [YR1969]:1970 [YR1970]:1971 [YR1971]:1972 [YR1972]:1973 [YR1973]:1974 [YR1974]:1975 [YR1975]:1976 [YR1976]:1977 [YR1977]:1978 [YR1978]:1979 [YR1979]:1980 [YR1980]:1981 [YR1981]:1982 [YR1982]:1983 [YR1983]:1984 [YR1984]:1985 [YR1985]:1986 [YR1986]:1987 [YR1987]:1988 [YR1988]:1989 [YR1989]:1990 [YR1990]:1991 [YR1991]:1992 [YR1992]:1993 [YR1993]:1994 [YR1994]:1995 [YR1995]:1996 [YR1996]:1997 [YR1997]:1998 [YR1998]:1999 [YR1999]:2000 [YR2000]:2001 [YR2001]:2002 [YR2002]:2003 [YR2003]:2004 [YR2004]:2005 [YR2005]:2006 [YR2006]:2007 [YR2007]:2008 [YR2008]:2009 [YR2009]:2010 [YR2010]:2011 [YR2011]:2012 [YR2012]:2013 [YR2013]:2014 [YR2014]:2015 [YR2015]:2016 [YR2016]:2017 [YR2017]:2018 [YR2018]:2019 [YR2019]:2020 [YR2020]:2021 [YR2021]:2022 [YR2022]:2023 [YR2023]:2024 [YR2024]:2025 [YR2025]:2026 [YR2026]:2027 [YR2027]:2028 [YR2028]:2029 [YR2029]:2030 [YR2030]:2031 [YR2031]:2032 [YR2032]:2033 [YR2033]:2034 [YR2034]:2035 [YR2035]:2036 [YR2036]:2037 [YR2037]:2038 [YR2038]:2039 [YR2039]:2040 [YR2040]:2041 [YR2041]:2042 [YR2042]:2043 [YR2043]:2044 [YR2044]:2045 [YR2045]:2046 [YR2046]:2047 [YR2047]:2048 [YR2048]:2049 [YR2049]:2050 [YR2050]:,string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Blog Authorship Corpus , Rachael Tatman , www.kaggle.com/rtatman/blog-authorship-corpus , Wed Aug 16 2017 02:50:54 GMT+0530 (IST) , Over 600000 posts from more than 19 thousand bloggers ,42, languages- linguistics- internet- ,"Context “A blog (a truncation of the expression ""weblog"") is a discussion or informational website published on the World Wide Web consisting of discrete often informal diary-style text entries (""posts""). Posts are typically displayed in reverse chronological order so that the most recent post appears first at the top of the web page. Until 2009 blogs were usually the work of a single individual occasionally of a small group and often covered a single subject or topic.” -- Wikipedia article “Blog” This dataset contains text from blogs written on or before 2004 with each blog being the work of a single user. Content The Blog Authorship Corpus consists of the collected posts of 19320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681288 posts and over 140 million words - or approximately 35 posts and 7250 words per person.   Each blog is presented as a separate file the name of which indicates a blogger id# and the blogger’s self-provided gender age industry and astrological sign. (All are labeled for gender and age but for many industry and/or sign is marked as unknown.) All bloggers included in the corpus fall into one of three age groups * 8240 ""10s"" blogs (ages 13-17) * 8086 ""20s"" blogs(ages 23-27) * 2994 ""30s"" blogs (ages 33-47). For each age group there are an equal number of male and female bloggers.    Each blog in the corpus includes at least 200 occurrences of common English words. All formatting has been stripped with two exceptions. Individual posts within a single blogger are separated by the date of the following post and links within a post are denoted by the label urllink. Acknowledgements The corpus may be freely used for non-commercial research purposes. Any resulting publications should cite the following J. Schler M. Koppel S. Argamon and J. Pennebaker (2006). Effects of Age and Gender on Blogging in Proceedings of 2006 AAAI Spring Symposium on Computational Approaches for Analyzing Weblogs. URL http//www.cs.biu.ac.il/~schlerj/schler_springsymp06.pdf Inspiration  This dataset contains information on writers demographics including their age gender and zodiac sign. Can you build a classifier to guess someone’s zodiac sign from blog posts they’ve written? Which are bigger differences between demographic groups or differences between blogs on different topics?  You may also like  News and Blog Data Crawl Content section from over 160000 news and blog articles 20 Newsgroups A collection of ~18000 newsgroup documents from 20 different newsgroups ",id:,numeric:,
CMS Open Payments Dataset 2013 , Centers for Medicare & Medicaid Services , www.kaggle.com/cms/cms-open-payments-dataset-2013 , Mon Nov 07 2016 11:49:23 GMT+0530 (IST) , Creating Public Transparency into Industry-Physician Financial Relationship ,261, human medicine- finance- health- ,Context Open Payments is a national disclosure program created by the Affordable Care Act (ACA) and managed by Centers for Medicare & Medicaid Services (CMS). The purpose of the program is to promote transparency into the financial relationships between pharmaceutical and medical device industries and physicians and teaching hospitals. The financial relationships may include consulting fees research grants travel reimbursements and payments from industry to medical practitioners.  Content There are 3 datasets that represent 3 different payment types   General Payments Payments not made in connection with a research agreement. This dataset contains 65 variables. Research Payments Payments made in connection with a research agreement. This dataset contains 166 variables. Physician Ownership or Investment Interest Information about physicians who hold ownership or investment interest in the manufacturer/GPO or who have an immediate family member holding such interest. This dataset contains 29 variables. Deleted/Removed Records Contains any deleted/removed records.  A comprehensive methodology overview and data dictionary for each dataset can be found here.  Acknowledgements The original datasets can be found here. Inspiration  Using the General Payments dataset can you determine any trends in the total amount of payment to hospitals and physicians across the medical specialties or by the form/nature of the payments? According to the Research Payments dataset which area(s) of research or the type of drug/medical device receive the most amount of payment? ,Change_Type:Program_Year:Payment_Type:Record_ID:,string:numeric:string:numeric:,
65 World Indexes , JoniHoppen , www.kaggle.com/joniarroba/65-world-indexes-gathered , Mon Feb 27 2017 01:55:21 GMT+0530 (IST) , Why are some countries so different? ,671, international relations- ,Context Why some countries are so different from other?  Content I have gathered manually most of the information at World Bank Unicef and so on. Some data were not there so I used K-nn to guess some values and have a full dataset that can be used of our data science community.   Information of each of the 65 variables were made available here http//bit.ly/2l2Hjh3 Acknowledgements Thanks www.aquare.la Advanced Analytics that came up with the idea of creating this dataset to test their VORTX tool. Also Thanks to  professionals involved in creating Indexes and collecting them this is such a great valuable work to help better see the world.  Inspiration What would be the best way to equalize the world? ,Id:Human Development Index HDI-2014:Gini coefficient 2005-2013:Adolescent birth rate 15-19 per 100k 20102015:Birth registration funder age 5 2005-2013:Carbon dioxide emissionsAverage annual growth:Carbon dioxide emissions per capita 2011 Tones:Change forest percentable 1900 to 2012:Change mobile usage 2009 2014:Consumer price index 2013:Domestic credit provided by financial sector 2013:Domestic food price level 2009 2014 index:Domestic food price level 2009-2014 volitility index:Electrification rate or population:Expected years of schooling - Years:Exports and imports percentage GPD 2013:Female Suicide Rate 100k people:Foreign direct investment net inflows percentage GDP 2013:Forest area percentage of total land area 2012:Fossil fuels percentage of total 2012:Fresh water withdrawals 2005:Gender Inequality Index 2014:General government final consumption expenditure - Annual growth 2005 2013:General government final consumption expenditure - Perce of GDP 2005-2013:Gross domestic product GDP 2013:Gross domestic product GDP percapta:Gross fixed capital formation of GDP 2005-2013:Gross national income GNI per capita - 2011  Dollars:Homeless people due to natural disaster 2005 2014 per million people:Homicide rate per 100k people 2008-2012:Infant Mortality 2013 per thousands:International inbound tourists thausands 2013:International student mobility of total tetiary enrolvemnt 2013:Internet users percentage of population 2014:Intimate or nonintimate partner violence ever experienced 2001-2011:Life expectancy at birth- years:MaleSuicide Rate 100k people:Maternal mortality ratio deaths per 100 live births 2013:Mean years of schooling - Years:Mobile phone subscriptions per 100 people 2014:Natural resource depletion:Net migration rate per 1k people 2010-2015:Physicians per 10k people:Population affected by natural desasters average annual per million people 2005-2014:Population living on degraded land Percentage 2010:Population with at least some secondary education percent 2005-2013:Pre-primary 2008-2014:Primary-2008-2014:Primary school dropout rate 2008-2014:Prison population per 100k people:Private capital flows percentage GDP 2013:Public expenditure on education Percentange GDP:Public health expenditure percentage of GDP 2013:Pupil-teacher ratio primary school pupils per teacher 2008-2014:Refugees by country of origin:Remittances inflows percentual GDP 2013:Renewable sources percentage of total 2012:Research and development expenditure  2005-2012:Secondary 2008-2014:Share of seats in parliament percentage held by womand 2014:Stock of immigrants percentage of population 2013:Taxes on income profit and capital gain 205 2013:Tertiary -2008-2014:Total tax revenue of GDP 2005-2013:Tuberculosis rate per thousands 2012:Under-five Mortality 2013 thousands:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Synthetic data from a financial payment system , TESTIMON @ NTNU , www.kaggle.com/ntnu-testimon/banksim1 , Tue Jul 11 2017 20:18:56 GMT+0530 (IST) , Synthetic datasets generated by the BankSim payments simulator ,324, finance- ,Context BankSim is an agent-based simulator of bank payments based on a sample of aggregated transactional data provided by a bank in Spain. The main purpose of BankSim is the generation of synthetic data that can be used for fraud detection research.  Statistical and a Social Network Analysis (SNA) of relations between merchants and customers were used to develop and calibrate the model.  Our ultimate goal is for BankSim to be usable to model relevant scenarios that combine normal payments and injected known fraud signatures.  The data sets generated by BankSim contain no personal information or disclosure of legal and private customer transactions. Therefore it can be shared by academia and others to develop and reason about fraud detection methods. Synthetic data has the added benefit of being easier to acquire faster and at less cost for experimentation even for those that have access to their own data. We argue that BankSim generates data that usefully approximates the relevant aspects of the real data.  Content We ran BankSim for 180 steps (approx. six months) several times and calibrated the parameters in order to obtain a distribution that get close enough to be reliable for testing. We collected several log files and selected the most accurate. We injected thieves that aim to steal an average of three cards per step and perform about two fraudulent transactions per day. We produced 594643 records in total. Where 587443 are normal payments and 7200 fraudulent transactions. Since this is a randomised simulation the values are of course not identical to original data. Acknowledgements This research was conducted during my PhD studies in Sweden at Blekinge Institute of Technology (BTH ww.bth.se). More about it http//edgarlopez.net Original paper Please refer to this dataset using the following citations Lopez-Rojas Edgar Alonso ; Axelsson Stefan Banksim A bank payments simulator for fraud detection research Inproceedings 26th European Modeling and Simulation Symposium EMSS 2014 Bordeaux France pp. 144–152 Dime University of Genoa 2014 ISBN 9788897999324. https//www.researchgate.net/publication/265736405_BankSim_A_Bank_Payment_Simulation_for_Fraud_Detection_Research,step:customer:age:gender:zipcodeOri:merchant:zipMerchant:category:amount:fraud:,numeric:string:string:string:string:string:string:string:numeric:numeric:,
Taxi Routes of Mexico City Quito and more , Mario Navas , www.kaggle.com/mnavas/taxi-routes-for-mexico-city-and-quito , Wed Aug 02 2017 22:31:09 GMT+0530 (IST) , Data collected from Taxi Cabify and Uber trips using EC Taximeter ,155, telecommunications- road transport- ,Context This dataset was collected using our App EC Taximeter.  An easy to use tool developed to compare fees giving the user an accurate fee based on GPS to calculate a cost of the taxi ride. Due to the ability to verify that you are charged fairly our App is very popular in several cities. We encourage our users to send us URLs with the taxi/transportation fees in their cities to keep growing our database. ★ Our App gets the available fares for your location based on your GPS perfect when traveling and not getting scammed. ★ Users can start a taximeter in their own phone and check they are charged fairly ★ Several useful information is displayed to the user during the ride Speed Wait time Distance GPS update GPS precision Range of error. ★ Each fare has information available for reference like Schedule Minimum fee Source Last update. ★ It’s possible to surf through several cities and countries which fares are available for use. If a fare is not in the app now it’s easier than ever to let us know thanks to Questbee Apps. We invite users to contribute to our project and expect this data set to be useful please don't hesitate to contact us to info@ashkadata.com to add your city or to contribute with this project. Content The data is collected from June 2016 until July 20th 2017. The data is not completely clean many users forget to turn off the taximeter when done with the route. Hence we encourage data scientist to explore it and trim the data a little bit Acknowledgements We have to acknowledge the valuable help of our users who have contributed to generate this dataset and have push our growth by mouth to mouth recommendation. Inspiration Our first inspiration for the App was after being scammed in our home city Quito. We started it as a tool for people to be fairly charged when riding a taxi. Currently with other transportation options available we also help user to compare fares in their cities or the cities which they are visiting. File descriptions mex_clean.csv - the dataset contains information of routes in Mexico City uio_clean.csv - the dataset contains information of routes in Quito Ecuador bog_clean.csv - the dataset contains information of routes in Bogota all-data_clean.csv - the dataset contains information of routes in different cities ,id:vendor_id:pickup_datetime:dropoff_datetime:pickup_longitude:pickup_latitude:dropoff_longitude:dropoff_latitude:store_and_fwd_flag:trip_duration:dist_meters:wait_sec:,numeric:string:dateTime:dateTime:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:,
FourSquare - NYC and Tokyo Check-ins , chetan , www.kaggle.com/chetanism/foursquare-nyc-and-tokyo-checkin-dataset , Thu Apr 27 2017 16:42:36 GMT+0530 (IST) , Check-ins in NYC and Tokyo collected for about 10 months ,296, cities- geography- internet- ,Context This dataset contains check-ins in NYC and Tokyo collected for about 10 month (from 12 April 2012 to 16 February 2013). It contains 227428 check-ins in New York city and 573703 check-ins in Tokyo. Each check-in is associated with its time stamp its GPS coordinates and its semantic meaning (represented by fine-grained venue-categories). This dataset is originally used for studying the spatial-temporal regularity of user activity in LBSNs. Content This dataset includes long-term (about 10 months) check-in data in New York city and Tokyo collected from Foursquare from 12 April 2012 to 16 February 2013. It contains two files in tsv format. Each file contains 8 columns which are  User ID (anonymized) Venue ID (Foursquare) Venue category ID (Foursquare) Venue category name (Fousquare) Latitude Longitude Timezone offset in minutes (The offset in minutes between when this check-in occurred and the same time in UTC) UTC time  The file dataset_TSMC2014_NYC.txt contains 227428 check-ins in New York city. The file dataset_TSMC2014_TKY.txt contains 537703 check-ins in Tokyo. Acknowledgements This dataset is acquired from here Following is the citation of the dataset author's paper Dingqi Yang Daqing Zhang Vincent W. Zheng Zhiyong Yu. Modeling User Activity Preference by Leveraging User Spatial Temporal Characteristics in LBSNs. IEEE Trans. on Systems Man and Cybernetics Systems (TSMC) 45(1) 129-142 2015. PDF Inspiration One of the questions that I am trying to answer is if there is a pattern in users' checkin behaviour. For example if it's a Friday evening what all places they might be interested to visit.,userId:venueId:venueCategoryId:venueCategory:latitude:longitude:timezoneOffset:utcTimestamp:,numeric:string:string:string:numeric:numeric:numeric:string:,
Home Mortgage Disclosure Act Data NY 2015 , Jacob Boysen , www.kaggle.com/jboysen/ny-home-mortgage , Thu Aug 17 2017 21:46:27 GMT+0530 (IST) , Data on ~440k Home Mortgage Decisions in NY ,61, ,Context The Home Mortgage Disclosure Act (HMDA) requires many financial institutions to maintain report and publicly disclose information about mortgages. Content This dataset covers all mortgage decisions made in 2015 for the state of New York. Data for additional states and years can be accessed here. Acknowledgements This dataset was compiled by the Consumer Finance Protection Board. Inspiration  Where are mortgages most likely to be approved? Can you predict mortgage decisions based on the criteria provided here? ,action_taken:action_taken_name:agency_code:agency_abbr:agency_name:applicant_ethnicity:applicant_ethnicity_name:applicant_income_000s:applicant_race_1:applicant_race_2:applicant_race_3:applicant_race_4:applicant_race_5:applicant_race_name_1:applicant_race_name_2:applicant_race_name_3:applicant_race_name_4:applicant_race_name_5:applicant_sex:applicant_sex_name:application_date_indicator:as_of_year:census_tract_number:co_applicant_ethnicity:co_applicant_ethnicity_name:co_applicant_race_1:co_applicant_race_2:co_applicant_race_3:co_applicant_race_4:co_applicant_race_5:co_applicant_race_name_1:co_applicant_race_name_2:co_applicant_race_name_3:co_applicant_race_name_4:co_applicant_race_name_5:co_applicant_sex:co_applicant_sex_name:county_code:county_name:denial_reason_1:denial_reason_2:denial_reason_3:denial_reason_name_1:denial_reason_name_2:denial_reason_name_3:edit_status:edit_status_name:hoepa_status:hoepa_status_name:lien_status:lien_status_name:loan_purpose:loan_purpose_name:loan_type:loan_type_name:msamd:msamd_name:owner_occupancy:owner_occupancy_name:preapproval:preapproval_name:property_type:property_type_name:purchaser_type:purchaser_type_name:respondent_id:sequence_number:state_code:state_abbr:state_name:hud_median_family_income:loan_amount_000s:number_of_1_to_4_family_units:number_of_owner_occupied_units:minority_population:population:rate_spread:tract_to_msamd_income:,numeric:string:numeric:string:string:numeric:string:numeric:numeric:numeric:string:string:string:string:string:string:string:string:numeric:string:numeric:numeric:numeric:numeric:string:numeric:string:string:string:string:string:string:string:string:string:numeric:string:numeric:string:string:string:string:string:string:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:,
Foreign Direct Investment in India , Rajanand Ilangovan / இராஜ்ஆனந்த் இளங்கோவன் , www.kaggle.com/rajanand/fdi-in-india , Fri Aug 18 2017 20:17:57 GMT+0530 (IST) , Sector & Financial year wise time series data from 2000-2016. ,140, india- finance- ,Context To understand the Foreign direct investment in India for the last 17 years from 2000-01 to 2016-17. Content This dataset contains sector and financial year wise data of FDI in India. Acknowledgements Ministry of Commerce and Industry has published Financial Year wise FDI Equity Inflows from 2000-01 to 2016-17 dataset in Open Government Data Platform India under Govt. Open Data License - India. Inspiration  How much FDI has changed over the year? How much has varied since 2014 after Narendra Modi become PM of India? ,Sector:2000-01:2001-02:2002-03:2003-04:2004-05:2005-06:2006-07:2007-08:2008-09:2009-10:2010-11:2011-12:2012-13:2013-14:2014-15:2015-16:2016-17:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Billboard 1964-2015 Songs + Lyrics , RakanNimer , www.kaggle.com/rakannimer/billboard-lyrics , Sun Apr 16 2017 15:09:22 GMT+0530 (IST) , 50 years of pop music lyrics ,437, music- linguistics- ,"Original Dataset Author  https//github.com/walkerkq From https//github.com/walkerkq/musiclyrics  50 Years of Pop Music Lyrics Billboard has published a Year-End Hot 100 every December since 1958. The chart measures the performance of singles in the U.S. throughout the year. Using R I’ve combined the lyrics from 50 years of Billboard Year-End Hot 100 (1965-2015) into one dataset for analysis. You can download that dataset here. The songs used for analysis were scraped from Wikipedia’s entry for each Billboard Year-End Hot 100 Songs (e.g. 2014). This is the year-end chart not weekly rankings. Many artists have made the weekly chart but not the final year end chart. The final chart is calculated using an inverse point system based on the weekly Billboard charts (100 points for a week at number one 1 point for a week at number 100 etc). I used the xml and RCurl packages to scrape song and artist names from each Wikipedia entry. I then used that list to scrape lyrics from sites that had predictable URL strings (for example metrolyrics.com uses metrolyrics.com/SONG-NAME-lyrics-ARTIST-NAME.html). If the first site scrape failed I moved onto the second and so on. About 78.9% of the lyrics were scraped from metrolyics.com 15.7% from songlyrics.com 1.8% from lyricsmode.com. About 3.6% (187/5100) were unavailable. The dataset features 5100 observations with the features rank (1-100) song artist year lyrics and source. The artist feature is fairly standardized thanks to Wikipedia but there is still quite a bit of noise when it comes to artist collaborations (Justin Timberlake featuring Timbaland for example). If there were any errors in the lyrics that were scraped such as spelling errors or derivatives like ""nite"" instead of ""night"" they haven't been corrected.   Full analysis can be found here.  walkerkq  Acknowledgements Dataset is a mirror of  https//github.com/walkerkq/musiclyrics All credits to gathering it goes to https//github.com/walkerkq Inspiration What makes a song's lyrics popular ?",Rank:Song:Artist:Year:Lyrics:Source:,numeric:string:string:numeric:string:numeric:,
Parole hearings in New York State , Parole Hearing Data Project , www.kaggle.com/parole-hearing-data/parole-hearings-in-new-york-state , Thu Dec 08 2016 12:48:52 GMT+0530 (IST) , Scraped list of parole hearings between 2014-2016 ,142, crime- law- ,"Context In New York over 10000 parole eligible prisoners are denied release every year and while the consequences of these decisions are costly (at $60000 annually to incarcerate one individual and more to incarcerate older individuals with illnesses) the process of how these determinations are made is unclear.  Advocates for parole reform argue that parole commissioners too often base their decisions on ""the nature of the crime"" for which the individual was convicted rather than on that individual's accomplishments and growth while serving  a sentence in prison. The Parole Hearing Data Project is part of a broader body of work that can be found on the Museum of the American Prison's website.   Content Dataset includes sex race / ethnicity housing or interview facility parole board interview type and interview decision among other factors. Scraping is up-to-date as of July 2016.  Descriptions provided by the Department of Corrections and Community Service (DOCCS) can be found here. Acknowledgements Data was collected and managed by Nikki Zeichner Rebecca Ackerman and John Krauss. Original dataset including a scraper to gather the latest updates can be found here. Inspiration  Does the housing or interview facility play a role in the parole decision? Are any of these facilities particularly likely to influence a positive decision? Do interview decisions vary based on race / ethnicity? Sex? What is the typical time between entry and release? ",parole board interview date:din:scrape date:nysid:sex:birth date:race / ethnicity:housing or interview facility:parole board interview type:interview decision:year of entry:aggregated minimum sentence:aggregated maximum sentence:release date:release type:housing/release facility:parole eligibility date:conditional release date:maximum expiration date:parole me date:post release supervision me date:parole board discharge date:crime 1 - crime of conviction:crime 1 - class:crime 1 - county of commitment:crime 2 - crime of conviction:crime 2 - class:crime 2 - county of commitment:crime 3 - crime of conviction:crime 3 - class:crime 3 - county of commitment:crime 4 - crime of conviction:crime 4 - class:crime 4 - county of commitment:crime 5 - crime of conviction:crime 5 - class:crime 5 - county of commitment:crime 6 - crime of conviction:crime 6 - class:crime 6 - county of commitment:crime 7 - crime of conviction:crime 7 - class:crime 7 - county of commitment:crime 8 - crime of conviction:crime 8 - class:crime 8 - county of commitment:,string:string:dateTime:string:string:dateTime:string:string:string:string:numeric:dateTime:string:dateTime:string:string:dateTime:dateTime:dateTime:dateTime:dateTime:dateTime:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:,
Fracking Well Chemical Disclosure Datasets , Fracking Analysis , www.kaggle.com/frackinganalysis/fracking-well-chemical-disclosure-datasets , Thu Jun 01 2017 08:30:50 GMT+0530 (IST) , Datasets of fracking well chemical disclosures and toxicities ,113, energy- mining- ,"Context These datasets are extractions provided by FrackingData.org of the SQL Server 2012 backup file obtained on a monthly basis from FracFocus.org's ""FracFocus Data Download"" web page.  As FracFocus.org's SQL Server 2012 backup file is inconvenient to ingest for most citizen-scientists or data analysts FrackingData.org ingests the database and outputs both CSV and SQLite files more readily suitable for analysis.  The files in question available herein are also available at FracFocus.org's ""FracFocus Data"" web page. Content Fracking well chemical disclosures the ""Registry"" files hierarchy as follows  RegistryUpload this is the header file. RegistryPurpose this is an intermediate file between the header and the ingredients. RegistryIngredients this is the detail file of the chemical ingredients used in each well.  Chemical health effects and toxicities by Chemical Abstract Society Registry Number (CASRN). Acknowledgements  FrackingData.org for the ingestion and conversion of the FracFocus Registry database. FracFocus.org for the collection of the fracking well chemical disclosures. Scorecard Chemical Health Effects for the compilation of the various chemicals' health effects and toxicities.  Inspiration  Start by associating each fracking well chemical disclosure to its chemical health effects using the CASNumber or CASRN as appropriate. ",tox_cas_edf_id:tox_chemical_name:tox_category:tox_cancer:tox_cardiovascular_blood:tox_developmental:tox_endocrine:tox_gastrointestinal_liver:tox_immunotoxicity:tox_kidney:tox_musculoskeletal:tox_neurotoxicity:tox_reproductive:tox_respiratory:tox_skin_sense:,dateTime:string:string:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:boolean:,
International Air Traffic from and to India , Rajanand Ilangovan / இராஜ்ஆனந்த் இளங்கோவன் , www.kaggle.com/rajanand/international-air-traffic-from-and-to-india , Thu Jul 27 2017 00:34:05 GMT+0530 (IST) , Country City pair & Airline wise from 2015Q1 to 2017Q1. ,262, india- aviation- ,Context This dataset contains detail about the international air traffic from and to Indian territories from Jan-2015 to Mar-2017 in the below level. a) Country wise b) City pair wise c) Airline wise  Content Time Period 2015Q1 - 2017Q1 Granularity Quarterly and Monthly Acknowledgements Directorate General of Civil Aviation India has published this dataset at their website.,AIRLINE NAME:YEAR:MONTH:QUARTER:CARRIER TYPE:PASSENGERS TO INDIA:PASSENGERS FROM INDIA:FREIGHT TO INDIA:FREIGHT FROM INDIA:,string:dateTime:string:string:string:numeric:numeric:numeric:numeric:,
Now That's What I Call Music (U.S. releases) , athontz , www.kaggle.com/athontz/nowthatswhaticallmusic , Thu Feb 02 2017 07:23:34 GMT+0530 (IST) , A collection of all 61 original Now That is What I Call Music tracklistings ,235, popular culture- music- ,Context I am working on building a classifier that will examine today's 'top 40' and determine whether or not they are worthy of appearing on the next 'Now That's What I Call Music' album. Content The dataset includes all 61 US released Now That's what I call Music tracklistings. Columns are volume_number - the album number corresponding with the volume. (ex a value of 60 would represent the album 'Now That's What I Call Music Vol. 60) artist - the name of the artist singing the track title - the song name number - the song's track number on it's album duration - the song's length in seconds Acknowledgements Thanks to Wikipedia contributors for maintaining this data! Improvements I am currently working on adding another csv file that contains this same data joined with each song's audio features from the Spotify Web API. In the future I would also be interested in scraping Now releases in other countries as well as the 'special' releases (ex Now That's What I Call Christmas music etc).,speechiness:key:time_signature:liveness:loudness:duration_ms:danceability:duration:valence:acousticness:spotify_id:volume_number:energy:tempo:instrumentalness:mode:number:artist:title:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:string:string:,
NASA Facilities , NASA , www.kaggle.com/nasa/nasa-facilities , Wed Aug 23 2017 01:27:13 GMT+0530 (IST) , A dataset of NASA facility names and locations ,46, space- organizations- spaceflight- ,"Context NASA has something like 400 different facilities across the United States! This dataset is a collection of those facilities and their locations. Content  Center Name of the ""Center"" a collection facilities Center Search Status Public or...? Facility Name of the facility FacilityURL Occupied Status URL Link Record Date Last Update Country Location City State Zipcode  Acknowledgements This dataset was downloaded from https//data.nasa.gov/Management-Operations/NASA-Facilities/gvk9-iz74. The original file was modified to remove contact information for each facility.",Center:,string:,
New York City Census Data , MuonNeutrino , www.kaggle.com/muonneutrino/new-york-city-census-data , Fri Aug 04 2017 11:47:42 GMT+0530 (IST) , Demographic Economic and Location Data for Census Tracts in NYC ,146, united states- demographics- ,Context There are a number of Kaggle datasets that provide spatial data around New York City. For many of these it may be quite interesting to relate the data to the demographic and economic characteristics of nearby neighborhoods. I hope this data set will allow for making these comparisons without too much difficulty. Exploring the data and making maps could be quite interesting as well. Content This dataset contains two CSV files  nyc_census_tracts.csv This file contains a selection of census data taken from the ACS DP03 and DP05 tables. Things like total population  racial/ethnic demographic information employment and commuting characteristics and more are contained here. There is a  great deal of additional data in the raw tables retrieved from the US Census Bureau website so I could easily add more fields if  there is enough interest. I obtained data for individual census tracts which typically contain several thousand residents.  census_block_loc.csv For this file I used an online FCC census block lookup tool to retrieve the census block code for a 200 x 200 grid containing  New York City and a bit of the surrounding area. This file contains the coordinates and associated census block codes along  with the state and county names to make things a bit more readable to users. Each census tract is split into a number of blocks so one must extract the census tract code from the block code.  Acknowledgements The data here was taken from the American Community Survey 2015 5-year estimates (https//factfinder.census.gov/faces/nav/jsf/pages/index.xhtml). The census block coordinate data was taken from the FCC Census Block Conversions API (https//www.fcc.gov/general/census-block-conversions-api) As public data from the US government this is not subject to copyright within the US and should be considered public domain.,Latitude:Longitude:BlockCode:County:State:,numeric:numeric:numeric:string:string:,
Consumer Price Index in Denver CO , US Bureau of Labor Statistics , www.kaggle.com/bls/denver-cpi , Tue Aug 22 2017 21:53:26 GMT+0530 (IST) , 104 years of monthly CPI data ,24, economics- ,Context The Consumer Price Indexes (CPI) program produces monthly data on changes in the prices paid by urban consumers for a representative basket of goods and services. It is a useful way to compare changes in the economy across time. Content This data covers Jan 1913-May 2017 and is normalized to “CPI-U all items 1982-84=100 not seasonally adjusted”. Fields include time of measurement and CPI score. Acknowledgements This dataset was compiled on behalf of the Bureau of Labor Statistics (BLS) via Colorado Department of Labor & Employment (CDLE) and hosted on data.colorado.gov. Inspiration  What periods of time have seen the highest/lowest CPI?  When has inflation been the worse? Can you predict present CPI? ,stateFips:area:areaType:period:periodYear:periodType:periodTypeDescription:cpi:title:type:source:cpiSourceDescription:percentChangeYear:percentChangeMonth:dataRegion:areaName:areaDescription:,numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:string:numeric:numeric:string:numeric:numeric:string:string:string:,
ICLR 2017 Reviews , Abhinav Maurya , www.kaggle.com/ahmaurya/iclr2017reviews , Tue Aug 22 2017 09:33:14 GMT+0530 (IST) , ICLR 2017 paper titles authors abstracts reviews and 4-way decisions. ,27, research- linguistics- artificial intelligence- computer science- ,"Context ICLR (International Conference on Learning Representations) is a premier machine learning conference. Unlike the other two flagship machine learning conferences ICML and NIPS ICLR chooses a single-blind public review process in which the reviews and their rebuttals are both carried out transparently and in the open. This dataset was created by crawling the public ICLR 2017 paper review site. It seems ICLR is going double-blind from 2018 so my guess is that authors will remain anonymous during the review process. So this dataset is unique because it captures a public academic review process with academic affiliations and all paper decisions including rejections. Content The dataset consists of two CSV files  iclr2017_papers.csv This file has a row per submission. It includes the paper title authors author conflicts abstracts tl;dr (a simplified abstract) and final decision (Accept/Oral Accept/Poster Accept/InviteToWorkshop Reject). Each row has a unique identifier key called the ""paper_id."" iclr2017_conversations.csv This file has a row per textual review rebuttal or comment. It is related to the previous papers dataset using the secondary key ""paper_id."" All rows talking about a single paper share the same ""paper_id."" The conversations associated with each paper can be thought of as a forest. Each tree in the forest begins with a review followed by rebuttals and further comments/conversation. Each such textual entry composed by an individual is listed in its own row. The nodes of the tree are connected using the fields ""child_id"" and ""parent_id"" which can be used to construct the entire conversation hierarchy.  Acknowledgements All rights for abstracts rest with the paper authors. Reproduction of abstracts here is solely for purposes of research. Thanks to the authors of Beautiful Soup 4 Python package which considerably simplified the process of curating this dataset. Inspiration This dataset was created to understand gender disparities in paper submissions and acceptances. Annotating each author with a binary gender is a pending task. The dataset can also be used to model communication processes employed in negotiation persuasion and decision-making. Another use of this dataset could be in modeling and understanding textual time-series data.",author:child_id:comment:confidence:decision:paper_id:parent_id:question:rating:review:,string:string:string:string:string:string:string:string:string:string:,
Bad teeth sugar and government health spending , churandy , www.kaggle.com/angelmm/healthteethsugar , Fri Aug 19 2016 20:24:43 GMT+0530 (IST) , Thanks to Gapminder Data ,1761, public health- dentistry- health- ,If you get richer your teeth could get worse (if you eat more sugar foods) or better (because of better health assistance or even more education and health-conciousness).  These variables can be analysed with these data downloaded from Gapminder Data  Bad teeth per child (12 yr WHO) GDP/capita (US$ inflation-adjusted World Bank) Government health spending per person (US$ WHO) Sugar comsumption per person (g per day FAO) Literacy rate adult total (% of people ages 15 and above UNESCO) ,Adult..15...literacy.rate......Total:X1975:X1976:X1977:X1978:X1979:X1980:X1981:X1982:X1983:X1984:X1985:X1986:X1987:X1988:X1989:X1990:X1991:X1992:X1993:X1994:X1995:X1996:X1997:X1998:X1999:X2000:X2001:X2002:X2003:X2004:X2005:X2006:X2007:X2008:X2009:X2010:X2011:,string:string:string:string:string:numeric:numeric:string:string:string:numeric:string:string:numeric:string:numeric:string:numeric:string:string:string:string:string:string:string:string:string:numeric:numeric:string:string:string:numeric:string:numeric:string:string:numeric:,
Publicly Supported Symbols of the Confederacy , DaveRosenman , www.kaggle.com/daverosenman/publicly-supported-symbols-of-the-confederacy , Sat Aug 26 2017 01:51:13 GMT+0530 (IST) , Dataset containing over 1500 publicly supported symbols of the confederacy. ,27, ,"Context The Southern Poverty Law Center maintains a list of publicly supported symbols of the confederacy. It is available here. There data table can be downloaded in multiple formats here Content I cleaned up the data set a bit.  Removed the following columns cartodb_id the_geomfield_1uidsecondary_class_for_internal_use Changed 'Unknown' dates to NA Arranged records by states and by feature_name Removed Holidays Changed year_dedicated for the following feature names     - 'City of Confederate Corners' from '1860's (late)' to '1865'         (sourcehttp//www.amap1.org/images/2008%20Folder/AMAP%20Newsletter%2012-08.pdf ...says '1865-ish' so just an estimate) - 'Confederate Monument La Plaza Del Constitucion' from '~1880' to 1879. Source http//www.drbronsontours.com/bronsonconfederatememorial.html  - Changed 'Confederate Women Fountain (Women of the Sixties)' from 1911-1920 to 1916. Source http//www.arkansaspreservation.com/National-Register-Listings/PDF/PU4770S.nr.pdf  - Changed 'Confederate Monument' 'Carline County Courthouse' from 'Unknown (perhaps 1906 see last link in sources)' to 1906.  source  'A History of Caroline County Virginia' By Marshall Wingfield page 243 (https//books.google.com/books?id=xxVhymOH3usC&pg=PA276&lpg=PA276&dq=%22caroline+county%22+confederate+memorial+1906&source=bl&ots=qyRGTV13Js&sig=ii-kA__3BhZg9WzTaD5VCKHb3b8&hl=en&sa=X&ved=0ahUKEwjq-eqj-uHVAhUKJCYKHU-aAs4Q6AEIUzAM#v=snippet&q=monument&f=false)  - Changed ""To Our Soldiers of the Confederacy"" ""King William Courthouse"" from '1901-1903' to 1903. Source http//docsouth.unc.edu/commland/monument/15/   Added rededicated column. Removed rededicated values from year_dedicated column. Rededicated column also includes     -remodeled replacereopened and relocated monuments.  -readopted flags   Acknowledgements Would like to thank the SPLC for making the dataset that this dataset is based on available and for their interesting and important report on the history of confederate public symbols.",feature_name:,string:,
Urban Dictionary Terms , athontz , www.kaggle.com/athontz/urban-dictionary-terms , Tue Mar 28 2017 03:41:16 GMT+0530 (IST) , A collection of 4272 words from UrbanDictionary ,226, dictionaries- linguistics- ,Context I scraped all of the currently available Urban Dictionary pages (611) on 3/26/17 Content  word - the slang term added to urban dictionary definition - the definition of said term author - the user account who contributed the term tags - a list of the hashtags used up - upvotes down - downvotes date - the date the term was added to Urban Dictionary  Acknowledgements I would like to thank my good friend Neil for giving the idea to scrape these terms.,definition:word:author:tags:up:down:date:,string:string:string:string:numeric:numeric:dateTime:,
Wikipedia Edits , ShradhaJoshi , www.kaggle.com/shradhapj/wikipedia-edits , Mon Aug 21 2017 00:34:57 GMT+0530 (IST) , Dataset containing list of wikipedia edits over a period of 20 minutes ,42, ,Context Hey everyone out there! Wikipedia is a publicly available encyclopedia which can be modified by anyone. Some of these modifications are useful whereas some are not. This data set captures all the edits done to English Wikipedia by anyone across the globe. As there are two edits per second the data which I have collected is for just 20 minutes. Content I have revised the original data set removed the duplicates and included only the relevant and useful columns. This data set has below mentioned columns a) action  only edits action is captured. Other actions maybe Talk etc. b) change_size  the number of characters added or deleted. Positive size means the change was added and negative means the change was deleted. c) geo_ip  This is null if the user is registered in Wikipedia otherwise it is a JSON object containing city latitude country_name region_name and longitude d) is_anonymous  This is a flag/boolean value(true/false) that notifies whether the user is registered or unregistered(anonymous) e) is_bot  This flag/boolean value(true/false) determines if the user is a bot(robot) or a human. f) is_minor Thus flag/boolean value(true/false) identifies whether the change made to Wikipedia article was minor or major one. g) page_title  This is the title of the Wikipedia article edited by the user. h) url  This field has the URL or link which compares the Wikipedia article before and after the change. i) user  If the user is unregistered this field will have IP Address either in IPv4 or IPv6 format and if the user is register it will contain the username used when registering on Wikipedia. Acknowledgements I would like to thank hatnote.com from which I could get this data. If you need the original data you may visit www.hatnote.com or directly connect this WebSocket  - ws//wikimon.hatnote.com/en/,edit:-1:null:false:Apollon Patras B.C.:https://en.wikipedia.org/w/index.php?diff=795330615&amp;oldid=794447219:Thanbla:,string:numeric:string:boolean:string:string:string:,
Person of the Year 1927-Present , Time Magazine , www.kaggle.com/timemagazine/magazine-covers , Tue Mar 07 2017 20:31:00 GMT+0530 (IST) , Who has been featured on the magazine cover as Man/Woman of the Year? ,477, news agencies- history- ,"Context TIME's Person of the Year hasn't always secured his or her place in the history books but many honorees remain unforgettable Gandhi Khomeini Kennedy Elizabeth II the Apollo 8 astronauts Anders Borman and Lovell. Each has left an indelible mark on the world. TIME's choices for Person of the Year are often controversial. Editors are asked to choose the person or thing that had the greatest impact on the news for good or ill — guidelines that leave them no choice but to select a newsworthy not necessarily praiseworthy cover subject. Controversial choices have included Adolf Hitler (1938) Joseph Stalin (1939 1942) and Ayatullah Khomeini (1979). TIME's choices for Person of the Year are often politicians and statesmen. Eleven American presidents from FDR to George W. Bush have graced the Person of the Year cover many of them more than once. As commander in chief of one of the world's greatest nations it's hard not to be a newsmaker. Content This dataset includes a record for every Time Magazine cover which has honored an individual or group as ""Men of the Year"" ""Women of the Year"" or (as of 1999) ""Person of the Year"". Acknowledgements The data was scraped from Time Magazine's website. Inspiration Who has been featured on the magazine cover the most times? Did any American presidents not receive the honor for their election victory? How has the selection of Person of the Year changed over time? Have the magazine's choices become more or less controversial?",,,
Hypernymy , Vered Shwartz , www.kaggle.com/vered1986/hypernymy , Sun Aug 13 2017 16:32:40 GMT+0530 (IST) , Pairs of terms annotated to whether one is a hypernym of the other ,44, ,"Context Hypernymy is an important lexical-semantic relation for NLP tasks. For instance knowing that Tom Cruise is an actor can help a question answering system answer the question ""which actors are involved in Scientology?"". While semantic taxonomies like WordNet define hypernymy relations between word types they are limited in scope and domain. Therefore automated methods have been developed to determine for a given term-pair (x y) whether y is an hypernym of x based on their occurrences in a large corpus. To facilitate training neural methods for hypernymy detection which typically require a large amount of training data we followed the common methodology of creating a dataset using distant supervision from knowledge resources and extracted hypernymy relations from WordNet DBPedia Wikidata and Yago. Content All instances in our dataset both positive and negative are pairs of terms that are directly related in at least one of the resources. These resources contain thousands of relations some of which indicate hypernymy with varying degrees of certainty. To avoid including questionable relation types we consider as denoting positive examples only indisputable hypernymy relations (Table 1) which we manually selected from the set of hypernymy indicating relations in Shwartz et al. (2015). Term-pairs related by other relations (including hyponymy) are considered as negative instances and there is a ratio of 14 positive to negative pairs in the dataset.    resourcerelations  WordNetinstance hypernym hypernym  DBPediatype  Wikidatasubclass of instance of  Yagosubclass of    Table 1 hypernymy relations in each resource. We provide two dataset splits random - 70/25/5 ratio for train/test/validation and lexical - where each set has a distinct vocabulary preventing models from overfitting to the most common class of x/y (this split maintains a similar ratio). Files  train_rnd.csv test_rnd.csv val_rnd.csv - the training test and validation set of the random split. train_lex.csv test_lex.csv val_lex.csv - the training test and validation set of the lexical split.  Each file is a comma-separated file with the following fields  x - the first term y - the second term label - TRUE if y is a hypernym of x else FALSE  Acknowledgements If you use this dataset for research purposes please cite the following publication Improving Hypernymy Detection with an Integrated Path-based and Distributional Method.  Vered Shwartz Yoav Goldberg and Ido Dagan. ACL 2016.",menheniot:village:TRUE:,string:string:boolean:,
Proper-names Categories , Vered Shwartz , www.kaggle.com/vered1986/propernames-categories , Sun Aug 13 2017 17:51:18 GMT+0530 (IST) , Is-A relation between a name (e.g. Lady Gaga) and a common noun (e.g. singer) ,44, ,"Context Recognizing lexical inference is an important component in semantic tasks. Various lexical semantic relations such as synonomy class membership part-of and causality may be used to infer the meaning of one word from another in order to address lexical variability. As many of the existing lexical inference datasets are constructed from WordNet important linguistic components that are missing from them are proper-names (Lady Gaga) and recent terminology (social networks). This dataset contains both components.  To construct the dataset we sampled articles from different topics in online magazines. As candidate (x y) pairs we extracted pairs of noun phrases x and y that belonged to the same paragraph in the original text selecting those in which x is a proper-name. These pairs were manually annotated. To balance the ratio of positive and negative pairs in the dataset we sampled negative examples according to the frequency of y in positive pairs creating ""harder"" negative examples such as (Sherlock lady) and (Kylie Minogue vice president). Content This dataset contains pairs of (x y) terms in which x is a proper-name and y is a common noun annotated to whether x is a y. For instance (Lady Gaga singer) is true but (Lady Gaga film) is false.  Files  full_dataset.csv the full dataset train.csv the training set test.csv the test set validation.csv the validation set  Each file is a comma-separated file with the following format  x the x term (proper-name) y the y term (common noun) label TRUE if x is a y else FALSE  Acknowledgements If you use the dataset for any published research please include the following citation ""Learning to Exploit Structured Resources for Lexical Inference"". Vered Shwartz Omer Levy Ido Dagan and Jacob Goldberger. CoNLL 2015.",action bronson:rapper:TRUE:,string:string:boolean:,
LA Vacant Building Complaints , LA Times Data Desk , www.kaggle.com/la-times/la-vacant-building-complaints , Thu Apr 06 2017 03:51:31 GMT+0530 (IST) , Complaints filed with the Los Angeles Department of Building and Safety ,56, cities- architecture- civil engineering- ,"Los Angeles residents have made roughly 4000 complaints since 2011 about abandoned and vacant buildings in the city according to an analysis by the LA Times. This dataset was originally collected and analyzed for ""Fire officials were concerned about Westlake building where 5 died in a blaze"" a June 15 2016 story by the Los Angeles Times. Lists of open and closed complaints filed with the Los Angeles Department of Building and Safety were downloaded from the city's data portal. The two files were combined into a single spreadsheet. A new column called ""Year Received"" was generated from the existing ""Date Received"" field using LibreOffice's YEAR() function. The new file was named combined_complaints.csv. Acknowledgements Data and analysis originally published on the LA Times Data Desk GitHub.",CSR Number:LADBS Inspection District:Address House Number:Address House Fraction Number:Address Street Direction:Address Street Name:Address Street Suffix:Address Street Suffix Direction:Address Street Zip:Date Received:Year Received:Date Closed:Due Date:Case Flag:CSR Priority:GIS Parcel Identification Number(PIN):CSR Problem Type:Area Planning Commission (APC):Case Number Related to CSR:Response Days:Latitude/Longitude:CSR_CASE_NUMBER:,numeric:numeric:numeric:string:string:string:string:string:numeric:dateTime:numeric:string:dateTime:string:numeric:string:string:string:string:string:string:string:,
Racing Kings (chess variant) , SalvadorDali , www.kaggle.com/salvadordali/racingkings , Tue Nov 29 2016 13:06:50 GMT+0530 (IST) , Over 1.5 million racing king chess variant positions ,116, board games- ,1.8 million positions of racing king chess variant  Racing kings is a popular chess variant.  Each player has a standard set of pieces without pawns. The opening setup is as below.    In this game check is entirely forbidden not only is it forbidden to move ones king into check but it is also forbidden to check the opponents king.   The purpose of the game is to be the first player that moves his king to the eight row. When white moves their king to the eight row and black moves directly after that also their king to the last row the game is a draw (this rule is to compensate for the advantage of white that they may move first.)   Apart from the above pieces move and capture precisely as in normal chess.  To learn a little bit more about a game and to experience the evaluation of the position you can play a couple of games here. Do not forget to select Racing kings chess variant and to analyse the game at the end with the machine. Keep in mind that the evaluation score on lichess website is from -10 to 10 and slightly different than in my dataset.  What you get 2 csv files train.csv and validate.csv with 1.5 mln and ~0.35 mln positions. Both have an identical structure FEN of the position and the score. The score is real value in [-1 1] range. The closer it is to 1/-1 the more probable is the win of a white/black player. Due to the symmetry I will explain the score only for a white player (for black is the same just with a negative sign.  1 means that white already won (the game is already finished) 0.98 white has a guaranteed(*) win in maximum 1 move 0.96 ... 2 moves 0.94 ... 3 moves .... 0.82 ... in 9 moves 0.80 ... in 10 or more moves  from 0.4 to 0.8 - white has big advantage. For a good player it is not hard to win in such situation from 0.2 to 0.4 - white has some advantage. Might be hard to convert it to a win from 0 to 0.2 - white has tiny advantage 0 means that the position is either a draw or very close to a draw  (*) Guaranteed means that the machine has found a forced sequence of moves that allows white player to win no matter what moves the opponent will make. If the opponent makes the best moves - the game will finish in x moves but it can finish faster if the black player makes a mistake.  Your goal is to use predict a score of the position knowing its FEN. Use train.csv to build your model and evaluate the performance on the validate.csv dataset (without looking/using it). I used MAE score in my analysis. Construction of the dataset Dataset was constructed by me. I created a bot that plays many games against itself. The bot takes 1 second to analyse the position and selects the move based on the score of position. It took almost a month to generate these positions.  What is the purpose? Currently the plan is to use ML + reinforcement learning to build my own chess bot that will not use alpha-beta prunning for position evaluation and self-play. In a couple of days I will release my own findings as kernels.,,,
Subtitles of The Eleventh House podcast , Binks , www.kaggle.com/binksbiz/robert , Sun Aug 20 2017 02:55:26 GMT+0530 (IST) , Find out hidden meaning behind current affairs ,14, popular culture- storytelling- politics- linguistics- psychology- ,Context Youtube has introduced automatic generation of subtitles based on speech recognition of uploaded video. This dataset provides collection of subtitles Robert Phoenix The 11th House uploaded podcasts. It serves as database for an introduction to algorithmic analysis of spoken language. From the podcasts author description “The Eleventh House is the home of Robert Phoenix a journalist blogger interviewer astrologer and psychic medium with over 30 years experience in personal readings and coaching and has been a media personality in TV and radio. The 11th house delves into the supernatural geopolitics exopolitics conspiracy theories and pop culture.”  Content The 11th House speeches dataset consists of 543 subtitles (sets of words) retrieved from Youtube playlists  https//www.youtube.com/user/FreeAssociationRadio/videos This dataset consists of a single CSV file RobertPhoenixThe11thHouse.csv. The columns are 'id' 'playlist' 'upload_date' 'title' 'view_count' 'average_rating' 'like_count' 'dislike_count' 'subtitles' which are delimited with a comma. Text data in columns 'subtitles' is not sentence based there are not commas or dots. It is only stream of words being translated from speech into text by GoogleVoice (more here https//googleblog.blogspot.com.au/2009/11/automatic-captions-in-youtube.html). Acknowledgements The data was downloaded using youtube-dl package. Inspiration I'm interested in a deeper meaning behind current affairs. (For example see http//www.blogtalkradio.com/freeassociationradio),id:playlist:upload_date:title:view_count:average_rating:like_count:dislike_count:subtitles:,string:string:numeric:string:numeric:numeric:numeric:numeric:string:,
#Charlottesville on Twitter , VincentLa , www.kaggle.com/vincela9/charlottesville-on-twitter , Tue Aug 22 2017 04:06:17 GMT+0530 (IST) , A snapshot of American history in the making ,183, politics- linguistics- twitter- internet- ,"Charlottesville Virgina Charlottesville is home to a statue of Robert E. Lee which is slated to be removed. (For those unfamiliar with American history Robert E. Lee was a US Army general who defected to the Confederacy during the American Civil War and was considered to be one of their best military leaders.) While many Americans support the move believing the main purpose of the Confederacy was to defend the institution of slavery many others do not share this view. Furthermore believing Confederate symbols to be merely an expression of Southern pride many have not taken its planned removal lightly. As a result many people--including white nationalists and neo-Nazis--have descended to Charlottesville to protest its removal. This in turn attracted many counter-protestors. Tragically one of the counter-protestors--Heather Heyer--was killed and many others injured after a man intentionally rammed his car into them. In response President Trump blamed ""both sides"" for the chaos in Charlottesville leading many Americans to denounce him for what they see as a soft-handed approach to what some have called an act of ""domestic terrorism."" This dataset below captures the discussion--and copious amounts of anger--revolving around this past week's events. The Data Description This data set consists of a random sample of 50000 tweets per day (in accordance with the Twitter Developer Agreement) of tweets mentioning Charlottesville or containing ""#charlottesville"" extracted via the Twitter Streaming API starting on August 15.  The files were copied from a large Postgres database containing--currently--over 2 million tweets. Finally a table of tweet counts per timestamp was created using the whole database (not just the Kaggle sample). The data description PDF provides a full summary of the attributes found in the CSV files.  Note While the tweet timestamps are in UTC the cutoffs were based on Eastern Standard Time so the August 16 file will have timestamps ranging from 2017-08-16 40000 UTC to 2017-08-17 40000 UTC. Format The dataset is available as either separate CSV files or a single SQLite database. License I'm releasing the dataset under the CC BY-SA 4.0 license. Furthermore because this data was extracted via the Twitter Streaming API its use must abide by the Twitter Developer Agreement. Most notably the display of individual tweets should satisfy these requirements. More information can be found in the data description file or on Twitter's website. Acknowledgements Obviously I would like to thank Twitter for providing a fast and reliable streaming service. I'd also like to thank the developers of the Python programming language psycopg2 and Postgres for creating amazing software with which this data set would not exist. Image Credit The banner above is a personal modification of these images  Evan Nesterak Image Source Image License Wikipedia user Cville Dog Image Source The Associated Press Image Source  Inspiration I almost removed the header ""inspiration"" from this section because this is a rather sad and dark data set. However this is preciously why this is an important data set to analyze. Good history books have never shied away from unpleasant events and never should we. This data set provides a rich opportunity for many types of research including  Natural language processing Sentiment analysis Data visualization  Furthermore given the political nature of this dataset there are a lot of social science questions that can potentially be answered or at least piqued by this data.",id:user_id:user_name:screen_name:user_statuses_count:user_favorites_count:friends_count:followers_count:user_location:user_description:user_time_zone:user_profile_text_color:user_profile_background_color:full_text:created_at:is_retweet:retweeted_status_text:retweeted_status_id:quoted_status_text:quoted_status_id:in_reply_to_screen_name:in_reply_to_status_id:in_reply_to_user_id:hashtags:,numeric:numeric:string:string:numeric:numeric:numeric:numeric:string:string:string:numeric:numeric:string:dateTime:string:string:string:string:numeric:string:numeric:numeric:string:,
Opendata AIG Brazil , Nosbielcs , www.kaggle.com/nosbielcs/opendataaigbrazil , Mon Oct 02 2017 23:00:29 GMT+0530 (IST) , Aircraft Accidents in Brazil ,94, brazil- aviation- ,"Opendata AIG Brazil Sobre o Projeto  Download dos Dados  OCORRÊNCIAS AERONÁUTICAS AERONAVES ENVOLVIDAS FATORES CONTRIBUINTES RECOMENDAÇÕES DE SEGURANÇA  Notas Técnicas  Os textos dentro das colunas estão denotados por aspas duplas (""""). As colunas das tabelas estão separadas por til (~). As tabelas contém cabeçalhos que identificam suas colunas. Em cada tabela existe uma coluna contendo a informação sobre a data de extração dos dados.  Outras Informações ""For Dummies""  Os relatórios finais podem ser consultados no site do CENIPA - Relatórios. As recomendações de segurança podem ser consultadas no site do CENIPA - Recomendações. Artigos científicos sobre o tema podem ser encontrados / publicados na Revista Conexão SIPAER.  Outros Recursos Outras bases de dados para consultas  NTSB BEA RISCO DA FAUNA RAIO LASER RISCO BALOEIRO AERÓDROMOS BRASILEIROS AEROVIAS BRASILEIRAS  Dicas para melhor aproveitamento dos recursos  Antes de fazer o download dos dados leia com calma todo o texto desta página. Este recurso irá guiá-lo(a) para um adequado entendimento sobre os relacionamentos entre os conjuntos de dados disponíveis (ocorrencia aeronave envolvida fator_contribuinte e recomendações de segurança). Para aprofundar-se no tema visite o site do CENIPA e confira as LEGISLAÇÕES que norteiam a investigação e prevenção de acidentes aeronáuticos no Brasil. Conheça o Manual de Investigação do SIPAER. Nos anexos deste documento você encontrará uma tabela de domínios (taxonomia) para algumas das variáveis disponíveis nos conjuntos de dados. Devido ao dinamismo dos trabalhos de investigação e preocupação do CENIPA com a agilidade na disponibilização dos dados os conjuntos de dados estarão sujeitos a modificações sempre que forem atualizados. Portanto sempre que possível utilize a ""data de extração"" dos conjuntos de dados para justificar/referenciar os seus estudos e análises. Saiba como trabalhar com dados no formato CSV. Clique aqui para aprender  Dúvidas Se persistirem dúvidas por gentileza me enviem uma Issue (relatar problema). Clique aqui para relatar um Problema",codigo_ocorrencia:ocorrencia_classificacao:ocorrencia_tipo:ocorrencia_dia:ocorrencia_horario:ocorrencia_cidade:ocorrencia_uf:ocorrencia_pais:ocorrencia_aerodromo:aeronave_matricula:aeronave_equipamento:aeronave_fabricante:aeronave_modelo:aeronave_tipo_motor:aeronave_quantidade_motores:aeronave_peso_maximo_decolagem:aeronave_quantidade_assentos:aeronave_ano_fabricacao:aeronave_pais_registro:aeronave_categoria_registro:aeronave_segmento_aviacao:aeronave_origem_voo:aeronave_destino_voo:aeronave_fase_voo:aeronave_tipo_operacao:aeronave_nivel_dano:quantidade_fatalidades:quantidade_fatores_contribuintes:fator_1:fator_2:fator_3:fator_4:fator_5:fator_6:fator_7:fator_8:fator_9:fator_10:fator_11:fator_12:fator_13:fator_14:fator_15:fator_16:fator_17:fator_18:fator_19:fator_20:fator_21:fator_22:fator_23:fator_24:fator_25:fator_26:fator_27:fator_28:fator_29:fator_30:fator_31:fator_32:fator_33:fator_34:fator_35:fator_36:fator_37:fator_38:fator_39:fator_40:fator_41:fator_42:fator_43:fator_44:fator_45:fator_46:fator_47:fator_48:fator_49:fator_50:fator_51:fator_52:fator_53:fator_54:fator_55:fator_56:fator_57:fator_58:fator_59:fator_60:fator_61:fator_62:fator_63:fator_64:fator_65:fator_66:fator_67:fator_68:fator_69:fator_70:fator_71:fator_72:fator_73:fator_74:fator_75:fator_76:fator_77:fator_78:fator_79:fator_80:fator_81:fator_82:fator_83:fator_84:fator_85:fator_86:fator_87:dia_extracao:,numeric:string:string:dateTime:dateTime:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:dateTime:,
Hong Kong Marathon 2016 results , melvincheung , www.kaggle.com/melvincheung/hong-kong-marathon-2016 , Tue Oct 04 2016 19:55:11 GMT+0530 (IST) , A race participated by 12k+ athletes from 50+ countries ,1082, running- walking- ,"From the data you will have   - Results from 12k+ participants with the fastest one of 2hr12mins from world class athlete  - Midway time at 10km halfway and 30km  - Overall and gender ranking  The original source The data are captured from its official site http//www.hkmarathon.com/Results/Search_2016_Results.htm Only marathon results are included (but not 10km nor half marathon) because only this results has midway time which can serve better analysis purposes.  The fields Race No runner ID Category gender and age group. (e.g. MMS and MFS denote male and female while the age group are the same.) Official Time the ""gun time"" Net Time the time between one passes the starting line and final line. It is usually a few minutes less than Official Time. 10km Time Half Way Time 30km Time they are the midway times as described  The files Marathon challenge and Marathon Run 1 uses the same running path for racing but with a different starting time. Athletes in challenge group are generally run faster.  Improving the dataset   - Comparing the results of different marathons all over the world to find which one is the toughest or having the best participants etc.  - Please let me know if there is any centralized database collecting the results from different races.",Overall Position:Gender Position:Category Position:Category:Race No:Country :Official Time:Net Time:10km Time:Half Way Time:30km Time:,numeric:numeric:numeric:string:numeric:string:numeric:numeric:numeric:numeric:numeric:,
KCBS Barbeque Competitions ,73805, www.kaggle.com/jaysobel/kcbs-bbq , Thu Jul 20 2017 23:22:21 GMT+0530 (IST) , Competition context and results from 1559 KCBS Barbeque Competitions ,119, food culture- food and drink- ,"Context This data set is the aggregate of 1559 KCBS competitions from July 2013 through December 2016. The Kansas City Barbeque Society (KCBS) is ""world's largest organization of barbeque and grilling enthusiasts with over 20000 members worldwide."" The data set was constructed by scraping the KCBS events page A Standard Competition At a standard KCBS BBQ Competition 30 certified barbeque judges (CBJs) blindly judge the BBQ served by 36 teams. Judges are broken up into tables of 6. There are four categories of meat chicken pork ribs pork and brisket. Each judge receives six samples representing six different teams.  Scoring Samples are scored across three characteristics appearance taste and tenderness. Scores range from 0 to 9 with a 9 being perfect a 6 corresponding to average and a 0 given as part of a DQ or other official sanction.      A team's score within a category is calculated by a weighted sum of the six judges' scores. The KCBS scoring weights were last changed in July 2013 which aligns with the start date of this data set. The maximum score in a category is 180 (9 points * 3 characteristics * 6 judges). The maximum overall score in a standard 4-category competition is 720 (180 points * 4 categories). Not all competitions in this data set are standard 4-category; see the is_standard feature. Content Competition Data Features This CSV file contains 1559 rows of competition data. Scoring and placing resultsare stored separately across five category-specific files. The scoring results are linked to their competitions by a foreign key. There are many results for each competition in this file.  contest_key - the primary key used to link rows of results to a competition date - the date of the competition title - the name of the competition location_str - the full string of the location ie New Palestine IN city - the city extracted from location_str state - the state abbreviation extracted from location_str state_full - the full name of the state extrapolated from state prize - the total prize money awarded (I believe it's total and not just 1st place) cbj_percentage - the percentage of judges that are certified barbeque judges (CBJs) is_championsip - a boolean indicating if the competition is a ""state championship"" (note each state has more than one per year) is_standard - a boolean indicating if the competition consists of and only of the four categories chicken pork ribs pork and brisket. Some competitions include extra categories like dessert and these are considered non-standard (note overall scores in a non-standard competition may be greater that 4 * 180)  Results Data Features There are five separate tables of results; one for each of the standard categories. The features are the same across each of these tables.   contest_key - the foreign key linking a result row to its competition place - the place earned by a competing team (1st 2nd 3rd as 1 2 3) score - the total score (0-180 in a chicken ribs pork and brisket 0-720 in overall-- assuming a standard competition) team_name - the name of the team (usually clever and good for a word cloud!)  Acknowledgements I'd like to thank the KCBS for providing fun opportunities to taste great BBQ and recording event data on the website in an fairly accessible and light-weight manner. In the future I'd love to experiment with anonymized judge scoring data. A judge can view their scoring history and how it compared sample-by-sample with other judges' scores at the table.  Inspiration I've been a CBJ for 4 years!",contest_key:date:title:location_str:city:state:state_full:prize:cbj_percentage:is_championship:is_standard:url:,numeric:dateTime:string:string:string:string:string:numeric:numeric:boolean:boolean:string:,
Austin Weather , GrubenM , www.kaggle.com/grubenm/austin-weather , Tue Aug 15 2017 08:19:18 GMT+0530 (IST) , Historical temperature precipitation humidity and windspeed for Austin Texas ,64, ,Context This dataset is meant to complement the Austin Bikesharing Dataset. Content Contains the  Date (YYYY-MM-DD)  TempHighF (High temperature in Fahrenheit)  TempAvgF (Average temperature in Fahrenheit)  TempLowF (Low temperature in Fahrenheit)  DewPointHighF (High dew point in Fahrenheit)  DewPointAvgF (Average dew point in Fahrenheit)  DewPointLowF (Low dew point in Fahrenheit)  HumidityHighPercent (High humidity as a percentage)  HumidityAvgPercent (Average humidity as a percentage)  HumidityLowPercent (Low humidity as a percentage)  SeaLevelPressureHighInches (High sea level pressure in inches)  SeaLevelPressureAvgInches (Average sea level pressure in inches)  SeaLevelPressureLowInches (Low sea level pressure in inches)  VisibilityHighMiles (High visibility in miles)  VisibilityAvgMiles (Average visibility in miles)  VisibilityLowMiles (Low visibility in miles)  WindHighMPH (High wind speed in miles per hour)  WindAvgMPH (Average wind speed in miles per hour)  WindGustMPH (Highest wind speed gust in miles per hour)  PrecipitationSumInches (Total precipitation in inches)  ('T' if Trace)  Events (Adverse weather events.  ' ' if None)   This dataset contains data for every date from 2013-12-21 to 2017-07-31. Acknowledgements This dataset was obtained from WeatherUnderground.com at the Austin KATT station. Inspiration Can we use this dataset to explain some of the variation in the Austin Bikesharing Dataset?,TempHighF:TempAvgF:TempLowF:DewPointHighF:DewPointAvgF:DewPointLowF:HumidityHighPercent:HumidityAvgPercent:HumidityLowPercent:SeaLevelPressureHighInches:SeaLevelPressureAvgInches:SeaLevelPressureLowInches:VisibilityHighMiles:VisibilityAvgMiles:VisibilityLowMiles:WindHighMPH:WindAvgMPH:WindGustMPH:PrecipitationSumInches:Events:Date:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:dateTime:,
Crop Nutrient Database , Chris Crawford , www.kaggle.com/crawford/crop-nutrient-database , Sat Aug 19 2017 00:00:49 GMT+0530 (IST) , USDA data about crop nutrients in the U.S. ,79, food and drink- science and culture- united states- plants- health- ,Context The PLANTS Database provides standardized information about the vascular plants mosses liverworts hornworts and lichens of the U.S. and its territories. It includes names plant symbols checklists distributional data species abstracts characteristics images plant links references and crop information and automated tools. This particular dataset is the Crop Nutrient Database. Content These are the fields included in the dataset. I'll be honest I have no idea what some of them mean  Crop ScientificName Symbol NuContAvailable PlantPartHarvested CropCategory YieldUnit AvYieldUnitWeight(lb) AvMoisture% AvN%(dry) AvP%(dry) AvK%(dry) YieldUnitWeight(lb)_set YieldUnitWeight(lb)_Bau YieldUnitWeight(lb)_Joh YieldUnitWeight(lb)_Roberts YieldUnitWeight(lb)_WEEP YieldUnitWeight(lb)_Men YieldUnitWeight(lb)_Guy YieldUnitWeight(lb)_Mc YieldUnitWeight(lb)_Mah YieldUnitWeight(lb)_Sha YieldUnitWeight(lb)_Sch YieldUnitWeight(lb)_Atu YieldUnitWeight(lb)_Zim YieldUnitWeight(lb)_Scu YieldUnitWeight(lb)_John YieldUnitWeight(lb)_Arc DryMatter%_M-FF DryMatter%_NAS DryMatter%_F&L DryMatter%_F&N DryMatter%_Alb DryMatter%_Est1 DryMatter%_Est2 DryMatter%_Est3 DryMatter%_Est4 DryMatter%_Est5 DryMatter%_Est6 DryMatter%_M&R DryMatter%_M&L DryMatter%_Sun DryMatter%_Gro DryMatter%_AgH8-9 DryMatter%_AgH8-12 DryMatter%_B788 AvDryMatter% N%(dry)_NAS N%(dry)_F&L N%(dry)_F&N N%(dry)_Swa N%(dry)_Chapko N%(dry)_Hill N%(dry)_Bru N%(dry)_AgH8-9 N%(dry)_AgH8-12 N%(dry)_B788 N%(dry)_M&L N%(dry)_M-FF N%(dry)_M&R N%(dry)_Foster N%(dry)_Rob1 N%(dry)_Rob2 N%(dry)_Coa N%(dry)_And N%(dry)_Gol1 N%(dry)_Gol2 N%(dry)_Wol N%(dry)_Pete N%(dry)_Col N%(dry)_Alb N%(dry)_Arc N%(dry)_Bis N%(dry)_Gar N%(dry)_Heg N%(dry)_Flo N%(dry)_Feil N%(dry)_Bre N%(dry)_Burns N%(dry)_Coc P%(dry)_M-FF P%(dry)_NAS P%(dry)_F&L P%(dry)_F&N P%(dry)_AgH8-9 P%(dry)_AgH8-12 P%(dry)_B788 P%(dry)_M&L P%(dry)_L&V P%(dry)_Foster P%(dry)_Rob1 P%(dry)_Rob2 P%(dry)_Coa P%(dry)_And P%(dry)_Gol1 P%(dry)_Gol2 P%(dry)_Sims P%(dry)_Wol P%(dry)_Pete P%(dry)_Col P%(dry)_Alb P%(dry)_Arc P%(dry)_Swa P%(dry)_Rei K%(dry)_M-FF K%(dry)_NAS K%(dry)_F&L K%(dry)_F&N K%(dry)_AgH8-9 K%(dry)_AgH8-12 K%(dry)_B788 K%(dry)_Foster K%(dry)_Rob1 K%(dry)_Rob2 K%(dry)_Coa K%(dry)_And K%(dry)_Gol1 K%(dry)_Gol2 K%(dry)_Sims K%(dry)_Wol K%(dry)_Pete K%(dry)_Col K%(dry)_Alb K%(dry)_Arc K%(dry)_Swa K%(dry)_Rei Moisture%_M&R Moisture%_M&L Moisture%_Sun Moisture%_Gro gWater/100g_AgH8-9 gWater/100g_AgH8-12 gWater/100g_B788 Protein%(dry)_NAS Protein%(dry)_F&L Protein%(dry)_F&N Protein%(dry)_Swa Protein%(dry)_Chapko Protein%(dry)_Hill Protein%(dry)_Bru Protein%(dry)_Bis Protein%(dry)_Gar Protein%(dry)_Heg Protein%(dry)_Flo Protein%(dry)_Feil Protein%(dry)_Bre Protein%(dry)_Burns gProtein/100g(wet)_AgH8-9 gProtein/100g(wet)_AgH8-12 gProtein/100g(wet)_B788 Protein%(wet)_M&L N%(wet)_M-FF P%(wet)_M-FF gP/100g(wet)_AgH8-9 gP/100g(wet)_AgH8-12 gP/100g(wet)_B788 P%(wet)_M&L K%(wet)_M-FF gK/100g(wet)_AgH8-9 gK/100g(wet)_AgH8-12 gK/100g(wet)_B788 ,Crop:ScientificName:Symbol:NuContAvailable:PlantPartHarvested:CropCategory:YieldUnit:AvYieldUnitWeight(lb):AvMoisture%:AvN%(dry):AvP%(dry):AvK%(dry):YieldUnitWeight(lb)_set:YieldUnitWeight(lb)_Bau:YieldUnitWeight(lb)_Joh:YieldUnitWeight(lb)_Roberts:YieldUnitWeight(lb)_WEEP:YieldUnitWeight(lb)_Men:YieldUnitWeight(lb)_Guy:YieldUnitWeight(lb)_Mc:YieldUnitWeight(lb)_Mah:YieldUnitWeight(lb)_Sha:YieldUnitWeight(lb)_Sch:YieldUnitWeight(lb)_Atu:YieldUnitWeight(lb)_Zim:YieldUnitWeight(lb)_Scu:YieldUnitWeight(lb)_John:YieldUnitWeight(lb)_Arc:DryMatter%_M-FF:DryMatter%_NAS:DryMatter%_F&L:DryMatter%_F&N:DryMatter%_Alb:DryMatter%_Est1:DryMatter%_Est2:DryMatter%_Est3:DryMatter%_Est4:DryMatter%_Est5:DryMatter%_Est6:DryMatter%_M&R:DryMatter%_M&L:DryMatter%_Sun:DryMatter%_Gro:DryMatter%_AgH8-9:DryMatter%_AgH8-12:DryMatter%_B788:AvDryMatter%:N%(dry)_NAS:N%(dry)_F&L:N%(dry)_F&N:N%(dry)_Swa:N%(dry)_Chapko:N%(dry)_Hill:N%(dry)_Bru:N%(dry)_AgH8-9:N%(dry)_AgH8-12:N%(dry)_B788:N%(dry)_M&L:N%(dry)_M-FF:N%(dry)_M&R:N%(dry)_Foster:N%(dry)_Rob1:N%(dry)_Rob2:N%(dry)_Coa:N%(dry)_And:N%(dry)_Gol1:N%(dry)_Gol2:N%(dry)_Wol:N%(dry)_Pete:N%(dry)_Col:N%(dry)_Alb:N%(dry)_Arc:N%(dry)_Bis:N%(dry)_Gar:N%(dry)_Heg:N%(dry)_Flo:N%(dry)_Feil:N%(dry)_Bre:N%(dry)_Burns:N%(dry)_Coc:P%(dry)_M-FF:P%(dry)_NAS:P%(dry)_F&L:P%(dry)_F&N:P%(dry)_AgH8-9:P%(dry)_AgH8-12:P%(dry)_B788:P%(dry)_M&L:P%(dry)_L&V:P%(dry)_Foster:P%(dry)_Rob1:P%(dry)_Rob2:P%(dry)_Coa:P%(dry)_And:P%(dry)_Gol1:P%(dry)_Gol2:P%(dry)_Sims:P%(dry)_Wol:P%(dry)_Pete:P%(dry)_Col:P%(dry)_Alb:P%(dry)_Arc:P%(dry)_Swa:P%(dry)_Rei:K%(dry)_M-FF:K%(dry)_NAS:K%(dry)_F&L:K%(dry)_F&N:K%(dry)_AgH8-9:K%(dry)_AgH8-12:K%(dry)_B788:K%(dry)_Foster:K%(dry)_Rob1:K%(dry)_Rob2:K%(dry)_Coa:K%(dry)_And:K%(dry)_Gol1:K%(dry)_Gol2:K%(dry)_Sims:K%(dry)_Wol:K%(dry)_Pete:K%(dry)_Col:K%(dry)_Alb:K%(dry)_Arc:K%(dry)_Swa:K%(dry)_Rei:Moisture%_M&R:Moisture%_M&L:Moisture%_Sun:Moisture%_Gro:gWater/100g_AgH8-9:gWater/100g_AgH8-12:gWater/100g_B788:Protein%(dry)_NAS:Protein%(dry)_F&L:Protein%(dry)_F&N:Protein%(dry)_Swa:Protein%(dry)_Chapko:Protein%(dry)_Hill:Protein%(dry)_Bru:Protein%(dry)_Bis:Protein%(dry)_Gar:Protein%(dry)_Heg:Protein%(dry)_Flo:Protein%(dry)_Feil:Protein%(dry)_Bre:Protein%(dry)_Burns:gProtein/100g(wet)_AgH8-9:gProtein/100g(wet)_AgH8-12:gProtein/100g(wet)_B788:Protein%(wet)_M&L:N%(wet)_M-FF:P%(wet)_M-FF:gP/100g(wet)_AgH8-9:gP/100g(wet)_AgH8-12:gP/100g(wet)_B788:P%(wet)_M&L:K%(wet)_M-FF:gK/100g(wet)_AgH8-9:gK/100g(wet)_AgH8-12:gK/100g(wet)_B788:,string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:numeric:string:numeric:numeric:numeric:numeric:string:string:string:string:string:numeric:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:string:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:numeric:string:string:numeric:numeric:string:numeric:string:string:numeric:string:numeric:string:,
Delhi Weather Data , MahirKukreja , www.kaggle.com/mahirkukreja/delhi-weather-data , Tue Apr 25 2017 02:28:52 GMT+0530 (IST) , Delhi Weather Data from 1997 to 2016 december ,666, climate- ,Context This dataset contains weather data for New Delhi India. Content This data was taken out from wunderground with the help of their easy to use api. It contains various features such as temperature pressure humidity rain precipitationetc. Acknowledgements This data is owned by wunderground and although I ended up using noaa's data for my research i thought that i'd share this data here as I haven't worked on hourly data yet and this might be of huge importance. Inspiration The main target is to develop a prediction model accurate enough for predicting the weather. We can try something like predicting the weather in the next 24 hours like microsoft tried some time back. https//blogs.microsoft.com/next/2015/08/10/hows-the-weather-using-artificial-intelligence-for-better-answers/#sm.018l60051a9neka10is1m5qpi6u5y,datetime_utc: _conds: _dewptm: _fog: _hail: _heatindexm: _hum: _precipm: _pressurem: _rain: _snow: _tempm: _thunder: _tornado: _vism: _wdird: _wdire: _wgustm: _windchillm: _wspdm:,string:string:numeric:numeric:numeric:string:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:numeric:,
1000 Netflix Shows , Chase Willden , www.kaggle.com/chasewillden/netflix-shows , Sun Jun 11 2017 09:00:16 GMT+0530 (IST) , Understand the rating distributions of Netflix shows ,765, film- internet- ,Context Netflix in the past 5-10 years has captured a large populate of viewers. With more viewers there most likely an increase of show variety. However do people understand the distribution of ratings on Netflix shows? Content Because of the vast amount of time it would take to gather 1000 shows one by one the gathering method took advantage of the Netflix’s suggestion engine. The suggestion engine recommends shows similar to the selected show. As part of this data set I took 4 videos from 4 ratings (totaling 16 unique shows) then pulled 53 suggested shows per video. The ratings include G PG TV-14 TV-MA. I chose not to pull from every rating (e.g. TV-G TV-Y etc.). Acknowledgements The data set and the research article can be found at The Concept Center Inspiration I was watching Netflix with my wife and we asked ourselves why are there so many R and TV-MA rating shows?,title:rating:ratingLevel:ratingDescription:release year:user rating score:user rating size:,string:string:string:numeric:numeric:numeric:numeric:,
Historical American Lynching , Rachael Tatman , www.kaggle.com/rtatman/historical-american-lynching , Thu Aug 17 2017 05:18:54 GMT+0530 (IST) , Information on 2806 lynchings in the United States ,28, united states- death- crime- violence- ,"Context ""Lynching"" historically includes not only Southern lynching but frontier lynching and vigilantism nationwide and many labor-related incidents.  Persons of any race or ethnicity and either gender may have been either perpetrators or victims of lynching. The lynchings in this dataset follow an NAACP definition for including an incident in the inventory of lynchings  There must be evidence that someone was killed; The killing must have occurred illegally; Three or more persons must have taken part in the killing; and The killers must have claimed to be serving justice or tradition.  Content The original data came from the NAACP Lynching Records at Tuskegee Institute Tuskegee Alabama.  Stewart Tolnay and E.M. Beck examined these records for name and event duplications and other errors with funding from a National Science Foundation Grant and made their findings available to Project HAL in 1998. Project HAL is inactive now but it’s original purpose was to build a data set for researchers to use and to add to.  The dataset contains the following information for each of the 2806 reported lynchings  State State where the lynching took place Year Year of the lynching Mo Month Day Day Victim Name of the victim County County where the lynching occurred (keep in mind that county names have changed & boundaries redrawn) Race Race of the victim Sex Sex of the victim Mob Information on the mob Offense Victim’s alleged offense Note Note (if any) 2nd Name Name of the 2nd victim (if any) 3rd Name Name of the 3rd victim (if any) Comments Comments (if any) Source Source of the information (if any)  Acknowledgements This dataset was compiled by Dr. Elizabeth Hines and Dr. Eliza Steelwater. If you use this dataset in your work please include the following citation  Hines E. & Steelwater E. (2006). Project Hal Historical American Lynching Data Collection Project. University of North Carolina http//people.uncw.edu/hinese/HAL/HAL%20Web%20Page.htm You may also like  Bryan Stevenson’s Equal Justice Initiative EJI posts lynching information and stories and is currently quite active  https//www.eji.org/ First Person Narratives of the American South Personal accounts of Southern life between 1860 and 1920  Inspiration  Can you use the county-level data in this dataset to create a map of lynchings in the US? What demographic qualities were most associated with lynching victims? How did patterns of lynching change over time? ",State:Year:Mo:Day:Victim:County:Race:Sex:Mob:Offense:Note:2nd Name:3rd Name:Comments:Source:,string:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:,
UK Land Registry Transactions , HM Land Registry , www.kaggle.com/hm-land-registry/uk-land-registry-transactions , Thu Aug 17 2017 23:21:38 GMT+0530 (IST) , Applications for first registrations leases dealings searches etc ,48, housing- finance- government- ,Transaction data gives numbers of applications for first registrations leases transfers of part dealings official copies and searches lodged with HM Land Registry by account holders in the preceding month. The information is divided into data showing all applications lodged transactions for value by region and local authority district. Transactions for value include freehold and leasehold sales. The data published on this page gives you information about the number and types of applications. The data reflects the volume of applications lodged by customers using an HM Land Registry account number on their application form. The data does not include applications that are not yet completed or were withdrawn. Content This dataset has been altered from its original format. Specifically the monthly files have been aggregated and columns whose names changed over time have been merged to use the current title.  Some acronyms that will be helpful to know while reading the column names per the documentation Acronym Title   Description DFL Dispositionary first lease  An application for the registration of a new lease granted by the proprietor of registered land DLG Dealing An application in respect of registered land. This includes transfers of title charges and notices FR  First registration  An application for a first registration of land both freehold and leasehold. For leasehold this applies when  the landlord’s title is not registered TP  Transfer of part    An application to register the transfer of part of a registered title OS(W)   Search of whole An application to protect a transaction for value such as purchase lease or charge for the whole of a title OS(P)   Search of part  An application to protect a transaction for value such as purchase lease or charge for part of a title OS(NPW) Non-priority search of whole    An application to search the whole of the register without getting priority OS(NPP) Non-priority search of part An application to search a part of the register without getting priority OC1 Official copy   An application to obtain an official copy of a register or title plan represents a true record of entries in the register and extent of the registered title at a specific date and time. The data includes historical editions of the register and title plan where they are kept by the registrar in electronic form OC2 Official copy of a deed or document An application to obtain a copy of a document referred to in the register or relates to an application. This includes correspondence surveys application forms and emails relating to applications that are pending cancelled or completed SIM Search of the index map An application to find out whether or not land is registered and if so to obtain the title number Acknowledgements This data was kindly released by HM Land Registry under the Open Government License 3.0. You can find their current release here. Inspiration -What does this dataset tell us about the HM Land Registry's records of housing Prices Paid? Are searches a leading indicator of price changes?,Account Customer:FR:DFL:TP:DLG:OS(W):OS(NPW):OS(P):OS(NPP):SIMS:OC1:OC2:Total:date:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:dateTime:,
NASCAR Champion History (1949-Present) , David Rubal , www.kaggle.com/drubal/nascar-champion-history-1949present , Thu Aug 17 2017 21:20:34 GMT+0530 (IST) , 67 Years of NASCAR Champion History Data ,43, ,Context I have been a NASCAR fan since the 1970s and share the amazing history of this sport by creating and posting a simple dataset focused on 67 years of NASCAR Champion history (1949-Present). Content There are five columns (Year Driver Car Number Manufacturer and Wins) and 116 rows in this dataset. I will update the dataset every every year going forward after the champion has been determined. Please suggest other data to be included in the dataset! Acknowledgements The NASCAR information was compiled from information found on https//en.wikipedia.org/wiki/List_of_Monster_Energy_NASCAR_Cup_Series_champions,Year:Driver:Car Number:Car Manufacturer:Wins:,numeric:string:numeric:string:numeric:,
Moscow Ring Roads , Chippy , www.kaggle.com/nigelcarpenter/sberbankmoscowroads , Sat May 27 2017 04:57:38 GMT+0530 (IST) , Shapefiles for use in Sberbank ,1119, russia- geography- ,Context This data set was created for use in the Sberbank Kaggle competition.  Content The data consists of three GIS shapefiles one for each of the 3 major Moscow ring roads; the MKAD TTK (or third ring) and Sadovoe (or garden ring). Acknowledgements The road shapefiles have been extracted from OpenStreetMap data processed in QGiS to extract only the roads of interest.    OpenStreetMap License https//www.OpenStreetMap.org/copyright  Inspiration With these files and the distances given in the Sberbank dataset it should be possible to better understand the location of properties. With a better understanding of location it may be possible to improve the quality of the overall dataset which contains material amounts of missing or poorly coded data.,key:id:lat:lon:tolerance_m:,string:numeric:numeric:numeric:numeric:,
United States Energy Census and GDP 2010-2014 , Lislejoem , www.kaggle.com/lislejoem/us_energy_census_gdp_10-14 , Sat Mar 25 2017 19:28:43 GMT+0530 (IST) , Examining the relationships between various data collected by the US government ,1278, energy- ,"The purpose of this data set is to allow exploration between various types of data that is commonly collected by the US government across the states and the USA as a whole. The data set consists of three different types of data  Census and Geographic Data; Energy Data; and  Economic Data.  When creating the data set I combined data from many different types of sources all of which are cited below. I have also provided the fields included in the data set and what they represent below. I have not performed any research on the data yet but am going to dive in soon. I am particularly interested in the relationships between various types of data (i.e. GDP or birth rate) in prediction algorithms. Given that I have compiled 5 years’ worth of data this data set was primarily constructed with predictive algorithms in mind. An additional note before you delve into the fields  * There could have been many more variables added across many different fields of metrics. I have stopped here but it could potentially be beneficial to observe the interaction of these variables with others (i.e. the GDP of certain industries the average age in a state the male/female gender ratio etc.) to attempt to find additional trends. Census and Geographic Data  StateCodes The state 2-letter abbreviations. Note that I added ""US"" for the United States. Region The number corresponding to the region the state lies within according to the 2010 census. (1 = Northeast 2 = Midwest 3 = South 4 = West) Division The number corresponding to the division the state lies within according to the 2010 census. (1 = New England 2 = Middle Atlantic 3 = East North Central 4 = West North Central 5 = South Atlantic 6 = East South Central 7 = West South Central 8 = Mountain 9 = Pacific) Coast Whether the state shares a border with an ocean. (1 = Yes 0 = No) Great Lakes Whether the state shares a border with a great lake. (1 = Yes 0 = No CENSUS2010POP 4/1/2010 resident total Census 2010 population POPESTIMATE{year} 7/1/{year} resident total population estimate RBIRTH{year} Birth rate in period 7/1/{year - 1} to 6/30/{year} RDEATH{year} Death rate in period 7/1/{year - 1} to 6/30/{year} RNATURALINC{year} Natural increase rate in period 7/1/{year - 1} to 6/30/{year} RINTERNATIONALMIG{year} Net international migration rate in period 7/1/{year - 1} to 6/30/{year} RDOMESTICMIG{year} Net domestic migration rate in period 7/1/{year - 1} to 6/30/{year} RNETMIG{year} Net migration rate in period 7/1/{year - 1} to 6/30/{year}  As noted from the census  Net international migration for the United States includes the international migration of both native and foreign-born populations. Specifically it includes (a) the net international migration of the foreign born (b) the net migration between the United States and Puerto Rico (c) the net migration of natives to and from the United States and (d) the net movement of the Armed Forces population between the United States and overseas. Net international migration for Puerto Rico includes the migration of native and foreign-born populations between the United States and Puerto Rico.  Codes for most of the data information about the geographic terms and coditions and more information about the methodology behind the population estimates can be found on the US Census website. Energy Data  TotalC{year} Total energy consumption in billion BTU in given year. TotalP{year} Total energy production in billion BTU in given year. TotalE{year} Total Energy expenditures in million USD in given year. TotalPrice{year} Total energy average price in USD/million BTU in given year. TotalC{first year}–{second year} The first year’s total energy consumption divided by the second year’s total energy consumption times 100. (The percent change between years in total energy consumption.) TotalP{first year}–{second year} The first year’s total energy production divided by the second year’s total energy production times 100. (The percent change between years in total energy production.) TotalE{first year}–{second year} The first year’s total energy expenditure divided by the second year’s total energy expenditure times 100. (The percent change between years in total energy expenditure.) TotalPrice{first year}–{second year} The first year’s total energy average price divided by the second year’s total energy average price times 100. (The percent change between years in total energy average price.) BiomassC{year} Biomass total consumption in billion BTU in given year. CoalC{year} Coal total consumption in billion BTU in given year. CoalP{year} Coal total production in billion BTU in given year. CoalE{year} Coal total expenditures in million USD in given year. CoalPrice{year} Coal average price in USD per million BTU in given year. ElecC{year} Electricity total consumption in billion BTU in given year. ElecE{year} Electricity total expenditures in million USD in given year. ElecPrice{year} Electricity average price in USD per million BTU in given year. FossFuelC{year} Fossil fuels total consumption in billion BTU in given year. GeoC{year} Geothermal energy total consumption in billion BTU in given year. GeoP{year} Geothermal energy net generation in the electric power sector in million kilowatt hours in given year. HydroC{year} Hydropower total consumption in billion BTU in given year. HydroP{year} Hydropower total net generation in million kilowatt hours in given year. NatGasC{year} Natural gas total consumption (including supplemental gaseous fuels) in billion BTU in given year. NatGasE{year} Natural gas total expenditures in million USD in given year. NatGasPrice{year} Natural gas average price in USD per million BTU in given year.  LPGC{year} LPG total consumption in billion BTU in given year. LPGE{year} LPG total expenditures in million USD in given year. LPGPrice{year} LPG average price in USD per million BTU in given year.   Notes  BTU stands for British Thermal Unit and is a unit of measurement for energy. One BTU is equal to the amount of energy used to raise the temperature of one pound of water on degree Fahrenheit. Many other types of energy and their associated consumption production expenditure and price totals can be found from the EIA; this is where I received the data I used in compiling this dataset.  Economic Data  GDP{year}{quarter} The GDP in the provided quarter of the given year (in million USD). GDP{year} The average GDP throughout the given year (in million USD).  Notes  The GDP is reported by the Bureau of Economic Analysis from the U.S. Department of Commerce and measures the value of the goods and services produced by the economy in a given period. The quarterly GDP data can be downloaded from the BEA. The yearly GDP data can be downloaded from the BEA.  Image credit http//www.freelargeimages.com/wp-content/uploads/2014/11/Map_of_united_states-3.jpg",StateCodes:,string:,
Global Shark Attacks , toby jolly , www.kaggle.com/teajay/global-shark-attacks , Wed Jun 21 2017 22:23:28 GMT+0530 (IST) , Data compiled by the global shark attack file ,3013, oceans- ,Context This is a table of shark attack incidents compiled by the Global Shark Attack File Please see their website for more details on where this data comes from. Acknowledgements This data was downloaded with permission from the Global Shark Attack File's website,Case Number:,dateTime:,
Volcanic Eruptions in the Holocene Period , The Smithsonian Institution , www.kaggle.com/smithsonian/volcanic-eruptions , Tue Jan 24 2017 04:30:21 GMT+0530 (IST) , Name location and type of volcanoes active in the past 10000 years ,455, geology- ,Content The Smithsonian Institution's Global Volcanism Program (GVP) documents Earth's volcanoes and their eruptive history over the past 10000 years. The GVP reports on current eruptions from around the world and maintains a database repository on active volcanoes and their eruptions. The GVP is housed in the Department of Mineral Sciences part of the National Museum of Natural History on the National Mall in Washington D.C. The GVP database includes the names locations types and features of more than 1500 volcanoes with eruptions during the Holocene period (approximately the last 10000 years) or exhibiting current unrest.,Number:Name:Country:Region:Type:Activity Evidence:Last Known Eruption:Latitude:Longitude:Elevation (Meters):Dominant Rock Type:Tectonic Setting:,numeric:string:string:string:string:string:string:numeric:numeric:numeric:string:string:,
NASDAQ financial fundamentals , finintelligence.com , www.kaggle.com/finintelligence/nasdaq-financial-fundamentals , Mon Aug 07 2017 07:39:50 GMT+0530 (IST) , Essential fundamental indicators for 2389 companies included into NASDAQ index. ,155, business- finance- economics- ,Context Dataset contains essential financial fundamental indicators for 2389 companies included into NASDAQ index extracted from https//finintelligence.com service. Dataset contains 10 indicators from Income Cash Flow and Assets statements. Content Dataset contains essential financial fundamental indicators for 2389 companies included into NASDAQ index extracted from https//finintelligence.com service. Dataset contains 10 indicators from Income Cash Flow and Assets statements. Some indicators are automatically calculated for example  Companies often don’t report Q4 indicators. From this reasons Q4 amounts may be calculated as annual amount - (Q1 + Q2 + Q3) amounts. Companies report some indicators ambiguously. For example companies may report Revenue as Sales of Services Sales of Goods and in many other ways. From that reason Revenue and some other indicators were automatically mapped from variety of reported source indicators.  All indicators in datasets are provided for calendar quarters for years of 2014 2015 and 2016. Periods are rounded to calendar quarters for example Feb 1 - May 1 period is included as Q1 into dataset. Each record contains period company name stock tickers (some companies have several tickers) indicator name and amount. Data is originally extracted from companies SEC filings. Acknowledgements Data is prepared and provided by https//finintelligence.com service. Service provides intelligent access to variety of corporate financial data extracted from companies documents press releases and news. Service is absolutely free no payment required. Visit us today! Happy data hacking!,,,
News and Blog Data Crawl , Patrick J , www.kaggle.com/patjob/articlescrape , Sat May 13 2017 13:44:16 GMT+0530 (IST) , Content section from over 160000 news and blog articles ,144, news agencies- linguistics- internet- ,Context This content was scraped for a previous project in 2014. I thought this community might find it useful.  It was originally used as part of an English learning application which automatically tailored exercises that were optimized to accelerate language acquisition.  Unfortunately the app was not commercially viable. Content Each record contains the following variables  body The article body text. title The article header. last_crawl_date The date that this article was crawled. url The original URL of the article.  Due to upload size limits I've had to remove many of the articles. But the original is well over the 500MB upload limit. The file may contain duplicate or low-value records. It also contains broken tags and characters. The corpus should be cleaned before use.  Inspiration Use NLP and classification to figure out which web site an article came from. ,:body:title:last_crawl_date:url:,numeric:string:string:dateTime:string:,
Spy Plane Finder , Jacob Boysen , www.kaggle.com/jboysen/spy-plane-finder , Sat Aug 12 2017 00:43:10 GMT+0530 (IST) , Identify Candidate US Government Spy Planes ,60, government agencies- government- ,"Context BuzzFeed had previously reported on flights of spy planes operated by the FBI and the Department of Homeland Security (DHS) and reasoned that it should be possible to train a machine learning algorthim to identify other aircraft performing similar surveillance based on characteristics of the aircraft and their flight patterns. You can read the story here and additional analysis and code by Peter Aldhous can be found here. Content BuzzFeed News obtained more than four months of aircraft transponder detections from the plane tracking website Flightradar24 covering August 17 to December 31 2015 UTC containing all data displayed on the site within a bounding box encompassing the continental United States Alaska Hawaii and Puerto Rico. Flightradar24 receives data from its network of ground-based receivers supplemented by a feed from ground radars provided by the Federal Aviation Administration (FAA) with a five-minute delay. After parsing from the raw files supplied by Flightradar24 the data included the following fields for each transponder detection  adshex Unique identifier for each aircraft corresponding to its ""Mode-S"" code in hexademical format. flight_id Unique identifier for each ""flight segment"" in hexadecimal format. A flight segment is a continuous series of transponder detections for one aircraft. There may be more than one segment per flight if a plane disappears from Flightradar24's coverage for a period --- for example when flying over rural areas with sparse receiver coverage. While being tracked by Fightradar24 planes were typically detected several times per minute. latitude longitude Geographic location in digital degrees. altitude Altitude in feet. speed Ground speed in knots. squawk Four-digit code transmitted by the transponder. type Aircraft manufacter and model if identified. timestamp Full UTC timestamp. track Compass bearing in degrees with 0 corresponding to north.  We also calculated  steer Change in compass bearing from the previous transponder detection for that aircraft; negative values indicate a turn to the left positive values a turn to the right.  Feature engineering First we filtered the data to remove planes registered abroad based on their adshex code common commercial airliners based on their type and aircraft with fewer than 500 transponder detections. Then we took a random sample of 500 aircraft and calculated the following for each one  duration of each flight segment recorded by Flightradar24 in minutes. boxes Area of a rectangular bounding box drawn around each flight segment in square kilometers.  Finally we calculated the following variables for each of the aircraft in the larger filtered dataset  duration1duration2duration3duration4duration5 Proportion of flight segment durations for each plane falling into each of five quantiles calculated from duration for the sample of 500 planes. The proportions for each aircraft must add up to 1; if the durations of flight segments for a plane closely matched those for a typical plane from the sample these numbers would all approximate to 0.2; a plane that mostly flew very long flights would have large decimal fraction for duration5. boxes1boxes2boxes3boxes4boxes5 Proportion of bounding box areas for each plane falling into each of five quantiles calculated from boxes for the sample of 500 planes. speed1speed2speed3speed4speed5 Proportion of speed values recorded for the aircraft falling into each of five quantiles recorded for speed for the sample of 500 planes. altitude1altitude2altitude3altitude4altitude5 Proportion of altitude values recorded for the aircraft falling into each of five quantiles recorded for altitude for the sample of 500 planes. steer1steer2steer3steer4steer5steer6steer7steer8 Proportion of steer values for each aircraft falling into bins set manually after observing the distribution for the sample of 500 planes using the breaks -180 -25 -10 -1 0 1 22 45 180. flights Total number of flight segments for each plane. squawk_1 Squawk code used most commonly by the aircraft. observations Total number of transponder detections for each plane. type Aircraft manufacter and model if identified else unknown.  The resulting data for 19799 aircraft are in the file planes_features.csv. Acknowledgements This dataset was created by Peter Aldhous from raw Flightradar24 data as well as FAA data. Inspiration  Peter used a Random Forest classifier--would another approach be better? Worse? Compare your list of candidates to his here. This data is from 2015--can you grab up to date data from ADS-B Exchange and find any new candidate planes? ",N-NUMBER:SERIAL NUMBER:MFR MDL CODE:ENG MFR MDL:YEAR MFR:TYPE REGISTRANT:NAME:STREET:STREET2:CITY:STATE:ZIP CODE:REGION:COUNTY:COUNTRY:LAST ACTION DATE:CERT ISSUE DATE:CERTIFICATION:TYPE AIRCRAFT:TYPE ENGINE:STATUS CODE:MODE S CODE:FRACT OWNER:AIR WORTH DATE:OTHER NAMES(1):OTHER NAMES(2):OTHER NAMES(3):OTHER NAMES(4):OTHER NAMES(5):EXPIRATION DATE:UNIQUE ID:KIT MFR:KIT MODEL:MODE S CODE HEX:X35:,numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:string:string:string:string:string:numeric:numeric:string:string:string:string:,
FAA Laser Incident Reports , Chris Crawford , www.kaggle.com/crawford/laser-incident-report , Wed Aug 09 2017 03:16:16 GMT+0530 (IST) , A report of laser incidents from 2010 to 2014 ,50, time series- aviation- ,"Context On February 14 2012 the President signed Public Law 112-95  the ""FAA Modernization and Reform Act of 2012."" Section 311 amended Title 18 of the United States Code (U.S.C.) Chapter 2 § 39 by adding § 39A which makes it a federal crime to aim a laser pointer at an aircraft. As a result of this law the FAA has compiled a report of laser incidents Content There is a datafile for each year and the column headers changed a little from year to year so keep that in mind when you're loading the data.  DATE - Date of report TIME (UTC) - Time of laser incident ACID - Aircraft ID (AC/ID Aircraft ID etc) No. A/C - Number of aircraft TYPE A/C - Type of aircraft ALT - Altitude MAJOR CITY - Nearest major city abbreviation COLOR - Color of laser Injury Reported - Were there injuries? CITY - Nearest city STATE - State  Acknowledments Original file was converted into separate CSV files for each year. Original dataset can be found here https//www.faa.gov/about/initiatives/lasers/laws/ ",DATE:TIME (UTC):ACID:No. A/C:TYPE A/C:ALT:MAJOR CITY:COLOR:Injury Reported:CITY:STATE:,dateTime:numeric:string:numeric:string:numeric:string:string:string:string:string:,
Congressional Voting Records , VoteView , www.kaggle.com/voteview/congressional-voting-records , Fri Aug 11 2017 02:07:43 GMT+0530 (IST) , All roll call votes made by the United States Congress 1789-2017 ,64, history- government- politics- ,DW-Nominate scores of congressional voting behavior regularly appears in media such as the New York Times Washington Post and 538. This dataset contains the voting records used to generate those scores and additional features related to the DW-NOMINATE calculations. Content This dataset contains descriptive data as well as ideological data for congressional rollcalls individual member votes members of congress and parties. You can find information such the descriptions of rollcalls what proportion of voting members were correctly classified by the ideological cutting line for that rollcall the ideological position of members of congress and more. Both the rollcall data and the data on members are split into chambers and congresses. The data on parties is a dataset with some metadata about all of the different parties as well as their average ideological position and membership size broken down by congress and chamber. The full details behind the DW-NOMINATE calculations may be helpful in interpreting some of this data. The technical details of the DW-NOMINATE model can be found in Poole's Spatial Models of Parliamentary Voting. Poole and Rosenthal's Ideology and Congress explores the nature of voting in Congress and the political history of the United States through the lens of the ideological dimensions recovered by DW-NOMINATE. Acknowledgements This dataset was prepared by the team at VoteView. Please visit their site if you require up-to-date records. You may also be interested in their blog. Inspiration -Using national scores as a training set can you develop polarization scores for you own state legislature? -Can you find correlates that help explain changes in DW-NOMINATE scores?,congress:chamber:icpsr:state_icpsr:district_code:state_abbrev:party_code:occupancy:last_means:bioname:bioguide_id:born:died:dim1:dim2:log_likelihood:geo_mean_probability:number_of_votes:number_of_errors:conditional:,numeric:string:numeric:numeric:numeric:string:numeric:numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:,
Internal Navigation Dataset , leigh , www.kaggle.com/ljewell/internal-navigation-dataset , Fri Aug 11 2017 18:15:47 GMT+0530 (IST) , Figure out a way to navigate accurately with your wireless network data ,27, navigation- ,Context Global Positioning Systems (GPS) available in many consumer products such as mobile phones has mostly solved the problem of navigation but remains a challenge for indoor locations. A possible solution exists with 802.11 wireless networks and Location Based Services (LBS) that are able to compute location of a Wireless Station (WS) using triangulation of telemetry such as Receiver Signal Strength Indicators (RSSI) from nearby Wireless Access Points (WAP). The WS coordinates have inaccuracies due to it being “a function of distance geometry and materials” (Mengual Marbán & Eibe 2010) making distance travelled calculation inaccurate. In an experiment plotting a moving workstation the estimated distanced travelled was 483 metres compared to the actual distance of 149 metres (322% difference). Content The LBS system receives data from the wireless network computes location information for each workstation and stores the data for later retrieval. The data can be sourced from the LBS using an REST API that returns JSON formatted data. To enable comparison to the estimated calculation a controlled experiment with a wireless station moving to 20 known locations and turning on the wireless interface for 90 sec periods at a time was conducted. The continual stream of coordinates from the LBS can change not only due to the WS physically moving but also due to the errors in the location calculation itself. These errors can be significant and render any distance calculation meaningless. The experiment captured the calculated position from the wireless network and the actual measured x and y coordinates of a workstation in 20 locations in an office building.  The challenge is to figure out using the wireless location ways to improve the accuracy of the prediction.  Field Name  Description time - Conversion of Singapore time to to seconds from 000000  x - x axis coordinates of floor map in feet y - y axis coordinates of floor map origin is top left of floor map cf - 95% confidence in feet of radius away from x and y client likely to be. realx - x axis measured coordinates of the real location of the test subject realy - x axis measured coordinates of the real location of the test subject Inspiration The distance travelled by the workstation was 149 mtrs. How close can you get to this calculation used the predicted locations ?,time:x:y:cf:realx:realy:,numeric:numeric:numeric:numeric:numeric:numeric:,
Demonetization in India , shan , www.kaggle.com/shan4224/demonetization-in-india , Tue Jan 17 2017 19:38:53 GMT+0530 (IST) , Withdrawal of  500 and 1000 bills in India ,1207, money- economics- ,Withdrawal of a particular form of currency (such a gold coins currency notes) from circulation is known as demonetization . Context  On November 8th India’s Prime Minister  announced that 86% of the country’s currency would be rendered null and void in 50 days and it will withdraw all 500 and 1000 rupee notes — the country’s most popular currency denominations from circulation while a new 2000 rupee note added in.  It was posited as a move to crackdown on corruption and the country’s booming under-regulated and virtually untaxed grassroots economy. Content  The field names are following ID  QUERY  TWEET_ID  INSERTED DATE  TRUNCATED  LANGUAGE  possibly_sensitive  coordinates  retweeted_status  created_at_text  created_at  CONTENT  from_user_screen_name  from_user_id    from_user_followers_count  from_user_friends_count  from_user_listed_count  from_user_statuses_count  from_user_description  from_user_location  from_user_created_at  retweet_count  entities_urls  entities_urls_counts  entities_hashtags  entities_hashtags_counts  entities_mentions  entities_mentions_counts  in_reply_to_screen_name  in_reply_to_status_id  source  entities_expanded_urls  json_output  entities_media_count  media_expanded_url  media_url  media_type  video_link  photo_link  twitpic                                             Acknowledgements  Dataset is created by pulling tweets by hashtag from twitter. Inspiration  Dataset can be used to understand trending tweets. Dataset can be used for sentiment analysis and topic mining. Dataset can be used for time series analysis of tweets. What questions would you like answered by the community ?  What is the general sentiment of tweets ?  Conclusion regarding tweet sentiments varying over time. What feedback would be helpful on the data itself ? An in depth analysis of data.,ID:QUERY:TWEET_ID:INSERTED DATE:TRUNCATED:LANGUAGE:possibly_sensitive:coordinates:retweeted_status:created_at_text:created_at:CONTENT:from_user_screen_name:from_user_id:from_user_followers_count:from_user_friends_count:from_user_listed_count:from_user_statuses_count:from_user_description:from_user_location:from_user_created_at:retweet_count:entities_urls:entities_urls_counts:entities_hashtags:entities_hashtags_counts:entities_mentions:entities_mentions_counts:in_reply_to_screen_name:in_reply_to_status_id:source:entities_expanded_urls:json_output:entities_media_count:media_expanded_url:media_url:media_type:video_link:photo_link:twitpic:,numeric:string:numeric:string:numeric:string:numeric:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:string:string:string:numeric:string:numeric:string:numeric:string:numeric:string:string:string:string:string:numeric:string:string:string:numeric:numeric:numeric:,
Marathon time Predictions , Andrea Girardi , www.kaggle.com/girardi69/marathon-time-predictions , Sat May 13 2017 15:26:01 GMT+0530 (IST) , Predict Marathon Results from Athletes Open Data Sources ,356, running- ,"Context Every Marathoner has a time goal in mind and this is the result of all the training done in months of exercises. Long runs Strides Kilometers and phisical exercise all add improvement to the result. Marathon time prediction is an art generally guided by expert physiologists that prescribe the weekly exercises and the milestones to the marathon.  Unfortunately Runners have a lot of distractions while preparing the marathon work family illnes and therefore each one of us arrives to the marathon with his own story.  The ""simple"" approach is to look at data after the competition the Leaderboard.   But what if we could link the Marathon result to the training history of the Athlete? Could we find that ""non orthodox"" training plans give good results? The Athlete Training History As a start I'll take just two data from the Athlete History easy to extract. Two meaningful data the average km run during the 4 weeks before the marathon and the average speed that the athlete has run these km.   Meaningful because in the last month of the training I have the recap of all the previous months that brought me to the marathon.   Easy to extract because I can go to Strava and I have a ""side-by-side"" comparison myself and the reference athlete. I said easy well that's not so easy since I have to search every athlete and write down those numbers the exact day the marathon happened otherwise I will put in the average the rest days after the marathon. I've set my future work in extracting more data and build better algorithms. Thank you for helping me to understand or suggest. Content id  simple counter Marathon  the Marathon name where the data were extracted. I use the data coming out from Strava ""Side by side comparison"" and the data coming from the final marathon result Name  The athlete's name still some problems with UTF-8 I'll fix that soon Category  the sex and age group of a runner - MAM Male Athletes under 40 years - WAM Women under 40 Years - M40 Male Athletes between 40 and 45 years km4week  This is the total number of kilometers run in the last 4 weeks before the marathon marathon included. If for example the km4week is 100 the athlete has run 400 km in the four weeks before the marathon  sp4week  This is the average speed of the athlete in the last 4 training weeks. The average counts all the kilometers done included the slow kilometers done before and after the training. A typic running session can be of 2km of slow running then 12-14km of fast running and finally other 2km of slow running. The average of the speed is this number and with time this is one of the numbers that has to be refined cross training  If the runner is also a cyclist or a triathlete does it counts? Use this parameter to see if the athlete is also a cross trainer in other disciplines Wall21 In decimal. The tricky field. To acknowledge a good performance as a marathoner I have to run the first half marathon with the same split of the second half. If for example I run the first half marathon in 1h30m I must finish the marathon in 3h (for doing a good job). If I finish in 3h20m I started too fast and I hit ""the wall"". My training history is therefore less valid since I was not estimating my result Marathon time  In decimal. This is the final result. Based on my training history I must predict my expected Marathon time Category  This is an ancillary field. It gives some direction so feel free to use or discard it. It groups in  - A results under 3h  - B results between 3h and 3h20m  - C results between 3h20m and 3h40m  - D results between 3h40 and 4h Acknowledgements Thank you to the main Athletes data sources GARMIN and STRAVA The Goal of this Competition Based on my training history I must predict my expected Marathon time. Which other relevant data could help me to be more precise? Heart rate cadence speed training what else? And how could I get those data?",id:Marathon:Name:Category:km4week:sp4week:CrossTraining:Wall21:MarathonTime:CATEGORY:,numeric:string:string:string:numeric:numeric:string:numeric:numeric:string:,
Weather Madrid 1997 - 2015 , Julian Simon de Castro , www.kaggle.com/juliansimon/weather_madrid_lemd_1997_2015.csv , Tue Sep 06 2016 02:27:19 GMT+0530 (IST) , Location: Barajas Airport Madrid. Data: The Weather Company LLC ,753, climate- history- ,"Weather data Barajas Airport Madrid between 1997 and 2015. Gathered web https//www.wunderground.com/ The Weather Company LLC Fields  Max TemperatureC Mean TemperatureC Min TemperatureC Dew PointC MeanDew PointC Min DewpointC Max Humidity Mean Humidity Min Humidity Max Sea Level PressurehPa Mean Sea Level PressurehPa Min Sea Level PressurehPa Max VisibilityKm Mean VisibilityKm Min VisibilitykM Max Wind SpeedKm/h Mean Wind SpeedKm/h Max Gust SpeedKm/h Precipitationmm CloudCover Events WindDirDegrees  Script for download the data #!/bin/bash  LOCAL='weather_madrid' STATION='LEMD' INI=1997 END=2015 FILE=${LOCAL}_${STATION}_${INI}_${END}.csv SITE='airport'  echo ""CETMax TemperatureCMean TemperatureCMin TemperatureCDew PointCMeanDew PointCMin DewpointCMax Humidity Mean Humidity Min Humidity Max Sea Level PressurehPa Mean Sea Level PressurehPa Min Sea Level PressurehPa Max VisibilityKm Mean VisibilityKm Min VisibilitykM Max Wind SpeedKm/h Mean Wind SpeedKm/h Max Gust SpeedKm/hPrecipitationmm CloudCover EventsWindDirDegrees"" > ${FILE}  for YEAR in $(seq ${INI} ${END}) do    echo ""Year $YEAR""    wget ""https//www.wunderground.com/history/${SITE}/${STATION}/${YEAR}/1/1/CustomHistory.html?dayend=31&monthend=12&yearend=${YEAR}&req_city=&req_state=&req_statename=&reqdb.zip=&reqdb.magic=&reqdb.wmo=&format=1"" -O ""${LOCAL}_${YEAR}.csv""    tail -n +3 ${LOCAL}_${YEAR}.csv > ${LOCAL}_${YEAR}_1.csv    sed 's/<br\ \/>//g' ${LOCAL}_${YEAR}_1.csv >> ${FILE}    rm ${LOCAL}_${YEAR}.csv ${LOCAL}_${YEAR}_1.csv done ",CET:Max TemperatureC:Mean TemperatureC:Min TemperatureC:Dew PointC:MeanDew PointC:Min DewpointC:Max Humidity: Mean Humidity: Min Humidity: Max Sea Level PressurehPa: Mean Sea Level PressurehPa: Min Sea Level PressurehPa: Max VisibilityKm: Mean VisibilityKm: Min VisibilitykM: Max Wind SpeedKm/h: Mean Wind SpeedKm/h: Max Gust SpeedKm/h:Precipitationmm: CloudCover: Events:WindDirDegrees:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:,
Delpher Dutch Newspaper Archive (1618-1699) , Rachael Tatman , www.kaggle.com/rtatman/delpher-dutch-newspaper-archive-16181699 , Thu Aug 10 2017 23:44:33 GMT+0530 (IST) , Can you identify linguistic features that predict a market crash? ,21, languages- europe- finance- product- linguistics- ,"Context ""Tulip mania tulipmania or tulipomania (Dutch names include tulpenmanie tulpomanie tulpenwoede tulpengekte and bollengekte) was a period in the Dutch Golden Age during which contract prices for bulbs of the recently introduced tulip reached extraordinarily high levels and then dramatically collapsed in February 1637. It is generally considered the first recorded speculative bubble (or economic bubble)."" -- From Wikipedia CC BY-SA Market forecasting is difficult. There are many factors that may affect the market and a high degree of uncertainty. One thing that some researchers have been investigating is whether natural language processing (NLP) of news texts can help with market forecasting. Recent publications suggest that it can be.  Peng Y. & Jiang H. (2016). Leverage Financial News to Predict Stock Price Movements Using Word Embeddings and Deep Neural Networks. In Proceedings of NAACL-HLT (pp. 374-379). Fraiberger S. P. (2016). News Sentiment and Cross-Country Fluctuations. NLP+ CSS 2016 125.  This dataset an interesting test case for these methodologies. It contains Dutch-language newspapers from the years immediately preceding and following tulip mania. Can you use NLP techniques to model the tulip market over time? Content This dataset contains the texts of 8559 newspaper deliveries from the 17th century from June 14th 1618 to December 31 1699. The text is in Dutch. Since the text was scraped from old newspapers using OCR (optical character recognition) there are some errors in the text. Acknowledgments This dataset was compiled by Delpher an archive service provided by the National Library of the Netherlands. It is provided under a CC-BY 4.0 license. For more information and newspapers from other years please visit their website (in Dutch). If you use this dataset in your work please include this citation Delpher open newspaper archive (1.0). Creative Commons Attribution 4.0  The Hague 2017 .",year:month:day:paper:fileName:text:,numeric:numeric:numeric:string:string:string:,
Catalonia GDP by demand components (2000-2016) , XavierMartinezBartra , www.kaggle.com/xavier14/catalonia-gdp-by-demand-components-20002016 , Wed Aug 09 2017 12:39:36 GMT+0530 (IST) , Macroeconomic GDP indicators ,31, business- social sciences- economics- ,Context In this DataSet we have a compilation of demand components of the GDP - Gross Domestic Product -of CATALONIA -one of the 17 autonomous comunities of Spain- and the spanish region with the highest GDP output.  Content Columns  GDP  Domestic demand  Consumer expenditure household  Consumer public adm     Gross capital  Equip. Goods others  Const.  Ext. Balance    Foreign balance  Total exports goods and services  Exports goods and services  Foreign consump.  Territory   Total imports goods and services  Imports goods and services  National residents consump. Abroad Acknowledgements All units of the DataFrame are presented in Millions of euros (Base 2010). The data has been extracted from the Idescat economic annual Accounts of Catalonia.,Year:GDP:Domestic demand:Consumer expenditure household:Consumer public adm:Gross capital:Equip. Goods others:Const.:Ext. Balance :Foreign balance :Total exports goods and services:Exports goods and services:Foreign consump. Territory:Total imports goods and services:Imports goods and services:National residents consump. Abroad:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
UNHCR Refugee Data , United Nations , www.kaggle.com/unitednations/refugee-data , Tue Aug 01 2017 01:20:20 GMT+0530 (IST) , Data on Uprooted Populations and Asylum Processing ,382, politics- demographics- ,Context The mass movement of uprooted people is a highly charged geopolitical issue. This data gathered by the UN High Commissioner for Refugees (UNHCR) covers movement of displaced persons (asylum seekers refugees internally displaced persons (IDP) stateless). Also included are destination country responses to asylum petitions. Content This dataset includes 6 csv files covering  Asylum monthly applications opened (asylum_seekers_monthly.csv) Yearly progress through the refugee system (asylum_seekers.csv)  Refugee demographics (demographics.csv) Yearly time series data on UNHCR’s populations of concern (time_series.csv) Yearly population statistics on refugees by residence and destination (persons_of_concern.csv) Yearly data on resettlement arrivals with or without UNHCR assistance (resettlement.csv)  Acknowledgements This dataset was gathered from UNHCR. Photo by Ali Tareq. Inspiration What are the most frequent destination countries for refugees? How has refugee flow changed? Any trends that could predict future refugee patterns?,Year:Country / territory of asylum/residence:Origin:RSD procedure type / level:Tota pending start-year:of which UNHCR-assisted(start-year):Applied during year:decisions_recognized:decisions_other:Rejected:Otherwise closed:Total decisions:Total pending end-year:of which UNHCR-assisted(end-year):,numeric:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
2016 Olympics in Rio de Janeiro , Rio 2016 , www.kaggle.com/rio2016/olympic-games , Tue Jan 10 2017 01:05:12 GMT+0530 (IST) , Athletes medals and events from summer games ,1230, olympic games- ,This dataset consists of the official statistics on the 11538 athletes and 306 events at the 2016 Olympic Games in Rio de Janeiro. The athletes file includes the name nationality (as a three letter IOC country code) gender age (as date of birth) height in meters weight in kilograms sport and quantity of gold silver and/or bronze medals won for every Olympic athlete at Rio. The events file lists the name sport discipline (if available) gender of competitors and venue(s) for every Olympic event at Rio 2016. CREDITS Source Data Rio 2016 website Data Files GitHub user flother,id:name:nationality:sex:dob:height:weight:sport:gold:silver:bronze:,numeric:string:string:string:dateTime:numeric:numeric:string:numeric:numeric:numeric:,
ACLED Asian Conflicts 2015-2017 , Jacob Boysen , www.kaggle.com/jboysen/asian-conflicts , Wed Aug 09 2017 00:40:04 GMT+0530 (IST) , 35k Conflicts Across Developing Asian Countries ,25, war- ,Context The Armed Conflict Location and Event Data Project is designed for disaggregated conflict analysis and crisis mapping. This dataset codes the dates and locations of all reported political violence and protest events in developing Asian countries in. Political violence and protest includes events that occur within civil wars and periods of instability public protest and regime breakdown. The project covers 2015 to the present. Content These data contain information on  Dates and locations of conflict events; Specific types of events including battles civilian killings riots protests and recruitment activities; Events by a range of actors including rebels governments militias armed groups protesters and civilians; Changes in territorial control; and Reported fatalities.  Event data are derived from a variety of sources including reports from developing countries and local media humanitarian agencies and research publications. Please review the codebook and user guide for additional information the codebook is for coders and users of ACLED whereas the brief guide for users reviews important information for downloading reviewing and using ACLED data. A specific user guide for development and humanitarian practitioners is also available as is a guide to our sourcing materials. Acknowledgements ACLED is directed by Prof. Clionadh Raleigh (University of Sussex). It is operated by senior research manager Andrea Carboni (University of Sussex) for Africa and Hillary Tanoff for South and South-East Asia. The data collection involves several research analysts including Charles Vannice James Moody Daniel Wigmore-Shepherd Andrea Carboni Matt Batten-Carew Margaux Pinaud Roudabeh Kishi Helen Morris Braden Fuller Daniel Moody and others. Please cite Raleigh Clionadh Andrew Linke Håvard Hegre and Joakim Karlsen. 2010. Introducing ACLED-Armed Conflict Location and Event Data. Journal of Peace Research 47(5) 651-660. Inspiration Do conflicts in one region predict future flare-ups? How do the individual actors interact across time?,GWNO:EVENT_ID_CNTY:EVENT_ID_NO_CNTY:EVENT_DATE:YEAR:TIME_PRECISION:EVENT_TYPE:ACTOR1:ALLY_ACTOR_1:INTER1:ACTOR2:ALLY_ACTOR_2:INTER2:INTERACTION:COUNTRY:ADMIN1:ADMIN2:ADMIN3:LOCATION:LATITUDE:LONGITUDE:GEO_PRECISION:SOURCE:NOTES:FATALITIES:,numeric:string:numeric:dateTime:numeric:numeric:string:string:string:numeric:string:string:numeric:numeric:string:string:string:string:string:numeric:numeric:numeric:string:string:numeric:,
UFO Sightings , National UFO Reporting Center (NUFORC) , www.kaggle.com/NUFORC/ufo-sightings , Thu Nov 17 2016 09:20:44 GMT+0530 (IST) , Reports of unidentified flying object reports in the last century ,2694, space- ,Context This dataset contains over 80000 reports of UFO sightings over the last century.  Content There are two versions of this dataset scrubbed and complete. The complete data includes entries where the location of the sighting was not found or blank (0.8146%) or have an erroneous or blank time (8.0237%). Since the reports date back to the 20th century some older data might be obscured. Data contains city state time description and duration of each sighting. Inspiration  What areas of the country are most likely to have UFO sightings? Are there any trends in UFO sightings over time? Do they tend to be clustered or seasonal? Do clusters of UFO sightings correlate with landmarks such as airports or government research centers? What are the most common UFO descriptions?   Acknowledgement This dataset was scraped geolocated and time standardized from NUFORC data by Sigmond Axel here.,datetime:city:state:country:shape:duration (seconds):duration (hours/min):comments:date posted:latitude:longitude:,dateTime:string:string:string:string:numeric:string:string:dateTime:numeric:numeric:,
Nominal € GDP per capita of Spain (by regions) , XavierMartinezBartra , www.kaggle.com/xavier14/nominal-gdp-per-capita-of-spain-by-regions , Thu Aug 10 2017 11:03:48 GMT+0530 (IST) , Series from the years 2000 to 2016 ,71, business- social sciences- economics- ,Context Some countries have a very divergent GDP per capita between its regions. Sometimes a given country's regions tend to converge over time while in other cases the disparity between the poorer and the richer regions is kept over the decades. In this DataSet we can examine the Spanish case. Which has been the evolution of the nominal GDP per capita by regions in Spain since the year 2000 ? Have the regions converged ? Which is the spread between regions ?   Can we make a cluster analysis of the regions ?  Content We have a DataFrame of the evolution of the nominal GDP per capita across the 19 Spanish regions (autonomous communities & cities) since 2000 to 2016. ** Acknowledgements ** The Data used has been compiled by the INE (spanish institute of statistics). http//www.ine.es/,REGION:,string:,
Tel-Aviv Sublets Posts on Facebook , sab30226 , www.kaggle.com/sab30226/telaviv-sublets-posts-on-facebook , Mon Jun 19 2017 22:11:24 GMT+0530 (IST) , Find yourself a sublet in Israel's most challenging housing market ,50, home- internet- ,"Context In 2015 I was looking for subletting an apartment in Tel Aviv. Since housing in Tel-Aviv is in high demand I thought I'll try to scrap the facebook groups of Tel Aviv sublets in order to find one. This dataset is in hebrew mostly eventhough some posts are in English. It is best suited for people who are looking for NLP challenges and to try working with an hebrew dataset (Which is a challenge in itself).  Content The dataset is made of real posts that I've scraped in 2015 from a facebook group for subletting in Tel-Aviv named ""sublets in telaviv for short periods"" or in hebrew סאבלטים בתל אביב לתקופות קצרות. Acknowledgements Using the Facebook Graph API which allows to get the data easily. Inspiration This dataset holds several challenges. First of all I wonder how much a sublet for a month should cost in the city and how the prices change over the years (The dataset hold a few years of posts). Also it can be interesting to find the differences in prices between different regions of the city(הצפון הישן מרכז העיר פלורנטין).",data__story:data__message:data__updated_time:data__id:paging__previous:paging__next:,string:string:dateTime:string:string:string:,
TechCrunch Posts Compilation , Thiago Balbo , www.kaggle.com/thibalbo/techcrunch-posts-compilation , Wed Oct 19 2016 04:55:52 GMT+0530 (IST) , 40k compiled posts with a rich set of features will boost your visualizations ,425, linguistics- internet- ,Inspiration I'm a big fan of TechCrunch for a while now. Kind of because I get to know about new startups that's coming up or maybe just because I find Tito Hamze videos fun. But TechCrunch got plenty of good content. And where we find good content we produce great exploratory analysis. This dataset is a great opportunity for you to boost your skills as an EDA expert! It provides several features that make you able to create different analyses such as time series clustering predictive segmenting classification and tons of others. Let's not forget about word2vec for that. It would be awesome to see that in action here! I've made the scraper available on github if you want to check it out here is the link techcrunch scraper repo Content This dataset comes with a rich set of features. You will have  authors authors of the post - can be one or multiple authors category post category content post content - each paragraph can be extracted by splitting on the \n date post date id post id - the same id used on techcrunch website img_src post main image url section post section - each section is one of the options on the main page dropdown menu tags post tags - can be zero or multiple tags title post title topics post topics url post url  Acknowledgements All posts were scraped from the TechCrunch website on mid oct-16. Each line contains information about one post and each post appear in no more than one line.,,,
OpenAddresses - Europe , OpenAddresses , www.kaggle.com/openaddresses/openaddresses-europe , Thu Aug 03 2017 23:39:42 GMT+0530 (IST) , Addresses and geolocations for European countries ,136, ,Context OpenAddresses's goal is to connect the digital and physical worlds by sharing geographic coordinates street names house numbers and postal codes.  Content This dataset contains one data file for each of these countries States included in this dataset Field descriptions  LON - Longitude LAT - Latitude NUMBER - Street number STREET - Street name UNIT - Unit or apartment number CITY - City name DISTRICT - ? REGION - ? POSTCODE - Postcode or zipcode ID - ? HASH - ?  Acknowledgements Data collected around 2017-07-25 by OpenAddresses (http//openaddresses.io). Address data is essential infrastructure. Street names house numbers and postal codes when combined with geographic coordinates are the hub that connects digital to physical places. Data licenses can be found in LICENSE.txt. Data source information can be found at https//github.com/openaddresses/openaddresses/tree/9ea72b079aaff7d322349e4b812eb43eb94d6d93/sources Inspiration Use this dataset to create maps in conjunction with other datasets to map weather crime or how your next canoing trip.,LON:LAT:NUMBER:STREET:UNIT:CITY:DISTRICT:REGION:POSTCODE:ID:HASH:,numeric:numeric:numeric:string:string:string:string:string:numeric:string:string:,
OpenAddresses - Asia and Oceania , OpenAddresses , www.kaggle.com/openaddresses/openaddresses-asia-and-oceania , Thu Aug 03 2017 22:30:18 GMT+0530 (IST) , Addresses and geolocations for Asia and Oceania ,95, ,Context OpenAddresses's goal is to connect the digital and physical worlds by sharing geographic coordinates street names house numbers and postal codes.  Content This dataset contains one data file for each of these countries in Asia and Oceania.  United Arab Emirates - arab_emirates.csv Australia - australia.csv China - china.csv Iceland - iceland.csv Israel - israel.csv Japan - japan.csv Kazakhstan - kazakhstan.csv Kuwait - kuwait.csv New Caldonia - new_caldonia.csv New Zealand - new_zealand.csv Qatar - qatar.csv Saudi Arabia - saudiarabia.csv Singapore - singapore.csv South Korea - south_korea.csv Taiwan - taiwan.csv  Field descriptions  LON - Longitude LAT - Latitude NUMBER - Street number STREET - Street name UNIT - Unit or apartment number CITY - City name DISTRICT - ? REGION - ? POSTCODE - Postcode or zipcode ID - ? HASH - ?  Acknowledgements Data collected around 2017-07-25 by OpenAddresses (http//openaddresses.io). Address data is essential infrastructure. Street names house numbers and postal codes when combined with geographic coordinates are the hub that connects digital to physical places. Data licenses can be found in LICENSE.txt. Data source information can be found at https//github.com/openaddresses/openaddresses/tree/9ea72b079aaff7d322349e4b812eb43eb94d6d93/sources Inspiration Use this dataset to create maps in conjunction with other datasets to map weather crime or how your next canoing trip.,LON:LAT:NUMBER:STREET:UNIT:CITY:DISTRICT:REGION:POSTCODE:ID:HASH:,numeric:numeric:string:string:string:string:string:string:string:string:string:,
Texas Death Row Executions Info and Last Words , ianmobbs , www.kaggle.com/ianmobbs/texas-death-row-executions-info-and-last-words , Fri Jun 09 2017 19:44:23 GMT+0530 (IST) , Information and last words of Texas death row executions between 1982 and 2017 ,193, languages- death- law- linguistics- ,Context The death penalty was authorized by 32 states the Federal Government and the U.S. Military. While Connecticut Maryland and New Mexico no longer have death penalty statutes they do currently incarcerate death-sentenced offenders. Texas leads the nation in the number of executions since the death penalty was reinstated in 1976. California Florida Texas and Pennsylvania have the largest death row populations.  The following crimes are Capital Murder in Texas   murder of a peace officer or fireman who is acting in the lawful discharge of an official duty and who the person knows is a peace officer or fireman; murder during the commission or attempted commission of kidnapping burglary robbery aggravated sexual assault arson obstruction or retaliation or terroristic threat; murder for remuneration or promise of remuneration or employs another to commit murder for remuneration or promise of remuneration; murder during escape or attempted escape from a penal institution; murder while incarcerated in a penal institution of a correctional employee or with the intent to establish maintain or participate in a combination or in the profits of a combination; murder while incarcerated in a penal institution for a conviction of murder or capital murder; murder while incarcerated in a penal institution serving a life sentence or a 99 year sentence for a conviction of aggravated kidnapping aggravated sexual assault or aggravated robbery; murder of more than one person during the same criminal transaction or during different criminal transactions but the murders are committed pursuant to the same scheme or course of conduct; murder of an individual under ten years of age; or murder in retaliation for or on account of the service or status of the other person as a judge or justice of the supreme court the court of criminal appeals a court of appeals a district court a criminal district court a constitutional county court a statutory county court a justice court or a municipal court.  Content The Texas Department of Criminal Justice publishes various details including the last words of every inmate on death row they execute. This dataset includes information on the name age race county date and last words of Texas death row inmates from 1982 to 2017. Acknowledgments This dataset on last statements by executed offenders was obtained here https//www.tdcj.state.tx.us/death_row/dr_executed_offenders.html Start a new kernel,TDCJ Number:Link:Last Name:First Name:Date of Birth:Gender:Race:Date Received:County:Date of Offense:,numeric:string:string:string:dateTime:string:string:dateTime:string:dateTime:,
New York City Taxi Trip - Distance Matrix , Debanjan , www.kaggle.com/debanjanpaul/new-york-city-taxi-trip-distance-matrix , Thu Aug 03 2017 09:16:47 GMT+0530 (IST) ," Google's Distance Matrix API for ""New York City Taxi Trip Duration"" challenge ",90, ,"Context The idea is to measure recommended route distance and duration(average based on historical data) between two co-ordinates using Google's Distance Matrix API. Content Google's distance and duration data appended (as fetched from the API based on the co-ordinate given) to the Kaggle's dataset for ""New York City Taxi Trip Duration"" challenge. Additionally great-circle distance between two co-ordinates are also given. Acknowledgements The data was retrieved on 29th of July 2017 from the Google's Distance Matrix API based on Kaggle's dataset given for ""New York City Taxi Trip Duration"" challenge. Great Circle distance calculated between two co-ordinates using ""geopy"".",id:,string:,
OpenAddresses - U.S. Midwest , OpenAddresses , www.kaggle.com/openaddresses/openaddresses-us-midwest , Wed Aug 02 2017 04:38:28 GMT+0530 (IST) , Addresses and geo locations for the U.S. Midwest ,69, ,Context OpenAddresses's goal is to connect the digital and physical worlds by sharing geographic coordinates street names house numbers and postal codes.  Content This dataset contains one datafile for each state in the U.S. Midwest region (although some are arguably not in the Midwest). States included in this dataset  Iowa - ia.csv Illinois - il.csv Indiana - in.csv Kansas - ks.csv Michigan - mi.csv Minnesota - mn.csv Missouri - mo.csv North Dakota - nd.csv Nebraska - ne.csv Ohio - oh.csv South Dakota - sd.csv Wisconsin  -wi.csv  Field descriptions  LON - Longitude LAT - Latitude NUMBER - Street number STREET - Street name UNIT - Unit or apartment number CITY - City name DISTRICT - ? REGION - ? POSTCODE - Postcode or zipcode ID - ? HASH - ?  Acknowledgements Data collected around 2017-07-25 by OpenAddresses (http//openaddresses.io). Address data is essential infrastructure. Street names house numbers and postal codes when combined with geographic coordinates are the hub that connects digital to physical places. Data licenses can be found in LICENSE.txt. Data source information can be found at https//github.com/openaddresses/openaddresses/tree/9ea72b079aaff7d322349e4b812eb43eb94d6d93/sources Inspiration Use this dataset to create maps in conjunction with other datasets for housing prices crime or weather!,LON:LAT:NUMBER:STREET:UNIT:CITY:DISTRICT:REGION:POSTCODE:ID:HASH:,numeric:numeric:numeric:string:string:string:string:string:string:string:string:,
Equitable Sharing Spending Dataset , The Washington Post , www.kaggle.com/washingtonpost/equitable-sharing-spending-dataset , Sat Dec 03 2016 01:54:43 GMT+0530 (IST) , Raw Data from the Controversial Equitable Sharing Program ,79, finance- ,"Context In early 2016 The Washington Post wrote that the Justice Department is ""resuming a controversial practice that allows local police departments to funnel a large portion of assets seized from citizens into their own coffers under federal law. The ""Equitable Sharing Program"" gives police the option of prosecuting some asset forfeiture cases under federal instead of state law particularly in instances where local law enforcement officers have a relationship with federal authorities as part of a joint task force. Federal forfeiture policies are more permissive than many state policies allowing police to keep up to 80 percent of assets they seize."" (link to the full article can be found here). This is the raw data from the Department of Justice’s Equitable Sharing Agreement and Certification forms that was released by the U.S. Department of Justice Asset Forfeiture and Money Laundering Section. Content  spending_master.csv is the main spending dataset that contains 58 variables.  notes.csv lists the descriptions for all variables.  Acknowledgements The original dataset can be found here. The data was originally obtained from a Freedom of Information Act request fulfilled in December 2014. Inspiration  Which agency/sector/item received the most amount of funds from the Justice Department? How many agencies received non-cash assets from the federal government through Equitable Sharing?  Are there any trends in the total equitable sharing fund across agencies? ",table:field name:description:,string:string:string:,
North Carolina Schools: Report Cards and Metadata , JustinMoore , www.kaggle.com/lazyjustin/ncschools , Tue Aug 01 2017 00:50:36 GMT+0530 (IST) , NC School Report Cards for all North Carolina Public Schools ,92, united states- schools and traditions- education- ,Context North Carolina school report cards provide an efficient method for comparing and reviewing student academic performance across all public schools in North Carolina. The following data set combines school report card (SPG) grades and scores with other school metadata gathered by the state and other local organizations.  Content School report card grades and scores for three consecutive school years of state testing (2013/14 2014/15 and 2015/16). Additional school metadata is also included (addresses geo-codes poverty indicators transportation and budget information etc...) Acknowledgements All data sourced from public resources https//ncreportcards.ondemand.sas.com/src/#/?_k=mpdibp For additional information please consult a full data dictionary here http//www.ncpublicschools.org/docs/src/researchers/data-dictionary.pdf Special thanks to gmaps D. Kahle and H. Wickham. ggmap Spatial Visualization with ggplot2. The R Journal 5(1) 144-161. http//journal.r-project.org/archive/2013-1/kahle-wickham.pdf Inspiration This data set was constructed as part of a data science project related to my Master's degree studies. Some of my findings and basic information can be found here https//ncschoolreportcard.wordpress.com/. Additional ideas include  Better visualizations for counties cities etc... Prediction of future school performance Feature engineering for school performance ,full_address:lon:lat:School.Code:District.Name:School.Name.x:State.Board.District:Grade.Span:Title.I.School:grade:SPG.Score:EVAAS.Growth.Status:Number.of.Participation.Targets:Graduatio0.Project:Summer.Program:X4.Year.Cohort.Graduation.Rate.Percent:X5.Year.Cohort.Graduation.Rate.Percent:SPG.Grade_14:SPG.Score_14:SPG.Grade_15:SPG.Score_15:avg_daily_attend_pct:crime_per_c_num:short_susp_per_c_num:long_susp_per_c_num:expelled_per_c_num:stud_internet_comp_num:lea_avg_daily_attend_pct:lea_crime_per_c_num:lea_short_susp_per_c_num:lea_long_susp_per_c_num:lea_expelled_per_c_num:lea_stud_internet_comp_num:st_avg_daily_attend_pct:st_crime_per_c_num:st_short_susp_per_c_num:st_long_susp_per_c_num:st_expelled_per_c_num:st_stud_internet_comp_num:digital_media_pct:Byod:avg_age_media_collection:X_1_to_1_access:books_per_student:wap_num:wap_per_classroom:Category_Cd:sat_avg_score_num:lea_sat_avg_score_num:st_sat_avg_score_num:nat_sat_avg_score_num:sat_participation_pct:lea_sat_participation_pct:st_sat_participation_pct:nat_sat_participation_pct:ap_participation_pct:lea_ap_participation_pct:st_ap_participation_pct:ap_pct_3_or_above:lea_ap_pct_3_or_above:st_ap_pct_3_or_above:street_ad:scity_ad:state_ad:szip_ad:type_cd:sna_pgm_type_cd:school_type_txt:calendar_only_txt:student_num:Grad_project_status:stem:flicensed_teach_pct:tchyrs_0thru3_pct:tchyrs_4thru10_pct:tchyrs_11plus_pct:class_teach_num:nbpts_num:advance_dgr_pct:X_1yr_tchr_trnovr_pct:emer_prov_teach_pct:lateral_teach_pct:highqual_class_pct:LEA.Number:School.No:LEA:School.Name.y:total_pop:pct_male:pct_female:pct_am_in:pct_asian:pct_hispanic:pct_black:pct_white:pct_multi:pct_pac_is:CEP:Final.ADM:Free:Reduced:EDS_pct:three_yr_atten_ratio:three_yr_atten_rank:Appro_Amount:Per_Pupil_Appro:Rank_Appro:No.Degree_pct:Vocational_pct:Bachelor_pct:Masters_pct:Advanced_pct:Doctorate_pct:State_PPE:State_PPE_Rank:Federal_PPE:Federal_PPE_Rank:Local_PPE:Local_PPE_Rank:Total_PPE:Total_PPE_Rank:num_teaching_positions:num_teachers_rec_suppl:average_suppl:num_principals:principals_rec_suppl:princ_avg_suppl:num_asst_prin:asst_prin_rec_suppl:avg_asst_prin_supp:t_num_of_buses:t_num_of_Pupils:t_Miles:t_Cost:t_Cost_Per_Bus:t_Cost_Per_Pupil:t_Cost_Per_Mile:,string:numeric:numeric:numeric:string:string:string:dateTime:numeric:string:numeric:string:numeric:numeric:numeric:numeric:numeric:string:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:numeric:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Cook County Asset Forfeiture (Chicago IL) , Reason Foundation , www.kaggle.com/reason-foundation/cook-county-asset-forfeiture-chicago-il , Fri Jul 21 2017 01:15:47 GMT+0530 (IST) , A FOIA request for asset forfeiture in Cook County IL ,18, ,"Context ""Law enforcement in Cook County which includes Chicago seized items from residents ranging from a cashier's check for 34 cents to a 2010 Rolls Royce Ghost with an estimated value of more than $200000. They also seized Xbox controllers televisions nunchucks 12 cans of peas a pair of rhinestone cufflinks and a bayonet."" -Reason.com Content There wasn't much documentation on the dataset but the data fields are somewhat explanatory.  InventNumb Inventory number PolRptNumb Police report number INumber ? SeizeDate Date siezed SeizeAddress Address where it was siezed SeizeCity City where it was siezed SeizeState State where it was siezed SeizeZip Zip code for where it was siezed InvItemNumb Invenotry Item number? Descr Description of item EstValue estimated value of item Vin VIN number? (vehicles) Findings ? ForfDate Forfieture date? ForfValue Value of forfieture? CaseNumb Case number AD ? ADDate Date?  Acknowledgements This dataset is the result of FOIA request by Lucy Parsons Labs a Chicago-based transparency non-profit. It contains information about to the seizures of assets in Cook County (Chicago IL). These data were presented in a Reason.com article showing the disparity of Police seizures between poor and wealthier parts of Cook County IL. http//reason.com/blog/2017/06/13/poor-neighborhoods-hit-hardest-by-asset The original excel file was converted to CSV Inspiration This dataset comes from a Freedom of Information Act request. I love datasets like these because of the potential for finding new socioeconomic insights and improving government accountability.",InventNumb:PolRptNumb:INumber:SeizeDate:SeizeAddress:SeizeCity:SeizeState:SeizeZip:InvItemNumb:Descr:EstValue:Vin:Findings:ForfDate:ForfValue:CaseNumb:AD:ADDate:,numeric:string:string:dateTime:string:string:string:string:numeric:string:numeric:string:string:dateTime:numeric:string:string:string:,
Cuss words and Deaths in Quentin Tarantino Films , FiveThirtyEight , www.kaggle.com/fivethirtyeight/cuss-words-and-deaths-in-quentin-tarantino-films , Thu Jul 20 2017 02:26:53 GMT+0530 (IST) , A tally of every cuss word and death in Tarentino's films up to 2012 ,48, news agencies- film- death- linguistics- ,Context I found this dataset after reading a Five Thirty Eight article. The author got a tally of every death and cuss word in Tarantino's movies. That's no small feat considering the content of Tarantino flicks! Such endurance!    Content  movie Film title type  Whether the event was a profane word or a death word The specific profane word if the event was a word minutes_in The number of minutes into the film the event occurred  Acknowledgements Thanks to FiveThirtyEight for throwing this dataset up on github and sharing with everyone. The original article can be found on FiveThirtyEight's website here https//fivethirtyeight.com/features/complete-catalog-curses-deaths-quentin-tarantino-films/ And the dataset is can be found here https//github.com/fivethirtyeight/data/tree/master/tarantino Inspiration Try some word counting and see how Tarantino's murderdeathcuss ratios have changed over time.  What are his favorite cuss words? Which movies have the most deaths? Shared under MIT License,movie:type:word:minutes_in:,string:string:string:numeric:,
NYC Rejected Vanity Plates , Chris Crawford , www.kaggle.com/crawford/nyc-rejected-vanity-plates , Sat Jul 15 2017 03:51:34 GMT+0530 (IST) , Rejected vanity license plates in NYC from 2010 - 2014 ,55, linguistics- automobiles- ,"Context This is a small dataset New York personalized license plate applications received from the New York DMV in response to a July 2014 Freedom of Information Law (FOIL) request. Covers applications from 10/1/2010 to 9/26/2014. Content  accepted-plates.csv CSV of plate applications that were accepted and issued with order date and plate configuration. rejected-plates.csv CSV of plate applications that were rejected by the department with order date and plate configuration. red-guide.csv A copy of the Red Guide the list of ""inappropriate"" plate configurations that are automatically disallowed by the New York DMV as of July 2015. procedure.pdf A document listing the DMV's plate review and cancellation procedures as of June 2014.  Acknowledgements This dataset is from a FOIL request by Noah Veltman at Data News. Here are some notes about the process but check the original source for more information. Thanks to Noah for letting us share this dataset with the Kaggle community! https//github.com/datanews/license-plates  This data may contain explicit or offensive language. Plate configurations in accepted-plates.csv may have since been revoked by the DMV. Plate configurations in rejected-plates.csv were rejected by the department. It does not include plates that were reserved banned by the Red Guide or cancelled for administrative reasons. Some plate configurations may exist in multiple applications. A small number of rows may contain erroneous data because of Excel cell formatting in the original prepared files. Although the DMV collects an explanation of the requested combination from each online applicant that information is not preserved.  Inspiration Your data will be in front of the world's largest data science community. What questions do you want to see answered?https//github.com/datanews/license-plateshttps//github.com/datanews/license-plates",date:plate:,dateTime:string:,
Describing New York City Roads , Curtis Chong , www.kaggle.com/splacorn/speed-limits-in-nyc-taxi-playground-challenge , Sun Aug 06 2017 02:29:43 GMT+0530 (IST) , A Collection of Road Variables in New York for the Taxi Playground Challenge ,53, road transport- taxi services- ,"Author's Note This dataset was originally coined ""Speed Limits in New York City"". Since then I have changed the name of the dataset to ""Describing New York City Roads"" to better reflect the contents of the dataset. - Curtis Context New York City Speed Limits The New York Department of Transportation Regulates the speed limits for its roads (Afterall we can't be hitting 88 MPH on a regular day). This dataset describes the speed limits for particular road segments of New York City streets. The New York City Centerline Which streets are inherently faster? How will speed limits come into play? How will nearby bike lanes slow down vehicles (and ultimately taxis)? These are the kinds of questions that can only be answered with contextual data of the streets themselves. Fortunately most major cities provide a public Centerline file that describes the path of all railroads ferry routes and streets in the city. I've taken the New York City Centerline and packaged a dataset that tries to extract meaning out of all the road connections within the city. Content New York City Speed Limits Every speed limit region is a straight line. (Which represents a segment of road). These lines are expressed by two pairs of coordinates. lat1 - The first latitude coord lon1 - The first longitude coord lat2 - The second latitude coord lat2 - The second longitude coord street - The name of the street the speed limit is imposed on speed - The speed limit of that road section signed - Denotes if there is a physical sign on the street that displays the speed limit to cars. region - The city region that the road resides in. There are 5 regions (Bronx Brooklyn Manhattan Queens and Staten Island) distance - The length of the speed limit road section (in Miles). The New York City Centerline street - The name of the street post_type* - The extension for the street name. st_width - The width of the street (in feet). There are varying widths for the size of a street so it was hard to derive a lane count/ street using this feature. As a rule of thumb the average lane is around 12 feet wide. bike_lane - Defines which segments are part of the bicycle network as defined by the NYC Department of Transportation. There are 11 classes   1 =  Class I 2 = Class II 3 = Class III 4 = Links 5 = Class I II 6 = Class II III 7 = Stairs 8 = Class I III 9 = Class II I 10 = Class III I 11 = Class III II  Bike class information https//en.wikipedia.org/wiki/Cycling_in_New_York_City#Bikeway_types bike_traf_dir** - Describes the direction of traffic (FT = With TF = Against TW = Two-Way) traf_dir** - Describes the direction of traffic (FT = With TF = Against TW = Two-Way) rw_type - The type of road. There are 6 types of roads (1 = Street 2 = Highway 3 = Bridge 4 = Tunnel 9 = Ramp 13 = U-Turn). Note I parsed awkward path types such as ""Ferry route"" and ""trail"". start_contour*** - Numeric value indicating the vertical position of the feature's ""from"" node relative to grade level. end_contour*** - Numeric value indicating the vertical position of the feature's ""to"" node relative to grade level. snow_pri - The Department of Sanitation (DSNY) snow removal priority designation.  V = Non-DSNY C = Critical (These streets have top priority) S = Sector (These streets are second priority) H = Haulster (Small spreaders with plows attached for treating areas with limited accessibility - can hold two tons of salt)  region - The city region that the road resides in. There are 5 regions (Bronx Brooklyn Manhattan Queens and Staten Island) length - The length of the road (in Miles).  points -  The coordinates that define the road. Each coordinate is separated by '|' and the lat and lon values per coordinate are separated by ';'. (Side note Round road sections are plotted by points along the curve). *For those who may not be aware road names are based on a convention. ""Avenue""s ""Boulevard""s and ""Road""s are different for distinct reasons. I left these fields in the dataset in case you wish to find any patterns that are pertinent to those types of roads. To learn more about road conventions visit this link http//calgaryherald.com/news/local-news/in-naming-streets-strict-rules-dictate-roads-rises-trails-and-more **To explain how direction works I'll provide you with an image http//imgur.com/a/UflwX. Think of every road on the centerline as a vector. It points from one location to another. It always points from the very first coordinate to the very last coordinate. Now pay attention to the direction of the road (circled). Note how it points in the same direction as the vector denoted by the centerline data. The ""traf_dir"" attribute of the street is ""FT"" because the vector is headed in the same direction as traffic is (it is a one-way street). For ""traf_dir"" with a value of ""TW"" the direction of the vector doesn't matter as the road is a two-way street. ***I've had little luck finding what the ""grade levels"" represent. The original aliases are ""TO_LVL_CO"" and ""FRM_LVL_CO"". I'll keep searching tonight and will try to dig up what elevation these grades represent. I highly suspect the grades are contour lines because I know they have some relevance to elevation.  In the meantime here are the ""grades"" that each value represents  1 = Below Grade 1 2 = Below Grade 2 3 = Below Grade 3 4 = Below Grade 4 5 = Below Grade 5 6 = Below Grade 6 7 = Below Grade 7 8 = Below Grade 8 9 = Below Grade 9 10 = Below Grade 10 11 = Below Grade 11 12 = Below Grade 12 13 = At Grade 14 = Above Grade 1 15 = Above Grade 2 16 = Above Grade 3 17 = Above Grade 4 18 = Above Grade 5 19 = Above Grade 6 20 = Above Grade 7 21 = Above Grade 8 22 = Above Grade 9 23 = Above Grade 10 24 = Above Grade 11 25 = Above Grade 12 26 = Above Grade 13 99 = Not Applicable  All in all their documentation could be better and here is a reference to it if you want to look at the source (https//data.cityofnewyork.us/api/views/exjm-f27b/files/cba8af99-6cd5-49fd-9019-b4a6c2d9dff7?download=true&filename=Centerline.pdf) Acknowledgements I want to thank the New York City Department of Transportation (NYCDOT) and the city of New York for aggregating the original data sets. New York City Speed Limits http//www.nyc.gov/html/dot/html/about/vz_datafeeds.shtml 28‐11 Queens Plaza 8th FL Long Island City New York 11101 The New York City Centerline https//catalog.data.gov/dataset/nyc-street-centerline-cscl data.cityofnewyork.us New York NY 10007",id:street:post_type:st_width:bike_lane:bike_traf_dir:traf_dir:rw_type:start_contour:end_contour:snow_pri:region:length:points:,numeric:string:string:numeric:numeric:string:string:numeric:numeric:numeric:string:string:numeric:string:,
Intermediate point data (Taxi trip duration) , Soumitra Agarwal , www.kaggle.com/artimous/intermediate-point-data-taxi-trip-duration , Sun Jul 30 2017 05:57:54 GMT+0530 (IST) , First 2000 rows with intermediate point data using Google Maps API ,37, ,Context Realising which routes a taxi takes while going from one location to another gives us deep insights into why some trips take longer than others. Also most taxis rely on navigation from Google Maps which reinforces the use case of this dataset. On a deeper look we can begin to analyse patches of slow traffic and number of steps during the trip (explained below).   Content The data as we see it contains the following columns   trip_id pickup_latitude pickup_longitude (and equivalents with dropoff) are picked up from the original dataset. distance  Estimates the distance between the start and the end latitude in miles. start_address and end_address are directly picked up from the Google Maps API params  Details set of parameters flattened out into a single line. (Explained below)  Parameters The parameters field is a long string of a flattened out JSON object. At its very basic the field has space separated steps. The syntax is as follows    Step1{ ... } Step2{ ...  Each step denotes the presence of an intermediate point. Inside the curly braces of each of the steps we have the distance for that step measured in ft and the start and end location. The start and end location are surrounded by round braces and are in the following format    Step1{distance=X ft/mi start_location=(latitude longitude) end_location ...} ...  One can split the internal params over space to get all the required values.  Acknowledgements All the credit for the data goes to the Google Maps API though limited to 2000 queries per day. I believe that even that limited amount would help us gain great insights. Future prospects  More data  Since the number of rows processed are just 2000 with a good response we might be able to get more. If you feel like contributing please have a look at the script here and try and run in for the next 2000 rows. Driver instructions  I did not include the driver instruction column in the data from the google API as it seemed to complex to use in any kind of models. If that is not the general opinion I can add it here. ,trip_id:distance:pickup_latitude:pickup_longitude:dropoff_latitude:dropoff_longitude:start_address:end_address:parameters:,string:string:numeric:numeric:numeric:numeric:string:string:string:,
Country Socioeconomic Status Scores Part II , sdorius , www.kaggle.com/sdorius/countryses , Sat Jul 15 2017 03:05:05 GMT+0530 (IST) , Country-weighted measures of SES ,90, demographics- economics- sociology- ,"This dataset contains estimates of the socioeconomic status (SES) position of each of 149 countries covering the period 1880-2010. Measures of SES which are in decades allow for a 130 year time-series analysis of the changing position of countries in the global status hierarchy. SES scores are the average of each country’s income and education ranking and are reported as percentile rankings ranging from 1-99. As such they can be interpreted similarly to other percentile rankings such has high school standardized test scores. If country A has an SES score of 55 for example it indicates that 55 percent of the countries in this dataset have a lower average income and education ranking than country A. ISO alpha and numeric country codes are included to allow users to merge these data with other variables such as those found in the World Bank’s World Development Indicators Database and the United Nations Common Database. See here for a working example of how the data might be used to better understand how the world came to look the way it does at least in terms of status position of countries.  VARIABLE DESCRIPTIONS  unid ISO numeric country code (used by the United Nations)  wbid ISO alpha country code (used by the World Bank)  SES Country socioeconomic status score (percentile) based on GDP per capita and educational attainment (n=174)  country Short country name  year Survey year  gdppc GDP per capita Single time-series (imputed)  yrseduc Completed years of education in the adult (15+) population  region5 Five category regional coding schema regionUN United Nations regional coding schema DATA SOURCES  The dataset was compiled by Shawn Dorius (sdorius@iastate.edu) from a large number of data sources listed below. GDP per Capita   Maddison Angus. 2004. 'The World Economy Historical Statistics'. Organization for Economic Co-operation and Development Paris. GDP & GDP per capita data in (1990 Geary-Khamis dollars PPPs of currencies and average prices of commodities). Maddison data collected from http//www.ggdc.net/MADDISON/Historical_Statistics/horizontal-file_02-2010.xls.  World Development Indicators Database Years of Education 1. Morrisson and Murtin.2009. 'The Century of Education'. Journal of Human Capital(3)11-42. Data downloaded from http//www.fabricemurtin.com/ 2. Cohen Daniel & Marcelo Cohen. 2007. 'Growth and human capital Good data good results' Journal of economic growth 12(1)51-76. Data downloaded from http//soto.iae-csic.org/Data.htm  Barro Robert and Jong-Wha Lee 2013 ""A New Data Set of Educational Attainment in the World 1950-2010."" Journal of Development Economics vol 104 pp.184-198. Data downloaded from http//www.barrolee.com/  Maddison Angus. 2004. 'The World Economy Historical Statistics'. Organization for Economic Co-operation and Development Paris. 13.  United Nations Population Division. 2009. ",unid:wbid:country:year:ses:class:gdppc:yrseduc:region5:regionUN:,numeric:string:string:numeric:numeric:string:numeric:numeric:string:string:,
Stanford Open Policing Project - California , Stanford Open Policing Project , www.kaggle.com/stanford-open-policing/stanford-open-policing-project-california , Tue Jul 11 2017 02:11:07 GMT+0530 (IST) , Data on Traffic and Pedestrian Stops by Police in California ,53, government agencies- crime- law- ,Context On a typical day in the United States police officers make more than 50000 traffic stops. The Stanford Open Policing Project team is gathering analyzing and releasing records from millions of traffic stops by law enforcement agencies across the country. Their goal is to help researchers journalists and policymakers investigate and improve interactions between police and the public. If you'd like to see data regarding other states please go to https//www.kaggle.com/stanford-open-policing. Content This dataset includes over 2gb of stop data from California covering all of 2013 onwards. Please see the data readme for the full details of the available fields. Acknowledgements This dataset was kindly made available by the Stanford Open Policing Project. If you use it for a research publication please cite their working paper E. Pierson C. Simoiu J. Overgoor S. Corbett-Davies V. Ramachandran C. Phillips S. Goel. (2017) “A large-scale analysis of racial disparities in police stops across the United States”. Inspiration  How predictable are the stop rates? Are there times and places that reliably generate stops? Concerns have been raised about jurisdictions using civil forfeiture as a funding mechanism rather than to properly fight drug trafficking. Can you identify any jurisdictions that may be exhibiting this behavior? ,id:state:stop_date:stop_time:location_raw:county_name:county_fips:fine_grained_location:police_department:driver_gender:driver_age_raw:driver_age:driver_race_raw:driver_race:violation_raw:violation:search_conducted:search_type_raw:search_type:contraband_found:stop_outcome:is_arrested:ethnicity:,string:string:dateTime:string:string:string:numeric:string:string:string:string:string:string:string:string:string:boolean:string:string:boolean:string:boolean:string:,
2016 EU Referendum in the United Kingdom , Electoral Commission , www.kaggle.com/electoralcommission/brexit-results , Wed Jan 18 2017 20:15:04 GMT+0530 (IST) , How did population demographics impact the Brexit vote? ,393, politics- demographics- ,Context A referendum was held on the 23 June 2016 to decide whether the United Kingdom should remain a member of the European Union or leave. Approximately 52% or more than 17 million people voted to leave the EU. The referendum turnout was 72.2% with more than 33.5 million votes cast. Content The Electoral Commission published the results of the EU referendum by district and region after the vote. The Office of National Statistics provided the population demographics by district from the 2011 United Kingdom Census.,Type:Code:Area:All Residents:Age 0 to 4:Age 5 to 9:Age 10 to 14:Age 15 to 19:Age 20 to 24:Age 25 to 29:Age 30 to 34:Age 35 to 39:Age 40 to 44:Age 45 to 49:Age 50 to 54:Age 55 to 59:Age 60 to 64:Age 65 to 69:Age 70 to 74:Age 75 to 79:Age 80 to 84:Age 85 to 89:Age 90 and Over:,string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
South Africa Stock Market Data , NeilS , www.kaggle.com/neilslab/south-africa-stock-market-data , Sun Jul 02 2017 02:24:59 GMT+0530 (IST) , Price financials and rates ,208, finance- ,South African Stock Price Predictions Welcome to SA Stock Market Data ) The dataset contains information for the largest 34 companies in South Africa by market cap as well as data for the SA40 Futures.  The Price data  (P.csv) is in the format Close   Open   High   Low   Vol   Change The Financials data (F.csv) is in the format Revenue   Cost of Sales   Gross profit   Net Profit   Issue of shares   Share repurchase   Non-current assets   Current assets  Non-current liabilities   Current liabilities   Net cash inflow/outflow from operating activities Interest rate data (R.csv) has a single column rates Symbol reference BTIJ = British American Tobacco PLC BILJ = BHP Billiton PLC BGAJ = Barclays Africa Group Ltd CFRJ = Compagnie Financiere Richemont SA DRC CCOJ = Capital & Counties Properties PLC AGLJ = Anglo American PLC MTNJ = MTN Group Ltd NPNJn = Naspers Ltd SOLJ = Sasol Ltd SBKJ = Standard Bank Group Ltd VODJ = Vodacom Group Ltd KIOJ = Kumba Iron Ore Ltd FSRJ = Firstrand Ltd OMLJ = Old Mutual PLC SLMJ = Sanlam Ltd SHPJ = Shoprite Holdings Ltd REMJ = Remgro Ltd NEDJ = Nedbank Group Ltd APNJ = Aspen Pharmacare Holdings Ltd BVTJ = The Bidvest Group Ltd ANGJ = Anglogold Ashanti Ltd IMPJ = Impala Platinum Holdings Ltd WHLJ = Woolworths Holdings Ltd TBSJ = Tiger Brands Ltd EXXJ = Exxaro Resources Ltd RMHJ = RMB Holdings Ltd ITUJ = Intu Properties PLC GRTJ = Growthpoint Properties Ltd MNDJ = Mondi Ltd SNHJ = Steinhoff International Holdings Ltd INPJ = Investec PLC LHCJ = Life Healthcare REIJ = Reinet DSYJ = Discovery Holdings Ltd IPLJ = Imperial Holdings Ltd ARIJ = African Rainbow Minerals Ltd SA = FTSE/JSE Top 40 Futures If you are interested in how I put everything together to build a single model you can look at the following Github link please note this contains a lot of copy-pasta and needs to be simplified with some loops and functions before I put it on Kaggle  https//github.com/Nlabbert/SA-Stock-Market,Date:Revenue:Cost of Sales:Gross profit:Operating profit:Net Profit:Issue of shares:Share repurchase:Non-current assets:Current assets:Non-current liabilities:Current liabilities:Net cash inflow/outflow from operating activities:,dateTime:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Noun Compositionality Judgements , Rachael Tatman , www.kaggle.com/rtatman/noun-compositionality-judgements , Wed Jul 26 2017 22:56:05 GMT+0530 (IST) , Is a flea market a market for fleas? ,40, languages- linguistics- ,Context “Compositionality” is a concept from linguistics where the meaning of a phrase is made up of the meaning of each of its individual words. So “the red apple” refers literally to an apple that is red. Sometimes when you combine words however the meaning of the phrase isn’t the same as the combined meanings of the individual words. “The Big Apple” for example means “New York City” not a literal large apple. This dataset contains human judgements of the compositionality of common English phrases with two nouns. Content This dataset contains two files summary data of the human judgements and the annotations by individual judges. All judgements are on a scale of 0 to 5 with 0 being “not literal” and 5 being “literal”. Acknowledgements This dataset was collected by Siva Reddy Diana McCarthy and Suresh Manandhar. If you use this dataset in your work please cite the following paper Reddy S. McCarthy D. & Manandhar S. (2011 November). An Empirical Study on Compositionality in Compound Nouns. In IJCNLP (pp. 210-218). Inspiration  Is there a relationship between how frequent a word is and how often it’s used literally?  (You can estimate word frequency using the corpora included in the Natural Language Toolkit which is already ready to run in any Python kernel!) Given this dataset can you predict whether other compound nouns will be literal or not? Which phrases are the most literal? Which are the least literal? Are there any patterns you notice? ,word:workerID:hitID:status:score:senseID:remarks:,string:string:string:string:numeric:numeric:string:,
First Voyage of Christopher Columbus , Donyoe , www.kaggle.com/donyoe/columbus-first , Wed Oct 19 2016 13:18:12 GMT+0530 (IST) , Columbus's logbook written in the 1530's by Bartolome de las Casas ,37, sailing- history- ,Christopher Columbus or Cristóbal Colón in Spanish is an amazingly difficult man to pin down. Born about 1451 he died on 20 May 1506. We know that he sailed the Atlantic and reached the Americas on October 12 1492 under the sponsorship of the Spanish kingdom of Castile.  His voyage in 1492 marked the beginning of European exploration of the Americas. More information http//www.christopher-columbus.eu/logs.htm Content   Date Complete date year-month-day Day Day of month Month Month in character Year 1492 or 1493 Text The logbook itself nmonth Month as decimal number (1–12) Leagues Distance in leagues Course Course of the voyage  More things that can be done What says Christopher Columbus and what Bartolome de las Casas locations voyage indications etc,date:day:month:year:text:nmonth:leagues:Course:,dateTime:numeric:string:numeric:string:numeric:string:string:,
Film Locations in San Francisco , Suchit Gupta , www.kaggle.com/suchitgupta60/film-locations-in-san-francisco , Thu Jun 01 2017 03:39:20 GMT+0530 (IST) , If you love movies and you love San Francisco you're bound to love this! ,50, film- geography- ,"Introduction If you love movies and you love San Francisco you're bound to love this -- A listing of filming locations of movies shot in San Francisco starting from 1924. You'll find the titles locations fun facts names of the director writer actors and studio for most of these films. Inspiration  Combine with the popular IMDB 5000 dataset on Kaggle to see how movies filmed in San Francisco are rated. Click on ""New Kernel"" and add this dataset source by clicking on ""Input Files"".  Start a new kernel",Title:Release Year:Locations:Fun Facts:Production Company:Distributor:Director:Writer:Actor 1:Actor 2:Actor 3:,numeric:numeric:string:string:string:string:string:string:string:string:string:,
2011 - 2013 NYC Traffic Volume Counts , MihwaHan , www.kaggle.com/hanriver0618/2011-2013-nyc-traffic-volume-counts , Sat Jul 22 2017 09:59:02 GMT+0530 (IST) , Hourly Traffic Counts in NYC ,67, ,Context In order to optimize my estimate for the NYC Taxi Trip Duration Competition I thought it would be helpful to include historical traffic volume data in various parts of NYC. This dataset was compiled from 2011 -2013 and consists of over 100 days in which traffic counts were recorded on an hourly basis for numerous locations (anywhere from a few to hundreds of locations). Content The traffic counts are measured on a particular road (Roadway Name) from one intersection to another (From and To). The data set also specifies a direction of traffic that is being measured (Direction - NB SB WB EB). Acknowledgements I found this dataset on the NYC Open Data(https//opendata.cityofnewyork.us/). Inspiration My hope is that with these data one can better predict the patterns of traffic in NYC on hourly and daily basis.,ID:GIS ID:Roadway Name:From:To:Direction:Date:12:00-1:00 AM:1:00-2:00AM:2:00-3:00AM:3:00-4:00AM:4:00-5:00AM:5:00-6:00AM:6:00-7:00AM:7:00-8:00AM:8:00-9:00AM:9:00-10:00AM:10:00-11:00AM:11:00-12:00PM:12:00-1:00PM:1:00-2:00PM:2:00-3:00PM:3:00-4:00PM:4:00-5:00PM:5:00-6:00PM:6:00-7:00PM:7:00-8:00PM:8:00-9:00PM:9:00-10:00PM:10:00-11:00PM:11:00-12:00AM:,numeric:numeric:string:string:string:string:dateTime:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
NBA Free Throws , Sebastian Mantey , www.kaggle.com/sebastianmantey/nba-free-throws , Thu Jan 05 2017 20:34:18 GMT+0530 (IST) , Over 600k free throws between 2006 and 2016 ,512, basketball- ,Context The data set includes information when the free throw was taken during the game who took the shot and if it went in or not. Content The data was scraped from ESPN.com. One example site is http//www.espn.com/nba/playbyplay?gameId=261229030,end_result:game:game_id:period:play:player:playoffs:score:season:shot_made:time:,string:string:numeric:numeric:string:string:string:string:string:numeric:dateTime:,
Quarterback Stats from 1996 - 2016 , James Littiebrant , www.kaggle.com/speckledpingu/nfl-qb-stats , Thu Jan 12 2017 22:07:50 GMT+0530 (IST) , Over 5000 Regular Season Games ,472, american football- ,Why? The NFL ESPN and many others have their own Quarterback rating system. Can you create your own? How many points does a QB contribute to a given game? And with MVP trophy season coming up who really stands out as an MVP and who is carried by their team? QB Stats This is scraped from footballdb.com using Pandas' read_html function. This dataset contains every regular season NFL game and every NFL passer (including non-quarterbacks) from 1996 to 2016. Individual years are available for the past 10 years and all 21 years are in QBStats_all. In addition to the traditional stats the total points from the game have been appended to the stats. Win/Loss is up and coming but is not a priority at the moment since a QB cannot control how well the defense stops the opposing offense. Content Inside you'll find  Quarterback Name (qb) Attempts (att) Completions (cmp) Yards (yds) Yards per Attempt (ypa) Touchdowns (td) Interceptions (int) Longest Throw (lg) Sacks (sack) Loss of Yards (loss) The NFL's Quarterback Rating for the game (rate) Total points scored in the game (game_points) Home or Away Game (home_away) Year (year)  Important Note Because of the way that these were scraped the the game week is not supplied. However the games are all in oldest to most recent which would allow for some time-series analysis. Additionally Feel free to make any requests for additional information. But due to the time that it takes to scrape 21 years of NFL stats it will likely take a while before I finish updating the dataset. Acknowledgements I would very much like to thank footballdb.com for not blacklisting me after numerous scrapes and potential future scrapes for information on other positions.,qb:att:cmp:yds:ypa:td:int:lg:sack:loss:rate:game_points:home_away:year:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:,
Smogon 6v6 Pokemon Tiers , Gibs , www.kaggle.com/notgibs/smogon-6v6-pokemon-tiers , Fri Dec 30 2016 07:46:22 GMT+0530 (IST) , Tiering of Smogon 6v6 Format (12/29/16) ,89, video games- ,"This dataset stems from Alberto Barradas' popular Pokemon with stats dataset by listing the tiered Pokemon in Smogon 6v6. Smogon 6v6 is one of the most popular formats for competitive Pokemon. Although it is not the ""official"" competitive format there is still a significant number of people who play the format. There are a number of 'tiers' of Pokemon in which people can play the most popular being OU. This dataset seeks to display both a Pokemon's stats and corresponding tier for easier competitive analysis. In addition to the addition of the 'Tier' variable there are several other changes I made to the set  Classified Mythical Pokemon as 'Legendary' Changed the naming convention of Mega Evolutions and some form changes Addition of 'Mega' tier to signify Mega Evolutions  Note that this dataset includes only Pokemon tiered from PU to AG. NFE and LC Pokemon are not included unless they appear in Smogon's list. List of which Pokemon are in which tier was found here. Thank you to Alberto Barradas for his comprehensive Pokemon dataset.",X.:Name:Type.1:Type.2:Total:HP:Attack:Defense:Sp..Atk:Sp..Def:Speed:Generation:Legendary:Mega:Tier:,numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:boolean:boolean:string:,
KNYC Metars 2016 , CarlesBalsach , www.kaggle.com/cabaki/knycmetars2016 , Sat Jul 22 2017 01:27:19 GMT+0530 (IST) , The hourly weather info - KNYC - 2016 ,154, weather- ,Context METAR is a format for reporting weather information. A METAR weather report is predominantly used by pilots in fulfillment of a part of a pre-flight weather briefing and by meteorologists who use aggregated METAR information to assist in weather forecasting. Content This is the METARs aggregated information for 2016 in KNYC. Acknowledgements Thanks to wunderground for providing the data Inspiration This dataset is ment to be used as a extra information for those willing to extract conclusions from their own dataset where hourly the weather information could be useful for their predictions / analysis. You can contact me if you have any doubt or suggestion.,,,
FAspell , Rachael Tatman , www.kaggle.com/rtatman/faspell , Sat Jul 15 2017 03:45:46 GMT+0530 (IST) , Naturally-occurring Persian (Farsi) spelling mistakes ,16, linguistics- ,Context FASpell dataset was developed for the evaluation of spell checking algorithms. It contains a set of pairs of misspelled Persian (Farsi) words and their corresponding corrected forms similar to the ASpell dataset used for English. Content The dataset consists of two parts  faspell_main list of 5050 pairs collected from errors made by elementary school pupils and professional typists. faspell_ocr list of 800 pairs collected from the output of a Farsi OCR system.   Acknowledgements Based on a work at http//pars.ie/lr/FAspell_Dataset. Please acknowledge the use of this dataset by referencing one of the following papers  Barari L. & QasemiZadeh B. (2005). CloniZER spell checker adaptive language independent spell checker. In AIML 2005 Conference CICC Cairo Egypt (pp. 65-71). QasemiZadeh B. Ilkhani A. & Ganjeii A. (2006 June). Adaptive language independent spell checking using intelligent traverse on a tree. In Cybernetics and Intelligent Systems 2006 IEEE Conference on (pp. 1-6). IEEE.  License FASpell by Behrang QasemiZadeh is licensed under a Creative Commons Attribution 4.0 International License. Based on a work at http//pars.ie/lr/FAspell_Dataset. Inspiration  Which kinds of misspellings occurs more often?  Are certain characters more likely to be misspelled? Certain words?  Can you construct a finite state automaton spell checker for Persian based on this data? ,#misspelt:corrected:error-category:,string:string:numeric:,
Fall Detection Data from China , MACHINE LEARNING DATASETS , www.kaggle.com/pitasr/falldata , Thu Apr 20 2017 16:30:46 GMT+0530 (IST) , Activity of elderly patients along with their medical information ,554, gerontology- health- ,Falls among the elderly is an important health issue. Fall detection and movement tracking are therefore instrumental in addressing this issue. This paper responds to the challenge of classifying different movements as a part of a system designed to fulfill the need for a wearable device to collect data for fall and near-fall analysis. Four different fall trajectories (forward backward left and right) three normal activities (standing walking and lying down) and near-fall situations are identified and detected.  Falls are a serious public health problem and possibly life threatening for people in fall risk groups. We develop an automated fall detection system with wearable motion sensor units fitted to the subjects’ body at six different positions. Each unit comprises three tri-axial devices (accelerometer gyroscope and magnetometer/compass). Fourteen volunteers perform a standardized set of movements including 20 voluntary falls and 16 activities of daily living (ADLs) resulting in a large dataset with 2520 trials. To reduce the computational complexity of training and testing the classifiers we focus on the raw data for each sensor in a 4 s time window around the point of peak total acceleration of the waist sensor and then perform feature extraction and reduction.  We successfully distinguish falls from ADLs using six machine learning techniques (classifiers) the k-nearest neighbor (k-NN) classifier least squares method (LSM) support vector machines (SVM) Bayesian decision making (BDM) dynamic time warping (DTW) and artificial neural networks (ANNs). We compare the performance and the computational complexity of the classifiers and achieve the best results with the k-NN classifier and LSM with sensitivity specificity and accuracy all above 95%. These classifiers also have acceptable computational requirements for training and testing. Our approach would be applicable in real-world scenarios where data records of indeterminate length containing multiple activities in sequence are recorded. If you are using this dataset don't forget to cite  Özdemir Ahmet Turan and Billur Barshan. “Detecting Falls with Wearable Sensors Using Machine Learning Techniques.” Sensors (Basel Switzerland) 14.6 (2014) 10691–10708. PMC. Web. 23 Apr. 2017.,ACTIVITY:TIME:SL:EEG:BP:HR:CIRCLUATION:,numeric:numeric:numeric:numeric:numeric:numeric:dateTime:,
2017 Military Strength Ranking , Blitzer , www.kaggle.com/blitzr/gfp2017 , Fri Jul 14 2017 14:53:23 GMT+0530 (IST) , The complete Global Firepower list for 2017 ,299, military- international relations- ,"Context The complete Global Firepower list for 2017 puts the military powers of the world into full perspective. Content GlobalFirePower.csv Contains all columns without categories. GlobalFirePower_multiindex.csv has 2 level columns see the kernel for a parsing example. Fields list  Manpower  Total Populations   Available Manpower   Manpower Fit-for-Service   Manpower Reaching Military Age Annually   Active Military Manpower   Active Reserve Military Manpower   Air Power  Total Aircraft Strength   Fighters & Interceptors   Attack Aircraft   Transports   Trainers   Total Helicopters   Attack Helicopters   Serviceable Airports   Army Strengths  Combat Tanks   Armored Fighting Vehicles   Self-Propelled Artillery   Towed Artillery   Rocket Projectors   Naval Power  Total Naval Strength   Aircraft Carriers   Frigates   Destroyers   Corvettes   Submarines   Patrol Craft   Mine Warfare   Financial Resources  Annual Defense Budgets   External Debt   Reserves of Foreign Exchange and Gold   Purchasing Power Parity   Logistical Resources  Labor Force Strength   Merchant Marine Strength   Major Ports & Terminals   Roadway Coverage   Railway Coverage   Natural Resources  Oil Production   Oil Consumption   Proven Oil Reserves   Geography  Square Land Areas   Coastline   Shared Borders   Waterway Coverage     The finalized Global Firepower ranking relies on over 50 factors to determine a given nation's PowerIndex ('PwrIndx') score. Our formula allows smaller though more technologically-advanced nations to compete with larger lesser-developed ones. Modifiers (in the form of bonuses and penalties) are added to further refine the list. Some items to observe in regards to the finalized ranking  Ranking does not simply rely on the total number of weapons available to any one country but rather focuses on weapon diversity within the number totals to provide a better balance of firepower available (i.e. fielding 100 minesweepers does not equal the strategic and tactical value of fielding 10 aircraft carriers). Nuclear stockpiles are NOT taken into account but recognized / suspected nuclear powers receive a bonus. Geographical factors logistical flexibility natural resources and local industry influence the final ranking. Available manpower is a key consideration; nations with large populations tend to rank higher. Land-locked nations are NOT penalized for lack of a navy; naval powers ARE penalized for lack of diversity in available assets. NATO allies receive a slight bonus due to the theoretical sharing of resources. Current political / military leadership is NOT taken into account.  For 2017 there are a total of 133 countries included in the GFP database.  Acknowledgements The CSV files were parsed from http//www.globalfirepower.com/countries-listing.asp .  ©2017 www.GlobalFirepower.com • Content ©2003-2017 GlobalFirepower.com   • All Rights Reserved • The GlobalFirepower.com logo are trademarks   and protected by all applicable domestic and international   intellectual property laws. All material presented on this site is ""as   is"" without any guarantee. Part of the MilitaryFactory.com network of   sites. ",Country:,string:,
Clap Emoji in Tweets , Rachael Tatman , www.kaggle.com/rtatman/clap-emoji-in-tweets , Fri Jul 14 2017 01:06:31 GMT+0530 (IST) , Where do clap emojis show up in tweets? ,28, linguistics- human-computer interaction- ,Context This dataset was collected to answer questions about where in tweets users put clap emoji especially when clap emoji are used 👏  between 👏 every 👏  word. 👏 Content This dataset is made of up information on 27035 unique tweets continaing at least on clap emoji collected on July 7th 2017. Tweets were collected through Fireant  using the Twitter streaming API. For each tweet every word in the tweet is marked as either the clap emoji or a different word. Acknowledgements This dataset was collected by Rachael Tatman during the process of linguistic research on the clap emoji. A blog post on an analysis of this data can be found here. The dataset here is released to the public domain.  Inspiration While this dataset was originally collected to look specific at the clap-word-clap-word pattern it can also be used to investigate other problems. -Do most tweets which contain the tweet emoji contain more than one? -When multiple claps are used together (👏👏👏)  are they more likely to show up at the beginning or the end of the tweet? -Can you predict the distribution of claps over the tweet? (Perhaps by using a Bernoulli distribution?) -How can you visualize where tweet emoji are used?,:tweet:clap:word:,numeric:numeric:string:numeric:,
Baseball Databank , Open Source Sports , www.kaggle.com/open-source-sports/baseball-databank , Mon Nov 14 2016 00:14:54 GMT+0530 (IST) , Data on baseball players teams and games from 1871 to 2015 ,845, baseball- ,Baseball Databank is a compilation of historical baseball data in a convenient tidy format distributed under Open Data terms. This version of the Baseball databank was downloaded from Sean Lahman's website. Note that as of v1 this dataset is missing a few tables because of a restriction on the number of individual files that can be added. This is in the process of being fixed. The missing tables are Parks HomeGames CollegePlaying Schools Appearances and FieldingPost. The Data The design follows these general principles.  Each player is assigned a unique number (playerID).  All of the information relating to that player is tagged with his playerID.  The playerIDs are linked to names and  birthdates in the MASTER table. The database is comprised of the following main tables  MASTER - Player names DOB and biographical info Batting - batting statistics Pitching - pitching statistics Fielding - fielding statistics  It is supplemented by these tables  AllStarFull - All-Star appearances HallofFame - Hall of Fame voting data Managers - managerial statistics Teams - yearly stats and standings  BattingPost - post-season batting statistics PitchingPost - post-season pitching statistics TeamFranchises - franchise information FieldingOF - outfield position data   FieldingPost- post-season fielding data ManagersHalf - split season data for managers TeamsHalf - split season data for teams Salaries - player salary data SeriesPost - post-season series information AwardsManagers - awards won by managers  AwardsPlayers - awards won by players AwardsShareManagers - award voting for manager awards AwardsSharePlayers - award voting for player awards Appearances - details on the positions a player appeared at Schools - list of colleges that players attended CollegePlaying - list of players and the colleges they attended  Descriptions of each of these tables can be found attached to their associated files below. Acknowledgments This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License.  For details see http//creativecommons.org/licenses/by-sa/3.0/ Person identification and demographics data are provided by Chadwick Baseball Bureau (http//www.chadwick-bureau.com) from its Register of baseball personnel. Player performance data for 1871 through 2014 is based on the Lahman Baseball Database version 2015-01-24 which is  Copyright (C) 1996-2015 by Sean Lahman. The tables Parks.csv and HomeGames.csv are based on the game logs and park code table published by Retrosheet. This information is available free of charge from and is copyrighted by Retrosheet.  Interested parties may contact Retrosheet at  http//www.retrosheet.org.,playerID:yearID:gameNum:gameID:teamID:lgID:GP:startingPos:,string:numeric:numeric:string:string:string:numeric:numeric:,
DC Metro Crime Data , LucasVinze , www.kaggle.com/vinchinzu/dc-metro-crime-data , Tue Apr 18 2017 20:04:49 GMT+0530 (IST) , Consolidated set of all registered crimes from crimemaps.dc.gov ,1563, crime- ,Dataset of all of the crimes in the DC metro police system ranging from Theft Arson Assault Homicide Sex Abuse Robbery and Burglary.  Data can be easily geocoded and mapped trends can be extracted and predictions can be made.  Would be interesting to combine with other datasets i.e. changes in housing prices history of construction sites etc.  j An informal hypothesis would be If the local government invests in fixing the sidewalks in a neighborhood how much would the investment decrease crime levels on a block by block basis. Raw Data can be accessed from http//crimemap.dc.gov/CrimeMapSearch.aspx#tabs-GeoOther The data is most easily accessed by downloading 1 ward at a time for the specific data range.,:X:REPORT_DAT:SHIFT:OFFENSE:METHOD:BLOCK:DISTRICT:PSA:WARD:ANC:NEIGHBORHOOD_CLUSTER:BLOCK_GROUP:CENSUS_TRACT:VOTING_PRECINCT:CCN:START_DATE:END_DATE:XBLOCK:YBLOCK:optional:date:year:month:day:hour:minute:second:EW:NS:quad:crimetype:,numeric:numeric:dateTime:string:string:string:string:numeric:numeric:numeric:string:string:dateTime:numeric:string:numeric:dateTime:dateTime:numeric:numeric:boolean:dateTime:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:,
Open Data 500 Companies , GovLab , www.kaggle.com/govlab/open-data-500-companies , Fri Jun 23 2017 02:16:14 GMT+0530 (IST) , The first comprehensive study of U.S. companies using open government data ,261, business- ,Context The Open Data 500 funded by the John S. and James L. Knight Foundation (http//www.knightfoundation.org/) and conducted by the GovLab is the first comprehensive study of U.S. companies that use open government data to generate new business and develop new products and services. Study Goals  Provide a basis for assessing the economic value of government open data Encourage the development of new open data companies Foster a dialogue between government and business on how government data can be made more useful  The Govlab's Approach The Open Data 500 study is conducted by the GovLab at New York University with funding from the John S. and James L. Knight Foundation. The GovLab works to improve people’s lives by changing how we govern using technology-enabled solutions and a collaborative networked approach. As part of its mission the GovLab studies how institutions can publish the data they collect as open data so that businesses organizations and citizens can analyze and use this information. Company Identification The Open Data 500 team has compiled our list of companies through (1) outreach campaigns (2) advice from experts and professional organizations and (3) additional research. Outreach Campaign  Mass email to over 3000 contacts in the GovLab network Mass email to over 2000 contacts OpenDataNow.com Blog posts on TheGovLab.org and OpenDataNow.com Social media recommendations Media coverage of the Open Data 500 Attending presentations and conferences  Expert Advice  Recommendations from government and non-governmental organizations Guidance and feedback from Open Data 500 advisors  Research  Companies identified for the book Open Data Now Companies using datasets from Data.gov Directory of open data companies developed by Deloitte Online Open Data Userbase created by Socrata General research from publicly available sources  What The Study Is Not The Open Data 500 is not a rating or ranking of companies. It covers companies of different sizes and categories using various kinds of data. The Open Data 500 is not a competition but an attempt to give a broad inclusive view of the field. The Open Data 500 study also does not provide a random sample for definitive statistical analysis. Since this is the first thorough scan of companies in the field it is not yet possible to determine the exact landscape of open data companies.,company_name_id:company_name:url:year_founded:city:state:country:zip_code:full_time_employees:company_type:company_category:revenue_source:business_model:social_impact:description:description_short:source_count:data_types:example_uses:data_impacts:financial_info:last_updated:,string:string:string:numeric:string:string:string:numeric:dateTime:string:string:string:string:string:string:string:string:string:string:string:string:dateTime:,
Olympic Sports and Medals 1896-2014 , The Guardian , www.kaggle.com/the-guardian/olympic-games , Tue Jan 24 2017 20:35:37 GMT+0530 (IST) , Which countries and athletes have won the most medals at the Olympic games? ,1901, olympic games- ,Content Which Olympic athletes have the most gold medals? Which countries are they from and how has it changed over time?  More than 35000 medals have been awarded at the Olympics since 1896. The first two Olympiads awarded silver medals and an olive wreath for the winner and the IOC retrospectively awarded gold silver and bronze to athletes based on their rankings. This dataset includes a row for every Olympic athlete that has won a medal since the first games. Acknowledgements Data was provided by the IOC Research and Reference Service and published by The Guardian's Datablog.,Country:Code:Population:GDP per Capita:,string:string:numeric:numeric:,
Rolling Stone's 500 Greatest Albums of All Time , Gibs , www.kaggle.com/notgibs/500-greatest-albums-of-all-time-rolling-stone , Fri Jan 06 2017 08:09:49 GMT+0530 (IST) , Data about Rolling Stone magazine's (2012) top 500 albums of all time list ,461, critical theory- music- ,"From Wikipedia   ""The 500 Greatest Albums of All Time"" is a 2003 special issue of American magazine Rolling Stone and a related book published in 2005. The lists presented were compiled based on votes from selected rock musicians critics and industry figures and predominantly feature American and British music from the 1960s and the 1970s. In 2012 Rolling Stone published a revised edition of the list drawing on the original and a later survey of albums in the 2000s. It was made available in ""bookazine"" format on newsstands in the US from April 27 to July 25. The new list contained 38 albums not present in the previous one 16 of them released after 2003.   I took the albums from MusicBrainz but the genres weren't listed. I wrote a Python script to get the genres and subgenres of each album from the Discogs API. The data collected are  Position on the list Year of release Album name Artist name Genre name Subgenre name  Some of the genres/subgenres may not be entirely correct - Discogs seems to not consider some of the smaller genres. Let me know if there are any glaring issues and I'll try to fix them.",Number:Year:Album:Artist:Genre:Subgenre:,numeric:numeric:string:string:string:string:,
Elon Musk Tweets 2010 to 2017 , LiamLarsen , www.kaggle.com/kingburrito666/elon-musk-tweets , Sun Apr 23 2017 14:38:35 GMT+0530 (IST) , All Elon Musk Tweets from 2010 to 2017 ,167, celebrity- technology forecasting- internet- ,Content  tweet id contains tweet-stamp date + time date and time of day (24hr) tweet text text of tweet remove 'b'  usage What's someone going to do with a bunch of tweets?  Maybe someone would want to generate text using this dataset or do sentiment analysis Or find out the most likely time of day Elon would tweet. pie his tweets per month ITS DATA!!  Either way its up to you! Inspiration ,id:created_at:text:,numeric:dateTime:string:,
Jester Collaborative Filtering Dataset , Aakaash Jois , www.kaggle.com/aakaashjois/jester-collaborative-filtering-dataset , Fri Jun 16 2017 00:46:21 GMT+0530 (IST) , 70000+ users' rating of 100 witty jokes ,98, humor- ,Context The funniness of joke is very subjective. Having more than 70000 users rate jokes can an algorithm be written to identify the universally funny joke? Content  The data file are in .csv format. The complete dataset is 100 rows and 73422 columns. The complete dataset is split into 3 .csv files. JokeText.csv contains the Id of the joke and the complete joke string. UserRatings1.csv contains the ratings provided by the first 36710 users. UserRatings2.csv contains the ratings provided by the last 36711 users. The dataset is arranged such that the initial users have rated higher number of jokes than the later users. The rating is a real value between -10.0 and +10.0. The empty values indicate that the user has not provided any rating for that particular joke.  Acknowledgements The dataset is associated with the below research paper. Eigentaste A Constant Time Collaborative Filtering Algorithm. Ken Goldberg Theresa Roeder Dhruv Gupta and Chris Perkins. Information Retrieval 4(2) 133-151. July 2001. More information and datasets can be found at http//eigentaste.berkeley.edu/dataset/ Inspiration Since funniness is a very subjective matter it will be very interesting to see if data science can bring out the details on what makes something funny.,JokeId:JokeText:,numeric:string:,
Raw Twitter Timelines w/ No Retweets , James Littiebrant , www.kaggle.com/speckledpingu/RawTwitterFeeds , Sat Oct 15 2016 20:47:32 GMT+0530 (IST) , These are complete twitter timelines of various popular celebs with no retweets ,690, celebrity- linguistics- internet- ,"This is a dataset of tweets from various active scientists and personalities ranging from Donald Trump and Hillary Clinton to Neil deGrasse Tyson. More are forthcoming. They were obtained through javascript scraping of the browser twitter timeline rather than a Tweepy python API or the twitter timeline API. The inspiration for this twitter dataset is comparing tweets in my own twitter analysis to find who tweets like whom e.g. does Trump or Hillary tweet more like Kim Kardashian than one another? Thus this goes further back in time than anything directly available from Twitter. The data is in JSON format rather than CSV which will be forthcoming as well. Kim Kardashian Adam Savage BillNye Neil deGrasse Tyson Donald Trump and Hillary Clinton have been collected up to 2016-10-14 Richard Dawkins Commander Scott Kelly Barack Obama NASA and The Onion tweets up to 2016-10-15. For your own pleasure with special thanks to the Trump Twitter Archive for providing some of the code here is the JavaScript used to scrape tweets off of a timeline and output the results to the clipboard in JSON format 1) Construct the query with fromTWITTERHANDLE sinceDATE untilDATE 2) In the browser console set up automatic scrolling with  setInterval(function(){ scrollTo(0 document.body.scrollHeight) } 2500) 3) Scrape the resulting timeline with var allTweets = []; var tweetElements = document.querySelectorAll('li.stream-item');  for (var i = 0; i < tweetElements.length; i++) { try {     var el = tweetElements[i]; var text = el.querySelector('.tweet-text').textContent; allTweets.push({ id el.getAttribute('data-item-id') date el.querySelector('.time a').textContent text text link el.querySelector('div.tweet').getAttribute('data-permalink-path') retweet text.indexOf('\""@') == 0 && text.includes('') ? true  false }); } catch(err) {} }; copy(allTweets); Have fun!",,,
Carbon Monoxide Daily Summary , US Environmental Protection Agency , www.kaggle.com/epa/carbon-monoxide , Fri Jun 30 2017 22:12:04 GMT+0530 (IST) , A summary of daily CO levels from 1990 to 2017 ,139, environment- ,Context Carbon Monoxide (CO) is a colorless odorless gas that can be harmful when inhaled in large amounts. CO is released when something is burned. The greatest sources of CO to outdoor air are cars trucks and other vehicles or machinery that burn fossil fuels. A variety of items in your home such as unvented kerosene and gas space heaters leaking chimneys and furnaces and gas stoves also release CO and can affect air quality indoors. Content The daily summary file contains data for every monitor (sampled parameter) in the Environmental Protection Agency (EPA) database for each day. This file will contain a daily summary record that is  The aggregate of all sub-daily measurements taken at the monitor. The single sample value if the monitor takes a single daily sample (e.g. there is only one sample with a 24-hour duration). In this case the mean and max daily sample will have the same value.  Within the data file you will find these fields 1. State Code The Federal Information Processing Standards (FIPS) code of the state in which the monitor resides.  County Code The FIPS code of the county in which the monitor resides. Site Num A unique number within the county identifying the site. Parameter Code The AQS code corresponding to the parameter measured by the monitor. POC This is the “Parameter Occurrence Code” used to distinguish different instruments that measure the same parameter at the same site. Latitude The monitoring site’s angular distance north of the equator measured in decimal degrees. Longitude The monitoring site’s angular distance east of the prime meridian measured in decimal degrees. Datum The Datum associated with the Latitude and Longitude measures. Parameter Name The name or description assigned in AQS to the parameter measured by the monitor. Parameters may be pollutants or non-pollutants. Sample Duration The length of time that air passes through the monitoring device before it is analyzed (measured). So it represents an averaging period in the atmosphere (for example a 24-hour sample duration draws ambient air over a collection filter for 24 straight hours). For continuous monitors it can represent an averaging time of many samples (for example a 1-hour value may be the average of four one-minute samples collected during each quarter of the hour). Pollutant Standard A description of the ambient air quality standard rules used to aggregate statistics. (See description at beginning of document.) Date Local The calendar date for the summary. All daily summaries are for the local standard day (midnight to midnight) at the monitor. Units of Measure The unit of measure for the parameter. QAD always returns data in the standard units for the parameter. Submitters are allowed to report data in any unit and EPA converts to a standard unit so that we may use the data in calculations. Event Type Indicates whether data measured during exceptional events are included in the summary. A wildfire is an example of an exceptional event; it is something that affects air quality but the local agency has no control over. No Events means no events occurred. Events Included means events occurred and the data from them is included in the summary. Events Excluded means that events occurred but data form them is excluded from the summary. Concurred Events Excluded means that events occurred but only EPA concurred exclusions are removed from the summary. If an event occurred for the parameter in question the data will have multiple records for each monitor. Observation Count The number of observations (samples) taken during the day. Observation Percent The percent representing the number of observations taken with respect to the number scheduled to be taken during the day. This is only calculated for monitors where measurements are required (e.g. only certain parameters). Arithmetic Mean The average (arithmetic mean) value for the day. 1st Max Value The highest value for the day. 1st Max Hour The hour (on a 24-hour clock) when the highest value for the day (the previous field) was taken. AQI The Air Quality Index for the day for the pollutant if applicable. Method Code  An internal system code indicating the method (processes equipment and protocols) used in gathering and measuring the sample. The method name is in the next column. Method Name A short description of the processes equipment and protocols used in gathering and measuring the sample. Local Site Name The name of the site (if any) given by the State local or tribal air pollution control agency that operates it. Address The approximate street address of the monitoring site. State Name The name of the state where the monitoring site is located. County Name The name of the county where the monitoring site is located. City Name The name of the city where the monitoring site is located. This represents the legal incorporated boundaries of cities and not urban areas. CBSA Name The name of the core bases statistical area (metropolitan area) where the monitoring site is located. Date of Last Change The date the last time any numeric values in this record were updated in the AQS data system.  Acknowledgements These data come from the EPA and are current up to May 1 2017. You can use Kernels to analyze share and discuss this data on Kaggle but if you’re looking for real-time updates and bigger data check out the data on BigQuery too https//cloud.google.com/bigquery/public-data/epa. Inspiration Breathing air with a high concentration of CO reduces the amount of oxygen that can be transported in the bloodstream to critical organs like the heart and brain. At very high levels which are  possible indoors or in other enclosed environments CO can cause dizziness confusion unconsciousness and death. Very high levels of CO are not likely to occur outdoors. However when CO levels are elevated outdoors they can be of particular concern for people with some types of heart disease. These people already have a reduced ability for getting oxygenated blood to their hearts in situations where the heart needs more oxygen than usual. They are especially vulnerable to the effects of CO when exercising or under increased stress. In these situations short-term exposure to elevated CO may result in reduced oxygen to the heart accompanied by chest pain also known as angina.,state_code:county_code:site_num:parameter_code:poc:latitude:longitude:datum:parameter_name:sample_duration:pollutant_standard:date_local:units_of_measure:event_type:observation_count:observation_percent:arithmetic_mean:first_max_value:first_max_hour:aqi:method_code:method_name:local_site_name:address:state_name:county_name:city_name:cbsa_name:date_of_last_change:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:dateTime:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:dateTime:,
Poems from poetryfoundation.org , ultra-jack , www.kaggle.com/ultrajack/modern-renaissance-poetry , Tue Jun 27 2017 14:17:15 GMT+0530 (IST) , Modern and Renaissance poetry for classification exercises ,77, poetry- linguistics- ,Context Study for poem classification. Trying to classified poems with targets age and type.  I use two Xgboost predictors to predict target and type separately.      Content Please refer to the website https//www.poetryfoundation.org/ For now I only crawl the data of   renaissance love modern love  renaissance nature modern nature renaissance  mythology & folklore modern  mythology & folklore  Some have copyrights. I only use for studying ) Acknowledgements https//www.poetryfoundation.org/ has the copyright  Inspiration classification is fun!!,author:content:poem name:age:type:,string:string:string:string:string:,
Current Properati Listing Information , Properati Data , www.kaggle.com/properati-data/properties , Tue Jul 04 2017 02:36:10 GMT+0530 (IST) , Property attributes of 1.5 million Latin American listings ,65, home- ,Properati is a competitive marketplace for Latin American real estate that strives to assist consumers in purchasing and renting homes while simultaneously providing location-specific property databases for the public.  Properati currently lists over 1.5 million properties through hubs in Argentina Mexico and Brazil. Listings include property name type price listing date surface area coordinates description and photos. Most of these premises are located in urban settings with few straying into suburban or rural areas. Innovators at Properati understand that a house is usually the most important and costly purchase an individual makes in his or her lifetime. Properati has developed tools such as Preciómetro to help people make well-educated property investments.  Properati also creates data analyses based on over 1.5 million properties to better understand the real estate market. Through these reports Properati uncovers social trends and urban processes that help characterize current and future listings. Visit Properati’s blog and website to join them in their advanced market knowledge.  Properati invites you to utilize their location based datasets from current and past listings in Big Query  https//bigquery.cloud.google.com/dataset/properati-data-publicproperties_ar https//bigquery.cloud.google.com/dataset/properati-data-publicproperties_br https//bigquery.cloud.google.com/dataset/properati-data-publicproperties_mx,id:created_on:operation:property_type:place_name:place_with_parent_names:country_name:state_name:geonames_id:lat-lon:lat:lon:price:currency:price_aprox_local_currency:price_aprox_usd:surface_total_in_m2:surface_covered_in_m2:price_usd_per_m2:price_per_m2:floor:rooms:expenses:properati_url:description:title:image_thumbnail:,string:dateTime:string:string:string:string:string:string:numeric:string:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:,
Olympic Track & Field Results , Jay Ravaliya , www.kaggle.com/jayrav13/olympic-track-field-results , Fri May 26 2017 08:12:35 GMT+0530 (IST) , Results from all Olympic Track & Field Events 1896 - 2016 ,259, olympic games- ,Context In an effort to database all results from the Olympic Track & Field Events this dataset is scraped from https//olympic.org/athletics. Content All column headers are provided below. Inspiration As a former (and hopefully future) runner I'm inspired by the idea that data can help us better understand the progression of athletes over time at one of the largest global stages for the events the Olympics! Code Scraper https//github.com/jayrav13/olympics-athletics,Gender:Event:Location:Year:Medal:Name:Nationality:Result:,string:string:string:numeric:string:string:string:string:,
Childhood Blood Lead Surveillance , Centers for Disease Control and Prevention , www.kaggle.com/cdc/childhood-blood-lead-surveillance , Mon May 01 2017 01:31:39 GMT+0530 (IST) , National and state-level surveillance data 1997 to 2015 ,108, epidemiology- human medicine- health- ,CDC began collecting childhood blood lead surveillance data in April 1995. The national surveillance system is composed of data from state and local health departments. States maintain their own child-specific databases so they can identify duplicate test results or sequential test results on individual children. These databases contain follow-up data on children with elevated blood lead levels including data on medical treatment environmental investigations and potential sources of lead exposure. States extract fields from their child-specific surveillance databases and transfer them to CDC for the national database. State child-specific databases contain follow-up data on children with elevated blood lead levels including data on medical treatment environmental investigations and potential sources of lead exposure. Surveillance fields for CDC's national database are extracted from state child-specific databases and transferred to CDC. State surveillance systems are based on reports of blood lead tests from laboratories. Ideally laboratories report results of all blood lead tests not just elevated values to state health departments. States determine the reporting level for blood lead tests and decide which data elements should accompany the blood lead test result. These data were collected for program management purposes. The data have limitations and we cannot compare across states or counties because data collection methods vary across grantees. Data are not generalizable at the national state or local level.,,,
Wage Estimates , US Bureau of Labor Statistics , www.kaggle.com/bls/wage-estimates , Thu Jun 29 2017 23:41:39 GMT+0530 (IST) , Modeled wage estimates of average hourly wages ,205, income- ,Context The Occupational Employment Statistics (OES) and National Compensation Survey (NCS) programs have produced estimates by borrowing from the strength and breadth of each survey to provide more details on occupational wages than either program provides individually. Modeled wage estimates provide annual estimates of average hourly wages for occupations by selected job characteristics and within  geographical location. The job characteristics include bargaining status (union and nonunion) part- and full-time work status incentive- and time-based pay and work levels by occupation. Direct estimates are based on survey responses only from the particular geographic area to which the estimate refers. In contrast modeled wage estimates use survey responses from larger areas to fill in information for smaller areas where the sample size is not sufficient to produce direct estimates. Modeled wage estimates require the assumption that the patterns to responses in the larger area hold in the smaller area. The sample size for the NCS is not large enough to produce direct estimates by area occupation and job characteristic for all of the areas for which the OES publishes estimates by area and occupation. The NCS sample consists of 6 private industry panels with approximately 3300 establishments sampled per panel and 1600 sampled state and local government units. The OES full six-panel sample consists of nearly 1.2 million establishments.  The sample establishments are classified in industry categories based on the North American Industry Classification System (NAICS). Within an establishment specific job categories are selected to represent broader occupational definitions. Jobs are classified according to the Standard Occupational Classification (SOC) system. Content Summary Average hourly wage estimates for civilian workers in occupations by job characteristic and work levels. These data are available at the national state metropolitan and nonmetropolitan area levels. Frequency of Observations Data are available on an annual basis typically in May.  Data Characteristics All hourly wages are published to the nearest cent. Acknowledgements This dataset was taken directly from the Bureau of Labor Statistics and converted to CSV format.  Inspiration This dataset contains the estimated wages of civilian workers in the United States. Wage changes in certain industries may be indicators for growth or decline. Which industries have had the greatest increases in wages? Combine this dataset with the Bureau of Labor Statistics Consumer Price Index dataset and find out what kinds of jobs you would need to afford your snacks and instant coffee!,area_code:area_text:display_level:selectable:sort_sequence:,numeric:string:numeric:numeric:numeric:,
Help with Real Estate Closed Price Model , samdeeplearning , www.kaggle.com/samdeeplearning/vt-nh-real-estate , Tue Jun 27 2017 20:28:00 GMT+0530 (IST) , Local Real Estate Firm Looking for Your Machine Learning Expertise ,236, home- ,Context A local Vermont/New Hampshire real estate firm is looking into modeling closed prices for houses. This dataset contains features of houses in three towns in Vermont which make up a sizable chunk of the real estate firm's business. Content MLS is the real estate information platform that is publicly available. Features were exported from an MLS web platform. Features include # of baths # of bedrooms and # of acres. There are also categorical features such as town and address.  Hint Natural language processing techniques that identify and leverage the road that a house is on may improve prediction accuracy.  Acknowledgements Thank you to AH. Goal There is a Train Validate and Test. Can you show a cross validated result that beats 10.0% error in closed price? You can use any measure to train your model - RMSE RMSLE etc.; however the accuracy metric is simply mean percent error! Please Note These houses can be uniquely identified on the MLS website which does also have photos of the houses. Computer Vision techniques that retrieve information from photos on the data are of interest to the company but are not encouraged for this simple dataset which serves as a jumping off point for future endeavors as it contains data that is already compiled and understood by the firm.,id:bedrooms_total:baths_total:acres:sq_ft_tot_fn: tax_gross_amount:assessment_value_town:garage_capacity:address:city:garage_type:year_built:total_stories:surveyed:seasonal:water_body_type:water_frontage_length:short_sale:rooms_total:garage:flood_zone:easements:current_use:covenants:common_land_acres:basement_access_type:basement:price_closed:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:numeric:numeric:string:string:string:numeric:string:numeric:string:string:string:string:string:string:string:string:string:,
NSE India stocks (Indices) , ramamet , www.kaggle.com/ramamet4/nse-stocks-database , Thu May 11 2017 23:51:22 GMT+0530 (IST) , 1 minute intraday datasets ,227, finance- ,Context nifty50.csv The NIFTY 50 index is National Stock Exchange of India's benchmark stock market index for Indian equity market. It is a well diversified 50 stock index accounting for 22 sectors of the economy. It is used for a variety of purposes such as bench-marking fund portfolios index based derivatives and index funds. banknifty.csv Bank Nifty represents the 12 most liquid and large capitalized stocks from the banking sector which trade on the National Stock Exchange (NSE). It provides investors and market intermediaries a benchmark that captures the capital market performance of Indian banking sector. Content A data frame with 8 variables index date time open high low close and id. For each year from 2013 to 2016 the number of trading data of each minute of given each date. The currency of the price is Indian Rupee (INR).  index  market id date numerical value (Ex. 20121203- to be converted to 2012/12/03) time factor (Ex. 0916) open numeric (opening price) high numeric (high price) low numeric (low price) close numeric (closing price)  Inspiration Initial raw data sets are very complex and mixed datatypes. These are processed properly using R libraries like dplyr stringr and other data munging packages. The desired outputs are then converted into a CSV format to use for further analysis.,index:date:time:open:high:low:close:,string:numeric:dateTime:numeric:numeric:numeric:numeric:,
Colbert 1k , Caio Lente , www.kaggle.com/ctlente/colbert-1k , Mon Jun 26 2017 19:20:55 GMT+0530 (IST) , Captions from almost a thousand videos of The Late Show's YouTube channel ,40, humor- linguistics- internet- ,"Context In this dataset you'll find the captions from 990 videos of The Late Show with Stephen Colbert. Captions were cleaned in order to make text mining easier. Content This dataset has only three columns id link and captions. The first one contains the video's ID the second one contains its link and the last one contains the video's captions. The data was collected in the week of 2017-06-19 with a script I created. I also tried to collect more information about the videos (like date and title) but YouTube's API was being too stubborn. Acknowledgements The content of all videos belong to The Late Show. Captions were extracted with the help of ccSubs. Inspiration I collected this data to write the blog post ""Colbert's Fixation"".",id:link:captions:,string:string:string:,
COMPAS Recidivism Racial Bias , Dan Ofer , www.kaggle.com/danofer/compass , Thu Jun 29 2017 15:57:15 GMT+0530 (IST) , Racial Bias in inmate COMPAS reoffense risk scores for Florida (ProPublica) ,44, crime- law- demographics- ,"Context COMPAS (Correctional Offender Management Profiling for Alternative Sanctions) is a popular commercial algorithm used by judges and parole officers for scoring criminal defendant’s likelihood of reoffending (recidivism). It has been shown that the algorithm is biased in favor of white defendants and against black inmates based on a 2 year follow up study (i.e who actually committed  crimes or violent crimes after 2 years). The pattern of mistakes as measured by precision/sensitivity is notable.  Quoting from ProPublica ""  Black defendants were often predicted to be at a higher risk of recidivism than they actually were. Our analysis found that black defendants who did not recidivate over a two-year period were nearly twice as likely to be misclassified as higher risk compared to their white counterparts (45 percent vs. 23 percent).   White defendants were often predicted to be less risky than they were. Our analysis found that white defendants who re-offended within the next two years were mistakenly labeled low risk almost twice as often as black re-offenders (48 percent vs. 28 percent).   The analysis also showed that even when controlling for prior crimes future recidivism age and gender black defendants were 45 percent more likely to be assigned higher risk scores than white defendants.   Black defendants were also twice as likely as white defendants to be misclassified as being a higher risk of violent recidivism. And white violent recidivists were 63 percent more likely to have been misclassified as a low risk of violent recidivism compared with black violent recidivists. The violent recidivism analysis also showed that even when controlling for prior crimes future recidivism age and gender black defendants were 77 percent more likely to be assigned higher risk scores than white defendants. ""  Content Data contains  variables used by the COMPAS algorithm in scoring defendants along with their outcomes within 2 years of the decision for over 10000 criminal defendants in Broward County Florida.  3 subsets of the data are provided including a subset of only violent recividism (as opposed to e.g. being reincarcerated for non violent offenses such as vagrancy or Marijuana). Indepth analysis by ProPublica can be found in their data methodology article. Acknowledgements Data & original analysis gathered by ProPublica.  Original Data methodology article https//www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm Original Article https//www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing Original data from ProPublica https//github.com/propublica/compas-analysis Additional ""simple"" subset provided by FairML based on the proPublica data http//blog.fastforwardlabs.com/2017/03/09/fairml-auditing-black-box-predictive-models.html Inspiration Ideas  Feature importance when predicting the COMPASS score itself or recividism/crime risks. Reweighting data to compensate for bias e.g. subsetting for the violent offenders or adjusting better for base risk.  Feature selection based on ""legal usage""/fairness (E.g. exclude race and see how well your model works. It worked for me). ",Person_ID:AssessmentID:Case_ID:Agency_Text:LastName:FirstName:MiddleName:Sex_Code_Text:Ethnic_Code_Text:DateOfBirth:ScaleSet_ID:ScaleSet:AssessmentReason:Language:LegalStatus:CustodyStatus:MaritalStatus:Screening_Date:RecSupervisionLevel:RecSupervisionLevelText:Scale_ID:DisplayText:RawScore:DecileScore:ScoreText:AssessmentType:IsCompleted:IsDeleted:,numeric:numeric:numeric:string:string:string:string:string:string:dateTime:numeric:string:string:string:string:string:string:dateTime:numeric:string:numeric:string:numeric:numeric:string:string:numeric:numeric:,
Diagnose Specific Language Impairment in Children , dgoke1 , www.kaggle.com/dgokeeffe/specific-language-impairment , Tue Apr 11 2017 16:01:46 GMT+0530 (IST) , Explore and create models using data derived from transcripts in CHILDES ,151, human medicine- children- linguistics- ,Context Specific Language Impairment  is a condition that effects roughly 7% of 5-year old children. It is characterised by a lack of language ability in comparison to your peers but with no obvious mental or physical disability. Diagnosis can tend to be laborious thus automating this process using NLP and ML techniques might be of interest to paediatricians and speech pathologists.  Content This study evaluated three datasets obtained via the CHILDES project. All the datasets consist of narratives from a child attempting to complete a wordless picture task. The choice to use only narrative corpora was based on previous research which indicated it has the best ability to distinguish a language impairment in children. The first dataset consists of samples from British adolescents the second from Canadian children aged 4 to 9 and the third from U.S. children aged 4 to 12.  Unfortunately finding transcript data of this kind is rare I have tried to find more data to no avail so 1163 samples will have to do. Conti-Ramsden 4 The Conti-Ramsden 4 dataset was collected for a study to assess the effectiveness of narrative tests on adolescents. It consists of 99 TD and 19 SLI samples of children between the ages of 13.10 and 15.90. Ideally all the corpora would only be from children as SLI is most prominent in children aged five years old and is best detected early. However it was included to enable a direct comparison between classifiers created by Gabani and this study. The corpus contains transcripts of a story telling task based on Mayer’s wordless picture book “Frog Where Are You”. The children first viewed the picture book in their own time before being prompted to retell the story in the past tense. If the children started telling the story in the present tense the interviewer would prompt them with the phrase “What happened next?” in order to attempt to revert them back to the past tense. If they failed to start to retell the story in the past tense after two prompts no further prompts were made. ENNI The ENNI dataset was collected during the course of a study aimed at identifying SLI children using an index of storytelling ability based on the story grammar model. The corpus consists of 300 TD and 77 SLI samples of children aged between 4 and 9 years old. Each child was presented with two wordless picture stories with one more complicated than the other. Unlike Conti-Ramsden 4 the examiner held the book and turned the page after the child appeared to be finished telling the story for a particular picture. The children were also given the opportunity to practice on a training story where the examiner gave more explicit prompts to the child about what to do. Gillam The Gillam dataset is based on another tool for narrative assessment known as “The Test of Narrative Language (TNL). It consists of 250 language impaired children and 520 controls aged between 5 and 12. A detailed description of each of the participants does not exist. The TNL consists of four storytelling tasks the first is a recall of a script based story the rest being wordless picture books. The first picture set depicts a story with a main protagonist having repeated attempts at the goal and the rest are single picture stories. The single picture stories require more input from the child and thus is better suited to older children. The TNL appears to be intermediary in difficulty compared to ENNI. Features Attribute | Name | Description   Y                         | The label  | 0 for typically developing children 1 for language impaired  child_TNW         | Total Number of Words | The total number of words in the transcript  child_TNS          | Total Number of Sentences | Children with SLI are more likely to speak in short sentences  group                 | Same as Y | BEWARE Is the same as Y but easier to graph in Python and R  examiner_TNW | Total Number of Words spoken by the examiner | Children with SLI are more likely to need support  freq_ttr                     | Frequency of Word Types to Word Token Ratio | Divides word types by word tokens and provides a rough measure of lexical diversity.  r_2_i_verbs| Ratio of raw to inflected verbs | Children with SLI often have difficulty with the morphemes -ed -s be and do. This results in the use of raw verbs instead of their inflected forms.  mor_words | Number of words in the %mor tier |  num_pos_tags | Number of different Part-of-Speech tags |  n_dos | Number of Do's | The number of time the word 'do' is used  repetition | Number of Repetitions  | Counts the number of repetitions as tagged in the CHAT format inside square brackets e.g. milk milk milk milk = milk [x 4]  retracing | Number of Retracings | A retracing is defined as when a speaker abandons an utterance but then continues again.  fillers | Number of Fillers | Counts the number of fillers used in total. A list of fillers was created by searching through the entire corpus (all 1038 samples) for all common variants of fillers such as um umm uh uhh etc.  s_1g_ppl | Perplexity of 1-gram SLI | The perplexity of this sample in comparison to a language model trained on all the SLI group for this corpora except the sample  s_2g_ppl | Perplexity of 2-gram SLI | Same as above but with a 2-gram LM  s_3g_ppl | Perplexity of 3-gram SLI | Same as above but with a 3-gram LM  d_1g_ppl | Perplexity of 1-gram TD | The perplexity of this sample in comparison to a language model trained on all the TD group for this corpora except the sample  d_2g_ppl | Perplexity of 2-gram TD | Same as above but with a 2-gram LM  d_3g_ppl | Perplexity of 3-gram TD | Same as above but with a 3-gram LM  z_mlu_sli | Sample Z-score using SLI group's Mean Length of Utterance |  z_mlu_td | Sample Z-score using TD group's Mean Length of Utterance |  z_ndw_sli | Sample Z-score using SLI group's RawInflected Verbs Ratio  |  z_ndw_td | Sample Z-score using TD group's RawInflected Verbs Ratio |  z_ipsyn_sli | Sample Z-score using SLI group's Developmental Sentence Score |  z_ipsyn_td | Sample Z-score using TD group's Developmental Sentence Score |  z_utts_sli |Sample Z-score using SLI group's Number of Verb Utterances |  z_utts_td |Sample Z-score using TD group's Number of Verb Utterances |  total_syl |  Total number of Syllables | Using a technique from  average_syl | Average number of Syllables per word |  mlu_words | Mean Length of Utterance of Words  |  mlu_morphemes |  i |  mlu100_utts | Mean Length of Utterance of 1st 100 words  |  verb_utt | Number of verb utterances |  dss | Developmental Sentence Score |  ipsyn_total | Index of Productive Syntax Score |  present_progressive | |  propositions_in | |  propositions_on | |  plural_s | |  irregular_past_tense | |  possessive_s | |  uncontractible_copula | |  articles | |  regular_past_ed | |  regular_3rd_person_s | |  irregular_3rd_person | |  uncontractible_aux | |  contractible_copula | |  contractible_aux | |  word_errors |  Number of Word Errors | As marked in CHILDES  f_k | |  n_v | |  n_aux | |  n_3s_v | |  det_n_pl | |  det_pl_n | |  pro_aux | |  pro_3s_v | |  total_error | |     This table will take some time to finish will get to it within a few days Past Research I have spent the last few months playing around with this data I have uploaded it here mainly to speed up the computation of the analysis I have already done. But I'm excited to see what other people can do with this. There are some nice graphs to be made; especially using the MLU attributes. Thus far using the combined corpora the best I have managed to get in terms of creating a predictive classifier is using Neural Networks with Feature Extraction and SMOTE to get a mean ROC of 0.8709 under 10-repeated-10-k-folds CV. You'll find that Random Forest and SVM with an RBF kernel do comparably well with SMOTE. Acknowledgements All the data here was derived by me using the open source transcripts provided on the CHILDES Talkbank (http//childes.talkbank.org/). The methods I used are very close to those in  K. Gabani T. Solorio Y. Liu K.-n. Hassanali and C. A. Dollaghan “Exploring a corpus-based approach for detecting language impairment in monolingual english-speaking children” Artificial Intelligence in Medicine vol. 53 no. 3 pp. 161–170 2011. Conti-4 D. Wetherell N. Botting and G. Conti-Ramsden “Narrative skills in adolescents with a history of SLI in relation to non-verbal IQ scores” Child Language Teaching and Therapy vol. 23 no. 1 pp. 95–113 2007. ENNI P. Schneider D. Hayward and R. V. Dub “Storytelling from pictures using the Edmonton Narrative Norms Instrument” 2006. Gillam R. Gillam and N. Pearson Test of Narrative Language. Austin TX Pro-Ed Inc. 2004. Inspiration I'm hoping somebody can beat my score. I'm keen to learn more and see if this can become anything that might be of use to some child/family someday.,filename:Y:,string:boolean:,
Fact-Checking Facebook Politics Pages , Megan Risdal , www.kaggle.com/mrisdal/fact-checking-facebook-politics-pages , Tue Jun 06 2017 00:39:40 GMT+0530 (IST) , Hyperpartisan Facebook pages and misleading information during the 2016 election ,151, news agencies- politics- political science- internet- ,Context During the 2016 US presidential election the phrase “fake news” found its way to the forefront in news articles tweets and fiery online debates the world over after misleading and untrue stories proliferated rapidly. BuzzFeed News analyzed over 1000 stories from hyperpartisan political Facebook pages selected from the right left and mainstream media to determine the nature and popularity of false or misleading information they shared. Content This dataset supports the original story “Hyperpartisan Facebook Pages Are Publishing False And Misleading Information At An Alarming Rate” published October 20th 2016. Here are more details on the methodology used for collecting and labeling the dataset (reproduced from the story) More on Our Methodology and Data Limitations “Each of our raters was given a rotating selection of pages from each category on different days. In some cases we found that pages would repost the same link or video within 24 hours which caused Facebook to assign it the same URL. When this occurred we did not log or rate the repeat post and instead kept the original date and rating. Each rater was given the same guide for how to review posts  “Mostly True The post and any related link or image are based on factual information and portray it accurately. This lets them interpret the event/info in their own way so long as they do not misrepresent events numbers quotes reactions etc. or make information up. This rating does not allow for unsupported speculation or claims. “Mixture of True and False Some elements of the information are factually accurate but some elements or claims are not. This rating should be used when speculation or unfounded claims are mixed with real events numbers quotes etc. or when the headline of the link being shared makes a false claim but the text of the story is largely accurate. It should also only be used when the unsupported or false information is roughly equal to the accurate information in the post or link. Finally use this rating for news articles that are based on unconfirmed information.     “Mostly False Most or all of the information in the post or in the link being shared is inaccurate. This should also be used when the central claim being made is false.     “No Factual Content This rating is used for posts that are pure opinion comics satire or any other posts that do not make a factual claim. This is also the category to use for posts that are of the “Like this if you think...” variety.  “In gathering the Facebook engagement data the API did not return results for some posts. It did not return reaction count data for two posts and two posts also did not return comment count data. There were 70 posts for which the API did not return share count data. We also used CrowdTangle's API to check that we had entered all posts from all nine pages on the assigned days. In some cases the API returned URLs that were no longer active. We were unable to rate these posts and are unsure if they were subsequently removed by the pages or if the URLs were returned in error.” Acknowledgements This dataset was originally published on GitHub by BuzzFeed News here https//github.com/BuzzFeedNews/2016-10-facebook-fact-check  Inspiration Here are some ideas for exploring the hyperpartisan echo chambers on Facebook  How do left mainstream and right categories of Facebook pages differ in the stories they share? Which types of stories receive the most engagement from their Facebook followers? Are videos or links more effective for engagement? Can you replicate BuzzFeed’s findings that “the least accurate pages generated some of the highest numbers of shares reactions and comments on Facebook”?  Start a new kernel,account_id:post_id:Category:Page:Post URL:Date Published:Post Type:Rating:Debate:share_count:reaction_count:comment_count:,numeric:numeric:string:string:string:dateTime:string:string:string:numeric:numeric:numeric:,
UK Constituency Results , Tiago Vinhoza , www.kaggle.com/tiagotvv/uk-constituency-results , Tue Jun 13 2017 14:21:17 GMT+0530 (IST) , 2015 General Election and 2016 Referendum results by constituency ,89, politics- ,Background On April 18 2017 prime minister Theresa May announced that she was seeking a general election to be held on June 8. The day after the MPs voted to dissolve Parliament and a new election is confirmed.  It would be interesting to do some analysis of past election results on the 650 constituencies in to find out  The most vulnerable seats from each party. The seats targeted by each party. Can the Brexit referendum result affect the outcome of this election in a particular region of the UK? How a swing of x% from party A to party B affect the seat distribution?  among many other relevant questions. Dataset Contents This dataset consists of a mixture between two tables that were scrapped from Wikipedia. 1) 2015 general election results by constituency https//en.wikipedia.org/wiki/Results_of_the_United_Kingdom_general_election_2015_by_parliamentary_constituency 2) 2016 referendum result by constituency https//en.wikipedia.org/wiki/Results_of_the_United_Kingdom_European_Union_membership_referendum_2016#List_of_constituency_results This table used results estimated by Chris Hanretty in [1]. The tables were joined and cleaned. Some imputation errors were found and corrected.  A couple of columns was created (or removed).  The following set of columns was obtained  Constituency name of constituency Region region where the constituency is located Con Conservative party votes Lab Labour party votes UKIP UKIP votes LD Liberal Democrat votes SNP Scottish National Party votes Grn Green party votes DUP Democratic Unionist Party votes PC Plaid Cymru votes SF Sinn Fein votes UUP Ulster Unionist Party votes SDLP Social Democratic Labour Party votes Alliance Alliance party votes Ind Independent votes Spk Speaker votes Others Other parties votes ValidVotes sum of votes received by all parties WinningParty party that holds the seat SecondPlace party that finished in 2nd place WinningVotes number of votes received by the winning party SecondPlaceVotes number of votes received by the 2nd placed party WinningPct percentage of votes received by winner Majority WinningVotes - SecondPlaceVotes MajorityPct Majority as a percentage of ValidVotes TurnoutPct2015 turnout in the last general election RemainPct percentage of Remain votes in 2016 referendum LeavePct percentage of Leave votes in 2016 referendum LeaveMajority LeavePct - RemainPct  Reference [1] https//medium.com/@chrishanretty/final-estimates-of-the-leave-vote-or-areal-interpolation-and-the-uks-referendum-on-eu-membership-5490b6cab878 Disclaimer Cover picture is from Chensiyuan and made availabe under a Creative Commons Attribution-Share Alike 4.0 International 3.0 Unported 2.5 Generic 2.0 Generic and 1.0 Generic license. https//commons.wikimedia.org/wiki/File1_westminster_palace_panorama_2012_dusk.jpg,,,
James Comey Testimony , Matt Snell , www.kaggle.com/mattsnellaai/comeytestimony , Wed Jun 21 2017 07:06:24 GMT+0530 (IST) , Full transcript of Comey's Testimony to Senate Intelligence Committee ,112, law- politics- ,Context Data gathered from the James Comey testimony to the Senate Intelligence Committee on June 8th 2017 regarding possible Russian influence in the 2016 U.S. presidential election. Content Content includes the full transcript in transcript.csv as well as a breakdown of questions asked by each senator their political affiliation and Comey's response.  All CSVs are UTF-8. Acknowledgements Rod Castor - Initial Python script. AppliedAI. Inspiration Initially I did analysis to determine length of question by party length of Comey response by party number of times each word is used and words with a large difference by party. (Clinton used 16x more by Republicans).  Further analysis to follow as time permits.,Senator:Party Affiliation:Full Question:Comey:Comey Response:,string:string:string:string:string:,
Largest Dog Breed Dataset , LiamLarsen , www.kaggle.com/kingburrito666/largest-dog-breed-data-set , Thu Mar 30 2017 23:41:56 GMT+0530 (IST) , Dog breed tags type color registered or not etc. ,513, animals- ,Content Dog LicenseType Breed Color DogName OwnerZip ExpYear ValidDate I've included all the data from 2007 to 2017 Inspiration I love dogs To see trends in dog breeds why are some more popular than others?,LicenseType:Breed:Color:DogName:OwnerZip:ExpYear:ValidDate:,string:string:string:string:numeric:numeric:dateTime:,
Beginner Projects - Ergonomic Study on Chopsticks , Priya_ds , www.kaggle.com/priya2908/chopsticks-1992 , Mon Jun 12 2017 01:14:20 GMT+0530 (IST) , Evaluate the effects of chopsticks length on food-serving performance ,71, food culture- food and drink- psychometrics- ,Question As per the 1992 ergonomics study What is the optimum length of chopsticks usable by adults & children? Acknowledgements An investigation for determining the optimum length of chopsticks. Hsu SH Wu SP. Appl Ergon. 1991 Dec;22(6)395-400. PMID 15676839 Inspiration Data Sets shared by a beginner for Beginners ) Thanks to David Venturi and Udacity that I was able to get started off on this. More details here  Link,Food.Pinching.Efficiency:Individual:Chopstick.Length:,numeric:numeric:numeric:,
Horse Racing - Tipster Bets , gunner38 , www.kaggle.com/gunner38/horseracing , Wed Sep 14 2016 17:22:59 GMT+0530 (IST) , Thirty nine thousand bets from thirty one tipsters ,897, horse racing- ,Horse Racing - A different and profitable approach The traditional approach in attempting to make a profit from horse-racing using machine learning techniques is to use systems involving dozens and dozens of variables. These systems include the following types of variables Horse - Name Sex Age Pedigree Weight Speed over various distances race data with finishing times and positions - etc. Trainer info. Jockey info. Track info - Track track conditions - etc. And a whole lot more. Finding compiling maintaining and updating this data is a massive task for the individual. Unless you have access to a database of such data - where would you even start? We have a different approach. We collect maintain and use data from various 'Tipsters'. The tipsters use their skill to study the horses and make a prediction - that they think a particular horse will win a particular race. We take those tipsters predictions and put them through a machine learning algorithm (microsoft azure) asking it to predict a 'win' or 'lose' based upon the tipsters performance history. We have a database of approx. 39000 bets using 31 odd tipsters. Fifteen tipsters are active and sixteen tipsters are inactive The betting history for the inactive tipsters is used in the dataset as it appears to add 'weight' to the system when considering active tips. We have been using this system live for three months now and although it has it's ups and downs - it makes money! One bookmaker has already closed our account. We are looking to further optimize the system to reach it's maximum efficiency coupled with a betting strategy  to increase profitability. We ask for your help. If you can produce an 'Azure' system more efficient than ours - then further information will be shared with you. Questions  Are bets from inactive tipsters critical to performance? Is it better to have all the tipsters 'stacked on top of each other' in one large dataset or is the system better served by separating them out?  Predicting Bets When we ask the system to predict if a bet will Win or Lose for say Tipster A - we take the last ID number for that Tipster and add one to it - making it a new ID - outside the systems experience. That ID is used for all that Tipsters bets until the system is updated. The system is updated once a week. Good hunting. Gunner38,,,
Solar and Lunar Eclipses , NASA , www.kaggle.com/nasa/solar-eclipses , Thu Feb 09 2017 21:14:17 GMT+0530 (IST) , Date time and location of every eclipse in five thousand years ,495, astronomy- space- ,Context Eclipses of the sun can only occur when the moon is near one of its two orbital nodes during the new moon phase. It is then possible for the Moon's penumbral umbral or antumbral shadows to sweep across Earth's surface thereby producing an eclipse. There are four types of solar eclipses a partial eclipse during which the moon's penumbral shadow traverses Earth and umbral and antumbral shadows completely miss Earth; an annular eclipse during which the moon's antumbral shadow traverses Earth but does not completely cover the sun; a total eclipse during which the moon's umbral shadow traverses Earth and completely covers the sun; and a hybrid eclipse during which the moon's umbral and antumbral shadows traverse Earth and annular and total eclipses are visible in different locations. Earth will experience 11898 solar eclipses during the five millennium period -1999 to +3000 (2000 BCE to 3000 CE). Eclipses of the moon can occur when the moon is near one of its two orbital nodes during the full moon phase. It is then possible for the moon to pass through Earth's penumbral or umbral shadows thereby producing an eclipse. There are three types of lunar eclipses a penumbral eclipse during which the moon traverses Earth's penumbral shadow but misses its umbral shadow; a partial eclipse during which the moon traverses Earth's penumbral and umbral shadows; and a total eclipse during which the moon traverses Earth's penumbral and umbral shadows and passes completely into Earth's umbra. Earth will experience 12064 lunar eclipses during the five millennium period -1999 to +3000 (2000 BCE to 3000 CE). Acknowledgements Lunar eclipse predictions were produced by Fred Espenak from NASA's Goddard Space Flight Center.,Catalog Number:Calendar Date:Eclipse Time:Delta T (s):Lunation Number:Saros Number:Eclipse Type:Quincena Solar Eclipse:Gamma:Penumbral Magnitude:Umbral Magnitude:Latitude:Longitude:Penumbral Eclipse Duration (m):Partial Eclipse Duration (m):Total Eclipse Duration (m):,numeric:string:dateTime:numeric:numeric:numeric:string:string:numeric:numeric:numeric:string:string:numeric:numeric:numeric:,
Trappist-1 Solar System , NASA , www.kaggle.com/nasa/trappist1 , Thu Feb 23 2017 23:41:03 GMT+0530 (IST) , Data from the recently announced 7 exoplanet system ,225, space- ,Context On February 22 2017 NASA announces the discovery of the Trappist-1 Solar System which contains 7 earth sized exoplanets orbiting close to a dim star.  The planets' orbits are situated in the  'Goldilocks zone' making them prime candidates for extraterrestrial life. Content The data published here was pulled from NASA and CalTech's Exoplanet Archive http//exoplanetarchive.ipac.caltech.edu/index.html Column contents are explained further http//exoplanetarchive.ipac.caltech.edu/docs/API_exoplanet_columns.html Acknowledgements Use of the NASA Exoplanet Archive which is operated by the California Institute of Technology under contract with the National Aeronautics and Space Administration under the Exoplanet Exploration Program Inspiration A playground to work with data from an exciting discovery.  A lot of questions remained to be answered pending future studies.,,,
Median Listing Price (1 Bedroom) , Zillow , www.kaggle.com/zillow/median-listing-price-1-bedroom , Mon Nov 07 2016 08:24:56 GMT+0530 (IST) , Aggregated by neighborhood price per square foot ,530, cities- home- ,Context This dataset includes the median list price divided by the square footage of a 1-bedroom home for a select number of neighborhoods around the United States.  Content When available data includes median price per square foot on a monthly basis between January 2010 and September 2016. Selected neighborhoods include  Upper East Side New York NY Spring Valley Las Vegas NV Hollywood Los Angeles CA  Williamsburg New York NY Harlem New York NY Enterprise Las VegasNV Downtown San Jose CA Sheepshead Bay New York NY Forest Hills New York NY Jackson Heights New York NY Gramercy New York NY Flagami Miami FL Downtown Memphis TN Chelsea New York NY Oak Lawn Dallas TX Greater Uptown Houston TX South Loop Chicago IL Makiki-Lower Punchbowl-Tantalus Honolulu HI Downtown Los Angeles CA Capitol Hill Seattle WA Clinton New York NY Alexandria West Alexandria VA Financial District New York NY Flatiron District New York NY Landmark-Van Dom Alexandria VA Flamingo Lummus Miami Beach FL Winchester Las Vegas NV Brickell Miami FL Waikiki Honolulu HI Back Bay Boston MA Sutton Place New York NY and several others  Inspiration  What neighborhoods have the most expensive real estate per square foot? Least expensive? Which neighborhoods and/or cities have the fastest growth rates in price? Are there any neighborhoods that remain relatively steady in price? Given that this metric is listing price per square foot is there a similar dataset that could help you compare median square footage in a 1-bedroom home across neighborhoods?  Acknowledgement This dataset is part of Zillow Data and the original source can be found here under the Neighborhoods link.,RegionName:City:State:Metro:CountyName:SizeRank:2010-01:2010-02:2010-03:2010-04:2010-05:2010-06:2010-07:2010-08:2010-09:2010-10:2010-11:2010-12:2011-01:2011-02:2011-03:2011-04:2011-05:2011-06:2011-07:2011-08:2011-09:2011-10:2011-11:2011-12:2012-01:2012-02:2012-03:2012-04:2012-05:2012-06:2012-07:2012-08:2012-09:2012-10:2012-11:2012-12:2013-01:2013-02:2013-03:2013-04:2013-05:2013-06:2013-07:2013-08:2013-09:2013-10:2013-11:2013-12:2014-01:2014-02:2014-03:2014-04:2014-05:2014-06:2014-07:2014-08:2014-09:2014-10:2014-11:2014-12:2015-01:2015-02:2015-03:2015-04:2015-05:2015-06:2015-07:2015-08:2015-09:2015-10:2015-11:2015-12:2016-01:2016-02:2016-03:2016-04:2016-05:2016-06:2016-07:2016-08:2016-09:,string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Vehicle Fuel Economy Estimates 1984-2017 , US Environmental Protection Agency , www.kaggle.com/epa/fuel-economy , Tue Jan 31 2017 20:25:34 GMT+0530 (IST) , Which makes and models have the highest city and highway MPG? ,497, vehicles- ,Content The purpose of EPA’s fuel economy estimates is to provide a reliable basis for comparing vehicles. Most vehicles in the database (other than plug-in hybrids) have three fuel economy estimates a “city” estimate that represents urban driving in which a vehicle is started in the morning (after being parked all night) and driven in stop-and-go traffic; a “highway” estimate that represents a mixture of rural and interstate highway driving in a warmed-up vehicle typical of longer trips in free-flowing traffic; and a “combined” estimate that represents a combination of city driving (55%) and highway driving (45%). Estimates for all vehicles are based on laboratory testing under standardized conditions to allow for fair comparisons. The database provides annual fuel cost estimates rounded to the nearest $50 for each vehicle. The estimates are based on the assumptions that you travel 15000 miles per year (55% under city driving conditions and 45% under highway conditions) and that fuel costs $2.33/gallon for regular unleaded gasoline $2.58/gallon for mid-grade unleaded gasoline and $2.82/gallon for premium. EPA’s fuel economy values are good estimates of the fuel economy a typical driver will achieve under average driving conditions and provide a good basis to compare one vehicle to another. However your fuel economy may be slightly higher or lower than EPA’s estimates. Fuel economy varies sometimes significantly based on driving conditions driving style and other factors. Acknowledgements Fuel economy data are produced during vehicle testing at the Environmental Protection Agency's National Vehicle and Fuel Emissions Laboratory in Ann Arbor Michigan and by vehicle manufacturers with EPA oversight.,Vehicle ID:Year:Make:Model:Class:Drive:Transmission:Transmission Descriptor:Engine Index:Engine Descriptor:Engine Cylinders:Engine Displacement:Turbocharger:Supercharger:Fuel Type:Fuel Type 1:Fuel Type 2:City MPG (FT1):Unrounded City MPG (FT1):City MPG (FT2):Unrounded City MPG (FT2):City Gasoline Consumption (CD):City Electricity Consumption:City Utility Factor:Highway MPG (FT1):Unrounded Highway MPG (FT1):Highway MPG (FT2):Unrounded Highway MPG (FT2):Highway Gasoline Consumption (CD):Highway Electricity Consumption:Highway Utility Factor:Unadjusted City MPG (FT1):Unadjusted Highway MPG (FT1):Unadjusted City MPG (FT2):Unadjusted Highway MPG (FT2):Combined MPG (FT1):Unrounded Combined MPG (FT1):Combined MPG (FT2):Unrounded Combined MPG (FT2):Combined Electricity Consumption:Combined Gasoline Consumption (CD):Combined Utility Factor:Annual Fuel Cost (FT1):Annual Fuel Cost (FT2):Gas Guzzler Tax:Save or Spend (5 Year):Annual Consumption in Barrels (FT1):Annual Consumption in Barrels (FT2):Tailpipe CO2 (FT1):Tailpipe CO2 in Grams/Mile (FT1):Tailpipe CO2 (FT2):Tailpipe CO2 in Grams/Mile (FT2):Fuel Economy Score:GHG Score:GHG Score (Alt Fuel):My MPG Data:2D Passenger Volume:2D Luggage Volume:4D Passenger Volume:4D Luggage Volume:Hatchback Passenger Volume:Hatchback Luggage Volume:Start Stop Technology:Alternative Fuel/Technology:Electric Motor:Manufacturer Code:Gasoline/Electricity Blended (CD):Vehicle Charger:Alternate Charger:Hours to Charge (120V):Hours to Charge (240V):Hours to Charge (AC 240V):Composite City MPG:Composite Highway MPG:Composite Combined MPG:Range (FT1):City Range (FT1):Highway Range (FT1):Range (FT2):City Range (FT2):Highway Range (FT2):,numeric:numeric:string:string:string:string:string:string:numeric:string:numeric:numeric:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:boolean:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:,
NBA Draft Value , Aaron Miles , www.kaggle.com/amiles/nbadraftvalue , Mon Aug 22 2016 07:05:38 GMT+0530 (IST) , Data from NBA Drafts and Seasons to evaluate draft effectiveness ,825, basketball- ,These datasets contain information from NBA draft classes and subsequent advanced stats years. The idea is to evaluate which draft classes are better than others and in which ways they are better (did they produce more stars in the top 10 or more solid role players at the middle or end. I posted an analysis of this data here but there's a lot more to be done. For example my initial analysis just looks at drafts as a whole not breaking it down by top 10 top 30 or top 60 picks. I also just analyzed drafts since 2000 but the dataset I uploaded has info all the way back to 1978. This data was scraped from baskeball-reference.com There are 2 datasets season78 which has the fields  Season The NBA season data is drawn from. The later year is the Season value (e.g. 2015-2016 season is 2016) Player Name of the player WS Win Shares produced that season.  draft78 has the fields  Pick The draft pick the player was. Player Name of the player Yrs Number of years the player played in the NBA Draft Year of the draft. ,Pick:Player:Yrs:Draft:,numeric:string:numeric:numeric:,
Member States of the European Union , Eurostat , www.kaggle.com/eurostat/european-union , Tue Mar 14 2017 23:42:13 GMT+0530 (IST) , What divides and unites the 28 countries in the European Union? ,230, politics- international relations- ,Context The European Union is a unique economic and political union between twenty-eight countries that together cover much of the continent. It was created in the aftermath of the Second World War to foster economic cooperation and thus avoid conflict. The result was the European Economic Community (EEC) established in 1958 with Belgium Germany France Italy Luxembourg and the Netherlands as its members. What began as an economic union has evolved into an organization spanning policy areas from climate environment and health to external relations and security justice and migration. The 1993 name change from the European Economic Community (EEC) to the European Union (EU) reflected this. The European Union has delivered more than half a century of peace stability and prosperity helped raise living standards and launched a single European currency the Euro. In 2012 the EU was awarded the Nobel Peace Prize for advancing the causes of peace reconciliation democracy and human rights in Europe. The single market is the EU's main economic engine enabling most goods services money and people to move freely. Content The European Union covers over 4 million square kilometers and has 508 million inhabitants — the world’s third largest population after China and India. This dataset includes information on each EU member state candidate state or European Free Trade Agreement (EFTA) signatory state. Acknowledgements The membership population and economic data was published by the European Commission's Eurostat. Gross domestic product and GDP per capita in US dollars was provided by the World Bank. Inspiration How has the European Union grown in the past fifty years? What is the largest country by population or surface area? Which country has the largest economy by gross domestic product? How many different languages are spoken across all the member states?,"Country:European Union:Accession Year:Council Votes:European Parliament Seats:European Free Trade Agreement:European Single Market:European Monetary Union:Currency:Currency Code:Language:Population:Area (km²):Population Density:GDP (€, millions):GDP ($, millions):GDP per capita ($, millions):",string:string:numeric:numeric:numeric:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:,
Vacation rental properties in Palm Springs CA , Datafiniti , www.kaggle.com/datafiniti/palm-springs-vacation-rentals , Wed Jan 18 2017 23:39:38 GMT+0530 (IST) , A list of over 2000 vacation rental properties in Palm Springs CA ,144, home- ,About This Data This is a list of over 2000 vacation rental properties in Palm Springs CA.  The data is provided by Datafiniti's Property Database. Each property will have an entry for each price found for it so a single property may have multiple entries.  Data includes property name # beds # bathrooms price and more. The data is part of a larger data set that was used to determine the most and least expensive cities for short-term vacation rentals in the US. About Datafiniti Datafiniti provides instant access to web data.  We compile data from thousands of websites to create standardized databases of business product and property information.  Learn more. Want More? If you're interested in more data like this please contact us.,city:country:dateAdded:dateUpdated:deposit:descriptions:features:fees:languages:lat:long:name:numBathroom:numBedroom:numBed:numPeople:people:petPolicy:prices.dateSeen:prices.dateValidEnd:prices.dateValidStart:prices.minStay:prices.period:prices.price:province:rules:,string:string:dateTime:dateTime:string:string:string:string:string:numeric:numeric:string:numeric:numeric:string:numeric:string:string:dateTime:dateTime:dateTime:string:string:string:string:string:,
Terrorism in America 2001-Present , New America , www.kaggle.com/newamerica/terrorist-activity , Wed Feb 01 2017 22:14:31 GMT+0530 (IST) , Terrorist activity in the United States and by Americans overseas since 9/11 ,409, history- crime- ,Content The data in this report consists of individuals accused of terrorism and related crimes since September 11 2001 who are either American citizens or who engaged in terrorist activity within the United States. The data includes some individuals who died before being charged with a crime but were widely reported to have engaged in terrorist activity. Acknowledgements This report was produced by the International Security Program at New America.,plot_ID:plot_name:plot_ideology:plot_status:prevention_method:attack_date:victims_wounded:victims_killed:,numeric:string:string:string:string:dateTime:numeric:numeric:,
Top Running Times , Jguerreiro , www.kaggle.com/jguerreiro/running , Sat May 20 2017 03:24:30 GMT+0530 (IST) , Who are the fastest people in the world? ,200, running- ,Content Track all-time top performances (top 1000) for Olympics distances and the half marathon. Acknowledgements The data was scraped from http//www.alltime-athletics.com/index.html,Rank:Time:Name:Country:Date of Birth:Place:City:Date:Gender:Event:,numeric:dateTime:string:string:dateTime:numeric:string:dateTime:string:string:,
Woodbine Horse Racing Results , Benji Visser , www.kaggle.com/noqcks/woodbine-races , Fri May 12 2017 22:53:03 GMT+0530 (IST) , Woodbine Race Track in Toronto ON ,78, horse racing- ,Context This represents race data for Woodbine Track in Toronto ON from the period of 06/2015 - 04/2017,track:,string:,
March Madness Forecasts - Men & Women's , tylerfuller , www.kaggle.com/tylerfuller/march-madness-forecasts , Wed Mar 15 2017 02:52:47 GMT+0530 (IST) , 2017 March Madness forecasts from FiveThirtyEight ,282, basketball- ,Use FiveThirtyEight's March Madness (men's basketball) forecasts to make the perfect bracket. Round-by-Round probability for each team. Be sure to account for upsets! Huge thanks to FiveThirtyEight for allowing public access to this data. Who can make the perfect bracket?,gender:forecast_date:playin_flag:rd1_win:rd2_win:rd3_win:rd4_win:rd5_win:rd6_win:rd7_win:team_alive:team_id:team_name:team_rating:team_region:team_seed:,string:dateTime:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:string:numeric:,
Technical Indicator Backtest , Zhijin , www.kaggle.com/zhijinzhai/technical-indicator-backtest , Tue May 30 2017 20:40:13 GMT+0530 (IST) , 1993-2017 SPY Index daily return ,73, finance- technology forecasting- ,Context Using TA-Lib  Technical Analysis Library. Backtest on the SPY Index data using support and resistance indicators or any other indicator.  Content Data contains daily SPY Index  Date    Open    High    Low Close   Adj Close   Volume Acknowledgements Support for Resistance Technical Analysis WIKI link https//en.wikipedia.org/wiki/Support_and_resistance Inspiration Do your best for the backtest and technical indicator implementation,Date:Open:High:Low:Close:Adj Close:Volume:,dateTime:numeric:numeric:numeric:numeric:numeric:numeric:,
Professional Hockey Database , Open Source Sports , www.kaggle.com/open-source-sports/professional-hockey-database , Sun Nov 27 2016 03:04:06 GMT+0530 (IST) , Data on hockey players teams and coaches from 1909 to 2011 ,818, ice hockey- ,"The Hockey Database is a collection of historical statistics from men's professional hockey teams in North America. Note that as of v1 this dataset is missing a few files due to Kaggle restrictions on the number of individual files that can be uploaded. The missing files will be noted in the description below. The Data The dataset contains the following tables (all are csv)  Master Names and biographical information Scoring Scoring statistics ScoringSup Supplemental scoring statistics. Missing in v1 ScoringSC Scoring for Stanley Cup finals 1917-18 through 1925-26 ScoringShootout Scoring statistics for shootouts Goalies Goaltending statistics GoaliesSC Goaltending for Stanley Cup finals 1917-18 through 1925-26 GoaliesShootout Goaltending statistics for shootouts AwardsPlayers Player awards trophies postseason all-star teams AwardsCoaches Coaches awards trophies postseason all-star teams AwardsMisc Miscellaneous awards. Missing in v1 Coaches Coaching statistics Teams Team regular season statistics TeamsPost Team postseason statistics TeamsSC Team Stanley Cup finals statistics 1917-18 through 1925-26 TeamsHalf First half / second half standings 1917-18 through 1920-21 TeamSplits Team home/road and monthly splits TeamVsTeam Team vs. team results SeriesPost Postseason series CombinedShutouts List of combined shutouts. abbrev Abbreviations used in Teams and SeriesPost tables HOF Hall of Fame information  Descriptions of the individual fields in each file can be found in the file's description. Copyright Notice The Hockey Databank project allows for free usage of its data including the production of a commercial product based upon the data subject to the terms outlined below.  1) In exchange for any usage of data in whole or in part you agree to display the following statement prominently and in its entirety on your end product ""The information used herein was obtained free of charge from and is copyrighted by the Hockey Databank project.  For more information about the Hockey Databank project please visit http//sports.groups.yahoo.com/group/hockey-databank"" 2) Your usage of the data constitutes your acknowledgment acceptance and agreement that the Hockey Databank project makes no guarantees regarding the accuracy of the data supplied and will not be held responsible for any consequences arising from the use of the information presented.  Acknowledgments This dataset was downloaded from the hockey database at Open Source Sports. The original acknowledgments are as follows A variety of sources were consulted while constructing this database.  These are listed below in no particular order. Books  National Hockey League Guide (various years) National Hockey League Official Record Book (1982-83 and 1983-84) National Hockey League Official Guide & Record Book (1984-85 to present) The Stanley Cup Records and Statistics (various years) World Hockey Association Media Guide (various years) WHA Schedule & Statistics (1974-75) The Sporting News Hockey Guide (various years) Official NHL Record Book 1917-64 The Complete Historical and Statistical Reference to the World Hockey Association 1972-1979 by Scott Surgent; Xaler Press (7th edition 2004; 8th edition 2008) Total Hockey; Total Sports Publishing (1st edition 1998; 2nd edition 2000) The Encyclopedia of Hockey by Robert A. Styer; A.S. Barnes (2nd edition 1973) The Hockey Encyclopedia by Stan Fischler and Shirley Walton Fischler; Macmillan (1983) The Trail of the Stanley Cup (Vol. 1 2 and 3) by Charles L. Coleman  Periodicals  The Sporting News  On-line sources  ESPN.com http//www.espn.com/nhl/statistics Find A Grave http//www.findagrave.com The Goaltender Home Page (Doug Norris)        http//hockeygoalies.org History Of NHL Trades         http//nhltradeshistory.blogspot.com Hockey Research Association        http//www.hockeyresearch.com/stats Hockey-Reference.com (Justin Kubatko)        http//www.hockey-reference.com Hockey Summary Project        http//sports.groups.yahoo.com/group/hockey_summary_project/         http//hsp.flyershistory.com        (previously at http//www.shrpsports.com/hsp) Internet Hockey Database (Ralph Slate)         http//www.hockeydb.com Legends of Hockey.net (Hockey Hall of Fame)        http//www.legendsofhockey.net/html/search.htm LostHockey.com        http//www.losthockey.com National Hockey League        http//www.nhl.com NHL Hockey Shootout Statistics        http//jeays.net/shootout/index.htm NHL Shootouts        http//www.nhlshootouts.com North American Pro Hockey        http//www.ottawavalleyonline.com/sites/tomking_01/index.html Puckerings        http//www.puckerings.com Society for International Hockey Research        http//www.sihrhockey.org The Sports Network        http//www.sportsnetwork.com USA Today hockey stats archive        http//www.usatoday.com/sports/hockey         http//www.usatoday.com/sports/hockey/archive.htm Yahoo Sports        http//sports.yahoo.com/nhl  Thanks to the following individuals  Ralph Dinger (NHL Publishing / Dan Diamond and Associates) has confirmed a number of corrections to errors found in the NHL's official statistics. Thanks also to Justin Kubatko of hockey-reference.com for a number of discussions in this area. Morey Holzman provided information on Lloyd Cook's 1921-22 goaltending appearance. Stu McMurray provided correct 1917-18 scoring statistics including GWG. Doug Norris provided corrected 1984-85 statistics for Rick St. Croix. Paul Reeths created the Hall of Fame table and provided updates for the Coaches table  Other contributors include Roger Brewer Mike Burton Eric Hornick and Claude Paradis. An acknowledgement is also given to the team led by Sean Forman and Sean Lahman that has developed and maintained the Lahman baseball database.  This database follows the same general design.",Type:Code:Fullname:,string:string:string:,
Crime in Bulgaria 2000 to 2014 , Rumen Manev , www.kaggle.com/rmanev/crime-in-bulgaria , Tue Apr 18 2017 20:43:56 GMT+0530 (IST) , Percentage of resolved cases per region ,142, crime- ,Context I've processed the data freely available from the Bulgarian Ministry of Interior Affairs and decided to provide it to see what interesting visualizations you might come up with. It would also be interesting to see a forecast of the same crime types for futures years based on the available data. Content The dataset contains information about various types of criminal activity. It shows the percentage of resolved crimes between 2000 and 2014 in all 28 regions of Bulgaria. Acknowledgements Data is taken from the reports found on the homepage of the Bulgarian Ministry of Interior Affairs.,"Year:Region:Total:Crimes against the person:Murder:Intentional murder:Attempted murder:Killing a newborn:Pushing to suicide:Lust:Molestation:Rape:Attempted rape:Pimping:Forced homosexualism:Body injury:Severe body injury:Kidnapping:Keeping hostage:Human trafficing:Crime against property:Robbery:Armed robbery:Armed robbery with firearms:Stealing:Pickpocketing:Breaking and entering:Office break in:Store break in:Vehicle break in :Fraud:Extortion:Generally dangerous crime:Arson:Damage through explosion:Illegal firearms ownership:Vehicle theft:Falsifying license plates:Illegal entry of a vehicle:Crimes related to drugs:Smuggling:Production, possession, distribution, carrying:",numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Front Door Motion & Brightness , Frank , www.kaggle.com/fdraeger/frontdoormotionbrightness , Fri May 26 2017 22:53:40 GMT+0530 (IST) , Can you tell when the newspaper is delivered? ,75, home- artificial intelligence- ,Context These data are from a couple of sensors of my dad's house. Content The data are from motion sensors at the front door which also regularly logs brightness. The front door motion detection data also includes motions of three cats. Data structure is pretty self explanatory. Load the csv files. Data Files I already added day-of-year year weekday and time of day to the data for easier handling. Brightness These time-stamped values resemble the brightness readings. They range from dark (low numbers) to bright day light (high numbers). The brightness nightly mean values differ. The reasons are Christmas decoration during the winter and solar lights being set up some time in mid April this year. Contacts These data indicate door and window openings. They are time-stamped. The boolean value isClosed indicates wether the contact has been closed. Motion There is a motion sensor at the front door which indicates movement. Movement detections also are time-stamped data. Questions  At what time of the day the newspaper is delivered? How can I tell from the brightness value what kind of weather it was on this day?  Additional information  Newspaper is not delivered on Sundays Newspaper is in the mailbox by 630 AM Newspaper is usually taken out of the mailbox around 700 AM (not on Saturdays) There is regular front door activity - someon leaving the house - at 730 (not on Saturdays and Sundays) There are three cats living at the house ,:timestamp:brightness:doy:dow:year:tod:,numeric:dateTime:numeric:numeric:numeric:numeric:dateTime:,
UjiIndoorLoc: An indoor localization dataset , GIANT: Machine learning for smart environments , www.kaggle.com/giantuji/UjiIndoorLoc , Wed Dec 21 2016 17:43:32 GMT+0530 (IST) , Compare WiFi fingerprinting indoor localization algorithms ,189, geography- computing and society- ,Context This data set is focused on WLAN fingerprint positioning technologies and methodologies (also know as WiFi Fingerprinting). It was the official database used in the IPIN2015 competition.  Many real world applications need to know the localization of a user in the world to provide their services. Therefore automatic user localization has been a hot research topic in the last years. Automatic user localization consists of estimating the position of the user (latitude longitude and altitude) by using an electronic device usually a mobile phone. Outdoor localization problem can be solved very accurately thanks to the inclusion of GPS sensors into the mobile devices. However indoor localization is still an open problem mainly due to the loss of GPS signal in indoor environments. Although there are some indoor positioning technologies and methodologies this database is focused on WLAN fingerprint-based ones (also know as WiFi Fingerprinting). Although there are many papers in the literature trying to solve the indoor localization problem using a WLAN fingerprint-based method there still exists one important drawback in this field which is the lack of a common database for comparison purposes. So UJIIndoorLoc database is presented to overcome this gap.  The UJIIndoorLoc database covers three buildings of Universitat Jaume I (http//www.uji.es) with 4 or more floors and almost 110.000m2. It can be used for classification e.g. actual building and floor identification or regression e.g. actual longitude and latitude estimation. It was created in 2013 by means of more than 20 different users and 25 Android devices. The database consists of 19937 training/reference records (trainingData.csv file) and 1111 validation/test records (validationData.csv file) The 529 attributes contain the WiFi fingerprint the coordinates where it was taken and other useful information. Each WiFi fingerprint can be characterized by the detected Wireless Access Points (WAPs) and the corresponding Received Signal Strength Intensity (RSSI). The intensity values are represented as negative integer values ranging -104dBm (extremely poor signal) to 0dbM. The positive value 100 is used to denote when a WAP was not detected. During the database creation 520 different WAPs were detected. Thus the WiFi fingerprint is composed by 520 intensity values. Then the coordinates (latitude longitude floor) and Building ID are provided as the attributes to be predicted. The particular space (offices labs etc.) and the relative position (inside/outside the space) where the capture was taken have been recorded. Outside means that the capture was taken in front of the door of the space. Information about who (user) how (android device & version) and when (timestamp) WiFi capture was taken is also recorded.  Content  Attributes 001 to 520 (WAP001-WAP520) Intensity value for WAP001. Negative integer values from -104 to 0 and +100. Positive value 100 used if WAP001 was not detected. Attribute 521 (Longitude) Longitude. Negative real values from -7695.9387549299299000 to -7299.786516730871000 Attribute 522 (Latitude) Latitude. Positive real values from 4864745.7450159714 to 4865017.3646842018. Attribute 523 (Floor) Altitude in floors inside the building. Integer values from 0 to 4.  Attribute 524 (BuildingID) ID to identify the building. Measures were taken in three different buildings. Categorical integer values from 0 to 2. Attribute 525 (SpaceID) Internal ID number to identify the Space (office corridor classroom) where the capture was taken.  Categorical integer values. Attribute 526 (RelativePosition) Relative position with respect to the Space (1 - Inside 2 - Outside in Front of the door). Categorical integer values. Attribute 527 (UserID) User identifier (see below). Categorical integer values. Attribute 528 (PhoneID) Android device identifier (see below). Categorical integer values. Attribute 529 (Timestamp) UNIX Time when the capture was taken.  Integer value.  Relevent Paper More information can be found in this paper Joaquín Torres-Sospedra Raúl Montoliu Adolfo Martínez-Usó Tomar J. Arnau Joan P. Avariento Mauri Benedito-Bordonau Joaquín Huerta. UJIIndoorLoc A New Multi-building and Multi-floor Database for WLAN Fingerprint-based Indoor Localization Problems. In Proceedings of the Fifth International Conference on Indoor Positioning and Indoor Navigation 2014. Available at http//www.ipin2014.org/wp/pdf/4A-3.pdf If your are going to use this dataset in your research please cite this paper Acknowledgements The dataset was created by  Joaquín Torres-Sospedra Raul Montoliu Adolfo Martínez-Usó Tomar J. Arnau Joan P. Avariento Mauri Benedito-Bordonau Joaquín Huerta Yasmina Andreu óscar Belmonte Vicent Castelló Irene Garcia-Martí Diego Gargallo Carlos Gonzalez Nadal Francisco Josep López Ruben Martínez Roberto Mediero Javier Ortells Nacho Piqueras Ianisse Quizán David Rambla Luis E. Rodríguez Eva Salvador Balaguer Ana Sanchís Carlos Serra and Sergi Trilles. Inspiration The objective is to estimate the building floor and coordinates (latitude and longitude) of the 1111 samples included in the validation set. Since the real values of the building floor and coordinates are also included it is posible to determine the localization error. The formula used in the IPIN2015 competition was the mean of the localization error of each sample. The localization error of each sample can be estimated as follows Error = building_penality * building_error + floor_penality * floor_error + coordinates_error where  building_error is 1 if the estimated building is not equal to the real one. 0 otherwise  floor_error is 1 if the estimated floor is not equal to the real one. 0 otherwise  coordinates_error is sqrt(   (estimated_latitude - real_latitude)^2 +  (estimated_longitude-real_longitude)^2)  In the IPIN2015 competition building_penalty and floor_penalty where set to 50 and 4 meters respectively.,WAP001:WAP002:WAP003:WAP004:WAP005:WAP006:WAP007:WAP008:WAP009:WAP010:WAP011:WAP012:WAP013:WAP014:WAP015:WAP016:WAP017:WAP018:WAP019:WAP020:WAP021:WAP022:WAP023:WAP024:WAP025:WAP026:WAP027:WAP028:WAP029:WAP030:WAP031:WAP032:WAP033:WAP034:WAP035:WAP036:WAP037:WAP038:WAP039:WAP040:WAP041:WAP042:WAP043:WAP044:WAP045:WAP046:WAP047:WAP048:WAP049:WAP050:WAP051:WAP052:WAP053:WAP054:WAP055:WAP056:WAP057:WAP058:WAP059:WAP060:WAP061:WAP062:WAP063:WAP064:WAP065:WAP066:WAP067:WAP068:WAP069:WAP070:WAP071:WAP072:WAP073:WAP074:WAP075:WAP076:WAP077:WAP078:WAP079:WAP080:WAP081:WAP082:WAP083:WAP084:WAP085:WAP086:WAP087:WAP088:WAP089:WAP090:WAP091:WAP092:WAP093:WAP094:WAP095:WAP096:WAP097:WAP098:WAP099:WAP100:WAP101:WAP102:WAP103:WAP104:WAP105:WAP106:WAP107:WAP108:WAP109:WAP110:WAP111:WAP112:WAP113:WAP114:WAP115:WAP116:WAP117:WAP118:WAP119:WAP120:WAP121:WAP122:WAP123:WAP124:WAP125:WAP126:WAP127:WAP128:WAP129:WAP130:WAP131:WAP132:WAP133:WAP134:WAP135:WAP136:WAP137:WAP138:WAP139:WAP140:WAP141:WAP142:WAP143:WAP144:WAP145:WAP146:WAP147:WAP148:WAP149:WAP150:WAP151:WAP152:WAP153:WAP154:WAP155:WAP156:WAP157:WAP158:WAP159:WAP160:WAP161:WAP162:WAP163:WAP164:WAP165:WAP166:WAP167:WAP168:WAP169:WAP170:WAP171:WAP172:WAP173:WAP174:WAP175:WAP176:WAP177:WAP178:WAP179:WAP180:WAP181:WAP182:WAP183:WAP184:WAP185:WAP186:WAP187:WAP188:WAP189:WAP190:WAP191:WAP192:WAP193:WAP194:WAP195:WAP196:WAP197:WAP198:WAP199:WAP200:WAP201:WAP202:WAP203:WAP204:WAP205:WAP206:WAP207:WAP208:WAP209:WAP210:WAP211:WAP212:WAP213:WAP214:WAP215:WAP216:WAP217:WAP218:WAP219:WAP220:WAP221:WAP222:WAP223:WAP224:WAP225:WAP226:WAP227:WAP228:WAP229:WAP230:WAP231:WAP232:WAP233:WAP234:WAP235:WAP236:WAP237:WAP238:WAP239:WAP240:WAP241:WAP242:WAP243:WAP244:WAP245:WAP246:WAP247:WAP248:WAP249:WAP250:WAP251:WAP252:WAP253:WAP254:WAP255:WAP256:WAP257:WAP258:WAP259:WAP260:WAP261:WAP262:WAP263:WAP264:WAP265:WAP266:WAP267:WAP268:WAP269:WAP270:WAP271:WAP272:WAP273:WAP274:WAP275:WAP276:WAP277:WAP278:WAP279:WAP280:WAP281:WAP282:WAP283:WAP284:WAP285:WAP286:WAP287:WAP288:WAP289:WAP290:WAP291:WAP292:WAP293:WAP294:WAP295:WAP296:WAP297:WAP298:WAP299:WAP300:WAP301:WAP302:WAP303:WAP304:WAP305:WAP306:WAP307:WAP308:WAP309:WAP310:WAP311:WAP312:WAP313:WAP314:WAP315:WAP316:WAP317:WAP318:WAP319:WAP320:WAP321:WAP322:WAP323:WAP324:WAP325:WAP326:WAP327:WAP328:WAP329:WAP330:WAP331:WAP332:WAP333:WAP334:WAP335:WAP336:WAP337:WAP338:WAP339:WAP340:WAP341:WAP342:WAP343:WAP344:WAP345:WAP346:WAP347:WAP348:WAP349:WAP350:WAP351:WAP352:WAP353:WAP354:WAP355:WAP356:WAP357:WAP358:WAP359:WAP360:WAP361:WAP362:WAP363:WAP364:WAP365:WAP366:WAP367:WAP368:WAP369:WAP370:WAP371:WAP372:WAP373:WAP374:WAP375:WAP376:WAP377:WAP378:WAP379:WAP380:WAP381:WAP382:WAP383:WAP384:WAP385:WAP386:WAP387:WAP388:WAP389:WAP390:WAP391:WAP392:WAP393:WAP394:WAP395:WAP396:WAP397:WAP398:WAP399:WAP400:WAP401:WAP402:WAP403:WAP404:WAP405:WAP406:WAP407:WAP408:WAP409:WAP410:WAP411:WAP412:WAP413:WAP414:WAP415:WAP416:WAP417:WAP418:WAP419:WAP420:WAP421:WAP422:WAP423:WAP424:WAP425:WAP426:WAP427:WAP428:WAP429:WAP430:WAP431:WAP432:WAP433:WAP434:WAP435:WAP436:WAP437:WAP438:WAP439:WAP440:WAP441:WAP442:WAP443:WAP444:WAP445:WAP446:WAP447:WAP448:WAP449:WAP450:WAP451:WAP452:WAP453:WAP454:WAP455:WAP456:WAP457:WAP458:WAP459:WAP460:WAP461:WAP462:WAP463:WAP464:WAP465:WAP466:WAP467:WAP468:WAP469:WAP470:WAP471:WAP472:WAP473:WAP474:WAP475:WAP476:WAP477:WAP478:WAP479:WAP480:WAP481:WAP482:WAP483:WAP484:WAP485:WAP486:WAP487:WAP488:WAP489:WAP490:WAP491:WAP492:WAP493:WAP494:WAP495:WAP496:WAP497:WAP498:WAP499:WAP500:WAP501:WAP502:WAP503:WAP504:WAP505:WAP506:WAP507:WAP508:WAP509:WAP510:WAP511:WAP512:WAP513:WAP514:WAP515:WAP516:WAP517:WAP518:WAP519:WAP520:LONGITUDE:LATITUDE:FLOOR:BUILDINGID:SPACEID:RELATIVEPOSITION:USERID:PHONEID:TIMESTAMP:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
How News Appears on Social Media , MorganMazer , www.kaggle.com/socialmedianews/how-news-appears-on-social-media , Mon May 01 2017 22:12:52 GMT+0530 (IST) , Comparing What's on Twitter and Reddit to What's Happening in the World ,295, news agencies- internet- ,Context As part of a capstone project we wanted to compare what social media users are talking about to what's going on in the world to see if and how social media users care about news events. We scraped data from Twitter Reddit reliable news sources and Google Trending Topics.  Content This data set includes nine tables Twitter news Google Trending Topics and six popular subreddits (news worldnews upliftingnews sports politics television).  Twitter trending topic date trending sentiment analysis scores most common word associated with the trend most common pairs of words associated with the trend. News headlines (collected from BBC News USA Today and the Washington Post) date the article was posted. Google Trending Topics trending topic date trending.  Subreddits post title time date score (upvotes - downvotes) number of comments.  Acknowledgements This data was collected as part of a semester project in the Capstone in Social Network Analytics at Virginia Tech Spring 2017 taught by Siddharth Krishnan. The data was collected over a period of eight days in April 2017.  Inspiration What do social media users care about and in what ways do they care? What may they not know about? What types of trends appear most on each social media platform? Are people who get the majority of their news from social media able to get an accurate and comprehensive idea of what is going on? How can algorithms such as Twitter’s trending topics algorithm influence and shape what users talk about read and react to?,:Title:Date:Time:Score:Number of Comments:,numeric:string:dateTime:dateTime:numeric:numeric:,
2014 Public Libraries Survey , Institute of Museum and Library Services , www.kaggle.com/imls/public-libraries , Thu Jan 26 2017 21:00:22 GMT+0530 (IST) , What state has the most library books per capita? ,195, libraries- ,Content The Public Libraries Survey (PLS) is conducted annually by the Institute of Museum and Library Services under the mandate in the Museum and Library Services Act of 2010. The data file includes all public libraries identified by state library administrative agencies in the 50 states and the District of Columbia. The reporting unit for the survey is the administrative entity defined as the agency that is legally established under local or state law to provide public library service to the population of a local jurisdiction. The FY 2014 PLS collected state characteristics data including the state total population estimate number of central and branch libraries and the total library visits and circulation transactions and data on each public library such as its name and location population of legal service area print and digital collections full-time-equivalent staff and operating revenue and expenditures. Acknowledgements The U.S. Census Bureau is the data collection agent for IMLS Public Libraries Survey.,State:Library ID:Submission Year:Library Name:Street Address:City:Zip Code:Longitude:Latitude:State Code:County Code:County:County Population:Public Library Definition:Legal Basis:Administrative Structure:Interlibrary Relationship:Service Population:Service Population Without Duplicates:Central Libraries:Branch Libraries:Bookmobiles:MLS Librarians:Librarians:Employees:Total Staff:Local Government Operating Revenue:State Government Operating Revenue:Federal Government Operating Revenue:Other Operating Revenue:Total Operating Revenue:Salaries:Benefits:Total Staff Expenditures:Print Collection Expenditures:Digital Collection Expenditures:Other Collection Expenditures:Total Collection Expenditures:Other Operating Expenditures:Total Operating Expenditures:Local Government Capital Revenue:State Government Capital Revenue:Federal Government Capital Revenue:Other Capital Revenue:Total Capital Revenue:Total Capital Expenditures:Print Collection:Digital Collection:Audio Collection:Downloadable Audio:Physical Video:Downloadable Video:Local Cooperative Agreements:State Licensed Databases:Total Licensed Databases:Print Subscriptions:Hours Open:Library Visits:Reference Transactions:Registered Users:Circulation Transactions:Interlibrary Loans Provided:Interlibrary Loans Received:Library Programs:Children’s Programs:Young Adult Programs:Library Program Audience:Children’s Program Audience:Young Adult Program Audience:Public Internet Computers:Internet Computer Use:Wireless Internet Sessions:Start Date:End Date:,string:string:numeric:string:string:string:numeric:numeric:numeric:numeric:numeric:string:numeric:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:dateTime:dateTime:,
My Chess Games , Gabriel Forsythe y Korzeniewicz , www.kaggle.com/gabfyk/chess-games , Thu Apr 06 2017 19:29:59 GMT+0530 (IST) , Played on the Lichess app ,158, board games- ,Context Since downloading the Lichess app on July 10 2016 (and as of March 16 2017) I have played 2237 games of chess on my phone. Lichess allows one to play chess against other players or computers with a variety of time formats and rule variations. It is my main phone addiction and occasional cause of procrastination. Upon discovering Kaggle I decided to explore the site by uploading the data of these games and playing around with them.  Content Most of the data is contained in 20170316_lichess_games.csv accompanied by two separate files for white and black featuring move times (in tenths of seconds) for each game. The main files includes data on  Unique identifiers (including game id url date/time created date/time of last move) Game parameters (including rated or not rule variant clock settings) Game results (including total playing time total turns last player to move winning color method of winning [checkmate/resigns/etc]) Game play content (including move list opening names) Player specific information (including player id ELO rating [before game] ELO rating change [if rated] total playing time and min/max move times)  Acknowledgements All data was downloaded via the Lichess API. Inspiration Besides the personal interests of seeing what variables are most predictive of my winning or what areas in which I have the most opportunity to improve it may be interesting to explore how to create a chess coach for individual players. ,id:,string:,
Pesticide Use in Agriculture , US Geological Survey , www.kaggle.com/usgs/pesticide-use , Wed Jan 25 2017 22:31:02 GMT+0530 (IST) , Which compounds are used most frequently in the United States? ,318, agriculture- ,Content This dataset includes annual county-level pesticide use estimates for 423 pesticides (active ingredients) applied to agricultural crops grown in the contiguous United States. Two different methods were used to estimate a range of pesticide use for all states except California. Both low and high estimate methods incorporated proprietary surveyed rates for United States Department of Agriculture Crop Reporting Districts but the estimates differed in how they treated situations when a district was surveyed and pesticide use was not reported. Low estimates assumed zero use in the district for that pesticide; however high estimates treated the unreported use of pesticides as missing data and estimated the pesticide usage from neighboring locations within the same region. Acknowledgements Data for the state of California was provided by the 2014 Department of Pesticide Regulation Pesticide Use Report. The 2015 report is not yet available.,COMPOUND:YEAR:STATE_CODE:COUNTY_CODE:LOW_ESTIMATE:HIGH_ESTIMATE:,string:numeric:numeric:numeric:numeric:numeric:,
2017 Conservative Party of Canada Leadership , Shane Smith , www.kaggle.com/smid80/2017conservativepartycanadaleadership , Sun May 28 2017 16:56:03 GMT+0530 (IST) , Results of the Leadership vote on 27 May 2017 ,49, politics- ,On 27 May 2017 the Conservative Party of Canada elected a new party leader. As the party with the second-most seats in the Parliament the new leader will become the official Leader of the Opposition.  The party rules dictate that each electoral district (riding) is equally represented in the leadership election regardless of the number of members in the riding although leadership contenders endeavour to sign up new members in order to increase their vote proportion in the riding. The election is an instant runoff vote with members completing their preferences on the ballot paper. If no candidate achieves a majority the candidate with the fewest votes is excluded and their votes distributed to remaining candidates based on the preferences of the voters. Fourteen candidates registered for the leadership ballot and engaged in debates in both official languages.  The Member for Regina—Qu'Appelle in Saskatchewan Andrew Scheer MP won the leadership on the thirteenth ballot with 50.95% of the vote compared to Maxime Bernier MP with 49.05% of the vote.  This dataset details the percentage of the vote received by each candidate in each round by province and by riding. The results were taken from the Conservative Party of Canada website https//www.intvoting.com/cpcresults/index.html?lang=en#results  It may be interesting to explore which candidates attracted the most preferences as other candidates were excluded and which were more polarising figures. It may also be interesting to see which candidates performed strongest in Conservative-held ridings and which candidates performed best in competitive ridings. Perhaps a relationship exists between support for a party at the 2015 election and support for a candidate in the leadership.,Province:Candidate name:Round:Percent:,string:string:numeric:numeric:,
French Presidential Election 2017 , GrishaSizov , www.kaggle.com/grishasizov/frenchpresidentialelection2017 , Fri May 26 2017 17:44:36 GMT+0530 (IST) , Results of both rounds at polling station level ,185, politics- ,Presidential elections have just finished in France with two rounds on April 23rd and May 7th 2017. The results of the elections are available online for each ~67000 polling stations around the country. This data can be used to gain insights about both the electorate and the candidates. Examples of basic questions worth looking at are   How are candidates' scores correlated with each other? Can you infer 'political affinity' of the candidates just looking at the data without any other a priori knowledge?  How are scores of various candidates correlated with the turnout? Supporters of which candidate are the most 'participative'?  How did the votes get redistributed from the first to the second round? Can you build an a posteriori predictive model of the second round results taking as an input the results of the first round ? The data provides coordinates of each polling station. Can you gain any insight from the geography?  Some preliminary analysis is described in two blog posts here and here. This dataset is inspired by an analogous one for the 2016 US elections by Ben Hamner.,:Department code:Department:Constituency code:Constituency:Commune code:Commune:Polling station:Registered:Abstentions:% Abs/Reg:Voters:% Vot/Reg:None of the above(NOTA):% NOTA/Reg:% NOTA/Vot:Nulls:% Nulls/Reg:% Nulls/Vot:Expressed:% Exp/Reg:% Exp/Vot:Signboard:Sex:Surname:First name:Voted:% Votes/Reg:% Votes/Exp:INSEE code:Coordinates:Polling station name:Address:Postal code:City:Poll.St.-unique:,numeric:numeric:string:numeric:string:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:numeric:numeric:numeric:numeric:string:string:string:numeric:string:string:,
Presidential Inaugural Addresses , AdhokshajaPradeep , www.kaggle.com/adhok93/presidentialaddress , Fri Mar 31 2017 13:46:51 GMT+0530 (IST) , US president name date and speech text ,181, politics- linguistics- ,Context Every Presidency starts off with the Inaugural Address. This defines the course for the next 4 years. How do the length word usage lexical diversity change from President to President? Content The data was scraped from http//www.bartleby.com/124/ using R's rvest web scraping library. The procedure can be found here The data set is in the .csv format. The columns are  Name Inaugural Address  Date and text. Acknowledgements I would like to thank http//www.bartleby.com for making their data available for free. Inspiration I saw a documentary by Vox on Presidential Inaugural Speeches. They conducted a study on the common characteristics amongst speeches by influential presidents. Through a data driven approach we can find several interesting insights which help correlate a President's influence and his inaugural speech. What word patterns do influential Presidents use often? How does speech length vary?,:Name:Inaugural Address:Date:text:,numeric:string:string:dateTime:string:,
RollerCoaster Tycoon Data , Nolan Conaway , www.kaggle.com/nolanbconaway/rollercoaster-tycoon-rides , Thu Aug 03 2017 06:54:45 GMT+0530 (IST) , Every roller coaster I have built in RCT2 for iPad ,117, video games- ,RollerCoaster Tycoon Data When I was a kid i loved RollerCoaster Tycoon. I recently found out that Atari had ported the classic game for iOS and I immediately purchased it. Now I play whenever I get a free moment. Usually I manage to play a few games a week while I watch TV or listen to podcasts. If you do not know a main aspect of the game involves designing custom roller coasters. When you build something new you can go to a special window to view the ride statistics  The most important metrics are at the top You want to maximize excitement without making the ride too intense or nauseating.  When I was a kid I had no patience for numbers (I created rides for maximum awesomeness) but these days I'm fond of that sort of thing. After I completed a few park scenarios I began to wonder If i can use my own data to build better roller coasters. So I started saving my ride stats in a spreadsheet After completing each scenario I just logged the stats from each ride into the spreadsheet. This repository contains that data as well as any analyses I might conduct on it. The Data I still play a few games a week (duh) so occasionally I will update the database with my future creations (feel free to send me your own!). Each ride is cataloged based on the info from the window above  park_id Integer. Unique park identifier zero-indexed. theme String. Title of the park scenario. rollercoaster_type String. Category of roller coaster. custom_design Boolean. True/False on whether I designed the ride or if it was pre-designed. excitement Float. Ride excitement from 0 (very low) with no specified maximum but it is very rarely above 10.0. Larger numbers are always better. intensity  Float. Ride intensity from 0 (very dull) with no specified maximum though most (well-designed) rides are under 10.0. Each customer has their own intensity preference. nausea Float. Ride nausea from 0 (very low) with no specified maximum but lower is better and rides rarely have values above 10.0. excitement_rating intensity_rating `nausea_rating String.  Descriptors of the excitement intensity and nausea ratings. max_speed Integer. Maximum speed (mph). avg_speed Integer. Average speed (mph). ride_time Integer. Total duration of the ride in seconds. ride_length Integer. Length of the ride in feet. max_pos_gs max_neg_gs max_lateral_gs Float. Values describing the maximum observed positive negative and lateral G-Forces. total_air_time Float. Number of seconds in which riders experience weightlessness. drops Integer. Number of downhill segments. highest_drop_height Integer. Highest height (with 0 being sea-level?) from which a drop takes place. Note rides can drop to -6 in the game. inversions Integer. Number of times riders are upside-down during the ride. This accounts for loops corkscrews etc. values of -1 indicate missing information (see caveat #2).  Caveats  So far I've only been keeping track of roller coasters so the data does not include customizable thrill rides or water rides (excepting the Dinghy Slide which is classified as a roller coaster in the game). It is unfortunate that the first handful of rides I built did not have any inversions and it took me several weeks to realize that the game does not show this info unless there are inversions. During that time I simply ignored the inversions count so we just do not have that info for many rides. Some rides cannot have inversions and I filled in that information after the fact. So a value for inversions = -1 indicates that the ride could have had inversions. ,park_id:,numeric:,
The UN Refugee Agency Speeches , Ben Rudolph , www.kaggle.com/benrudolph/unhcr-speeches , Wed May 24 2017 15:29:12 GMT+0530 (IST) , Speeches made by the High Commissioner of the UN Refugee Agency ,60, politics- international relations- linguistics- ,"Context This is speeches scraped from unhcr.org website. It includes all speeches made by the High Commissioner up until June 2014. Content JSON Array of speeches with the following keys ""author"" ""by"" ""content"" ""id"" ""title"".  Acknowledgements www.unhcr.org Inspiration What words are most used? Which countries are mentioned? What do the high commissioners think about innovation? Gay rights?",author:by:date:id:title:content:,string:string:numeric:numeric:string:string:,
Protocol Gifts , Izzie Toren , www.kaggle.com/ytoren/protocol-gifts , Wed Jan 11 2017 19:49:32 GMT+0530 (IST) ," Data from the ""Protocol Gift Unit"" in the US Department of State ",77, politics- international relations- ,"Context This data-set contains information from the ""Protocol Gift Util"" in the US department of state which documents all of the official gifts accepted by the president and white house staff. Quoting from the U.S. Department of State website  The Protocol Gift Unit within the Office of the Chief of Protocol serves as the central processing point for all tangible gifts received from foreign sources by employees of the Executive Branch of the Federal government. The Unit is responsible for the creation and maintenance of the official record of all gifts presented by the Department of State to officials of foreign governments. Working closely with the Chief of Protocol and the staffs of the President the Vice President and the Secretary of State the Gift Unit selects the gifts presented to foreign dignitaries. Gifts received by the President Vice President and the Secretary of State and their spouses from foreign governments are also handled by the Gift Unit in the Office of Protocol.   Content The file contains data scraped from the the Protocol Gift Unit website (the R script and more information about exclusions and possible issues can be found here.  Number of recorded gifts 1913 (after some exclusions) Years 2002 to 2015 Encoding UTF8 (with many special characters)  Inspiration Looking forward to see how people can use creative text mining techniques to extract more information about the different columns (for example classify givers / receivers tag geographies extract the gift object from the description text etc.). You can find my future humble attempts here.",pdf_link:pdf_year:row_id:Receiver:From:Justification:Gift:Disposition:Gift_Rec_Date:Value_USD:,string:numeric:numeric:string:string:string:string:string:dateTime:numeric:,
Lunar Daily Distance and Declination : 1800-2020 , MCrescenzo , www.kaggle.com/crescenzo/lunardistance , Wed May 03 2017 07:41:34 GMT+0530 (IST) , Geocentric: Range Declination Brightness Fullness and Constellation ,43, space- ,Source NASA Horizons System  https//ssd.jpl.nasa.gov/?horizons Notes Distance measured in astronomical units. Declination measured in degrees.,Date:Distance (AUs):Declination:Brightness:% Illuminated:Constellation:,dateTime:numeric:numeric:numeric:numeric:string:,
Azerbaijan Voter List 2016 , Ms Brown , www.kaggle.com/msbrown/azerbaijanvoterlist , Sat May 06 2017 01:17:20 GMT+0530 (IST) , Three files containing the list of voters scraped from site in 2016 ,38, politics- ,Context Azerbaijan Voter List in three files (as scraped from the Central Election Commission website in 2006) Content Includes the sequence column (meaningless) the district code (Dairənin kodu) the polling station code (Məntəqənin kodu) voters names (Seçicinin soyadı adı atasının adı) Permanent residence address (street house and apartment number) (Daimi yaşayış yerinin ünvanı (küçə ev və mənzilin nömrəsi) and year of birth (Təvəllüd).  Here is an example page with the table https//www.infocenter.gov.az/page/voters/?s=1 In total 125 districts; 5415 polling stations; 5139414 voter records  Inspiration Working on getting another earlier voter list for comparison. For now just some summary statistics and duplicate counts. ,URL:Voter_Number:Constituency:Precinct_Number:Name:Address:Year_of_Birth:error:,string:numeric:numeric:numeric:string:string:numeric:string:,
2016 US Presidential Primary Debates , Ed King , www.kaggle.com/kinguistics/2016-us-presidential-primary-debates , Wed Oct 19 2016 02:43:05 GMT+0530 (IST) , Full transcripts of the debates among all the 2016 contenders for US President ,566, politics- ,"Overview Only two major-party candidates are competing in the 2016 US presidential election but there was tough competition to get to the general election. This dataset contains transcripts of every Democratic Republican and Republican Undercard debate held during the 2016 primary season. This dataset is meant to be a complement to Megan Risdal's transcripts of the 2016 US Presidential (General Election) Debates.  So you can now take all of the questions (who talks the most? who has a wider vocabulary?) that you answered in the general election debates and apply the same procedures to see how your favorite (or least favorite) candidate has changed over time. The column names (and order) in this dataset are a superset of those found in the general election dataset and non-speech annotations (such as ""(applause)"") in this dataset are also a superset. Kernels uploaded for the general election dataset should be compatible with this dataset as well; please let me know if you have any compatibility issues. What in the world is an ""Undercard"" debate? The field of Republicans running for President in the primaries was (yuuuuge!) pretty big 17 candidates threw their hat in the ring at one point or another. Debate organizers realized that having 17 people on stage (each with a set amount of time to answer a question / respond to a criticism / interrupt each other) would in the best case lead to a three-to-four-hour-long debate (and in the worst case lead to a chaotic shout-fest as candidates tried to talk over each other for three to four hours). To alleviate this issue many of the Republican debate nights were split into two separate debates the main debate with the top party contenders aired live during primetime; and the Undercard debate which typically aired a few hours earlier than the main debate. The criteria for a candidate to be allowed into the main debate (rather than the ""kids' table"" debate as some pundits derisively called the Undercard event) varied a bit by event. Typically a poll showing of 1% in one of several specified polls was sufficient to gain admission to the Undercard. To get into the main debate candidates had to either (a) be polling above a different higher percentage in specific polls or (b) be among the top n Republican candidates in said polls. The details get a little thorny (certain debates had multiple criteria of which candidates had to meet at least one) so I refer questions to the individual Undercard debate pages at the American Presidency Project for detailed criteria. In this dataset the split between Republican debates is made in the Party column Republican is used for the primetime main events and Republican Undercard is used for the Undercard. Acknowledgements All transcripts were scraped from the presidential debates page of the American Presidency Project at the University of California Santa Barbara. Individual lines in the dataset contain links to the particular page for that debate. Updates v2 contains a few minor changes related to normalizing parenthesized elements (non-speech) within the Text field and adding a few lines of interruptions that persisted in the Text field The Data The fields are described more fully in the file description. This section describes the particular elements that can appear in the Speaker and Text fields. Who's Who? (aka the Speaker column) The primary debates had a ton of participants. This dataset contains utterances from 22 politicians and 49 moderators not to mention the occasional audience laughter or 2-minute timer.  Almost all Speaker columns contain either a single title-case name (listed below in the Participants and Moderators subsections) or a single upper-case word indicating non-speaker noise (listed below in the None-speaker Turns subsection); the exceptions to this are cases where a name is concatenated with a space and a parenthesized tag as follows  spkr (VIDEO) transcriptions of pre-recorded material of any of the candidates or moderators spkr (TRANSLATED) in the Univision/Telemundo debate some questions and answers are translated into English from the original Spanish; the transcript reflects the translations as spoken by a translator  Non-speaker Turns The non-speaker turns in the Speaker column are  AUDIENCE any laughter booing applause etc. from the audience CANDIDATES cross-talk between candidates OTHER non-speaker non-audience noise (such as commercial break timer bell national anthem etc.) QUESTION a question from an audience member (or a prerecorded question) UNKNOWN cases where the transcriber could hear a phrase but could not determine who said it  Here are the various speakers who appear in the dataset Candidates Democratic  Chafee Former Governor Lincoln Chafee (RI) Clinton Former Secretary of State Hillary Clinton O'Malley Former Governor Martin O'Malley (MD) Sanders Senator Bernie Sanders (VT) Webb Former Senator Jim Webb (VA)  Republican  Bush Former Governor Jeb Bush (FL) Carson Ben Carson Cruz Senator Ted Cruz (TX) Kasich Governor John Kasich (OH) Paul Senator Rand Paul (KY) Rubio Senator Marco Rubio (FL) Trump Donald Trump Walker Governor Scott Walker (WI)  Republican (Undercard ONLY)  Gilmore Former Governor Jim Gilmore (VA) Graham Senator Lindsey Graham (SC) Jindal Governor Bobby Jindal (LA) Pataki Former Governor George Pataki (NY) Perry Former Governor Rick Perry (TX) Santorum Former Senator Rick Santorum (PA)  Republican (Main AND Undercard)  Christie Governor Chris Christie (NJ) Fiorina Carly Fiorina Huckabee Former Governor Mike Huckabee (AR)  All candidates in a Python list for easy copy/paste ['Bush' 'Carson' 'Chafee' 'Christie' 'Clinton' 'Cruz' 'Fiorina' 'Gilmore' 'Graham' 'Huckabee' 'Jindal' 'Kasich' ""O'Malley"" 'Pataki' 'Paul' 'Perry' 'Rubio' 'Sanders' 'Santorum' 'Trump' 'Walker' 'Webb'] Moderators NOTE Some moderators are seen across various debates; in particular the Republican main debates and undercard debates on a given day tend to share the same moderators. Some moderators are public figures who are seen only in videos (with the (VIDEO) tag). Moderators  Arrarás María Celeste Arrarás (Telemundo) Baier Bret Baier (Fox News) Baker Gerard Baker (The Wall Street Journal) Bartiromo Maria Bartiromo (Fox Business Network) Bash Dana Bash (CNN) Blitzer Wolf Blitzer (CNN) Cavuto Neil Cavuto (Fox Business Network) Cooney Kevin Cooney (CBS News) Cooper Anderson Cooper (CNN) Cordes Nancy Cordes (CBS News) Cramer Jim Cramer (CNBC) Cuomo Governor Andrew Cuomo (NY) Dickerson John Dickerson (CBS News) Dinan Stephen Dinan (Washington Times) Epperson Sharon Epperson (CNBC) Garrett Major Garrett (CBS News) Ham Mary Katharine Ham (Hot Air) Hannity Sean Hannity (Fox News) Harwood John Harwood (CNBC) Hemmer Bill Hemmer (Fox News) Hewitt Hugh Hewitt (Salem Radio Network) Holt Lester Holt (NBC News) Ifill Gwen Ifill (PBS) Kelly Megyn Kelly (Fox News) Lemon Don Lemon (CNN) Levesque Neil Levesque (New Hampshire Institute of Politics) Lopez Juan Carlos Lopez (CNN en Espanol) Louis Errol Louis (NY1) MacCallum Martha MacCallum (Fox News) Maddow Rachel Maddow (MSNBC) Mcelveen Josh McElveen (WMUR-TV) Mitchell Andrea Mitchell (NBC News) Muir David Muir (ABC News) O'Reilly Bill O'Reilly (Fox News) Obradovich Kathie Obradovich (The Des Moines Register) Quick Becky Quick (CNBC) Quintanilla Carl Quintanilla (CNBC) Raddatz Martha Raddatz (ABC News) Ramos Jorge Ramos (Univision) Regan Trish Regan (Fox Business Network) Salinas María Elena Salinas (Univision) Santelli Rick Santelli (CNBC) Seib Gerald Seib (The Wall Street Journal) Strassel Kimberly Strassel (The Wall Street Journal) Tapper Jake Tapper (CNN) Todd Chuck Todd (MSNBC) Tumulty Karen Tumulty (The Washington Post) Wallace Chris Wallace (Fox News) Woodruff Judy Woodruff (PBS)  All moderators in a Python list for easy copy/paste ['Arrarás' 'Baier' 'Baker' 'Bartiromo' 'Bash' 'Blitzer' 'Cavuto' 'Cooney' 'Cooper' 'Cordes' 'Cramer' 'Cuomo' 'Dickerson' 'Dinan' 'Epperson' 'Garrett' 'Ham' 'Hannity' 'Harwood' 'Hemmer' 'Hewitt' 'Holt' 'Ifill' 'Kelly' 'Lemon' 'Levesque' 'Lopez' 'Louis' 'MacCallum' 'Maddow' 'Mcelveen' 'Mitchell' 'Muir' ""O'Reilly"" 'Obradovich' 'Quick' 'Quintanilla' 'Raddatz' 'Ramos' 'Regan' 'Salinas' 'Santelli' 'Seib' 'Strassel' 'Tapper' 'Todd' 'Tumulty' 'Wallace' 'Woodruff'] What's What? (aka the Text column) In general the Text column contains fully punctuated and appropriately capitalized speech transcriptions. Most parenthesized elements are non-speech elements with the following exceptions  (c) and (4) are spoken in reference to 501(c)(4)s (tax-exempt lobbying groups) (k) spoken in reference to 401(k)s (individual pension accounts)  The non-speech elements that can be found in parentheses in the Text column are  (ANTHEM) the national anthem is played (APPLAUSE) the audience expresses approval (BELL) a bell or buzzer indicating that a candidate's time has expired (BOOING) the audience expresses disapproval (COMMERCIAL) the televised debate breaks for a commercial advertisement (CROSSTALK) more than one candidate or moderator are speaking at the same time (LAUGHTER) the audience expresses a sense of humor (MOMENT.OF.SILENCE) the debate pauses for a moment of silence (SPANISH) the utterance is in Spanish (for the Democrats' Univision-hosted debate on 3/9/16 in Miami) (VIDEO.END) a video clip ends (VIDEO.START) a video clip begins (inaudible) the utterance was inaudible off-mike or too indecipherable to transcribe ",,,
Basic Computer Data , LiamLarsen , www.kaggle.com/kingburrito666/basic-computer-data-set , Sat May 06 2017 01:04:18 GMT+0530 (IST) , A dataset of basic computer stats ,210, statistics- computer science- ,For what? This dataset is for basic data analysis. Student Statisticians or Data-Analysists (like myself) could use this as a basic learning point. Even ML students could predict future prices and speeds of computers.  Unfortunately this dataset doesn't come with dates. (which are a pain to work with anyway) But the computers are in order from earliest to latest. I will be uploading another version with this and a more detailed CSV that has the computer name date and other stats. This dataset is free to use for any purpose.  This is simply to gain understanding in analyzing data. At least for me. Content price speed hd ram screen cd multi premium ads trend Something glorious is coming The largest computer CSV? Maybe? Maybe im scrapping it right now? Who knows? ;),:price:speed:hd:ram:screen:cd:multi:premium:ads:trend:,numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:numeric:numeric:,
Council Plan performance indicators , sichunlam , www.kaggle.com/sichunlam/coventrycc-performance-indicators , Mon Jul 31 2017 21:14:46 GMT+0530 (IST) , Coventry City Council ,18, politics- ,Council Plan performance indicators by Coventry City Council The Council Plan sets out Coventry City Council's vision and priorities for the city. Content These are the performance indicators in the Council Plan performance report in an open data format. Acknowledgements Coventry City Council Find out more at www.coventry.gov.uk/performance/  Visualisation https//smarturl.it/CovPerformanceData,Council Plan:Priority:Progress:Council Plan Indicator:Equality Indicator:Marmot Indicator: Sort Order :Indicator:Unit:2015/16 end of year indicator value:2015/16 end of year indicator scope:2015/16 end of year indicator date:2016/17 end of year indicator value:2016/17 end of year indicator scope:2016/17 end of year indicator date:2016/17 half year indicator value:2016/17 half year indicator scope:2016/17 half year indicator date:2016/17 end of year indicator comparator indicator value:2016/17 end of year indicator comparator indicator scope:2016/17 end of year indicator comparator indicator date:2016/17 half year indicator comparator indicator value:2016/17 half year indicator comparator indicator scope:2016/17 half year indicator comparator indicator date:2016/17 end of year indicator national indicator value:2016/17 end of year indicator national indicator scope:2016/17 end of year indicator national indicator date:2016/17 half year indicator national indicator value:2016/17 half year indicator national indicator scope:2016/17 half year indicator national indicator date:Directionality:2016/17 end of year progress:2016/17 end of year target:2016/17 end of year target status:,string:string:string:boolean:boolean:boolean:numeric:string:string:numeric:string:numeric:numeric:string:numeric:numeric:string:string:numeric:string:numeric:numeric:string:string:numeric:string:numeric:numeric:string:string:string:string:string:string:,
Nashville Housing Data , tmthyjames , www.kaggle.com/tmthyjames/nashville-housing-data , Tue Jan 31 2017 06:04:40 GMT+0530 (IST) , Home value data for the booming Nashville market ,490, home- ,Context This is home value data for the hot Nashville market. Content There are 56000+ rows altogether.  However I'm missing home detail data for about half. So if anyone wants to track that down then go for it! I'll be looking in the mean time. Enjoy. Will add the Python file that retrieved this data once I clean it up. Shameless plug visit this link for my latest project a SQL magic function for IPython Notebook.,:Unnamed: 0:Parcel ID:Land Use:Property Address:Suite/ Condo   #:Property City:Sale Date:Sale Price:Legal Reference:Sold As Vacant:Multiple Parcels Involved in Sale:Owner Name:Address:City:State:Acreage:Tax District:Neighborhood:image:Land Value:Building Value:Total Value:Finished Area:Foundation Type:Year Built:Exterior Wall:Grade:Bedrooms:Full Bath:Half Bath:,numeric:numeric:string:string:string:numeric:string:dateTime:numeric:string:string:string:string:string:string:string:numeric:string:numeric:string:numeric:numeric:numeric:numeric:string:numeric:string:string:numeric:numeric:numeric:,
Annual Nominal Fish Catches , Victor Genin , www.kaggle.com/victorgenin/ices-fish-catch , Sun May 29 2016 13:42:32 GMT+0530 (IST) , Explore the impact of overfishing in the Northeast Atlantic region. ,934, fishing- environmental engineering- ,The datasets provides data of annual nominal catches of more than 200 species of fish and shellfish in the Northeast Atlantic region which are officially submitted by 20 International Council for the Exploration of the Sea (ICES) member countries between 2006 and 2014.,,,
World Gender Statistics , World Bank , www.kaggle.com/theworldbank/world-gender-statistics , Mon Nov 28 2016 11:15:08 GMT+0530 (IST) , Sex-disaggregated and gender-specific data on demographics education etc. ,877, gender- education- demographics- ,The Gender Statistics database is a comprehensive source for the latest sex-disaggregated data and gender statistics covering demography education health access to economic opportunities public life and decision-making and agency. The Data The data is split into several files with the main one being Data.csv. The Data.csv contains all the variables of interest in this dataset while the others are lists of references and general nation-by-nation information. Data.csv contains the following fields Data.csv  Country.Name the name of the country Country.Code the country's code Indicator.Name the name of the variable that this row represents Indicator.Code a unique id for the variable 1960 - 2016 one column EACH for the value of the variable in each year it was available  The other files I couldn't find any metadata for these and I'm not qualified to guess at what each of the variables mean. I'll list the variables for each file and if anyone has any suggestions (or even better actual knowledge/citations) as to what they mean please leave a note in the comments and I'll add your info to the data description. Country-Series.csv  CountryCode SeriesCode DESCRIPTION  Country.csv  Country.Code Short.Name Table.Name Long.Name 2-alpha.code Currency.Unit Special.Notes Region Income.Group WB-2.code National.accounts.base.year National.accounts.reference.year SNA.price.valuation Lending.category Other.groups System.of.National.Accounts Alternative.conversion.factor PPP.survey.year Balance.of.Payments.Manual.in.use External.debt.Reporting.status System.of.trade Government.Accounting.concept IMF.data.dissemination.standard Latest.population.census Latest.household.survey Source.of.most.recent.Income.and.expenditure.data Vital.registration.complete Latest.agricultural.census Latest.industrial.data Latest.trade.data Latest.water.withdrawal.data  FootNote.csv  CountryCode SeriesCode Year DESCRIPTION  Series-Time.csv  SeriesCode Year DESCRIPTION  Series.csv  Series.Code Topic Indicator.Name Short.definition Long.definition Unit.of.measure Periodicity Base.Period Other.notes Aggregation.method Limitations.and.exceptions Notes.from.original.source General.comments Source Statistical.concept.and.methodology Development.relevance Related.source.links Other.web.links Related.indicators License.Type  Acknowledgements This dataset was downloaded from The World Bank's Open Data project. The summary of the Terms of Use of this data is as follows  You are free to copy distribute adapt display or include the data in other products for commercial and noncommercial purposes at no cost subject to certain limitations summarized below. You must include attribution for the data you use in the manner indicated in the metadata included with the data. You must not claim or imply that The World Bank endorses your use of the data by or use The World Bank’s logo(s) or trademark(s) in conjunction with such use. Other parties may have ownership interests in some of the materials contained on The World Bank Web site. For example we maintain a list of some specific data within the Datasets that you may not redistribute or reuse without first contacting the original content provider as well as information regarding how to contact the original content provider. Before incorporating any data in other products please check the list Terms of use Restricted Data.  -- [ed. note this last is not applicable to the Gender Statistics database]  The World Bank makes no warranties with respect to the data and you agree The World Bank shall not be liable to you in connection with your use of the data. This is only a summary of the Terms of Use for Datasets Listed in The World Bank Data Catalogue. Please read the actual agreement that controls your use of the Datasets which is available here Terms of use for datasets. Also see World Bank Terms and Conditions. ,Country.Code:Short.Name:Table.Name:Long.Name:2-alpha.code:Currency.Unit:Special.Notes:Region:Income.Group:WB-2.code:National.accounts.base.year:National.accounts.reference.year:SNA.price.valuation:Lending.category:Other.groups:System.of.National.Accounts:Alternative.conversion.factor:PPP.survey.year:Balance.of.Payments.Manual.in.use:External.debt.Reporting.status:System.of.trade:Government.Accounting.concept:IMF.data.dissemination.standard:Latest.population.census:Latest.household.survey:Source.of.most.recent.Income.and.expenditure.data:Vital.registration.complete:Latest.agricultural.census:Latest.industrial.data:Latest.trade.data:Latest.water.withdrawal.data:,string:string:string:string:string:string:string:string:string:string:numeric:numeric:string:string:string:string:string:numeric:string:string:string:string:string:numeric:string:string:string:numeric:numeric:numeric:numeric:,
US campsites , Caroline Cypranowska , www.kaggle.com/cypranowska/us-campsites , Sun Apr 30 2017 02:05:18 GMT+0530 (IST) , Data on campsites run by US Federal Government ,100, sports and recreation- ,New See this dataset visualized in D3 Context This data acquired from the Recreation Information Database Catalog contains campsite info for all campground facilities run by the United States National Park Service the United States Forest Service the Bureau of Land Management and other Federal Government agencies. Read the API documentation. Content Fields include facility ID campsite ID campsite type facility name facility location (latitude longitude state) and managing agency. Acknowledgements A humble thank you to the federal agencies that collect these data and maintain public access including USFS NPS BLM USACE FWS and BOR. Thank you to American tax payers for keeping these facilities afloat. Thank you to Levi Gadye for granting permission for the use of the cover photo.  Inspiration I was looking for a campsite for a group of friends in between Salt Lake City and Grand Teton NP and was struggling to find a tent-only campsite along the highway corridors leading to Grand Teton NP. In the past I had always felt that finding tent only campsites in California was quite easy compared to other places I’ve camped in the American West. I tidied this data set from RIDB to determine whether or not my ease in booking tent-only campsites in CA was due to a larger number of those sites or if the state of CA had a relative enrichment for tent-only campsites. ,:CampsiteID:CampsiteName:CampsiteType:FacilityID:FacilityLatitude:FacilityLongitude:FacilityName:AddressStateCode:OrgAbbrevName:,numeric:numeric:numeric:string:numeric:numeric:numeric:string:string:string:,
Technology Price Index 2016 , Irina Kalatskaya , www.kaggle.com/ikalats/TechnologyPriceIndex , Tue Jan 03 2017 09:20:26 GMT+0530 (IST) , Where can you buy an iPhone cheaper? ,527, finance- technology forecasting- ,Context Linio.com is Latin America’s leading eCommerce platform. It have recently released the 2016-17 Technology Price Index comparing the cost of 14 popular electronic devices and brands across 72 countries. Linio conducted a pretty impressive research study for better understanding the global economic trends in the price of most popular electronic devices.  From http//www.outsourcingportal.eu/en/linio-com-compares-the-cost-of-technology-products-in-72-countries To conduct the research Linio looked at the costs of all products in the study from several brick and mortar chain stores and smaller retailers in all major cities in each country. The study also took into account average costs from at least three reputable online outlets in each country. Taxes and other associated purchasing costs minus delivery were also accounted for. Content This dataset contains the cost of 14 different devices including smartphones laptops game consoles tablets smart devices and other gadgets across 72 different countries. ranking the countries on the average cost of all products researched.  The dataset was downloaded from Linio.com in December 2016. Acknowledgements The dataset was taken from here https//www.linio.com.mx/sp/technology-price-index-2016 without any modifications. Inspiration  Is it possible to predict the cost of my favorite iPhone based on 13 other devices?  What device has the most unpredictable trend?  What products have the highest variability in price and whether it was caused by the same countries? ,,,
Worldnews on Reddit from 2008 to Today , Chris , www.kaggle.com/rootuser/worldnews-on-reddit , Tue Nov 22 2016 23:05:02 GMT+0530 (IST) , Perfect for NLP or other tasks ,412, news agencies- linguistics- internet- ,Reddit is a social network which divide topics into so called 'subreddits'. In subreddit 'worldnews' news of the whole world are published. The dataset contains following columns time_created - a Unix timestamp of the submission creation date date_created - creation time in %Y-%m-%d up_votes - how often the submission was upvoted down_votes - how often the submission was downvoted title - the title of the submission over_18 - if the submission is for mature persons author - the reddit username of the author subreddit - this is always 'worldnews' With the dataset you can estimate several things in contrast to world politics and special events.,,,
Pisa Scores , JorgeZazueta , www.kaggle.com/zazueta/pisa-scores-2015 , Wed May 03 2017 20:24:37 GMT+0530 (IST) , Program for International Student Assessment mean scores (Pisa) from 2015 ,137, education- ,"Context PISA stands for ""Program for International Student Assessment"" and it is applied to 15 year-old students across the world to assess their performance in Math Reading and Science. These are the 2015 scores. Content The dataset contains mean (Pisa) attainment scores in math reading and science by country and gender. Acknowledgements Queried from the World Bank Learning outcomes database http//datatopics.worldbank.org/education/wDataQuery/QLearning.aspx Inspiration How attainment compares by country? Why some perform better than others? Can Pisa scores predict social environments such as freedom of press?",Code:Indicator Name:Long definition:Source:,string:string:string:string:,
National Footprint Accounts data set (1961-2013) , LiamLarsen , www.kaggle.com/kingburrito666/national-footprint-accounts , Sun Apr 23 2017 15:26:39 GMT+0530 (IST) , National Footprint measure the ecological resource use and capacity of nations ,112, ecology- geography- international relations- ,"Content EF- GDP Column descriptions  Country Ecological Footprint where record = ""EFConsTotGHA"" and year = 2013 | total ecological footprint Ecological Footprint where record = ""EFConsTotGHA"" and year = 2009 | total ecological footprint 2013 GDP (total; based on value of 2010 US Dollar) 2009 GDP (total; based on value of 2010 US Dollar) Difference of EF2013 - EF2009 Difference GDP2013 - GDP2009 GDPDelta_P - EFDelta_P Percent change in EF from 2009 to 2013 ((EF2013 - EF2009) / EF2009) * 100 Percent change in GDP from 2009 to 2013 ((GDP2013 - GDP2009)/ GDP2009) * 100 GDPDelta_P - EFDelta_P Ordinal ranking of DDelta_P (range 0-153) Ordinal ranking of EFDelta_P (range 0-153) Ordinal ranking of GDPDelta_P (range 0-153) ""Decoupled Flag"" 1 if (GDPDelta >= 0) & (EFDelta <= 0) else 0 GDP normalized to min-max scale 25-2500 (necessary for scaling size of markers properly in scatterplot).  NFA 2017 Column descriptions  Country Year country code Record-type The Ecological Footprint of cropland demand. The Ecological Footprint of grazing land demand. The Ecological Footprint of forest land demand. The Ecological Footprint of fishing ground demand. The Ecological Footprint of built-up land demand. The Ecological Footprint of carbon demand. The total Ecological Footprint of demand (sum of all land types) Data quality score  View my kernel to see a sample of data",Country:EF2013:EF2009:GDP2013:GDP2009:EFDelta:GDPDelta:DDelta:EFDelta_P:GDPDelta_P:DDelta_P:DDelta_Rank:EFDelta_Rank:GDPDelta_Rank:Dec_Flag:GDP_std:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
SP1 factor binding sites on Chromosome1 , Hossein Banki Koshki , www.kaggle.com/hobako1993/sp1-factor-binding-sites-on-chromosome1 , Sat Nov 12 2016 19:01:38 GMT+0530 (IST) , SP1 factor binding and non-binding sites on Ch1 for classification tasks ,201, human genetics- ,This dataset includes SP1 transcription factor binding and non-binding sites on human chromosome1. It can be used for binary classification tasks in bioinformatics. There are 1200 sequences for binding sites (BS) and 1200 sequences for non-biding sites (nBS)  We have labeled sequences with 1 for BS and 0 for nBS. Each sequence is 14 nucleobase length which is converted to numeric string using codes below assigned to each nucleobase 00 for A 01 for T 10 for C 11 for G,feature1:feature2:feature3:feature4:feature5:feature6:feature7:feature8:feature9:feature10:feature11:feature12:feature13:feature14:feature15:feature16:feature17:feature18:feature19:feature20:feature21:feature22:feature23:feature24:feature25:feature26:feature27:feature28:label:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Museums Aquariums and Zoos , Institute of Museum and Library Services , www.kaggle.com/imls/museum-directory , Tue Mar 07 2017 00:55:16 GMT+0530 (IST) , Name location and revenue for every museum in the United States ,213, museums- animals- ,Content The museum dataset is an evolving list of museums and related organizations in the United States. The data file includes basic information about each organization (name address phone website and revenue) plus the museum type or discipline. The discipline type is based on the National Taxonomy of Exempt Entities which the National Center for Charitable Statistics and IRS use to classify nonprofit organizations. Non-museum organizations may be included. For example a non-museum organization may be included in the data file because it has a museum-like name on its IRS record for tax-exempt organizations. Museum foundations may also be included. Museums may be missing. For example local municipal museums may be undercounted because original data sources used to create the compilation did not include them. Museums may be listed multiple times. For example one museum may be listed as both itself and its parent organization because it was listed differently in each original data sources. Duplicate records are especially common for museums located within universities. Information about museums may be outdated.  The original scan and compilation of data sources occurred in 2014.  Scans are no longer being done to update the data sources or add new data sources to the compilation.  Information about museums may have changed since it was originally included in the file. Acknowledgements The museum data was compiled from IMLS administrative records for discretionary grant recipients IRS records for tax-exempt organizations and private foundation grant recipients. Inspiration Which city or state has the most museums per capita? How many zoos or aquariums exist in the United States? What museum or related organization had the highest revenue last year? How does the composition of museum types differ across the country?,Museum ID:Museum Name:Legal Name:Alternate Name:Museum Type:Institution Name:Street Address (Administrative Location):City (Administrative Location):State (Administrative Location):Zip Code (Administrative Location):Street Address (Physical Location):City (Physical Location):State (Physical Location):Zip Code (Physical Location):Phone Number:Latitude:Longitude:Locale Code (NCES):County Code (FIPS):State Code (FIPS):Region Code (AAM):Employer ID Number:Tax Period:Income:Revenue:,numeric:string:string:string:string:string:string:string:string:numeric:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Baboon Mating and Genetic Admixture , Dryad Digital Repository , www.kaggle.com/dryad/baboon-mating , Mon Nov 07 2016 02:51:12 GMT+0530 (IST) , Data on genetic admixture and likelihood of successful mating between baboons ,161, animals- ,"This dataset contains over 12k observations of male-female baboon pairs from a population of baboons that has recently seen genetic admixture from a different (but closely-related) taxon. The data contains genetic and social information for the male and female baboons whether they mated and whether the mating resulted in conception of offspring. Acknowledgements The original journal article that this data was collected for  Tung J Charpentier MJE Mukherjee S Altmann J Alberts SC (2012) Genetic effects on mating success and partner choice in a social mammal. The American Naturalist 180(1) 113-129. http//dx.doi.org/10.1086/665993 The Data Dryad page that this data was downloaded from  Tung J Charpentier MJE Mukherjee S Altmann J Alberts SC (2012) Data from Genetic effects on mating success and partner choice in a social mammal. Dryad Digital Repository. http//dx.doi.org/10.5061/dryad.4r9h61v8 Abstract (from the original paper) Mating behavior has profound consequences for two phenomena—individual reproductive success and the maintenance of species boundaries—that contribute to evolutionary processes. Studies of mating behavior in relation to individual reproductive success are common in many species but studies of mating behavior in relation to genetic variation and species boundaries are less commonly conducted in socially complex species. Here we leveraged extensive observations of a wild yellow baboon (Papio cynocephalus) population that has experienced recent gene flow from a close sister taxon the anubis baboon (Papio anubis) to examine how admixture-related genetic background affects mating behavior. We identified novel effects of genetic background on mating patterns including an advantage accruing to anubis-like males and assortative mating among both yellow-like and anubis-like pairs. These genetic effects acted alongside social dominance rank inbreeding avoidance and age to produce highly nonrandom mating patterns. Our results suggest that this population may be undergoing admixture-related evolutionary change driven in part by nonrandom mating. However the strength of the genetic effect is mediated by behavioral plasticity and social interactions emphasizing the strong influence of social context on mating behavior in socially complex species. The Data This dataset contains over 12000 observations of the following variables  female_id three letter ""short name"" ID for the female in a potentially consorting pair; each female has a unique ID male_id three letter ""short name"" ID for the male in a potentially consorting pair; each male has a unique ID cycle_id a unique number assigned to each female-estrus cycle combination consort whether the female-male pair consorted (1) or not (0) given the opportunity to do so conceptive whether the estrus cycle resulted in a conception (1) or not (0) female_hybridscore an estimate of the proportion of the female's genome that represents anubis baboon ancestry; for details of the estimation procedure see Materials and Methods and Tung et al (2008) male_hybridscore an estimate of the proportion of the male's genome that represents anubis baboon ancestry; for details of the estimation procedure see Materials and Methods and Tung et al (2008) female_gendiv an estimate of the female's genetic diversity; for details of the estimation procedure see Materials and Methods male_gendiv an estimate of the male's genetic diversity; for details of the estimation procedure see Materials and Methods gen_distance an estimate of the genetic distance (Queller-Goodnight r) between the male and female of a potentially consorting pair female_age the age of the female in a potentially consorting pair male_rank the ordinal rank of the male in a potentially consorting pair female_rank the ordinal rank of the female in a potentially consorting pair males_present the number of adult males present in the group of the potentially consorting pair females_present the number of adult females present in the group of the potentially consorting pair male_rank_transform ordinal male rank transformed to reflect fit (given number of males in a group) to the priority-of-access model; see Materials and Methods and Appendix for more details gen_distance_transform genetic distance estimate transform to test whether consortship probabilities decrease with genetic distance as well as genetic similarity rank_interact the multiplicative interaction of male rank and female rank in the potentially consorting pair assort_index assortative mating index calculated from the hybrid scores of the male and female of a potentially consorting pair; see Materials and Methods for additional detail female_age_transform female age transformed to test for a higher probability of consortship behavior for maximally fertile (middle-aged) females  Inspiration Here are a few ideas for things to look at in this dataset  does genetic distance affect mating probability? does age of the female baboon affect conception probability? does social rank of the male affect mating probability? ",,,
The Metropolitan Museum of Art Open Access , The Metropolitan Museum of Art , www.kaggle.com/metmuseum/the-metropolitan-museum-of-art-open-access , Fri Apr 07 2017 13:27:15 GMT+0530 (IST) , Explore information on more than 420000 historic artworks ,142, culture and humanities- museums- ,"Dataset source https//github.com/metmuseum/openaccess The Metropolitan Museum of Art presents over 5000 years of art from around the world for everyone to experience and enjoy. The Museum lives in three iconic sites in New York City—The Met Fifth Avenue The Met Breuer and The Met Cloisters. Millions of people also take part in The Met experience online. Since it was founded in 1870 The Met has always aspired to be more than a treasury of rare and beautiful objects. Every day art comes alive in the Museum's galleries and through its exhibitions and events revealing both new ideas and unexpected connections across time and across cultures. The Metropolitan Museum of Art provides select datasets of information on more than 420000 artworks in its Collection for unrestricted commercial and noncommercial use. To the extent possible under law The Metropolitan Museum of Art has waived all copyright and related or neighboring rights to this dataset using Creative Commons Zero. This work is published from The United States Of America. You can also find the text of the CC Zero deed in the file LICENSE in this repository. These select datasets are now available for use in any media without permission or fee; they also include identifying data for artworks under copyright. The datasets support the search use and interaction with the Museum’s collection. At this time the datasets are available in CSV format encoded in UTF-8. While UTF-8 is the standard for multilingual character encodings it is not correctly interpreted by Excel on a Mac. Users of Excel on a Mac can convert the UTF-8 to UTF-16 so the file can be imported correctly. Additional usage guidelines Images not included Images are not included and are not part of the dataset. Companion artworks listed in the dataset covered by the policy are identified in the Collection section of the Museum’s website with the Creative Commons Zero (CC0) icon. For more details on how to use images of artworks in The Metropolitan Museum of Art’s collection please visit our Open Access page. Documentation in progress This data is provided “as is” and you use this data at your own risk. The Metropolitan Museum of Art makes no representations or warranties of any kind. Documentation of the Museum’s collection is an ongoing process and parts of the datasets are incomplete. We plan to update the datasets with new and revised information on a regular basis. You are advised to regularly update your copy of the datasets to ensure you are using the best available information. Pull requests Because these datasets are generated from our internal database we do not accept pull requests. If you have identified errors or have extra information to share please email us at openaccess@metmuseum.org and we will forward to the appropriate department for review. Attribution Please consider attributing or citing The Metropolitan Museum of Art's CC0 select datasets especially with respect to research or publication. Attribution supports efforts to release other datasets in the future. It also reduces the amount of ""orphaned data"" helping to retain source links. Do not misrepresent the dataset Do not mislead others or misrepresent the datasets or their source. You must not use The Metropolitan Museum of Art’s trademarks or otherwise claim or imply that the Museum or any other third party endorses you or your use of the dataset. Whenever you transform translate or otherwise modify the dataset you must make it clear that the resulting information has been modified. If you enrich or otherwise modify the dataset consider publishing the derived dataset without reuse restrictions. The writers of these guidelines thank the The Museum of Modern Art Tate Cooper-Hewitt and Europeana.",Object Number:Is Highlight:Is Public Domain:Object ID:Department:Object Name:Title:Culture:Period:Dynasty:Reign:Portfolio:Artist Role:Artist Prefix:Artist Display Name:Artist Display Bio:Artist Suffix:Artist Alpha Sort:Artist Nationality:Artist Begin Date:Artist End Date:Object Date:Object Begin Date:Object End Date:Medium:Dimensions:Credit Line:Geography Type:City:State:County:Country:Region:Subregion:Locale:Locus:Excavation:River:Classification:Rights and Reproduction:Link Resource:Metadata Date:Repository:,string:boolean:boolean:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:dateTime:string:,
Women's Tennis Association Matches , GMAdevs , www.kaggle.com/gmadevs/wta-matches , Sun Feb 05 2017 19:38:34 GMT+0530 (IST) , WTA matches from 2000 to 2016 ,536, tennis- ,Context A dataset of WTA matches including individual statistics. Content In these datasets there are individual csv files for WTA tournament from 2000 to 2016. The numbers in the last columns are absolute values using them you can calculate percentages. Acknowledgement Thanks to Jeff Sackmann for the excellent work. Be sure to visit his github profile https//github.com/JeffSackmann/tennis_wta Inspiration This dataset would be likely used to develop predictive modeling of tennis matches and to do statistic research. I'm planning to add historical odds and injuries data as soon as I have the time to get them.,tourney_id:tourney_name:surface:draw_size:tourney_level:tourney_date:match_num:winner_id:winner_seed:winner_entry:winner_name:winner_hand:winner_ht:winner_ioc:winner_age:winner_rank:winner_rank_points:loser_id:loser_seed:loser_entry:loser_name:loser_hand:loser_ht:loser_ioc:loser_age:loser_rank:loser_rank_points:score:best_of:round:,string:string:string:numeric:string:numeric:numeric:numeric:numeric:string:string:string:numeric:string:numeric:numeric:numeric:numeric:string:string:string:string:numeric:string:numeric:numeric:numeric:dateTime:numeric:string:,
Donald J. Trump For President Inc , Megan Risdal , www.kaggle.com/mrisdal/donald-j-trump-for-president-inc , Mon Apr 17 2017 06:26:21 GMT+0530 (IST) , Itemized expenditures totaling over 6M USD ,70, presidents- finance- politics- ,Did you know that Donald J. Trump For President Inc paid for a subscription to The New York Times on November 30th 2016? Curious to see where else over six million USD was spent and for what purposes? This dataset was downloaded from Pro Publica so you can find out. Content Here's what you get   Line number Entity type Payee name Payee state Date Amount Purpose  Contributions Want to contribute to this dataset? Download contributions to Donald J. Trump Inc here and share on the dataset's discussion forum. Acknowledgements This data was downloaded from Pro Publica. You can read about their data terms of use here.,Line number:Entity type:Payee name:Payee state:Date:Amount:Purpose:,string:string:string:string:dateTime:string:string:,
Type Allocation Code (TAC) , Richard Nagyfi , www.kaggle.com/sedthh/typeallocationtable , Tue Apr 18 2017 22:22:44 GMT+0530 (IST) , Type Allocation Code for mobile and wireless devices ,215, networks- telecommunications- ,Context The Type Allocation Code (TAC) is the initial eight-digit portion of the 15-digit IMEI and 16-digit IMEISV codes used to uniquely identify wireless devices. (Wikipedia) TAC numbers can be used to identify devices connected to networks. Complete TAC databases are hard to find and cost a furtune as maintaining them and keeping them up to date is labour intensive due to the large amount of devices being released every day.  Content The dataset contains information about the devices' TAC number manufacturer model aliases of the model operating system year of release and LTE compatibility. Some devices may have multiple TAC numbers as they are different subversions of the same hardware. This TAC database is nowhere near complete and some of the data provided here could be incorrect as even manufacturers sometimes share inaccurate information about their own devices. LTE capability is the worst offender in this case as companies often release TAC information with contradictory stats about LTE compatibility. Acknowledgements This is a merged and cleaned dataset based on free TAC databases found on the internet including http//tacdb.osmocom.org/ https//www.mulliner.org/tacdb/feed/ Inspiration This database is useful for anyone who works with telecommunication networks and wants to identify their users.,TAC:,numeric:,
Trump's World , SkyLord , www.kaggle.com/skylord/trumpworld , Wed Feb 22 2017 20:51:36 GMT+0530 (IST) , Help us map Trump's World ,377, geography- politics- ,Context The dataset has been downloaded from a BuzzFeed news article that was posted on Jan 15 2017. The link to the original source can be checked in the Acknowledgements section.  The authors have created a database of more than 1500 people/organization who have a connection with the Trump family his top advisors or his cabinet picks. The dataset can help us to capture how policy decisions may be impacted by these varied connections. Content You have three datasets to play with.  Person_Person.csv Each row represents a connection between a person and another person (eg. Charles Kushner and Alan Hammer) Person_Org.csv Each row represents a connection between a person and an organization (eg. 401 NORTH WABASH VENTURE LLC. and Donald J. Trump) Org_Org.csv Each row represents a connection between an organization and another organization (eg. TRUMP COMMERCIAL CHICAGO LLC and 401 NORTH WABASH VENTURE LLC. )  All the three files are in the following format  Column1 Person or Organization (A) Column2 Person or Organization (B) Column3 Connection between (A) and (B) Column4 Source url from which the connection is derived  Acknowledgements Source  https//www.buzzfeed.com/johntemplon/help-us-map-trumpworld Inspiration https//github.com/BuzzFeedNews/trumpworld This is an incomplete database and you are free to add more connections.,Organization A:Organization B:Connection:Source(s):,string:string:string:string:,
Interactive Fiction Competition Entrants , Brian Rushton , www.kaggle.com/brirush/ifcomp , Tue Apr 18 2017 12:02:59 GMT+0530 (IST) , Ranking and background data for IFComp games ,30, literature- video games- ,Context The Interactive Fiction Competition is the internet's oldest game programming competition starting in 1995 and continuing to this day. Interactive Fiction is an unusual genre because it has been centralized in the Interactive Fiction Database for the last decade and essentially all games of interest are recorded there. It is also a niche genre and the amount of public interest has varied much less than other genres since 1995. Content This database contains the placement (i.e. 1st place 2nd place etc.) of all games ever entered into the IFComp together with their genre number of ifdb ratings and average ifdb rating. It also contains the system; a few programming languages have tended to dominate the competition. It also contains the forgiveness rating which indicates how difficult the game can be expected to be. Much of the information is null. Note that the IFDB was created in 2006 11 years after the competition began. Inspiration IFDB ratings represent lasting interest as these have been gathered over many years while IFComp rankings represent a short 6-week period. It would be interesting to see the relationship between the two how that relationship has changed over time etc. Also Inform and TADS have always dominated the competition but it's recently been changing. The change in systems over the years should be interesting. Finally it would be interesting to see time-adjusted averages of reviews for comp games over time to see if new games are receiving less interest than old games. Acknowledgements Mike Roberts has been the curator of IFDB since its inception. The IFComp is currently run by Jason Macintosh under the aegis of the Interactive Fiction Technology Foundation.,title:,string:,
Pesticide Data Program (2013) , United States Department of Agriculture , www.kaggle.com/usdeptofag/pesticide-data-program-2013 , Thu Nov 17 2016 09:51:33 GMT+0530 (IST) , Study of pesticide residues in food ,275, food and drink- agriculture- ,Context This dataset contains information on pesticide residues in food. The U.S. Department of Agriculture (USDA) Agricultural Marketing Service (AMS) conducts the Pesticide Data Program (PDP) every year to help assure consumers that the food they feed themselves and their families is safe. Ultimately if EPA determines a pesticide is not safe for human consumption it is removed from the market. The PDP tests a wide variety of domestic and imported foods with a strong focus on foods that are consumed by infants and children. EPA relies on PDP data to conduct dietary risk assessments and to ensure that any pesticide residues in foods remain at safe levels. USDA uses the data to better understand the relationship of pesticide residues to agricultural practices and to enhance USDA’s Integrated Pest Management objectives. USDA also works with U.S. growers to improve agricultural practices. Content While the original 2013 MS Access database can be found here the data has been transferred to a SQLite database for easier more open use. The database contains two tables Sample Data and Results Data. Each sampling includes attributes such as extraction method the laboratory responsible for the test and EPA tolerances among others. These attributes are labeled with codes which can be referenced in PDF format here or integrated into the database using the included csv files.  Inspiration  What are the most common types of pesticides tested in this study? Do certain states tend to use one particular pesticide type over another? Does pesticide type correspond more with crop type or location (state)? Are any produce types found to have higher pesticide levels than assumed safe by EPA standards? By combining databases from several years of PDP tests can you see any trends in pesticide use?  Acknowledgement This dataset is part of the USDA PDP yearly database and the original source can be found here.,Annotate Code:Annotated Information:,string:string:,
Political Social Media Posts , Crowdflower , www.kaggle.com/crowdflower/political-social-media-posts , Mon Nov 21 2016 03:56:07 GMT+0530 (IST) , Classify partisan bias audience and goal based on politicians' social media ,345, politics- internet- ,"This dataset from Crowdflower's Data For Everyone Library provides text of 5000 messages from politicians' social media accounts along with human judgments about the purpose partisanship and audience of the messages. How was it collected? Contributors looked at thousands of social media messages from US Senators and other American politicians to classify their content. Messages were broken down into audience (national or the tweeter’s constituency) bias (neutral/bipartisan or biased/partisan) and finally tagged as the actual substance of the message itself (options ranged from informational announcement of a media appearance an attack on another candidate etc.) Acknowledgments Data was provided by the Data For Everyone Library on Crowdflower. Our Data for Everyone library is a collection of our favorite open data jobs that have come through our platform. They're available free of charge for the community forever. Inspiration Here are a couple of questions you can explore with this dataset  what words predict partisan v. neutral messages? what words predict support messages v. attack messages? do politicians use Twitter and Facebook for different purposes? (e.g. Twitter for attack messages Facebook for policy messages)?  The Data The dataset contains one file with the following fields  _unit_id a unique id for the message _golden always FALSE; (presumably whether the message was in Crowdflower's gold standard) _unit_state always ""finalized"" _trusted_judgments the number of trusted human judgments that were entered for this message; an integer between 1 and 3 _last_judgment_at when the final judgment was collected audience one of national or constituency audienceconfidence a measure of confidence in the audience judgment; a float between 0.5 and 1 bias one of neutral or partisan biasconfidence a measure of confidence in the bias judgment; a float between 0.5 and 1 message the aim of the message. one of -- attack the message attacks another politician  -- constituency the message discusses the politician's constituency  -- information an informational message about news in government or the wider U.S.  -- media a message about interaction with the media  -- mobilization a message intended to mobilize supporters  -- other a catch-all category for messages that don't fit into the other  -- personal a personal message usually expressing sympathy support or condolences or other personal opinions  -- policy a message about political policy  -- support a message of political support   messageconfidence a measure of confidence in the message judgment; a float between 0.5 and 1 orig__golden always empty; presumably whether some portion of the message was in the gold standard audience_gold always empty; presumably whether the audience response was in the gold standard bias_gold always empty; presumably whether the bias response was in the gold standard bioid a unique id for the politician embed HTML code to embed this message id unique id for the message WITHIN whichever social media site it was pulled from label a string of the form ""From firstname lastname (position from state)"" message_gold always blank; presumably whether the message response was in the gold standard source where the message was posted; one of ""facebook"" or ""twitter"" text the text of the message ",,,
Retrosheet events 1970 - 2015 , Ben Dilday , www.kaggle.com/bdilday/retrosheet-events-1970-2015 , Sun Aug 21 2016 21:01:32 GMT+0530 (IST) , A granular history of baseball ,303, baseball- history- ,"This data set comprises events for major league baseball provided by http//retrosheet.org.  The information used here was obtained free of  charge from and is copyrighted by Retrosheet.  Interested  parties may contact Retrosheet at ""www.retrosheet.org"".  Roughly speaking an event is an outcome in a baseball game. This includes the end result of a plate appearance (strikeout out in the field hit base on balls) events that occur within a plate appearance (stolen bases caught stealing) and rare other occurrences. The retrosheet event data prior to 1955 are not complete. The data subsequent to 1988 include pitch counts while the data prior do not. The data here cover the years 1970-2015 in three divisions (1970-1992 1993-2004 2005-2015) that correspond roughly to distinct eras with different run-scoring environments. These data have specifically been obtained with a mix of the data dumps available at baseball heatmaps and with the py-retrosheet Python package available on github. I have augmented the data provided by retrosheet with some additional fields. Most substantively the rows include the wOBA value of the event in the field woba_pts and an estimated time stamp in units of seconds since Jan. 1 1900 (time_since_1900). The conversion from retrosheet files to sql and csv is done by the chadwick software. A detailed description of all of the fields is available on the documentation for chadwick http//chadwick.sourceforge.net/doc/cwevent.html. In order to keep the file sizes down I have limited the fields in this data set to a subset of the fields described in the chadwick documentation. The master.csv file is a subset of the Baseball Databank data and is released under a Creative Commons Attribution-ShareAlike 3.0 Unported License.https//creativecommons.org/licenses/by-sa/3.0/. More details are available on the Baseball Databank github https//github.com/chadwickbureau/baseballdatabank",,,
ATP Matches 1968 to 2017 , Sijo VM , www.kaggle.com/sijovm/atpdata , Thu Mar 30 2017 10:42:34 GMT+0530 (IST) , Details of the ATP matches since 1968 ,517, tennis- ,The data set contains the details about all the ATP matches played since 1968. The data set has a lot of missing values especially for the period between 1968 - 1991.  Thanks to Xiaming Chen for making the data available to the online community.  Primarily I would like to understand how tennis matches/players have evolved over time and any other insights.,tourney_id:tourney_name:surface:draw_size:tourney_level:tourney_date:match_num:winner_id:winner_seed:winner_entry:winner_name:winner_hand:winner_ht:winner_ioc:winner_age:winner_rank:winner_rank_points:loser_id:loser_seed:loser_entry:loser_name:loser_hand:loser_ht:loser_ioc:loser_age:loser_rank:loser_rank_points:score:best_of:round:minutes:w_ace:w_df:w_svpt:w_1stIn:w_1stWon:w_2ndWon:w_SvGms:w_bpSaved:w_bpFaced:l_ace:l_df:l_svpt:l_1stIn:l_1stWon:l_2ndWon:l_SvGms:l_bpSaved:l_bpFaced:,string:string:string:numeric:string:numeric:numeric:numeric:numeric:string:string:string:numeric:string:numeric:string:string:numeric:numeric:string:string:string:string:string:string:string:string:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:,
Harvard Tuition , Harvard University , www.kaggle.com/harvard-university/harvard-tuition , Fri Nov 11 2016 11:00:42 GMT+0530 (IST) , Tuition data from Harvard's College and graduate/professional schools since 1985 ,226, education- ,"Harvard tuition data since 1985 for both the undergraduate College and the graduate and professional schools. The Data This dataset consists of two files tuition_graduate.csv and undergraduate_package.csv which contain the tuition and fees data for the graduate schools and undergraduate College respectively.  tuition_graduate.csv contains the following fields  academic.year the academic year between 1985 and 2017 school the name of the graduate or professional school; one of   GSAS Business (MBA) Design Divinity Education Government Law Medical/Dental Public Health (1-Year MPH) cost the cost of tuition at a given school in a given year  undergraduate_package.csv contains the following fields  academic.year the academic year between 1985 and 2017 component the component of undergraduate fees; one of Tuition*Health Services Fee*Student Services Fee*Room*Board*Total* cost the cost of the component; or if the component is Total the sum of the costs of the other components in that year  Acknowledgements All of the data in this dataset comes from The Harvard Open Data Dataverse. Specific citations are as follows for the graduate tuition data  Harvard Financial Aid Office 2015 ""Harvard graduate school tuition"" doi10.7910/DVN/LV0YSQ Harvard Dataverse V1 for the undergraduate tuition and fees data  Harvard Financial Aid 2015 ""Harvard College Tuition"" doi10.7910/DVN/MSS2BE Harvard Dataverse V1 [UNF6FyXNny+KBTgLX+DzewzEfg==]",academic.year:school:cost:,numeric:string:numeric:,
Open Flood Risk by Postcode , GetTheData , www.kaggle.com/getthedata/open-flood-risk-by-postcode , Tue Mar 21 2017 21:19:27 GMT+0530 (IST) , English postcodes with Environment Agency flood risk ,95, geography- ,Context This dataset takes the Environment Agency's Risk of Flooding from Rivers and Sea and places English postcodes in their appropriate flood risk area allowing you to look up flood risk from postcode. Content Risk of Flooding from Rivers and Sea consists of geographical areas within England which are at risk of flooding from rivers and sea. Each area is assigned a flood risk within a banding  High Medium Low Very low None  Open Flood Risk by Postcode takes postcodes as point locations (from Open Postcode Geo) and places the postcode in the appropriate flood risk area. It is important to note that actual properties within a specific postcode may have a slightly different point location and therefore be in a different flood risk area. Generally speaking the point location of a postcode is the point location of the central property in that postcode. For a full field list and explanations of values see the Open Flood Risk by Postcode documentation. Acknowledgements Open Flood Risk by Postcode is derived from two open datasets  Risk of Flooding from Rivers and Sea Open Postcode Geo  Both of these datasets are licensed under the OGL. The following attribution statements are required  Contains OS data © Crown copyright and database right 2017 Contains Royal Mail data © Royal Mail copyright and database right 2017 Contains National Statistics data © Crown copyright and database right 2017 Contains Environment Agency data licensed under the Open Government Licence v3.0.  The dataset is maintained by GetTheData. The latest version and full documentation is available here. Inspiration Example application Lookup or drill down to individual English postcodes to see a map of that postcode and its flood risk alongside surrounding postcodes and their flood risks  Application Flood Map by Postcode Example postcode RG9 2LP ,,,
Parking Violations December 2015 , ArcGIS Open Data , www.kaggle.com/arcgisopendata/dc-parking-violations , Wed Nov 30 2016 20:56:15 GMT+0530 (IST) , Parking citation locations in the District of Columbia ,205, automobiles- road transport- ,Context The Vision Zero data contained in this layer pertain to parking violations issued by the District of Columbia's Metropolitan Police Department (MPD) and partner agencies with the authority. Parking violation locations are summarized ticket counts based on time of day week of year year and category of violation. Data was originally downloaded from the District Department of Motor Vehicle's eTIMS meter work order management system.  Content This dataset contains 132850 rows of  OBJECTID (unique ID)   ROWID_  DAY_OF_WEEK (text)     HOLIDAY (number)   WEEK_OF_YEAR (number)  MONTH_OF_YEAR (number)     ISSUE_TIME (number)    VIOLATION_CODE (text)  VIOLATION_DESCRIPTION (text)       LOCATION (text)        RP_PLATE_STATE (text)  BODY_STYLE (text)  ADDRESS_ID (number)    STREETSEGID (number)       XCOORD (number)    YCOORD (number) TICKET_ISSUE_DATE (date or time)   X Y  Acknowledgements The dataset is shared by DCGISopendata and the original dataset and metadata can be found here. Inspiration Can you use the dataset to determine  Which area has the highest concentration of parking violations? How about by type of violation? Do areas with high concentration of parking violations change throughout the month of December? Can you identify any trends? ,X:Y:OBJECTID:ROWID_:DAY_OF_WEEK:HOLIDAY:WEEK_OF_YEAR:MONTH_OF_YEAR:ISSUE_TIME:VIOLATION_CODE:VIOLATION_DESCRIPTION:LOCATION:RP_PLATE_STATE:BODY_STYLE:ADDRESS_ID:STREETSEGID:XCOORD:YCOORD:TICKET_ISSUE_DATE:,numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:string:string:string:string:string:numeric:numeric:numeric:numeric:dateTime:,
The Global Avian Invasions Atlas , figshare , www.kaggle.com/figshare/the-global-avian-invasions-atlas , Sat Apr 08 2017 08:20:53 GMT+0530 (IST) , A database of alien bird distributions worldwide ,53, animals- ,This comma-separated text file contains the 27723 alien bird records that form the core of the Global AVian Invasions Atlas (GAVIA) project. These records represent 971 species introduced to 230 countries and administrative areas across all eight biogeographical realms spanning the period 6000 BCE – AD 2014. The data comprises taxonomic (species-level) spatial (geographic location realm land type) and temporal (dates of introduction and spread) components as well as details relating to the introduction event (how and why the species was introduced whether or not it is established). Each line of data consists of an individual record concerning a specific alien bird species introduced to a specific location. The data derives from both published and unpublished sources including atlases country species lists peer-reviewed articles websites and via correspondence with in-country experts. Acknowledgements Dyer Ellie; Redding David; Blackburn Tim (2016) Data from The Global Avian Invasions Atlas - A database of alien bird distributions worldwide. figshare.,Abbreviation:Meaning :,string:string:,
Dogs of Zurich , Kevin Mader , www.kaggle.com/kmader/dogs-of-zurich , Wed Mar 08 2017 20:37:26 GMT+0530 (IST) , Data about Dog Owners in Zurich Switzerland ,202, animals- sociology- ,All the data was taken from Open Data Zurich (https//data.stadt-zuerich.ch/dataset/pd-stapo-hundebestand) with the idea of making a useful few Kernel demos from it and let people look at information about the dogs that live here.  German Since German is the official language of Zurich most of the columns are in German but the translations to English aren't too tricky  ALTER -> Age GESCHLECHT ->  Gender STADTKREIS -> City Quarter or District RASSE1 -> Dog's Primary Breed RASSE2 -> Dog's Secondary Breed GEBURTSJAHR_HUND -> Dog's Year of Birth GESCHLECHT_HUND -> Dog's Gender HUNDEFARBE -> Dog's Color  Utility  It might also help people trying to find apartments in areas with the right kind of dogs Could be used to look at how dog trends have changed in time (by looking at the numbers by birth year) Helpful for picking the right kind of dog to get your 90 year old grandmother (what kind of dogs do other 90 year old women have) ,HALTER_ID:,numeric:,
Human Rights Project: Country Profiles by Year , University of Connecticut , www.kaggle.com/uconn/human-rights , Tue Jan 31 2017 22:20:23 GMT+0530 (IST) , Human rights data from US State Department and Amnesty International ,147, crime- war- international relations- ,"Content The Cingranelli-Richards human rights database contains quantitative information on government recognition of 15 internationally recognized human rights in more than 200 countries from 1981-2011. It includes measures of the practices of governments that allow or impede citizens who wish to exercise their physical integrity rights like the rights not to be tortured summarily executed disappeared or imprisoned for political beliefs; civil liberties such as free speech freedom of association and assembly freedom of movement freedom of religion and the right to participate in the selection of government leaders; employment rights; and rights of women to equal treatment politically economically and socially. The database is designed for use by scholars and students who seek to test theories about the causes and consequences of human rights violations as well as policy makers and analysts who seek to estimate the human rights effects of a wide variety of institutional changes and public policies including democratization economic aid military aid structural adjustment and humanitarian intervention. The primary source of information about human rights practices is obtained from the annual United States Department of State’s Country Reports on Human Rights Practices. Coders are instructed to use this source for all variables. For a group of four rights known as ""Physical Integrity Rights"" (the rights to freedom from extrajudicial killing disappearance torture and political imprisonment) coders use Amnesty International’s Annual Report in addition the Department of State reports. If discrepancies exist between the two sources coders are instructed to treat the Amnesty International report as authoritative; some scholars believe that this step is necessary to remove a potential bias in favor of American allies. Acknowledgements The human rights database was developed updated and published by Professor David Cingranelli of Binghamton University SUNY Professor David Richards of the University of Connecticut's Human Rights Institute and Professor K. Chad Clay of the University of Georgia.",Year:CIRI Country ID:Country:UN Country ID:UN Region:UN Subregion:Physical Integrity Rights Index:Disappearance:Extrajudicial Killing:Political Imprisonment:Torture:Empowerment Rights Index (Old):Empowerment Rights Index (New):Freedom of Assembly and Association:Freedom of Foreign Movement:Freedom of Domestic Movement:Freedom of Movement (Old):Freedom of Speech:Electoral Self-Determination:Freedom of Religion (Old):Freedom of Religion (New):Employment Rights:Women’s Economic Rights:Women’s Political Rights:Women’s Social Rights:Independence of Judiciary:,numeric:numeric:string:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Home Advantage in Soccer and Basketball , DrGuillermo , www.kaggle.com/drgilermo/home-advantage-in-soccer-and-basketball , Sat Jan 21 2017 20:56:40 GMT+0530 (IST) , Home and away performance of 9K+ Teams from 88 leagues around the world ,463, association football- basketball- ,Context The data set includes information about different leagues in different sports (Basketball and Soccer) all around the world as well as some basic facts about each country regarding the home advantage phenomenon in sports.  Content The data is comprised of 3 data sets  The home and away performance of 8365 soccer teams from a few dozens of countries during the years 2010-2016. The home and away performance of 1216 NBA teams during the years 1968-2010 General facts about 88 countries including soccer data such as their FIFA rank the average attendance of soccer matches and the Home Advatnage Factor of the leagure  Acknowledgement The soccer data was scraped from here http//footballdatabase.com/competitions-index The NBA data was scraped from NBA.com. The world facts were copied from Wikipedia.,Country:Region:Population:Area:,string:string:numeric:numeric:,
Metal Bands by Nation , mrpantherson , www.kaggle.com/mrpantherson/metal-by-nation , Thu Feb 16 2017 01:21:16 GMT+0530 (IST) , The data sets within contain information on metal bands and world population ,231, music- international relations- ,Context The story behind this data set and analysis is just a combination of my interest in data science and metal music.  I was looking for interesting data that I could analyze and this happen to be one of the first I started exploring. Content The world population information was a direct download so I did not have to do any work to get it.  This data set consists of population information for countries on earth from the years 1960 to 2015. The metal band information was scraped from the website http//metalstorm.net/ and consists of the following  - band name  - how many fans the band has on the website   - when the band formed  - when the band split  - the country of origin on the band  - the styles of the band Acknowledgements The metal information was compiled from information found on http//metalstorm.net/ the world population information is from http//www.worldbank.org/. Inspiration There has already been some great analysis of metal bands on Kaggle I wanted to contribute to the discussion by adding some new data and looking at it from a slightly different angle.  Also I thought it might be useful to share the process by which I came up with the visualizations and data management since the community has been a big help to me.,:band_name:fans:formed:origin:split:style:,numeric:string:numeric:numeric:string:numeric:string:,
Online Chinese Chess (Xiangqi) , boyofans , www.kaggle.com/boyofans/onlinexiangqi , Wed Feb 15 2017 04:27:49 GMT+0530 (IST) , 10000 games of Blitz xiangqi ,125, board games- ,Content Xiangqi also known as Chinese Chess is one of the most popular board game in China and Southeastern Asia that is played by millions of people every single day. More information on the rules and the history of Xiangqi can be found from the Xiangqi wikipedia page The dataset contains 10000 game logs of Blitz xiangqi played on playOK.com scraped off playOK API with Python. In particular the games in the dataset have ID numbers between 57380690 and 57390689. The game records are stored in two separate files  gameinfo.csv which contains players information and game result in gameID game_datetime blackID blackELO redID redELO winner moves.csv which contains game moves in gameID turn A number denoting at which turn of the game the move was made. side move Moves are recorded with the WXF notation. Explainations can be found at XQinEnglish.com  Acknowledgements Data is scraped from the playOK.com game logs API. Cover photo is from Rosino under CC BY-SA 2.0. Misc. There are millions of game logs on playOK.com but I decided to cut the data off at 10000 games due to file size. If you need more games check the GitHub repository of my online xiangqi scraper.,gameID:,numeric:,
Swedish central bank interest rate and inflation , Christian Nygaard , www.kaggle.com/cnygaard/sweden-interest-rate-inflation , Wed Sep 07 2016 15:50:21 GMT+0530 (IST) , Historic Swedish interest rate 1908-2001 and Swedish inflation consumer price ,423, finance- ,This a blend dataset that contains historic Swedish interest rates from 1908-2001 Source/Källa Sveriges riksbank and Swedish inflation rate 1908-2001 fetched from Sweden's statistic central bureau SCB. Content Blend of Swedish historic central bank interest rate diskkonto and Swedish SCB Consument price index Acknowledgements / Original data sets Swedish central bank interest rate diskkonto http//www.riksbank.se/sv/Rantor-och-valutakurser/Sok-rantor-och-valutakurser/ Consumer price index http//www.scb.se/sv_/Hitta-statistik/Statistik-efter-amne/Priser-och-konsumtion/Konsumentprisindex/Konsumentprisindex-KPI/33772/33779/Konsumentprisindex-KPI/33831/ Data set cover images  Wikipedia https//sv.wikipedia.org/wiki/Enkronan#/media/File1_Krona_1927_1.jpg https//en.wikipedia.org/wiki/Flag_of_Sweden#/media/FileFlag_of_Sweden.svg Inspiration  Question How does central bank interest rate effect inflation? What are the interest rate inflation rate delays? Verify ROC R^2 inflation/interest rate causation. Content Interestrate and inflation Sweden 1908-2001.csv Columns  Period   Year  Central bank interest rate diskonto average  Percent Inflation    Percent    Price level Integer ,,,
2015 Notebook UX Survey , Project Jupyter , www.kaggle.com/jupyter/2015-notebook-ux-survey , Mon May 01 2017 23:26:25 GMT+0530 (IST) , Understand user perspectives on Jupyter Notebooks ,801, human-computer interaction- ,At the end of 2015 the Jupyter Project conducted a UX Survey for Jupyter Notebook users. This dataset Survey.csv contains the raw responses. See the Google Group Thread for more context around this dataset. ,"Time Started:Date Submitted:Status:How often do you use Jupyter Notebook?:What, if anything, hinders you from making Jupyter Notebook an even more regular part of your workflow?:Roughly how long have you been using Jupyter Notebook?:Tool / Application #1:What tools and applications, if any, would you like to see more tightly integrated with Jupyter Notebook?    :Tool / Application #2:What tools and applications, if any, would you like to see more tightly integrated with Jupyter Notebook?    :Tool / Application #3:What tools and applications, if any, would you like to see more tightly integrated with Jupyter Notebook?    :How do you run the Jupyter Notebook?:Other - Write In:How do you run the Jupyter Notebook?:Workflow Need #1:What needs in your workflow does Jupyter Notebook address?:Workflow Need #2:What needs in your workflow does Jupyter Notebook address?:Workflow Need #3:What needs in your workflow does Jupyter Notebook address?:Workflow Need #1:What needs in your workflow does Jupyter Notebook not address?:Workflow Need #2:What needs in your workflow does Jupyter Notebook not address?:Workflow Need #3:What needs in your workflow does Jupyter Notebook not address?:Aspect #1:What aspects of Jupyter Notebook make it pleasant to use in your workflow?:Aspect #2:What aspects of Jupyter Notebook make it pleasant to use in your workflow?:Aspect #3:What aspects of Jupyter Notebook make it pleasant to use in your workflow?:Aspect #1:What aspects of Jupyter Notebook make it difficult to use in your workflow?:Aspect #2:What aspects of Jupyter Notebook make it difficult to use in your workflow?:Aspect #3:What aspects of Jupyter Notebook make it difficult to use in your workflow?:Feature / Change #1:What new features or changes would you like to see in Jupyter Notebook? (Please list anything that comes to mind that helps you in your workflow, big or small.):Feature / Change #2:What new features or changes would you like to see in Jupyter Notebook? (Please list anything that comes to mind that helps you in your workflow, big or small.):Feature / Change #3:What new features or changes would you like to see in Jupyter Notebook? (Please list anything that comes to mind that helps you in your workflow, big or small.):Enhancement #1:Thinking back to when you first started using Jupyter Notebook, what enhancements would have made your initial experience better?:Enhancement #2:Thinking back to when you first started using Jupyter Notebook, what enhancements would have made your initial experience better?:Enhancement #3:Thinking back to when you first started using Jupyter Notebook, what enhancements would have made your initial experience better?:Select all the words that best describe Jupyter Notebook.:Other word(s)::Select all the words that best describe Jupyter Notebook.:What is your primary role when using Jupyter Notebook (e.g., student, astrophysicist, financial modeler, business manager, etc.)?:How many years have you been in this role? :Industry #1:What industries does your role and analytical work support (e.g., Journalism, IT, etc.)?:Industry #2:What industries does your role and analytical work support (e.g., Journalism, IT, etc.)?:Industry #3:What industries does your role and analytical work support (e.g., Journalism, IT, etc.)?:How many people typically see and/or interact with the results of your work in Jupyter Notebook? (Consider people who view your notebooks on nbviewer, colleagues who rerun your notebooks, developers who star your notebook repos on GitHub, audiences who se:",dateTime:dateTime:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:,
Burritos in San Diego , Scott Cole , www.kaggle.com/srcole/burritos-in-san-diego , Mon Sep 26 2016 20:51:31 GMT+0530 (IST) , Mexican food enthusiasts rate 10 dimensions of hundreds of burritos in San Diego ,897, food and drink- ,Mexican cuisine is often the best food option is southern California. And the burrito is the hallmark of delicious taco shop food tasty cheap and filling. Appropriately an effort was launched to critique burritos across the county and make this data open to the lay burrito consumer. At this time the data set contains ratings from over 200 burritos from around 50 restaurants. There are 10 core dimensions of the San Diego burrito. * Volume * Tortilla quality *Temperature * Meat quality * Non-meat filling quality * Meat-to-filling ratio * Uniformity * Salsa quality * Flavor synergy * Wrap integrity All of these measures (except for Volume) are rated on a scale from 0 to 5 0 being terrible and 5 being optimal. Other information available for each burrito includes an overall rating cost Yelp rating of the restaurant and more. More information about the data set as well as a link to the continuously updated dataset can be found here.,Location:Burrito:Date:Neighborhood:Address:URL:Yelp:Google:Chips:Cost:Hunger:Length:Circum:Volume:Tortilla:Temp:Meat:Fillings:Meat:filling:Uniformity:Salsa:Synergy:Wrap:overall:Rec:Reviewer:Notes:Unreliable:NonSD:Beef:Pico:Guac:Cheese:Fries:Sour cream:Pork:Chicken:Shrimp:Fish:Rice:Beans:Lettuce:Tomato:Bell peper:Carrots:Cabbage:Sauce:Cilantro:Onion:Taquito:Pineapple:Ham:Chile relleno:Nopales:Lobster:Queso:Egg:Mushroom:Bacon:Sushi:Avocado:Corn:Zucchini:,string:string:dateTime:string:string:string:numeric:numeric:string:numeric:numeric:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:,
Presidential Approval Ratings , The Huffington Post , www.kaggle.com/huffingtonpost/presidential-approval , Tue Feb 28 2017 23:35:21 GMT+0530 (IST) , Public opinion survey methodology and results since 2008 ,168, politics- ,Context HuffPost Pollster (originally Pollster.com) aims to report the results of every public poll that claims to provide a representative sample of the population or electorate. We have included polls of varying methodology including automated or recorded voice telephone polls and online surveys using non-probability internet samples. As of 2010 we require all polls from a new organization (or one new to us) to meet all of the minimal disclosure requirements of the National Council on Public Polling. We have always excluded polls that fail to disclose survey dates sample size and sponsorship; however we may now choose in our editorial discretion to exclude polls or pollsters that do not provide sufficient methodological information for us or our readers to determine their quality. Content This dataset lists results from public opinion surveys regarding the president's job approval since 2008. Acknowledgements The presidential approval ratings were provided by the organization listed and aggregated by HuffPost Pollster. Inspiration How does public approval of the president change over time? How do current events and presidential responses impact approval ratings? Can you predict how Trump's approval rating will change over the course of his presidency?,,,
Taekwondo Techniques Classification , Ali Ghafour , www.kaggle.com/ali2020armor/taekwondo-techniques-classification , Wed Jan 18 2017 23:47:31 GMT+0530 (IST) , Can you determine technique type & intensity of a Taekwondo impact? ,168, sports- ,Context This dataset contains information obtained from an impact sensor within a Taekwondo chest protector. Participants were asked to perform various Taekwondo techniques on this chest protector for analysis of sensor readings. Content Data was obtained from 6 participants performing 4 different Taekwondo techniques – Roundhouse/Round Kick Back Kick Cut Kick & Punch. Participant details are summarized in Table 1. The table is organized in ascending order according to participant weight/experience level. In the file 'Taekwondo_Technique_Classification_Stats.csv’ the data is organized as follows. The rows display  Technique – Roundhouse/Round Kick (R) Back Kick (B) Cut Kick (C) Punch (P)  Participant ID – P1 P2 P3 P4 P5 P6  Trial # – For each Technique each participant performed a total of 5 trials  Sensor Readings – Data shows the ADC readings obtained from a 12-bit ADC connected to the sensor (not listed as Voltage but can be converted to it)  The columns identify type of technique participant trial # and showcase the sensor readings. There are a total of 115 columns of sensor readings. Each participant performed 5 trials for each type of technique with hard intensity. The only exception is that Participant 6 (P6) did not perform Back Kicks.  Acknowledgements The dataset was collected at a local Taekwondo school. We would like to thank the instructor and students for taking their time to participate in our data collection! Past Research Previous work to classify Taekwondo techniques included using a butter-worth low pass filter on Matlab and performing integration around the maximum signal peak. The goal was to observe a pattern in the resulting integration values to determine impact intensity for each type of technique. Inspiration Main analysis questions 1) Determine impact intensity that is proportional to the participant’s weight/experience level  Ideally impact intensity should increase with the increasing participant weight/experience level or ID (Participant ID in Table 1 corresponds to ascending weight/experience level)  2) Classify or distinguish between types of impact (Round Kick Back Kick Cut Kick or Punch)  Each Taekwondo technique usually has a unique waveform to be identified ,Participant ID:Sex:Age:Weight (kg):Experience (years):Belt:,string:string:numeric:numeric:numeric:string:,
NFL Arrests , The Washington Post , www.kaggle.com/washingtonpost/nfl-arrests , Mon Nov 28 2016 02:48:12 GMT+0530 (IST) , Public records of police arrests at NFL stadiums ,210, american football- crime- ,Context This dataset consists of public records requests made by the Washington Post to police departments that oversee security at each NFL stadium.  Content Twenty-nine of the 31 jurisdictions provided at least partial data though reporting methods differed from agency to agency; Cleveland and New Orleans did not submit data. Certain data were omitted if found to be incomplete or unreliable. Among those jurisdictions sending partial arrest figures for home games between 2011 and 2015 were Buffalo Miami and Oakland. St. Louis provided only year-by-year arrest data rather than game-by-game numbers. Detroit Minneapolis and Atlanta did not provide data for arrests that took place in stadium parking lots. The main dataset includes fields such as the day of the week which teams were playing on which home field and the score of the game between 2011 and 2015. Inspiration  Which stadiums had the most arrests? The least? Are arrests more likely when the home team lost a game? Does the score correlate with number of arrests? (For example if the game ended in a narrow loss for the home team does this correlate with more arrests?) Are there any stadiums with consistent arrest rates regardless of how the game ended?  Acknowledgements Data was collected and reported by Kent Babb and Steven Rich of the Washington Post and the original dataset can be found here.,season:week_num:day_of_week:gametime_local:home_team:away_team:home_score:away_score:OT_flag:arrests:division_game:,numeric:numeric:string:numeric:string:string:numeric:numeric:string:numeric:string:,
Aerial Bombing Operations in World War II , United States Air Force , www.kaggle.com/usaf/world-war-ii , Tue Jan 31 2017 01:33:25 GMT+0530 (IST) , Target aircraft used and bombs deployed for every mission in WWII ,272, history- war- ,Content This dataset consists of digitized paper mission reports from WWII. Each record includes the date conflict geographic location and other data elements to form a live-action sequence of air warfare from 1939 to 1945. The records include U.S. and Royal Air Force data in addition to some Australian New Zealand and South African air force missions. Acknowledgements Lt Col Jenns Robertson of the US Air Force developed the Theater History of Operations Reports (THOR) and posted them online after receiving Department of Defense approval.,Mission ID:Mission Date:Theater of Operations:Country:Air Force:Unit ID:Aircraft Series:Callsign:Mission Type:Takeoff Base:Takeoff Location:Takeoff Latitude:Takeoff Longitude:Target ID:Target Country:Target City:Target Type:Target Industry:Target Priority:Target Latitude:Target Longitude:Altitude (Hundreds of Feet):Airborne Aircraft:Attacking Aircraft:Bombing Aircraft:Aircraft Returned:Aircraft Failed:Aircraft Damaged:Aircraft Lost:High Explosives:High Explosives Type:High Explosives Weight (Pounds):High Explosives Weight (Tons):Incendiary Devices:Incendiary Devices Type:Incendiary Devices Weight (Pounds):Incendiary Devices Weight (Tons):Fragmentation Devices:Fragmentation Devices Type:Fragmentation Devices Weight (Pounds):Fragmentation Devices Weight (Tons):Total Weight (Pounds):Total Weight (Tons):Time Over Target:Bomb Damage Assessment:Source ID:,numeric:dateTime:string:string:string:string:string:string:numeric:string:string:numeric:numeric:numeric:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:string:string:numeric:string:string:numeric:string:string:string:string:string:string:string:string:string:numeric:string:string:numeric:,
Union Membership & Coverage , Megan Risdal , www.kaggle.com/mrisdal/union-membership-coverage , Mon Sep 05 2016 22:20:17 GMT+0530 (IST) , The state of unions in the United States (1983 to 2015) ,194, government- economics- ,"The United States Department of Labor tells us that ""Labor Day the first Monday in September is a creation of the labor movement and is dedicated to the social and economic achievements of American workers. It constitutes a yearly national tribute to the contributions workers have made to the strength prosperity and well-being of our country."" This database of state-level union membership and coverage from 1983 to 2015 was originally compiled by Barry Hirsch (Andrew Young School of Policy Studies Georgia State University) and David Macpherson (Department of Economics Trinity University). The database available at unionstats.com provides private and public sector labor union membership coverage and density estimates compiled from the monthly household Current Population Survey (CPS) using BLS methods. Use of this data requires citation of the following paper which also includes a description of how the database was created Barry T. Hirsch and David A. Macpherson ""Union Membership and Coverage Database from the Current Population Survey Note"" Industrial and Labor Relations Review Vol. 56 No. 2 January 2003 pp. 349-54. (PDF).",Code:State:Sector:Obs:Employment:Members:Covered:PctMem:PctCov:Year:,numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Freedom of Information Act Requests , Department of Justice , www.kaggle.com/doj/foia-requests , Sat Jan 21 2017 01:55:48 GMT+0530 (IST) , Which agency or department receives the most FOIA requests? ,74, information- politics- ,Context Since 1967 the Freedom of Information Act (FOIA) has provided the public the right to request access to records from any federal agency. It is often described as the law that keeps citizens in the know about their government. Federal agencies are required to disclose any information requested under the FOIA unless it falls under one of nine exemptions which protect interests such as personal privacy national security and law enforcement. As Congress the President and the Supreme Court have all recognized the Act is a vital part of our democracy. A FOIA request can be made for any agency record. You can also specify the format in which you wish to receive the records (for example printed or electronic form). The Act does not require agencies to create new records or to conduct research analyze data or answer questions when responding to requests. Each federal agency handles its own records in response to requests. There are currently one hundred agencies subject to the FOIA with several hundred offices that process FOIA requests. Content Annual Freedom of Information Act Reports are submitted to Congress and published by FOIA.gov to promote agency accountability for the administration of the Act.,Agency:Department:Year:Requests Pending Start Year:Requests Received:Requests Processed:Requests Pending End Year:Released in Full Ratio:Released in Part Ratio:Denied in Full Ratio:,string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Newspaper Endorsements of Presidential Candidates , WNYC , www.kaggle.com/wnyc/candidate-endorsements , Sat Feb 04 2017 03:10:37 GMT+0530 (IST) , Candidate endorsements and presidential election results since 1980 ,65, news agencies- politics- ,Content This dataset includes presidential candidates endorsed by the top 100 American newspapers by circulation for every election since 1980. Acknowledgements The historical candidate endorsements were compiled and documented by Github user veltman and the presidential election results were provided by the Federal Election Commission.,State:Carter (1980):Reagan (1980):Anderson (1980):Mondale (1984):Reagan (1984):Dukakis (1988):Bush (1988):Clinton (1992):Bush (1992):Perot (1992):Clinton (1996):Dole (1996):Perot (1996):Gore (2000):Bush (2000):Nader (2000):Kerry (2004):Bush (2004):Obama  (2008):McCain (2008):Obama (2012):Romney (2012):Clinton (2016):Trump (2016):Johnson  (2016):,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Party strength in each US state , GeneBurin , www.kaggle.com/kiwiphrases/partystrengthbystate , Fri Jan 13 2017 07:24:40 GMT+0530 (IST) , From 1980 to present; a collection of political office compositions per state ,99, politics- ,"Data on party strength in each US state The repository contains data on party strength for each state as shown on each state's corresponding party strength Wikipedia page (for example here is Virginia ) Each state has a table of a detailed summary of the state of its governing and representing bodies on Wikipedia but there is no data set that collates these entries. I scraped each state's Wikipedia table and collated the entries into a single dataset. The data are stored in the state_party_strength.csv and state_party_strength_cleaned.csv. The code that generated the file can be found in corresponding Python notebooks.  Data contents The data contain information from 1980 on each state's   1. governor and party   2. state house and senate composition   3. state representative composition in congress   4. electoral votes Clean Version Data in the clean version has been cleaned and processed substantially. Namely - all columns now contain homogenous data within the column - names and Wiki-citations have been removed - only the party counts and party identification have been left The notebook that created this file is here Uncleaned Data Version The data contained herein have not been altered from their Wikipedia tables except in two instances - Forced column names to be in accord across states - Any needed data modifications (ie concatenated string columns) to retain information when combining columns  To use the data  Please note that the right encoding for the dataset is ""ISO-8859-1"" not 'utf-8' though in future versions I will try to fix that to make it more accessible.  This means that you will likely have to perform further data wrangling prior to doing any substantive analysis. The notebook that has been used to create this data file is located here Raw scraped data The raw scraped data can be found in the pickle. This file contains a Python dictionary where each key is a US state name and each element is the raw scraped table in Pandas DataFrame format. Hope it proves as useful to you in analyzing/using political patterns at the state level in the US for political and policy research.",state:year:congress house:congress sen class 1:congress sen class 2:congress sen class 3:electoral:governor:legislature house:legislature sen:congress sen:,string:numeric:string:string:string:string:string:string:string:string:string:,
Seattle Police Reports , Sam Harris , www.kaggle.com/samharris/seattle-crime , Tue Oct 25 2016 05:54:27 GMT+0530 (IST) , Seattle Police Reports ,210, cities- crime- ,All recorded police reports as taken from https//data.seattle.gov/Public-Safety/Seattle-Police-Department-Police-Report-Incident/7ais-f98f,,,
AP Computer Science A Exam Dataset , Institute for Computing Education at Georgia Tech , www.kaggle.com/iceatgt/ap-computer-science-a-exam-dataset , Sun Nov 13 2016 08:15:18 GMT+0530 (IST) , AP CS A Exam Pass Rates Across States ,226, education- computer science- ,Context The datasets contain all the data for the number of CS AP A exam taken in each state from 1998 to 2013 and detailed data on pass rates race and gender from 2006-2013. The data was complied from the data available at http//research.collegeboard.org/programs/ap/data. This data was originally gathered by the CSTA board but Barb Ericson of Georgia Tech keeps adding to it each year. Content historical.csv contains data for the number of CS AP A exam taken in each state from 1998 to 2013  state US states 1998-2013 Pop population  pass_06_13.csv contains exam pass rates race and gender data from 2006 to 2013 for selected states. pass_12_13.csv contains exam pass rates race and gender information for every state for 2012 and 2013.  Acknowledgements The original datasets can be found here and here. Inspiration Using the datasets can you examine the temporal trends in the exam pass rates by race gender and geographical location?,state:1998:1999:2000:2001:2002:2003:2004:2005:2006:2007:2008:2009:2010:2011:2012:2013:Pop:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
SherLock , The BGU Cyber Security Research Center , www.kaggle.com/BGU-CSRC/sherlock , Wed Dec 07 2016 20:41:26 GMT+0530 (IST) , A long-term smartphone sensor dataset with a high temporal resolution ,431, computer science- ,"What is the SherLock dataset? A long-term smartphone sensor dataset with a high temporal resolution. The dataset also offers explicit labels capturing the to activity of malwares running on the devices. The dataset currently contains 10 billion data records from 30 users collected over a period of 2 years and an additional 20 users for 10 months (totaling 50 active users currently participating in the experiment).  The primary purpose of the dataset is to help security professionals and academic researchers in developing innovative methods of implicitly detecting malicious behavior in smartphones. Specifically from data obtainable without superuser (root) privileges. However this dataset can be used for research in domains that are not strictly security related. For example context aware recommender systems event prediction user personalization and awareness location prediction and more. The dataset also offers opportunities that aren't available in other datasets. For example the dataset contains the SSID and signal strength of the connected WiFi access point (AP) which is sampled once every second over the course of many months.  To gain full free access to the SherLock Dataset follow these two steps 1) Read complete and sign the license agreement. The general restrictions are -The license lasts for 3 years afterwhich the data must be deleted. -Do not share the data with those who are not bound by the license agreement. -Do not attempt to de-anonymize the individuals (volunteers) who have contributed the data. -Any of your publication that benefit from the SherLock project must cite the following article Mirsky Yisroel et al. ""SherLock vs Moriarty A Smartphone Dataset for Cybersecurity Research."" Proceedings of the 2016 ACM Workshop on Artificial Intelligence and Security. ACM 2016. 2)Send the scanned document as a PDF to bgu.sherlock@gmail.com and provide a gmail account to share a google drive folder with. More information can be found here or in this publication (download link). A 2 week data sample from a single user is provided on this Kaggle page. To access the full dataset for free please visit our site. Note The format of the sample dataset may differ from the full dataset. ",UserId:UUID:Extras:Action:timestamp:,string:numeric:string:string:dateTime:,
#Inauguration and #WomensMarch Tweets , AdhokshajaPradeep , www.kaggle.com/adhok93/inauguration-and-womensmarch-tweets , Wed Feb 08 2017 12:22:26 GMT+0530 (IST) , A look into how social media reacted to Trump's Inauguration ,179, gender- politics- internet- ,"The Presidency of Donald Trump On Jan 20th 2017 Donald J. Trump was elected as the 45th President of the United States. This marked the end of a brutal and contentious campaign. He goes in as one of the most unpopular presidents in modern history(based on the popular vote).  The Inauguration and the Women's March Trump's election to the presidency led to the organization of the Women's March  where millions of men and women took to the streets to protest the new government's stance on women's rights and healthcare. Social media blew up with searchable terms like ""#WomensMarch"" prompting major news organizations to cover the mass protests.  Data Acquisition The data was acquired using the twitteR package's searchTwitter() function. This function makes a call to the Twitter API. A total of 30000 tweets containing #Inauguration and #WomensMarch were obtained (15000 for each). Data Set Attributes 1 ""X""  Serial Number     2 ""text""   Tweet Text         3 ""favorited""  TRUE/FALSE    4 ""favoriteCount""  Number of Likes 5  ""replyToSN""  Screen Handle name of the receiver 6  ""created""  YYYY-MM-DD HMS 7 ""truncated""  If the Tweet is Truncated (TRUE/FALSE) 8 ""replyToSID"" ID of the receiver  9  ""id""  ID          10 ""replyToUID"" User ID of the receiver     11 ""statusSource"" Device Information (Web ClientIPhoneAndroid etc) 12 ""screenName""  Screen name of the Tweeter    13 ""retweetCount"" Number of Retweets  14 ""isRetweet""  TRUE/FALSE     15 ""retweeted""  Has this tweet been retweeted(TRUE/FALSE) 16 ""longitude""  longitude   17 ""latitude""  latitude  Some Questions How do the polarity/number of tweets change by time? Which locations had negative sentiments about the Inauguration? What about the Women's March? How to the retweet and mention networks look like for each case? Number of Tweets per Day? Which day has the most activity? What are the other hashtags used?",:text:favorited:favoriteCount:replyToSN:created:truncated:replyToSID:id:replyToUID:statusSource:screenName:retweetCount:isRetweet:retweeted:longitude:latitude:,numeric:string:boolean:numeric:string:dateTime:boolean:numeric:numeric:numeric:string:string:numeric:boolean:boolean:string:string:,
Academic Research from Indian Universities , Neel Shah , www.kaggle.com/neelshah18/scopusjournal , Wed Mar 15 2017 21:49:26 GMT+0530 (IST) , Collection of 1387 SCOPUS journal papers from Indian authors and institutions ,153, research- education- ,Context The main aim of this data analysis is to identify the ongoing research in Indian Universities and Indian Industry. It gives a basic answer about research source and trend with top authors and publication. It also shows the participation of Industry and Universities in research. Content  It is a collection of 1387 paper dataset from SCOPUS journal between 2001 to 2016 published by Indian Universities or India based research center of any industry. If a paper has multiple authors from Industry and Indian University we count that paper as university paper. If a paper published by industry and non-Indian university we count that paper as Industry paper. During cleaning of data we consider the different name of Institute as single Institute. For example IIT-Madras Indian Institute of Technology and IIT-M count as the same institute. We also consider the different name of same industry as single industry For example TCS and tata consultancy service count as the same industry.  Acknowledgements This dataset is available as open source on Scopus journal. We took only Indian researcher's detail from it. Detail of analysis and Blog  scopus journal blog,Authors:Title:Year:Source title:Volume:Issue:Art. No.:Page start:Page end:Page count:Cited by:DOI:Link:Affiliations:Authors with affiliations:Abstract:Author Keywords:Index Keywords:Correspondence Address:Editors:Publisher:ISSN:ISBN:CODEN:PubMed ID:Language of Original Document:Abbreviated Source Title:Document Type:Source:EID:,string:string:numeric:string:numeric:string:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:string:string:string:string:string:string:string:,
The Bachelor contestants , Brian Gonzalez , www.kaggle.com/brianbgonz/the-bachelor-contestants , Tue Mar 07 2017 06:28:52 GMT+0530 (IST) , Includes name age occupation hometown and week eliminated ,120, popular culture- ,Context I thought it might be neat to do some simple analytics on The Bachelor contestant data. Content Contestant info (incomplete) from seasons 1 2 5 9-21 of ABC's The Bachelor. Acknowledgements Pulled from Wikipedia and Reddit user u/nicolee314. Inspiration Are there any predictors for success on reality dating shows? Has the typical contestant changed over the years? Are certain qualities under/over-represented in these contestants?,Name:Age:Hometown:Height:Season:,string:numeric:string:string:numeric:,
2017 Iditarod Trail Sled Dog Race , Iditarod Trail Committee , www.kaggle.com/iditarod/iditarod-race , Wed Mar 22 2017 20:34:59 GMT+0530 (IST) , What strategy won the 1000 mile sled dog race across Alaska this year? ,59, sports- animals- ,Context The dog sled race covers 1000 miles of the roughest most beautiful terrain Mother Nature has to offer from Anchorage in south central Alaska to Nome on the western Bering Sea coast. She throws jagged mountain ranges frozen river dense forest desolate tundra and miles of windswept coast at the mushers and their dog teams. Add to that temperatures far below zero winds that can cause a complete loss of visibility the hazards of overflow long hours of darkness and treacherous climbs and side hills and you have the Iditarod — the Last Great Race on Earth! The race route is alternated every other year one year going north through Cripple Ruby and Galena and the next year south through Iditarod Shageluk Anvik. Content This dataset provides a record for mushers and dog teams at all seventeen checkpoints on the Iditarod trail including the musher's name and bib number status in the race country of origin checkpoint name and location distance in miles from the last checkpoint time in hours from departure at the last checkpoint average speed in miles per hour date and time of arrival and departure layover time at the checkpoint and the number of dogs at arrival and departure. Acknowledgements The data on mushers checkpoints and race standings was scraped from the Iditarod website. Inspiration Which competitor had the highest average speed during the race? Did race veterans outpace rookies on the trail? How did their strategies differ? Did the competitors' speed slow with less dogs on their team?,Number:Name:Status:Country:Checkpoint:Latitude:Longitude:Distance:Time:Speed:Arrival Date:Arrival Time:Arrival Dogs:Elapsed Time:Departure Date:Departure Time:Departure Dogs:,numeric:string:string:string:string:numeric:numeric:string:numeric:string:string:string:string:numeric:dateTime:dateTime:numeric:,
SF Historic Secured Property Tax Rolls , DataSF , www.kaggle.com/datasf/sf-historic-secured-property-tax-rolls , Sat Jan 07 2017 04:31:18 GMT+0530 (IST) , SF secured property tax roll spanning from 2007 to 2015 ,67, cities- finance- politics- ,Context This data set includes the Office of the Assessor-Recorder’s secured property tax roll spanning from 2007 to 2015 (~1.6M). It includes all legally disclosable information including location of property value of property the unique property identifier and specific property characteristics. The data is used to accurately and fairly appraise all taxable property in the City and County of San Francisco. The Office of the Assessor-Recorder makes no representation or warranty that the information provided is accurate and/or has no errors or omissions.  Potential question(s) to get started with!  Can the effects of Prop 13 been seen in the historic property tax rolls?  Fields There are 48 fields in this dataset.   A full data dictionary can be found here. We have included the following commonly used geographic shapefiles  Analysis Neighborhoods Supervisor Districts as of April 2012  Acknowledgements Data provided by the San Francisco Office of the Assessor-Recorder via the San Francisco Open Data Portal at https//data.sfgov.org/d/wv5m-vpq2 PDDL 1.0 ODC Public Domain Dedication and Licence (PDDL)  Photo from Flickr via Rebecca Morgan (CC BY-NC-SA 2.0),Closed Roll Fiscal Year:,numeric:,
Case Data from San Francisco 311 , DataSF , www.kaggle.com/datasf/case-data-from-san-francisco-311 , Sat Jan 14 2017 02:55:27 GMT+0530 (IST) , SF311 cases created since 7/1/2008 with location data ,106, crime- ,Context This San Francisco 311 dataset contains all 311 cases created since 7/1/2008 (~2M).  SF311 is a way for citizens to obtain information report problems or submit service requests to the City and County of San Francisco.   Potential question(s) to get started with!  What are some effective visualizations for conveying 311 incidences and trends? How do 311 requests vary by neighborhood? or source? Over time or seasonally? What attributes have the greatest effect on how long it takes a case to close? Is there a way to identify duplicative reports (when multiple people create a 311 report for the same incidence)?  Fields Please see DataSF's 311 Case Data FAQ here  CaseID - (Numeric) - The unique ID of the service request created. Opened - (Timestamp) - The date and time when the service request was made Closed - (Timestamp) - The date and time when the service request was closed Updated - (Timestamp) - The date and time when the service request was last modified. For requests with status=closed this will be the date the request was closed Status - (Text) - The current status of the service request. Status Notes - (Text) - Explanation of why status was changed to current state or more details on current status than conveyed with status alone Responsible Agency - (Text) - The agency responsible for fulfilling or otherwise addressing the service request. Category - (Text) - The Human readable name of the specific service request type Request Type - (Text) - More specific description of the problem related to the Category Request Details - (Text) - More specific description of the problem related to the Request Type Address - (Text) - Human readable address or description of location Supervisor District - (Numeric) - Supervisor District Neighborhood - (Text) - Neighborhood Point - (Geometry Point) - latitude and longitude using the (WGS84) projection. Source - (Text) - How the service request was made Media URL - (Text) - Url to media  We have included the following commonly used geographic shapefile(s)  Supervisor Districts as of April 2012 Neighborhoods  Acknowledgements Data provided by SF311 via the San Francisco Open Data Portal at https//data.sfgov.org/d/vw6y-z8j6 PDDL 1.0 ODC Public Domain Dedication and Licence (PDDL) Photo via Flickr Jeremy Brooks (CC BY-NC 2.0),CaseID:Opened:Closed:Updated:Status:Status Notes:Responsible Agency:Category:Request Type:Request Details:Address:Supervisor District:Neighborhood:Point:Source:Media URL:,numeric:dateTime:dateTime:dateTime:string:string:string:string:string:string:string:numeric:string:string:string:string:,
Norwegian Development Funds 2010-2015 , HenrikHeggland , www.kaggle.com/henrikheggland/norwegian-development-funds , Tue Nov 22 2016 07:48:03 GMT+0530 (IST) , Predict aid based on OECD markers ,77, finance- ,This data set gives you all funds given to development countries from Norway in the time period 2010-2015. The dataset includes OECD markers.  Some inspiration  Predict aid based on on OECD markers. Predict implementation partner based on the available features. ,,,
Executive Orders 1789-2016 , National Archives , www.kaggle.com/nationalarchives/executive-orders , Thu Feb 02 2017 09:14:49 GMT+0530 (IST) , Name years in office and executive orders signed by every American president ,290, history- politics- ,Content Executive orders are official documents numbered consecutively through which the President of the United States manages the operations of the federal government. The text of executive orders appears in the daily Federal Register as each executive order is signed by the President and received by the Office of the Federal Register. The total number of Executive orders issued by each administration includes number-and-letter designated orders such as 9577-A 9616-A etc. Acknowledgements The data was compiled and published by the National Archives as executive order disposition tables available for Franklin D. Roosevelt and later presidents.,President:Years:Executive Orders:Years in Office:Average Orders per Year:,string:numeric:numeric:numeric:numeric:,
Active Satellites in Orbit Around Earth , Union of Concerned Scientists , www.kaggle.com/ucsusa/active-satellites , Mon Jan 30 2017 20:10:25 GMT+0530 (IST) , Which country has the most satellites in orbit? What are they used for? ,197, space- ,Content The Satellite Database is a listing of active satellites currently in orbit around the Earth. The database includes basic information about the satellites and their orbits but does not contain the detailed information necessary to locate individual satellites. The information included in the database is publicly accessible and free and was collected from corporate scientific government military non-governmental and academic websites available to the public. No copyrighted material was used nor did we subscribe to any commercial databases for information. We have attempted to include all currently active satellites. However satellites are constantly being launched decommissioned or simply abandoned and the list may inadvertently contain some satellites that are no longer active but for which we have not yet received information. Acknowledgements The Satellite Database is produced and updated quarterly by Teri Grimwood.,Official Name of Satellite:Country/Organization of UN Registry:Operator/Owner:Country of Operator/Owner:Users:Purpose:Detailed Purpose:Class of Orbit:Type of Orbit:Longitude of Geosynchronous Orbit (Degrees):Perigee (Kilometers):Apogee (Kilometers):Eccentricity:Inclination (Degrees):Period (Minutes):Launch Mass (Kilograms):Dry Mass (Kilograms):Power (Watts):Date of Launch:Expected Lifetime (Years):Contractor:Country of Contractor:Launch Site:Launch Vehicle:COSPAR Number:NORAD Number:,string:string:string:string:string:string:string:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:dateTime:numeric:string:string:string:string:string:numeric:,
Israeli Settlements in the West Bank , Central Bureau of Statistics , www.kaggle.com/ilcbs/israeli-settlements , Fri Feb 03 2017 20:30:12 GMT+0530 (IST) , Is the population of Israeli settlements rising or falling? ,133, politics- ,Content This dataset includes a record for each Israeli neighborhood in East Jerusalem and settlement in the West Bank recognized by Israeli authorities; therefore Israeli outposts constructed without government authorization and Nahal settlements established by Israel Defense Forces and thus regarded as military bases are excluded. Each row includes the settlement name in English and Hebrew year established regional council location in latitude/longitude coordinates and relative to the West Bank Barrier and population estimates for the past fifteen years. Acknowledgements The settlement population statistics were collected by the Israel Central Bureau of Statistics.,Name:Hebrew Name:Year Established:Regional Council:Latitude:Longitude:West Bank Barrier:2015 Population:2010 Population:2005 Population:2000 Population:,string:string:numeric:string:numeric:numeric:string:numeric:numeric:numeric:numeric:,
Toxic Armories , Anton Prokopyev , www.kaggle.com/prokopyev/armories , Tue Feb 21 2017 06:15:26 GMT+0530 (IST) , Data from The Oregonian's investigation ,119, environment- military- ,Context According to The Oregonian hundreds of National Guard armories across the U.S. may have been contaminated with lead from indoor firing ranges. It was reported that areas populated by children under 7 years of age should have less than 40 micrograms of lead per square foot.  Content The Oregonian collected over 23000 pages of public records following a Freedom Of Information Act request.  The dataset covers armory inspections conducted since 2012 and may facilitate investigation of lead contamination in the U.S. Acknowledgements The data assembly process is described by Melissa Lewis here. Inspiration This dataset can be used to conduct research in the realm of public health. It will be especially useful if  1) you know about health effects of exposure to lead in relatively short terms periods; 2) you are able to find relevant health data to conduct a study on lead poisoning.,Oregonian ID:Site Name:Address:City:State:Lat:Long:Inspection conducted?:Inspection report available?:Inspection year:Lead present?:Earlier lead discovery reported:Highest lead level detected (ug):Where highest lead level detected?:Lead present outside range?:Notes:Had firing range?:Firing range use:Additional details:,numeric:string:string:string:string:numeric:numeric:string:string:numeric:string:string:numeric:string:string:string:string:string:string:,
Welfare Error Rates , BrandtCowan , www.kaggle.com/brandtcowan/govtassistpayerrors , Sat Feb 04 2017 00:46:54 GMT+0530 (IST) , Unemployment Error and Fraud / SNAP Payment Errors ,75, finance- politics- ,Context Data related to estimated fraud or payment errors for unemployment and food assistance used in discussion about alleged widespread fraud and abuse of welfare. Content Data pulled from Gov't Websites on February 3rd 2017. SNAP rates come from https//www.fns.usda.gov/sites/default/files/snap/2014-rates.pdf UI Error data comes from  https//www.dol.gov/general/maps/data > > >  2016 IPIA 1-year data [07/01/2015 - 06/30/2016] >> tab Integrity Rates with CI Inspiration Want to plot this against election results or possibly find polling data about alleged abuse of welfare system to match against actual findings,ST:Error:,string:string:,
Disputed Territories and Wars 1816-2001 , University of North Texas , www.kaggle.com/unt/disputed-territories , Thu Feb 02 2017 07:16:23 GMT+0530 (IST) , What territory claimed by two or more countries has caused the most violence? ,96, oceans- international relations- ,Content This dataset contains territorial claims across the entire interstate system between 1816-2001 and includes information on participants dates the significance of the claimed territories and militarization of these claims. A territorial claim is defined as explicit contention between two or more nation-states claiming sovereignty over a specific piece of territory. Official government representatives (i.e. individuals who are authorized to make or state foreign policy positions for their governments) must make explicit statements claiming sovereignty over the same territory. Our goal is to identify cases where nation-states have disagreed over specific issues in the modern era as well as measuring what made those issues valuable to them and studying how they chose to manage or settle those issues. The Issue Correlates of War (ICOW) project does not endorse official positions on any territorial claim. Inclusion/exclusion of specific cases and coding of details related to those cases follows strict guidelines presented in the project's coding manuals. Acknowledgements This data was collected by Professor Paul Hensel of the University of North Texas and his research assistants.,state_code:state_name:,numeric:string:,
Classified Ads for Cars , Miroslav Zoricak , www.kaggle.com/mirosval/personal-cars-classifieds , Fri Mar 17 2017 03:03:43 GMT+0530 (IST) , Used cars for sale in Germany and Czech Republic since 2015 ,755, automobiles- ,Context The data was scraped from several websites in Czech Republic and Germany over a period of more than a year. Originally I wanted to build a model for estimating whether a car is a good buy or a bad buy based on the posting. But I was unable to create a model I could be satisfied with and now have no use for this data. I'm a great believer in open data so here goes. Content The scrapers were tuned slowly over the course of the year and some of the sources were completely unstructured so as a result the data is dirty there are missing values and some values are very obviously wrong (e.g. phone numbers scraped as mileage etc.) There are roughly 35 Million rows and the following columns  maker - normalized all lowercase model - normalized all lowercase mileage - in KM manufacture_year engine_displacement - in ccm engine_power - in kW body_type - almost never present but I scraped only personal cars no motorcycles or utility vehicles color_slug - also almost never present stk_year - year of the last emission control transmission - automatic or manual door_count seat_count fuel_type - gasoline diesel cng lpg electric date_created - when the ad was scraped date_last_seen - when the ad was last seen. Our policy was to remove all ads older than 60 days price_eur - list price converted to EUR  Inspiration  Which factors determine the price of a car? With what accuracy can the price be predicted? Can a model trained on all cars be used to accurately predict prices of models with only a few samples?  In my analysis there is too much variance even within individual models to reliably predict the price can you prove me wrong? I would love to understand what I did wrong if you can.,model:mileage:manufacture_year:engine_displacement:engine_power:body_type:color_slug:stk_year:transmission:door_count:seat_count:fuel_type:date_created:date_last_seen:price_eur:maker:,string:numeric:numeric:numeric:numeric:string:string:string:string:numeric:numeric:string:dateTime:dateTime:numeric:string:,
Linux Gamers Survey Q1 2016 , Ekianjo , www.kaggle.com/sanqualis/linuxgamerssurvey , Thu Feb 02 2017 08:35:08 GMT+0530 (IST) , Who are Linux gamers and what do they want? ,118, video games- sociology- computing and society- ,Context The following is the results of an online survey conducted by BoilingSteam.com among the Linux Gamers' Community (n=560 sharing only here answers where respondents explicitly agreed to have their answers made public i.e. total n size was higher) in end of Q1 2016 to better understand their hardware usage habits and reactions to several of Valve's Steam Initiatives. Most of the answers are coming from members of the r/Linux_Gaming and r/Linux subreddits so you need to take in account that this may not be representative of your typical Linux user.   Content There are many variables in this data set with both numerical free text and categorical answers. Every line corresponds to an individual response. Note that answers are anonymous. The first row is the coding you can use for your analysis (that should save a bit of time) the second row is the actual question asked (you can erase it) and the data starts from the third row.  Questions cover some of the following attributes (there are much more in the actual datasheet)  Demographics / Geography Family Situation OS used for Work and at Home Linux Usage experience Linux Gaming Experience Type of Gamer (Hardcore or not) Playing Exclusively on Linux or not Time spent Playing per week Budget spent on Linux Games per month Games played recently Games Bought recently Hardware GPU for Gaming Hardware GPU Model General Hardware at Home using Linux Usage of Resellers (Steam GOG HumbleBundle) Satisfaction of different Resellers Awareness of Steam Machines Awareness of Steam Controller Steam Link Intent of Purchase of Steam Machines Intent of Building Steam Machine DIY SteamOS and opinion towards it General feeling towards future of Linux  Stance about DRM Stance about WINE WINE usage and satisfaction and much more...  Acknowledgements The questionnaire was designed by Ekianjo at BoilingSteam.com. If you have suggestions for improvements of future surveys of the same kind please reach us on Kaggle or on our contact page http//boilingsteam.com/about-boiling-steam/ Past Research You can see some analysis done a previous iteration of this survey (previous data can not be made public however) - this may serve as a good benchmark to measure changes http//boilingsteam.com/the-three-kinds-of-linux-gamers/ Inspiration Feel free to play with the data and share what insights you may find. We are big proponents of making data free in general for transparency purposes so if your analysis can help generate a better understanding of who are Linux Gamers this would be a great outcome. ,Time:Geography:Age:Gender:FamilySituation:DesktopOS:LinuxHardware:WorkOS:LinuxUserHowLong:LinuxUsageWhy:LinuxStayWhy:DesktopLinuxGamerHowLong:DesktopLinuxGamerWhy:HeavyGamer:DevicesForGames:GamesPlayedRecently:MainDeviceLinuxGaming:LinuxExclusivity:LinuxExclusiveGamesExamples:LinuxGamingHabitChange:LinuxGamingHabitChangeComment:LinuxGamingHabitFuture:LinuxGamingMachineShared:FolksAroundYouAwareLinux:LinuxGamesPurchaseFrequency:LinuxGamesResellersEverUsed:LinuxGamesResellersUsedLastMonth:LinuxGamesBoughtRecently:LinuxGamesMainReseller:DRMStance:SatisfactionSteam:SatisfactionGOG:SatisfactionHB:SatisfactionComment:LinuxGamingDistro:DistroChangeFrequency:DistroImpactPerformance:LinuxGamingMainGPU:LinuxGamingMainGPUModel:HardwareUpgradeIntent:HardwareUpgradeIntentGame:AwarenessBrandedSteamMachines:AwarenessSteamController:AwarenessSteamLink:SteamMachinesConceptLike:SteamMachinesExpandLinuxGaming:SteamMachinesLaunchEvaluation:SteamMachinesAwarenessAlienware:SteamMachinesAwarenessZotac:SteamMachinesAwarenessSyber:SteamMachinesWantToBuy:SteamMachinesMaximumPrice:SteamMachinesPurchasedWhy:SteamMachinesDIYIntent:SteamControllerPurchaseIntent:SteamControllerLike:SteamOSEverTried:SteamOSEverTriedComment:SteamIHSUsage:SteamLinkPurchaseIntent:SteamLinkComment:WINEUsageVanilla:WINEUsagePlayOnLinux:WINEUsageCrossover:WINEEvaluation:WINEStance:LeastEvil:LinuxGamingNewsSources:LinuxGamingWebsites:LinuxGamingHoursPerWeek:LinuxGamingSpendingPerMonth:LinuxGamingWebsitesOpinion:ShareAnswersPublicly:,dateTime:string:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:numeric:string:string:,
2017 #Oscars Tweets , Madhur Inani , www.kaggle.com/madhurinani/oscars-2017-tweets , Sat Mar 18 2017 01:20:40 GMT+0530 (IST) , 29000+ tweets about the 2017 Academy Awards ,187, film- linguistics- internet- ,Hi I have extracted the Tweets related to Oscar 2017.  The timeframe is from Feb 27th2017 to March 2nd2017. The number ofTweets is 29498.  The whole idea of extraction to know how people reacted in general about Oscars and also after the Best Picture mix up. ,Twitter Search Rule: #oscars::User Details:,dateTime:string:numeric:,
SciRate quant-ph , Peter Wittek , www.kaggle.com/peterwittek/scirate-quant-ph , Mon Feb 13 2017 14:12:11 GMT+0530 (IST) , Papers published in arXiv/quant-ph between 2012-2016 with number of Scites ,109, research- physics- linguistics- ,Context I was curious about the hot topics in quantum physics as reflected by the quant-ph category on arXiv. Citation counts have a long lag and so do journal publications and I wanted a more immediate measure of interest. SciRate is fairly well known in this community and I noticed that after the initial two-three weeks the number of Scites a paper gets hardly increases further. So the number of Scites is both immediate and near constant after a short while.  Content The main dataset (scirate_quant-ph.csv) is the metadata of all papers published in quant-ph between 2012-01-01 and 2016-12-31 that had at least ten Scites as crawled on 2016-12-31. It has six columns  The id column as exported by pandas. The arXiv id. The year of publication. The month of publication. The day of publication. The number of Scites (this column defines the order). The title. All authors separates by a semicolon. The abstract.  The author names were subjected to normalization and the chances are high that the same author only appears with a unique name. The name normalization was the difficult part in compiling this collection and this is why the number of Scites was lower bounded. A second file (scirate_quant-ph_unnormalized.csv) includes all papers that appeared between 2012-2016 irrespective of the number of Scites but the author names are not normalized. The actual number of Scites for each paper may show a slight variation between the two datasets because the unnormalized version was compiled more than a month later. Acknowledgements Many thanks to SciRate for tolerating my crawling trials and not blacklisting my IP address. Inspiration Unleash topic models and author analysis to find out what or who is hot in quantum physics today. Build a generative model to write trendy fake titles like SnarXiv does it for hep-th.,:,numeric:,
The Bachelor & Bachelorette Contestants , Brian Gonzalez , www.kaggle.com/brianbgonz/the-bachelorette-contestants , Wed Mar 08 2017 22:01:02 GMT+0530 (IST) , Includes name age occupation hometown and week eliminated ,216, popular culture- ,Context I thought it might be neat to do some simple analytics on The Bachelor/The Bachelorette contestant data. Content Contestant info from seasons 1 2 5 9-21 of ABC's The Bachelor and 1-12 of The Bachelorette -- very incomplete. Acknowledgements I just compiled this from Wikipedia. Some data on The Bachelor contestants comes from Reddit user u/nicolee314. Inspiration Are there any predictors for success on reality dating shows? Has the typical contestant changed over the years? Are certain qualities under/over-represented in these contestants?,Name:Age:Occupation:Hometown:Height:ElimWeek:Season:,string:numeric:string:string:string:numeric:numeric:,
Ofcom UK Broadband Speed 2016 Open dataset , mariakatosvich , www.kaggle.com/qwikfix/uk-broadband-speeds-2016 , Mon Aug 29 2016 13:05:35 GMT+0530 (IST) , Annual reports on UK's fixed broadband speed 2016 - An Open Dataset ,264, networks- ,Ofcom annual reports on the UK’s fixed broadband mobile and WiFi networks digital television digital radio and internet infrastructure. Ofcom gathers data from the main fixed broadband Internet Service Providers (BT KCOM Sky TalkTalk and Virgin Media) on both their retail services and the services they provide to other ISPs as a wholesale service. More information can be found here. GLA connectivity map shows a summary version of the download speed data. Next generation broadband map - https//maps.london.gov.uk/webmaps/nextgenbroadband/,,,
British Queen's Oversea Visits , LiLi , www.kaggle.com/lorcha/queenvisits , Mon Mar 13 2017 13:38:29 GMT+0530 (IST) , OD datasets for British Queen's oversea visits ,45, princesses- international relations- ,Context This dataset is for showing how to visualize OD datasets Content This dataset contains all the cities where the british queen has visited in her lifetime.  Acknowledgements The dataset is obtained from the internet.  Past Research No Inspiration Showing OD dataset is very fun.,FID:date_stamp:Dates:year:visit_type:country:map_locati:yes_if_dup:FID_:QueenID:date_sta_1:visiting_j:visited:x:y:lon:POINT_X:POINT_Y:,numeric:dateTime:string:numeric:string:string:string:string:numeric:numeric:dateTime:string:string:numeric:numeric:numeric:numeric:numeric:,
Harvard Course Enrollments Fall 2015 , Harvard University , www.kaggle.com/harvard-university/course-enrollment-stats , Sun Nov 13 2016 00:48:54 GMT+0530 (IST) , Enrollment numbers for every Harvard course offered in Fall Term 2015 ,241, education- ,"This dataset contains enrollment numbers for every course offered at Harvard during Fall Term 2015. The Data The course enrollment data contains the following fields  COURSE the course name (consists of the department/program abbreviation and a course number/letter; the abbreviation and the number/letter are separated by a space) DEPARTMENT the abbreviation for this course's department COURSEID a unique identifier for the course CLASSNBR another unique identifier for the course? TOTALENROLLMENT total number of students enrolled from every school GSAS number of students enrolled from the Graduate School of Arts and Sciences HCOL number of students enrolled from Harvard College (undergraduate) NONDGR number of non-degree-seeking students enrolled VUS number of students enrolled from the Visiting Undergraduate Students Program XREG number of students from other universities who are cross-registered in the course  Note that there is also a row whose COURSE value is TOTALS and whose DEPARTMENT COURSEID and CLASSNBR values are empty. This row lists the total number of students from each school (GSAS HCOL etc) in all of the courses. For more info on what each of the courses is check out the Harvard Course Catalog. Acknowledgments All of the data in this dataset comes from The Harvard Open Data Dataverse. The specific citation is Mehta Neel 2016 ""Course enrollment stats"" doi10.7910/DVN/9MWTYO Harvard Dataverse V1 [UNF6PA8A+2yr3nGT9I9XGhWeIg==]",COURSE:DEPARTMENT:COURSEID:CLASSNBR:TOTALENROLLMENT:GSAS:HCOL:NONDGR:VUS:XREG:,string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Ultimate Beastmaster: First Season , Kande Bonfim , www.kaggle.com/kandebonfim/ultimate-beastmaster , Mon Mar 06 2017 20:44:55 GMT+0530 (IST) , All the competitors and performances ,58, popular culture- music- ,Context I like to compensate my frustration with sports analyzing sports data so I put together every data I could from the first season of this Netflix series and here we are.,name:flag:age:job:country:result:episode:firstName:gender:points:,string:string:numeric:string:string:string:numeric:string:string:numeric:,
Farmers Markets in New York City , NYC Open Data , www.kaggle.com/nycopendata/farmers-markets , Tue Jan 24 2017 22:55:23 GMT+0530 (IST) , How do population demographics impact the location of farmers markets? ,240, food and drink- demographics- agriculture- ,Context The non-profit organization GrowNYC operates a network of 50+ Greenmarkets and 15 Youthmarkets throughout the city including the flagship Union Square Greenmarket to ensure that all New Yorkers have access to the freshest healthiest local food. Acknowledgements The farmers market directory was published by the NYC Department of Health and Mental Hygiene and the population statistics were provided by the US Census Bureau's 2015 American Community Survey.,Statistic:NYC Estimate:NYC Percent:Bronx Estimate:Bronx Percent:Brooklyn Estimate:Brooklyn Percent:Manhattan Estimate:Manhattan Percent:Queens Estimate:Queens Percent:Staten Island Estimate:Staten Island Percent:,string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:numeric:string:,
Vehicle and Tire Recalls 1967-Present , NHTSA , www.kaggle.com/nhtsa/safety-recalls , Tue Feb 07 2017 20:35:55 GMT+0530 (IST) , What manufacturer has recalled the most vehicles in the past fifty years? ,190, automobiles- ,Context The National Traffic and Motor Vehicle Safety Act (1966) gives the Department of Transportation’s National Highway Traffic Safety Administration (NHTSA) the authority to issue vehicle safety standards and to require manufacturers to recall vehicles that have safety-related defects or do not meet federal safety standards. More than 390 million cars trucks buses recreational vehicles motorcycles and mopeds 46 million tires 66 million pieces of motor vehicle equipment and 42 million child safety seats have been recalled to correct safety defects since 1967. Manufacturers voluntarily initiate many of these recalls while others are influenced by NHTSA investigations or ordered by NHTSA via the courts. If a safety defect is discovered the manufacturer must notify NHTSA vehicle or equipment owners dealers and distributors. The manufacturer is then required to remedy the problem at no charge to the owner. NHTSA is responsible for monitoring the manufacturer’s corrective action to ensure successful completion of the recall campaign. Acknowledgements This dataset was compiled and published by the NHTSA's Office of Defects Investigation (ODI).,Record ID:NHTSA Campaign:Manufacturer Campaign:Vehicle Make:Vehicle Model:Model Year:Vehicle Manufacturer:Recall Type:Recall Component:Manufacture Start Date:Manufacture End Date:Estimated Units:Recall Initiative:Recall Manufacturer:Recall Notification Date:,numeric:string:string:string:string:numeric:string:string:string:numeric:numeric:numeric:string:string:numeric:,
2016 Advanced Placement Exam Scores , College Board , www.kaggle.com/collegeboard/ap-scores , Fri Feb 03 2017 04:00:27 GMT+0530 (IST) , What is the relationship between student demographics and exam subjects/scores? ,569, education- ,Content The Advanced Placement Exam scores for the class of 2016 highlighted in this dataset show that students continue to demonstrate college-level skills and knowledge in increasing numbers. Even as AP teachers deliver rigor to an ever-diversifying population of students participation and performance continue to improve. Behind and within these data are the daily sacrifices of AP students and teachers including the late nights that students put in diligently studying and the weekends that teachers give up to help their students succeed. Their hard work and effort are worth celebrating. Acknowledgements This data was collected and released by the College Board after the May 2016 exam administration.,Exam Subject:Score:Students (11th Grade):Students (12th Grade):Students (Male):Students (Female):Students (White):Students (Black):Students (Hispanic/Latino):Students (Asian):Students (American Indian/Alaska Native):Students (Native Hawaiian/Pacific Islander):Students (Two or More Races):All Students (2016):,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:,
Build Bridges Not Walls , Brian Roach , www.kaggle.com/broach/build-bridges-not-walls , Sun Feb 12 2017 03:32:15 GMT+0530 (IST) , Data describing 600k bridges from the United States National Bridge Inventory ,101, transport- ,The United State Federal Highway Administration (FHWA) collects and updates information on the nation's bridges that are located on public roads including both interstate and US highways state and county roads and publicly accessible bridges on federal land.  This collection of information is known as the National Bridge Inventory (NBI) and it has been captured electronically since 1972.  While parts of the data were first made available to the public in 1997 it wasn't until 2007 that the FWHA decided to make all elements of the NBI database publicly available. This NBI data set contains 135 variables describing over 600000 bridges.  Variables describe the location structure maintenance usage status and other aspects of the bridges.  An extremely detailed (124 page) pdf guide to the variables codes and other metadata on the NBI can be found here https//www.fhwa.dot.gov/bridge/mtguide.pdf Acknowledgements The Department of Transportation FHWA collects and provides the NBI data as authorized by statue 23 U.S.C. 151 This data set was downloaded from the Homeland Infrastructure Foundation here https//hifld-dhs-gii.opendata.arcgis.com/datasets/94c41e96db0d4b85b9eb622923e0a0e8_0 Inspiration This data set contains variables describing the cost of bridge (ITEM94) and roadway (ITEM95) improvement in thousands of dollars.  How many improvement projects could be completed for $20B? Use of the NBI data also enables FHWA to satisfy its requirements under 23 U.S.C. 144 which mandate the inventory classification cost estimates for replacement or rehabilitation and assignment of replacement or rehabilitation priorities for all highway bridges on all public roads.  Can you come up with better cost estimates and classifications?  For example in the absence of additional information FHWA recommends using 10% of the bridge cost as a roadway improvement cost estimator. Using Latitude and Longitude data and operational status (ITEM41) can you find any bridges to nowhere?,X:Y:FID:STFIPS:REGION:ITEM8:ITEM5A:ITEM5B:ITEM5C:ITEM5D:ITEM5E:ITEM2:ITEM3:ITEM4:ITEM6A:ITEM6B:ITEM7:ITEM9:ITEM10:ITEM11:ITEM12:ITEM13A:ITEM13B:ITEM16:ITEM17:ITEM19:ITEM20:ITEM21:ITEM22:ITEM26:ITEM27:ITEM28A:ITEM28B:ITEM29:ITEM30:ITEM31:ITEM32:ITEM33:ITEM34:ITEM35:ITEM36A:ITEM36B:ITEM36C:ITEM36D:ITEM37:ITEM38:ITEM39:ITEM40:ITEM41:ITEM42A:ITEM42B:ITEM43A:ITEM43B:ITEM44A:ITEM44B:ITEM45:ITEM46:ITEM47:ITEM48:ITEM49:ITEM50A:ITEM50B:ITEM51:ITEM52:ITEM53:ITEM54A:ITEM54B:ITEM55A:ITEM55B:ITEM56:ITEM58:ITEM59:ITEM60:ITEM61:ITEM62:ITEM63:ITEM64:ITEM65:ITEM66:ITEM67:ITEM68:ITEM69:ITEM70:ITEM71:ITEM72:ITEM75A:ITEM75B:ITEM76:ITEM90:ITEM91:ITEM92A:ITEM92B:ITEM92C:ITEM93A:ITEM93B:ITEM93C:ITEM94:ITEM95:ITEM96:ITEM97:ITEM98A:ITEM98B:ITEM99:ITEM100:ITEM101:ITEM102:ITEM103:ITEM104:ITEM105:ITEM106:ITEM107:ITEM108A:ITEM108B:ITEM108C:ITEM109:ITEM110:ITEM111:ITEM112:ITEM113:ITEM114:ITEM115:ITEM116:FUNDED:FEDERAL:WO:DT:WO_2:STAT:SR1:SR2:EXTRA:STATUS:DATE:LONGDD:LATDD:,numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:string:string:string:numeric:numeric:numeric:numeric:numeric:string:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:numeric:numeric:string:string:numeric:numeric:numeric:string:string:string:string:string:string:string:string:string:string:string:string:string:numeric:string:numeric:string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:numeric:string:string:numeric:numeric:numeric:numeric:string:string:string:string:string:numeric:string:numeric:numeric:string:numeric:numeric:numeric:,
Executive Orders , BrandtCowan , www.kaggle.com/brandtcowan/executiveorders , Fri Feb 17 2017 09:19:21 GMT+0530 (IST) , Since Ronald Reagan with dates and titles ,112, politics- ,"Context With the events unfolding within the new administration I was curious if any President had been this active this early. I set out in search of a data set for executive orders but didn't have a whole lot of easy success. pulling from the American Presidency Project (which doesn't really make pulling mass amounts of data easy with my skill level) and adding ""memorandums"" from wikipedia I compiled this CSV to analyze and share. If anyone has datasets including full text of executive orders that would be fun to dive into! Content The data attached has the president's name date signed executive order id and title. Acknowledgements Data pulled from The American Presidency Project  http//www.presidency.ucsb.edu/executive_orders.php?year=2017&Submit=DISPLAY and wikipedia Cabinet confirmations pulled from https//www.senate.gov/reference/resources/pdf/cabinettable.pdf and wikipedia Inspiration One last thing I'd like to have added to this data set classification! Would be nice to analyze topics. Which president had more orders concering economy? Gov't? War? International relations?",Position:President:fname:lname:annMon:annDay:annYear:SenMon:SenDay:SenYear:ConMon:conDay:ConYear:vote:,string:string:string:string:string:numeric:numeric:string:numeric:numeric:string:numeric:numeric:string:,
SF Restaurant Inspection Scores , DataSF , www.kaggle.com/datasf/sf-restaurant-inspection-scores , Sat Jan 07 2017 04:33:20 GMT+0530 (IST) , SF Health Department records for restaurant inspections ,302, food and drink- ,Context The SF Health Department has developed an inspection report and scoring system. After conducting an inspection of the facility the Health Inspector calculates a score based on the violations observed. Violations can fall intohigh risk category records specific violations that directly relate to the transmission of food borne illnesses the adulteration of food products and the contamination of food-contact surfaces.moderate risk category records specific violations that are of a moderate risk to the public health and safety.low risk category records violations that are low risk or have no immediate risk to the public health and safety.The score card that will be issued by the inspector is maintained at the food establishment and is available to the public in this dataset. Potential question(s) to get started with!  What are some predictors of health scores?  What relevant outside data can you bring to bear on the question including restaurant reviews sentiment analysis demographic data etc?  Fields San Francisco's LIVES restaurant inspection data leverages the LIVES Flattened Schema (https//goo.gl/c3nNvr) which is based on LIVES version 2.0 cited on Yelp's website (http//www.yelp.com/healthscores).   Please refer to https//goo.gl/c3nNvr for detailed data dictionary.   Further info on the Food Safety Program can be found here. We have included the following commonly used geographic shapefiles  Analysis Neighborhoods Supervisor Districts as of April 2012  Acknowledgements Data provided by the San Francisco Health Department via the San Francisco Open Data Portal at https//data.sfgov.org/d/pyih-qa8i License PDDL 1.0 ODC Public Domain Dedication and Licence (PDDL)  Photo via Flickr Rob Hyndman Attribution-NonCommercial-ShareAlike 2.0 Generic (CC BY-NC-SA 2.0),business_id:business_name:business_address:business_city:business_state:business_postal_code:business_latitude:business_longitude:business_location:business_phone_number:inspection_id:inspection_date:inspection_score:inspection_type:violation_id:violation_description:risk_category:,numeric:string:string:string:string:numeric:numeric:numeric:string:numeric:string:dateTime:numeric:string:string:string:string:,
Presidential Cabinet Nominations , US Senate , www.kaggle.com/senate/confirmation-votes , Tue Feb 07 2017 23:05:26 GMT+0530 (IST) , Senate confirmation vote records for cabinet nominees since 1976 ,51, politics- ,"Context The United States Constitution provides that the president ""shall nominate and by and with the Advice and Consent of the Senate shall appoint Ambassadors other public Ministers and Consuls Judges of the Supreme Court and all other Officers of the United States whose Appointments are not herein otherwise provided for..."" (Article II section 2). This provision like many others in the Constitution was born of compromise and over the more than two centuries since its adoption has inspired widely varying interpretations. The president nominates all federal judges in the judicial branch and specified officers in cabinet-level departments independent agencies the military services the Foreign Service and uniformed civilian services as well as U.S. attorneys and U.S. marshals. The importance of the position the qualifications of the nominee and the prevailing political climate influence the character of the Senate's response to each nomination. Views of the Senate's role range from a narrow construction that the Senate is obligated to confirm unless the nominee is manifestly lacking in character and competence to a broad interpretation that accords the Senate power to reject for any reason a majority of its members deems appropriate. Just as the president is not required to explain why he selected a particular nominee neither is the Senate obligated to give reasons for rejecting a nominee. Acknowledgements The confirmation vote records were recorded compiled and published by the Office of the Secretary of the Senate.",Position:President:Nominee:Announced:Received:Withdrawn:Confirmed:Rejected:Vote Type:Votes For:Votes Against:,string:string:string:dateTime:dateTime:string:dateTime:string:string:numeric:numeric:,
Christmas Tweets , DhruvMangtani , www.kaggle.com/dhruvm/christmastwitterdata , Mon Dec 26 2016 00:28:34 GMT+0530 (IST) , 50000 scraped tweet metadata from this 2k16 Christmas ,252, religious faiths traditions and movements- internet- ,Context This dataset contains the metadata of over 50000 tweets from Christmas Eve and Christmas. We are hoping the data science and research community can use this to develop new and informative conclusions about this holiday season. Content We acquired this data through a web crawler written in Java. The first field is the id of the tweet and the second is the HTML metadata. We recommend using BeautifulSoup or another library to parse this data and extract information from each tweet. Inspiration We would especially like to see research on the use of emojis in tweets the type of sentiment there is on Christmas (Maybe determine how grateful each country is) or some kind of demographic on the age or nationality of active Twitter users during Christmas.,ID: Metadata:,numeric:string:,
Presidential Pardons 1900-2017 , Department of Justice , www.kaggle.com/doj/presidential-pardons , Fri Jan 20 2017 08:30:25 GMT+0530 (IST) , Petitions for executive clemency granted and denied by American presidents ,184, ,Context On April 23 2014 the Department of Justice at the behest of President Obama announced the Clemency Initiative inviting petitions for commutation of sentence from nonviolent offenders who among other criteria likely would have received substantially lower sentences if convicted of the same offenses today. As expected the announcement resulted in a record number of petitions – including thousands of petitions involving crimes not included in the initiative such as terrorism murder sex crimes public corruption and financial fraud. In the federal system commutation of sentence and pardon are different forms of executive clemency which is a broad term that applies to the President’s constitutional power to exercise leniency toward persons who have committed federal crimes. A commutation of sentence reduces a sentence either totally or partially that is then being served but it does not change the conviction signify innocence or remove civil disabilities from the criminal conviction. A commutation may include remission (or release) of the financial obligations that are imposed as part of a sentence such as payment of a fine or restitution; a remission applies only to the part of the financial obligation that has not already been paid. To be eligible to apply for commutation of sentence a person must have reported to prison to begin serving his sentence and may not be challenging his conviction in the courts. A pardon is an expression of the President’s forgiveness and is granted in recognition of the applicant’s acceptance of responsibility for the crime and established good conduct for a significant period of time after conviction or completion of sentence. It does not signify innocence. It does however remove civil disabilities – such as restrictions on the right to vote hold state or local office or sit on a jury – imposed because of the conviction. A person is not eligible to apply for a presidential pardon until a minimum of five years has elapsed since his release from any form of confinement imposed upon him as part of a sentence for his most recent criminal conviction. Acknowledgements The data was compiled and published by the Office of the Pardon Attorney. The Office of the Pardon Attorney receives and reviews petitions for all forms of executive clemency including pardon commutation (reduction) of sentence remission of fine or restitution and reprieve initiates the necessary investigations of clemency requests and prepares the report and recommendation of the Attorney General to the President.,President:Fiscal Year:Petitions Pending:Petitions Received:Petitions Granted:Pardons:Commutations:Respites:Remissions:Petitions Denied:Petitions Closed Without Presidential Action:Petitions Denied or Closed Without Presidential Action:,string:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:numeric:string:,
2014 World Cup Forecasts and Scores , FiveThirtyEight , www.kaggle.com/fivethirtyeight/world-cup , Thu Jan 26 2017 08:10:14 GMT+0530 (IST) , How well did FiveThirtyEight's algorithm predict match scores? ,211, association football- ,Content FiveThirtyEight’s World Cup forecasting model used ESPN’s Soccer Power Index (SPI) — a system that combines game and player ratings to estimate a team’s overall skill level — to calculate odds of each country’s performance during the two stages of the World Cup. The probabilities based on 10000 simulations were updated at the end of each match and aggregated into one file with the prediction date and time. Acknowledgements The 2014 prediction data was featured in the FiveThirtyEight article It's Brazil's World Cup to Lose and the interactive infographic 2014 World Cup Predictions. The World Cup match scores were scraped from the FIFA archive.,,,
Inside Crown Awards Policy , ushchent , www.kaggle.com/ushchent/uk-awards , Sat Jan 21 2017 17:45:39 GMT+0530 (IST) , Investigating the UK honours ,36, politics- ,"Context Many nations have their honours systems and many outstanding people receive awards every year. The research on this data is part of the project ""Awards policy"" - an multinational database of outstanding people who received various state or non-state awards and of the awards themselves. Content The dataset contains aggregated data about UK honours and the people who received them from 2008 to January 2017 - 20 493 records in total. So far only data from two honours lists has been included the Queen's Birthday List and the New Year's List. After some PDF-parsing other data may be added.  The fields in the dataset are  list (type of the honours list) year (year of the release) order (which order the honour belongs to) level (abbreviation) award (the award) name (full name of the honoured person) citation (additional info about the honoured person) county (person's residence)  Acknowledgements The data comes from the CSVs found at the wonderful Gov.uk website and is available under the Open Government Licence v3.0. Inspiration Although this data is expected to be used mostly as a reference (e.g. looking up particular people) statistical analysis may be insightful for studying social structures. So here some questions to ask  Are there any social groups (or people) in the UK that regularly receive honours from the Crown? And are any being neglected? Are there any geographical peculiarities of the award policy? (geocoding needed) Are there any remarkable changes in the awards policy over the given period (because of financial crisis Brexit ...)? ... ",:list:year:order:level:award:name:citation:county:,string:string:numeric:string:string:string:string:string:string:,
Water Conservation Supplier Compliance , California Environmental Protection Agency , www.kaggle.com/calepa/water-conservation-supplier-compliance , Thu Nov 17 2016 05:37:34 GMT+0530 (IST) , Reporting compliance by water suppliers in drought-stricken California ,189, ecology- agriculture- ,Context California has been dealing with the effects of an unprecedented drought. September 2016 marks the 16th month since the state’s 400-plus urban water suppliers were directed to be in compliance with the emergency conservation standards that followed the Governor’s April 1 2015 Executive Order. The State Water Board has been requiring water delivery information from urban water suppliers for 28 consecutive months following the historic July 2014 board action to adopt emergency water conservation regulations. On May 18 following the Governor’s May 9 Executive Order the Board adopted a statewide water conservation approach that replaces the prior percentage reduction-based water conservation standard with a localized “stress test” approach that mandates urban water suppliers act now to ensure at least a three-year supply of water to their customers under drought conditions. Content This fact sheet contains more details on how water conservation is monitored by the California EPA. This dataset describes the cumulative savings and compliance of water suppliers from June 2015 - August 2016.  Inspiration  What percentage of suppliers are actually meeting water conservation compliance standards? Which hydrologic regions of California are in most danger of not meeting their residents' water needs? Which city has the most residential gallons per capita per day (R-GPCD)? The least?  Are any cities outliers within their hydrological regions? Why might they be more or less successful in their water conservation efforts?  Acknowledgement This dataset is part of the CalEPA Water Boards Water Conservation Reporting and the original source can be found here.,August 2016 Non-filers (The following suppliers did not submit July 2016 data by September 19:,string:,
NYCHA Staten Island Asbestos Siebel Data , Progress Queens , www.kaggle.com/progressqueens/nycha-staten-island-asbestos-siebel-data , Thu Nov 10 2016 20:31:02 GMT+0530 (IST) , FOIL data from NYCHA's Siebel database ,35, architecture- ,This is a subset of only Asbestos-related maintenance requests for the Borough of Staten Island received by Progress Queens from the New York City Housing Authority in response to a request filed under the State's Freedom of Information Law. This subset was derived from the concatenation of the Siebel extracts which were included in the subject FOIL response. Because of the poor condition of the data the concatenation of the Siebel extracts was processed with some possible data loss. A general description of the quality of the data NYCHA produced was reported in an article published by Progress Queens. The publisher of Progress Queens formed this dataset to study how does NYCHA treat maintenance requests for Asbestos to determine how NYCHA escalates complaints made by tenants about Asbestos to ordering testing for Asbestos and to abatement if necessary.,CONTACT_ID:SR_ID:CREATED_D:UNIT_ID:SR_NUM:WORK_ORDER_NUM:LOCATION:LOCATION_TYPE:LOCATION_ID:DESCRIPTION:SCHEDULE_:SHIFT:RESP_SCHEDULER:PRIORITY:STATUS:WORK_ORDER_ITEM:WORK_ORDER_COMPLAINT:TDS_ID:SITE_NAME:BOROUGH:,string:string:numeric:string:string:numeric:string:string:string:string:string:string:string:numeric:string:string:string:numeric:string:string:,
Marginal Revolution Blog Post Data , williamnowak , www.kaggle.com/wpncrh/marginal-revolution-blog-post-data , Sun Sep 18 2016 08:56:10 GMT+0530 (IST) , Author Name Post Title Word count Comment Count Date Category Tag ,129, economics- linguistics- ,The following dataset contains data on blog posts from MarginalRevolution.com. For posts from Jan. 1 2010 to 9/17/2016 the following attributes are gathered.  Author Name Post Title  Post Date Post content (words) Number of Words in post Number of Comments in post Dummy variable for several commonly used categories  The data was scraped using Python's Beautiful Soup package and cleaned in R. See my github page (https//github.com/wnowak10/) for the Python and R code.,,,
